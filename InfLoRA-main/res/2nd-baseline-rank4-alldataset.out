nohup: ignoring input
logs/cifar100/20_20_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 09:29:01,333 [trainer.py] => config: ./configs/cifar100_inflora.json
2024-08-12 09:29:01,359 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 09:29:01,359 [trainer.py] => prefix: reproduce
2024-08-12 09:29:01,359 [trainer.py] => dataset: cifar100
2024-08-12 09:29:01,359 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 09:29:01,359 [trainer.py] => memory_size: 0
2024-08-12 09:29:01,360 [trainer.py] => memory_per_class: 0
2024-08-12 09:29:01,360 [trainer.py] => fixed_memory: True
2024-08-12 09:29:01,360 [trainer.py] => shuffle: True
2024-08-12 09:29:01,360 [trainer.py] => init_cls: 20
2024-08-12 09:29:01,360 [trainer.py] => increment: 20
2024-08-12 09:29:01,360 [trainer.py] => model_name: InfLoRA
2024-08-12 09:29:01,360 [trainer.py] => net_type: sip
2024-08-12 09:29:01,360 [trainer.py] => embd_dim: 768
2024-08-12 09:29:01,360 [trainer.py] => num_heads: 12
2024-08-12 09:29:01,360 [trainer.py] => total_sessions: 5
2024-08-12 09:29:01,360 [trainer.py] => seed: 1993
2024-08-12 09:29:01,360 [trainer.py] => EPSILON: 1e-08
2024-08-12 09:29:01,361 [trainer.py] => init_epoch: 20
2024-08-12 09:29:01,361 [trainer.py] => optim: adam
2024-08-12 09:29:01,361 [trainer.py] => init_lr: 0.0005
2024-08-12 09:29:01,361 [trainer.py] => init_lr_decay: 0.1
2024-08-12 09:29:01,361 [trainer.py] => init_weight_decay: 0.0
2024-08-12 09:29:01,361 [trainer.py] => epochs: 20
2024-08-12 09:29:01,361 [trainer.py] => lrate: 0.0005
2024-08-12 09:29:01,361 [trainer.py] => lrate_decay: 0.1
2024-08-12 09:29:01,361 [trainer.py] => batch_size: 48
2024-08-12 09:29:01,361 [trainer.py] => weight_decay: 0.0
2024-08-12 09:29:01,361 [trainer.py] => rank: 4
2024-08-12 09:29:01,361 [trainer.py] => lamb: 0.95
2024-08-12 09:29:01,361 [trainer.py] => lame: 1.0
2024-08-12 09:29:01,362 [trainer.py] => num_workers: 16
Files already downloaded and verified
Files already downloaded and verified
2024-08-12 09:29:02,839 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-12 09:29:05,015 [trainer.py] => All params: 108245531
2024-08-12 09:29:05,016 [trainer.py] => Trainable params: 108245531
2024-08-12 09:29:05,016 [inflora.py] => Learning on 0-20

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.745, Train_accy 79.09:   0%|          | 0/20 [00:33<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.745, Train_accy 79.09:   5%|▌         | 1/20 [00:33<10:45, 33.95s/it]
Task 0, Epoch 2/20 => Loss 0.352, Train_accy 88.99:   5%|▌         | 1/20 [01:08<10:45, 33.95s/it]
Task 0, Epoch 2/20 => Loss 0.352, Train_accy 88.99:  10%|█         | 2/20 [01:08<10:12, 34.04s/it]
Task 0, Epoch 3/20 => Loss 0.342, Train_accy 89.61:  10%|█         | 2/20 [01:42<10:12, 34.04s/it]
Task 0, Epoch 3/20 => Loss 0.342, Train_accy 89.61:  15%|█▌        | 3/20 [01:42<09:39, 34.10s/it]
Task 0, Epoch 4/20 => Loss 0.325, Train_accy 90.23:  15%|█▌        | 3/20 [02:16<09:39, 34.10s/it]
Task 0, Epoch 4/20 => Loss 0.325, Train_accy 90.23:  20%|██        | 4/20 [02:16<09:07, 34.20s/it]
Task 0, Epoch 5/20 => Loss 0.287, Train_accy 91.45:  20%|██        | 4/20 [02:50<09:07, 34.20s/it]
Task 0, Epoch 5/20 => Loss 0.287, Train_accy 91.45:  25%|██▌       | 5/20 [02:50<08:33, 34.23s/it]
Task 0, Epoch 6/20 => Loss 0.284, Train_accy 91.49:  25%|██▌       | 5/20 [03:25<08:33, 34.23s/it]
Task 0, Epoch 6/20 => Loss 0.284, Train_accy 91.49:  30%|███       | 6/20 [03:25<07:59, 34.24s/it]
Task 0, Epoch 7/20 => Loss 0.281, Train_accy 91.26:  30%|███       | 6/20 [03:59<07:59, 34.24s/it]
Task 0, Epoch 7/20 => Loss 0.281, Train_accy 91.26:  35%|███▌      | 7/20 [03:59<07:24, 34.22s/it]
Task 0, Epoch 8/20 => Loss 0.271, Train_accy 91.73:  35%|███▌      | 7/20 [04:33<07:24, 34.22s/it]
Task 0, Epoch 8/20 => Loss 0.271, Train_accy 91.73:  40%|████      | 8/20 [04:33<06:50, 34.23s/it]
Task 0, Epoch 9/20 => Loss 0.261, Train_accy 91.87:  40%|████      | 8/20 [05:07<06:50, 34.23s/it]
Task 0, Epoch 9/20 => Loss 0.261, Train_accy 91.87:  45%|████▌     | 9/20 [05:07<06:16, 34.23s/it]
Task 0, Epoch 10/20 => Loss 0.249, Train_accy 92.40:  45%|████▌     | 9/20 [05:42<06:16, 34.23s/it]
Task 0, Epoch 10/20 => Loss 0.249, Train_accy 92.40:  50%|█████     | 10/20 [05:42<05:42, 34.27s/it]
Task 0, Epoch 11/20 => Loss 0.238, Train_accy 92.59:  50%|█████     | 10/20 [06:16<05:42, 34.27s/it]
Task 0, Epoch 11/20 => Loss 0.238, Train_accy 92.59:  55%|█████▌    | 11/20 [06:16<05:08, 34.26s/it]
Task 0, Epoch 12/20 => Loss 0.237, Train_accy 92.72:  55%|█████▌    | 11/20 [06:50<05:08, 34.26s/it]
Task 0, Epoch 12/20 => Loss 0.237, Train_accy 92.72:  60%|██████    | 12/20 [06:50<04:33, 34.24s/it]
Task 0, Epoch 13/20 => Loss 0.230, Train_accy 92.91:  60%|██████    | 12/20 [07:24<04:33, 34.24s/it]
Task 0, Epoch 13/20 => Loss 0.230, Train_accy 92.91:  65%|██████▌   | 13/20 [07:24<03:59, 34.25s/it]
Task 0, Epoch 14/20 => Loss 0.218, Train_accy 93.24:  65%|██████▌   | 13/20 [07:59<03:59, 34.25s/it]
Task 0, Epoch 14/20 => Loss 0.218, Train_accy 93.24:  70%|███████   | 14/20 [07:59<03:25, 34.27s/it]
Task 0, Epoch 15/20 => Loss 0.206, Train_accy 93.63:  70%|███████   | 14/20 [08:33<03:25, 34.27s/it]
Task 0, Epoch 15/20 => Loss 0.206, Train_accy 93.63:  75%|███████▌  | 15/20 [08:33<02:51, 34.27s/it]
Task 0, Epoch 16/20 => Loss 0.218, Train_accy 93.38:  75%|███████▌  | 15/20 [09:07<02:51, 34.27s/it]
Task 0, Epoch 16/20 => Loss 0.218, Train_accy 93.38:  80%|████████  | 16/20 [09:07<02:17, 34.28s/it]
Task 0, Epoch 17/20 => Loss 0.204, Train_accy 93.71:  80%|████████  | 16/20 [09:41<02:17, 34.28s/it]
Task 0, Epoch 17/20 => Loss 0.204, Train_accy 93.71:  85%|████████▌ | 17/20 [09:41<01:42, 34.25s/it]
Task 0, Epoch 18/20 => Loss 0.201, Train_accy 93.52:  85%|████████▌ | 17/20 [10:16<01:42, 34.25s/it]
Task 0, Epoch 18/20 => Loss 0.201, Train_accy 93.52:  90%|█████████ | 18/20 [10:16<01:08, 34.26s/it]
Task 0, Epoch 19/20 => Loss 0.218, Train_accy 93.18:  90%|█████████ | 18/20 [10:50<01:08, 34.26s/it]
Task 0, Epoch 19/20 => Loss 0.218, Train_accy 93.18:  95%|█████████▌| 19/20 [10:50<00:34, 34.26s/it]
Task 0, Epoch 20/20 => Loss 0.208, Train_accy 93.64:  95%|█████████▌| 19/20 [11:24<00:34, 34.26s/it]
Task 0, Epoch 20/20 => Loss 0.208, Train_accy 93.64: 100%|██████████| 20/20 [11:24<00:00, 34.24s/it]
Task 0, Epoch 20/20 => Loss 0.208, Train_accy 93.64: 100%|██████████| 20/20 [11:24<00:00, 34.23s/it]
2024-08-12 09:40:57,735 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.208, Train_accy 93.64
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 10/768 type remove
Layer 4 : 10/768 type remove
Layer 5 : 14/768 type remove
Layer 6 : 17/768 type remove
Layer 7 : 17/768 type remove
Layer 8 : 22/768 type remove
Layer 9 : 29/768 type remove
Layer 10 : 30/768 type remove
Layer 11 : 8/768 type remove
Layer 12 : 24/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 09:41:40,610 [trainer.py] => Time:755.59428358078
2000 2000
2000 2000
2024-08-12 09:41:44,649 [trainer.py] => Time:4.038522243499756
2024-08-12 09:41:44,649 [inflora.py] => Exemplar size: 0
2024-08-12 09:41:44,649 [trainer.py] => CNN: {'total': 98.15, '00-19': 98.15, 'old': 0, 'new': 98.15}
2024-08-12 09:41:44,649 [trainer.py] => CNN top1 curve: [98.15]
2024-08-12 09:41:44,649 [trainer.py] => CNN top1 with task curve: [98.15]
2024-08-12 09:41:44,649 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 98.15
2024-08-12 09:41:44,651 [trainer.py] => All params: 108245531
2024-08-12 09:41:44,653 [trainer.py] => Trainable params: 89108
2024-08-12 09:41:44,653 [inflora.py] => Learning on 20-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.548, Train_accy 84.31:   0%|          | 0/20 [00:34<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.548, Train_accy 84.31:   5%|▌         | 1/20 [00:34<10:57, 34.59s/it]
Task 1, Epoch 2/20 => Loss 0.263, Train_accy 91.69:   5%|▌         | 1/20 [01:09<10:57, 34.59s/it]
Task 1, Epoch 2/20 => Loss 0.263, Train_accy 91.69:  10%|█         | 2/20 [01:09<10:23, 34.65s/it]
Task 1, Epoch 3/20 => Loss 0.237, Train_accy 92.27:  10%|█         | 2/20 [01:43<10:23, 34.65s/it]
Task 1, Epoch 3/20 => Loss 0.237, Train_accy 92.27:  15%|█▌        | 3/20 [01:43<09:47, 34.58s/it]
Task 1, Epoch 4/20 => Loss 0.239, Train_accy 92.59:  15%|█▌        | 3/20 [02:18<09:47, 34.58s/it]
Task 1, Epoch 4/20 => Loss 0.239, Train_accy 92.59:  20%|██        | 4/20 [02:18<09:13, 34.58s/it]
Task 1, Epoch 5/20 => Loss 0.214, Train_accy 92.95:  20%|██        | 4/20 [02:52<09:13, 34.58s/it]
Task 1, Epoch 5/20 => Loss 0.214, Train_accy 92.95:  25%|██▌       | 5/20 [02:52<08:38, 34.55s/it]
Task 1, Epoch 6/20 => Loss 0.206, Train_accy 93.56:  25%|██▌       | 5/20 [03:27<08:38, 34.55s/it]
Task 1, Epoch 6/20 => Loss 0.206, Train_accy 93.56:  30%|███       | 6/20 [03:27<08:03, 34.55s/it]
Task 1, Epoch 7/20 => Loss 0.201, Train_accy 93.63:  30%|███       | 6/20 [04:02<08:03, 34.55s/it]
Task 1, Epoch 7/20 => Loss 0.201, Train_accy 93.63:  35%|███▌      | 7/20 [04:02<07:29, 34.60s/it]
Task 1, Epoch 8/20 => Loss 0.195, Train_accy 93.92:  35%|███▌      | 7/20 [04:36<07:29, 34.60s/it]
Task 1, Epoch 8/20 => Loss 0.195, Train_accy 93.92:  40%|████      | 8/20 [04:36<06:55, 34.59s/it]
Task 1, Epoch 9/20 => Loss 0.205, Train_accy 93.39:  40%|████      | 8/20 [05:11<06:55, 34.59s/it]
Task 1, Epoch 9/20 => Loss 0.205, Train_accy 93.39:  45%|████▌     | 9/20 [05:11<06:20, 34.59s/it]
Task 1, Epoch 10/20 => Loss 0.190, Train_accy 93.74:  45%|████▌     | 9/20 [05:45<06:20, 34.59s/it]
Task 1, Epoch 10/20 => Loss 0.190, Train_accy 93.74:  50%|█████     | 10/20 [05:45<05:45, 34.58s/it]
Task 1, Epoch 11/20 => Loss 0.178, Train_accy 94.45:  50%|█████     | 10/20 [06:20<05:45, 34.58s/it]
Task 1, Epoch 11/20 => Loss 0.178, Train_accy 94.45:  55%|█████▌    | 11/20 [06:20<05:11, 34.56s/it]
Task 1, Epoch 12/20 => Loss 0.175, Train_accy 94.43:  55%|█████▌    | 11/20 [06:54<05:11, 34.56s/it]
Task 1, Epoch 12/20 => Loss 0.175, Train_accy 94.43:  60%|██████    | 12/20 [06:54<04:36, 34.55s/it]
Task 1, Epoch 13/20 => Loss 0.180, Train_accy 94.29:  60%|██████    | 12/20 [07:29<04:36, 34.55s/it]
Task 1, Epoch 13/20 => Loss 0.180, Train_accy 94.29:  65%|██████▌   | 13/20 [07:29<04:01, 34.57s/it]
Task 1, Epoch 14/20 => Loss 0.168, Train_accy 94.44:  65%|██████▌   | 13/20 [08:03<04:01, 34.57s/it]
Task 1, Epoch 14/20 => Loss 0.168, Train_accy 94.44:  70%|███████   | 14/20 [08:03<03:27, 34.54s/it]
Task 1, Epoch 15/20 => Loss 0.169, Train_accy 94.77:  70%|███████   | 14/20 [08:38<03:27, 34.54s/it]
Task 1, Epoch 15/20 => Loss 0.169, Train_accy 94.77:  75%|███████▌  | 15/20 [08:38<02:52, 34.54s/it]
Task 1, Epoch 16/20 => Loss 0.175, Train_accy 94.30:  75%|███████▌  | 15/20 [09:13<02:52, 34.54s/it]
Task 1, Epoch 16/20 => Loss 0.175, Train_accy 94.30:  80%|████████  | 16/20 [09:13<02:18, 34.54s/it]
Task 1, Epoch 17/20 => Loss 0.171, Train_accy 94.46:  80%|████████  | 16/20 [09:47<02:18, 34.54s/it]
Task 1, Epoch 17/20 => Loss 0.171, Train_accy 94.46:  85%|████████▌ | 17/20 [09:47<01:43, 34.54s/it]
Task 1, Epoch 18/20 => Loss 0.155, Train_accy 94.99:  85%|████████▌ | 17/20 [10:22<01:43, 34.54s/it]
Task 1, Epoch 18/20 => Loss 0.155, Train_accy 94.99:  90%|█████████ | 18/20 [10:22<01:09, 34.53s/it]
Task 1, Epoch 19/20 => Loss 0.156, Train_accy 95.09:  90%|█████████ | 18/20 [10:56<01:09, 34.53s/it]
Task 1, Epoch 19/20 => Loss 0.156, Train_accy 95.09:  95%|█████████▌| 19/20 [10:56<00:34, 34.51s/it]
Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.07:  95%|█████████▌| 19/20 [11:31<00:34, 34.51s/it]
Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.07: 100%|██████████| 20/20 [11:31<00:00, 34.53s/it]
Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.07: 100%|██████████| 20/20 [11:31<00:00, 34.56s/it]
2024-08-12 09:53:44,062 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.07
Threshold:  0.96
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 14/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 21/768 type remove
Layer 6 : 26/768 type remove
Layer 7 : 28/768 type remove
Layer 8 : 40/768 type remove
Layer 9 : 58/768 type remove
Layer 10 : 66/768 type remove
Layer 11 : 23/768 type remove
Layer 12 : 57/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 09:54:29,425 [trainer.py] => Time:764.7719531059265
4000 4000
4000 4000
2024-08-12 09:54:36,729 [trainer.py] => Time:7.3043084144592285
2024-08-12 09:54:36,730 [inflora.py] => Exemplar size: 0
2024-08-12 09:54:36,730 [trainer.py] => CNN: {'total': 95.62, '00-19': 96.0, '20-39': 95.25, 'old': 96.0, 'new': 95.25}
2024-08-12 09:54:36,730 [trainer.py] => CNN top1 curve: [98.15, 95.62]
2024-08-12 09:54:36,730 [trainer.py] => CNN top1 with task curve: [98.15, 98.22]
2024-08-12 09:54:36,730 [trainer.py] => CNN top1 task curve: [1.0, 0.968]
Average Accuracy (CNN): 96.88
2024-08-12 09:54:36,732 [trainer.py] => All params: 108245531
2024-08-12 09:54:36,733 [trainer.py] => Trainable params: 89108
2024-08-12 09:54:36,733 [inflora.py] => Learning on 40-60

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.615, Train_accy 82.44:   0%|          | 0/20 [00:34<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.615, Train_accy 82.44:   5%|▌         | 1/20 [00:34<10:56, 34.55s/it]
Task 2, Epoch 2/20 => Loss 0.309, Train_accy 90.24:   5%|▌         | 1/20 [01:08<10:56, 34.55s/it]
Task 2, Epoch 2/20 => Loss 0.309, Train_accy 90.24:  10%|█         | 2/20 [01:08<10:20, 34.46s/it]
Task 2, Epoch 3/20 => Loss 0.261, Train_accy 91.65:  10%|█         | 2/20 [01:43<10:20, 34.46s/it]
Task 2, Epoch 3/20 => Loss 0.261, Train_accy 91.65:  15%|█▌        | 3/20 [01:43<09:42, 34.29s/it]
Task 2, Epoch 4/20 => Loss 0.252, Train_accy 91.78:  15%|█▌        | 3/20 [02:17<09:42, 34.29s/it]
Task 2, Epoch 4/20 => Loss 0.252, Train_accy 91.78:  20%|██        | 4/20 [02:17<09:07, 34.19s/it]
Task 2, Epoch 5/20 => Loss 0.243, Train_accy 92.28:  20%|██        | 4/20 [02:51<09:07, 34.19s/it]
Task 2, Epoch 5/20 => Loss 0.243, Train_accy 92.28:  25%|██▌       | 5/20 [02:51<08:31, 34.13s/it]
Task 2, Epoch 6/20 => Loss 0.225, Train_accy 92.94:  25%|██▌       | 5/20 [03:25<08:31, 34.13s/it]
Task 2, Epoch 6/20 => Loss 0.225, Train_accy 92.94:  30%|███       | 6/20 [03:25<07:57, 34.10s/it]
Task 2, Epoch 7/20 => Loss 0.224, Train_accy 92.68:  30%|███       | 6/20 [03:59<07:57, 34.10s/it]
Task 2, Epoch 7/20 => Loss 0.224, Train_accy 92.68:  35%|███▌      | 7/20 [03:59<07:22, 34.07s/it]
Task 2, Epoch 8/20 => Loss 0.213, Train_accy 93.20:  35%|███▌      | 7/20 [04:33<07:22, 34.07s/it]
Task 2, Epoch 8/20 => Loss 0.213, Train_accy 93.20:  40%|████      | 8/20 [04:33<06:48, 34.07s/it]
Task 2, Epoch 9/20 => Loss 0.221, Train_accy 93.02:  40%|████      | 8/20 [05:07<06:48, 34.07s/it]
Task 2, Epoch 9/20 => Loss 0.221, Train_accy 93.02:  45%|████▌     | 9/20 [05:07<06:15, 34.13s/it]
Task 2, Epoch 10/20 => Loss 0.194, Train_accy 93.67:  45%|████▌     | 9/20 [05:41<06:15, 34.13s/it]
Task 2, Epoch 10/20 => Loss 0.194, Train_accy 93.67:  50%|█████     | 10/20 [05:41<05:40, 34.09s/it]
Task 2, Epoch 11/20 => Loss 0.202, Train_accy 93.47:  50%|█████     | 10/20 [06:15<05:40, 34.09s/it]
Task 2, Epoch 11/20 => Loss 0.202, Train_accy 93.47:  55%|█████▌    | 11/20 [06:15<05:07, 34.13s/it]
Task 2, Epoch 12/20 => Loss 0.190, Train_accy 93.82:  55%|█████▌    | 11/20 [06:49<05:07, 34.13s/it]
Task 2, Epoch 12/20 => Loss 0.190, Train_accy 93.82:  60%|██████    | 12/20 [06:49<04:32, 34.09s/it]
Task 2, Epoch 13/20 => Loss 0.190, Train_accy 93.99:  60%|██████    | 12/20 [07:23<04:32, 34.09s/it]
Task 2, Epoch 13/20 => Loss 0.190, Train_accy 93.99:  65%|██████▌   | 13/20 [07:23<03:58, 34.07s/it]
Task 2, Epoch 14/20 => Loss 0.191, Train_accy 93.98:  65%|██████▌   | 13/20 [07:57<03:58, 34.07s/it]
Task 2, Epoch 14/20 => Loss 0.191, Train_accy 93.98:  70%|███████   | 14/20 [07:57<03:24, 34.04s/it]
Task 2, Epoch 15/20 => Loss 0.182, Train_accy 94.12:  70%|███████   | 14/20 [08:31<03:24, 34.04s/it]
Task 2, Epoch 15/20 => Loss 0.182, Train_accy 94.12:  75%|███████▌  | 15/20 [08:31<02:50, 34.10s/it]
Task 2, Epoch 16/20 => Loss 0.182, Train_accy 94.12:  75%|███████▌  | 15/20 [09:06<02:50, 34.10s/it]
Task 2, Epoch 16/20 => Loss 0.182, Train_accy 94.12:  80%|████████  | 16/20 [09:06<02:16, 34.14s/it]
Task 2, Epoch 17/20 => Loss 0.182, Train_accy 94.21:  80%|████████  | 16/20 [09:40<02:16, 34.14s/it]
Task 2, Epoch 17/20 => Loss 0.182, Train_accy 94.21:  85%|████████▌ | 17/20 [09:40<01:42, 34.10s/it]
Task 2, Epoch 18/20 => Loss 0.185, Train_accy 94.25:  85%|████████▌ | 17/20 [10:14<01:42, 34.10s/it]
Task 2, Epoch 18/20 => Loss 0.185, Train_accy 94.25:  90%|█████████ | 18/20 [10:14<01:08, 34.08s/it]
Task 2, Epoch 19/20 => Loss 0.177, Train_accy 94.55:  90%|█████████ | 18/20 [10:48<01:08, 34.08s/it]
Task 2, Epoch 19/20 => Loss 0.177, Train_accy 94.55:  95%|█████████▌| 19/20 [10:48<00:34, 34.06s/it]
Task 2, Epoch 20/20 => Loss 0.178, Train_accy 94.30:  95%|█████████▌| 19/20 [11:22<00:34, 34.06s/it]
Task 2, Epoch 20/20 => Loss 0.178, Train_accy 94.30: 100%|██████████| 20/20 [11:22<00:00, 34.06s/it]
Task 2, Epoch 20/20 => Loss 0.178, Train_accy 94.30: 100%|██████████| 20/20 [11:22<00:00, 34.11s/it]
2024-08-12 10:06:28,485 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.178, Train_accy 94.30
Threshold:  0.97
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 26/768 type remove
Layer 6 : 35/768 type remove
Layer 7 : 40/768 type remove
Layer 8 : 58/768 type remove
Layer 9 : 87/768 type remove
Layer 10 : 105/768 type remove
Layer 11 : 38/768 type remove
Layer 12 : 94/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:07:14,588 [trainer.py] => Time:757.8544354438782
6000 6000
6000 6000
2024-08-12 10:07:25,291 [trainer.py] => Time:10.702645301818848
2024-08-12 10:07:25,291 [inflora.py] => Exemplar size: 0
2024-08-12 10:07:25,291 [trainer.py] => CNN: {'total': 93.0, '00-19': 94.1, '20-39': 92.95, '40-59': 91.95, 'old': 93.52, 'new': 91.95}
2024-08-12 10:07:25,291 [trainer.py] => CNN top1 curve: [98.15, 95.62, 93.0]
2024-08-12 10:07:25,291 [trainer.py] => CNN top1 with task curve: [98.15, 98.22, 97.73]
2024-08-12 10:07:25,291 [trainer.py] => CNN top1 task curve: [1.0, 0.968, 0.9446666666666667]
Average Accuracy (CNN): 95.59
2024-08-12 10:07:25,293 [trainer.py] => All params: 108245531
2024-08-12 10:07:25,295 [trainer.py] => Trainable params: 89108
2024-08-12 10:07:25,295 [inflora.py] => Learning on 60-80

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.637, Train_accy 81.36:   0%|          | 0/20 [00:34<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.637, Train_accy 81.36:   5%|▌         | 1/20 [00:34<10:57, 34.61s/it]
Task 3, Epoch 2/20 => Loss 0.295, Train_accy 90.49:   5%|▌         | 1/20 [01:09<10:57, 34.61s/it]
Task 3, Epoch 2/20 => Loss 0.295, Train_accy 90.49:  10%|█         | 2/20 [01:09<10:21, 34.55s/it]
Task 3, Epoch 3/20 => Loss 0.260, Train_accy 91.62:  10%|█         | 2/20 [01:43<10:21, 34.55s/it]
Task 3, Epoch 3/20 => Loss 0.260, Train_accy 91.62:  15%|█▌        | 3/20 [01:43<09:43, 34.34s/it]
Task 3, Epoch 4/20 => Loss 0.260, Train_accy 91.43:  15%|█▌        | 3/20 [02:17<09:43, 34.34s/it]
Task 3, Epoch 4/20 => Loss 0.260, Train_accy 91.43:  20%|██        | 4/20 [02:17<09:07, 34.23s/it]
Task 3, Epoch 5/20 => Loss 0.222, Train_accy 92.68:  20%|██        | 4/20 [02:51<09:07, 34.23s/it]
Task 3, Epoch 5/20 => Loss 0.222, Train_accy 92.68:  25%|██▌       | 5/20 [02:51<08:32, 34.18s/it]
Task 3, Epoch 6/20 => Loss 0.225, Train_accy 92.62:  25%|██▌       | 5/20 [03:25<08:32, 34.18s/it]
Task 3, Epoch 6/20 => Loss 0.225, Train_accy 92.62:  30%|███       | 6/20 [03:25<07:58, 34.19s/it]
Task 3, Epoch 7/20 => Loss 0.231, Train_accy 92.87:  30%|███       | 6/20 [03:59<07:58, 34.19s/it]
Task 3, Epoch 7/20 => Loss 0.231, Train_accy 92.87:  35%|███▌      | 7/20 [03:59<07:25, 34.24s/it]
Task 3, Epoch 8/20 => Loss 0.218, Train_accy 92.80:  35%|███▌      | 7/20 [04:34<07:25, 34.24s/it]
Task 3, Epoch 8/20 => Loss 0.218, Train_accy 92.80:  40%|████      | 8/20 [04:34<06:51, 34.29s/it]
Task 3, Epoch 9/20 => Loss 0.217, Train_accy 92.99:  40%|████      | 8/20 [05:08<06:51, 34.29s/it]
Task 3, Epoch 9/20 => Loss 0.217, Train_accy 92.99:  45%|████▌     | 9/20 [05:08<06:16, 34.23s/it]
Task 3, Epoch 10/20 => Loss 0.207, Train_accy 93.38:  45%|████▌     | 9/20 [05:42<06:16, 34.23s/it]
Task 3, Epoch 10/20 => Loss 0.207, Train_accy 93.38:  50%|█████     | 10/20 [05:42<05:41, 34.19s/it]
Task 3, Epoch 11/20 => Loss 0.190, Train_accy 93.97:  50%|█████     | 10/20 [06:16<05:41, 34.19s/it]
Task 3, Epoch 11/20 => Loss 0.190, Train_accy 93.97:  55%|█████▌    | 11/20 [06:16<05:07, 34.17s/it]
Task 3, Epoch 12/20 => Loss 0.200, Train_accy 93.79:  55%|█████▌    | 11/20 [06:50<05:07, 34.17s/it]
Task 3, Epoch 12/20 => Loss 0.200, Train_accy 93.79:  60%|██████    | 12/20 [06:50<04:33, 34.20s/it]
Task 3, Epoch 13/20 => Loss 0.189, Train_accy 93.97:  60%|██████    | 12/20 [07:24<04:33, 34.20s/it]
Task 3, Epoch 13/20 => Loss 0.189, Train_accy 93.97:  65%|██████▌   | 13/20 [07:24<03:59, 34.16s/it]
Task 3, Epoch 14/20 => Loss 0.187, Train_accy 93.76:  65%|██████▌   | 13/20 [07:59<03:59, 34.16s/it]
Task 3, Epoch 14/20 => Loss 0.187, Train_accy 93.76:  70%|███████   | 14/20 [07:59<03:24, 34.14s/it]
Task 3, Epoch 15/20 => Loss 0.181, Train_accy 94.27:  70%|███████   | 14/20 [08:33<03:24, 34.14s/it]
Task 3, Epoch 15/20 => Loss 0.181, Train_accy 94.27:  75%|███████▌  | 15/20 [08:33<02:50, 34.15s/it]
Task 3, Epoch 16/20 => Loss 0.189, Train_accy 93.84:  75%|███████▌  | 15/20 [09:07<02:50, 34.15s/it]
Task 3, Epoch 16/20 => Loss 0.189, Train_accy 93.84:  80%|████████  | 16/20 [09:07<02:16, 34.14s/it]
Task 3, Epoch 17/20 => Loss 0.175, Train_accy 94.59:  80%|████████  | 16/20 [09:41<02:16, 34.14s/it]
Task 3, Epoch 17/20 => Loss 0.175, Train_accy 94.59:  85%|████████▌ | 17/20 [09:41<01:42, 34.12s/it]
Task 3, Epoch 18/20 => Loss 0.169, Train_accy 94.66:  85%|████████▌ | 17/20 [10:15<01:42, 34.12s/it]
Task 3, Epoch 18/20 => Loss 0.169, Train_accy 94.66:  90%|█████████ | 18/20 [10:15<01:08, 34.15s/it]
Task 3, Epoch 19/20 => Loss 0.168, Train_accy 94.52:  90%|█████████ | 18/20 [10:50<01:08, 34.15s/it]
Task 3, Epoch 19/20 => Loss 0.168, Train_accy 94.52:  95%|█████████▌| 19/20 [10:50<00:34, 34.21s/it]
Task 3, Epoch 20/20 => Loss 0.170, Train_accy 94.47:  95%|█████████▌| 19/20 [11:24<00:34, 34.21s/it]
Task 3, Epoch 20/20 => Loss 0.170, Train_accy 94.47: 100%|██████████| 20/20 [11:24<00:00, 34.18s/it]
Task 3, Epoch 20/20 => Loss 0.170, Train_accy 94.47: 100%|██████████| 20/20 [11:24<00:00, 34.21s/it]
2024-08-12 10:19:17,542 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.170, Train_accy 94.47
Threshold:  0.98
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 19/768 type remove
Layer 4 : 24/768 type remove
Layer 5 : 35/768 type remove
Layer 6 : 52/768 type remove
Layer 7 : 62/768 type remove
Layer 8 : 94/768 type remove
Layer 9 : 148/768 type remove
Layer 10 : 183/768 type remove
Layer 11 : 88/768 type remove
Layer 12 : 180/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:20:03,771 [trainer.py] => Time:758.4760575294495
8000 8000
8000 8000
2024-08-12 10:20:17,767 [trainer.py] => Time:13.995333194732666
2024-08-12 10:20:17,767 [inflora.py] => Exemplar size: 0
2024-08-12 10:20:17,767 [trainer.py] => CNN: {'total': 90.62, '00-19': 93.1, '20-39': 92.55, '40-59': 88.1, '60-79': 88.75, 'old': 91.25, 'new': 88.75}
2024-08-12 10:20:17,767 [trainer.py] => CNN top1 curve: [98.15, 95.62, 93.0, 90.62]
2024-08-12 10:20:17,767 [trainer.py] => CNN top1 with task curve: [98.15, 98.22, 97.73, 97.38]
2024-08-12 10:20:17,767 [trainer.py] => CNN top1 task curve: [1.0, 0.968, 0.9446666666666667, 0.919875]
Average Accuracy (CNN): 94.35
2024-08-12 10:20:17,769 [trainer.py] => All params: 108245531
2024-08-12 10:20:17,770 [trainer.py] => Trainable params: 89108
2024-08-12 10:20:17,770 [inflora.py] => Learning on 80-100

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.605, Train_accy 83.07:   0%|          | 0/20 [00:34<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.605, Train_accy 83.07:   5%|▌         | 1/20 [00:34<10:48, 34.14s/it]
Task 4, Epoch 2/20 => Loss 0.294, Train_accy 91.37:   5%|▌         | 1/20 [01:08<10:48, 34.14s/it]
Task 4, Epoch 2/20 => Loss 0.294, Train_accy 91.37:  10%|█         | 2/20 [01:08<10:15, 34.22s/it]
Task 4, Epoch 3/20 => Loss 0.253, Train_accy 92.33:  10%|█         | 2/20 [01:42<10:15, 34.22s/it]
Task 4, Epoch 3/20 => Loss 0.253, Train_accy 92.33:  15%|█▌        | 3/20 [01:42<09:42, 34.24s/it]
Task 4, Epoch 4/20 => Loss 0.256, Train_accy 92.48:  15%|█▌        | 3/20 [02:16<09:42, 34.24s/it]
Task 4, Epoch 4/20 => Loss 0.256, Train_accy 92.48:  20%|██        | 4/20 [02:16<09:07, 34.24s/it]
Task 4, Epoch 5/20 => Loss 0.234, Train_accy 92.68:  20%|██        | 4/20 [02:51<09:07, 34.24s/it]
Task 4, Epoch 5/20 => Loss 0.234, Train_accy 92.68:  25%|██▌       | 5/20 [02:51<08:33, 34.23s/it]
Task 4, Epoch 6/20 => Loss 0.213, Train_accy 93.29:  25%|██▌       | 5/20 [03:25<08:33, 34.23s/it]
Task 4, Epoch 6/20 => Loss 0.213, Train_accy 93.29:  30%|███       | 6/20 [03:25<07:59, 34.22s/it]
Task 4, Epoch 7/20 => Loss 0.231, Train_accy 92.72:  30%|███       | 6/20 [03:59<07:59, 34.22s/it]
Task 4, Epoch 7/20 => Loss 0.231, Train_accy 92.72:  35%|███▌      | 7/20 [03:59<07:26, 34.33s/it]
Task 4, Epoch 8/20 => Loss 0.210, Train_accy 93.49:  35%|███▌      | 7/20 [04:34<07:26, 34.33s/it]
Task 4, Epoch 8/20 => Loss 0.210, Train_accy 93.49:  40%|████      | 8/20 [04:34<06:51, 34.31s/it]
Task 4, Epoch 9/20 => Loss 0.211, Train_accy 93.46:  40%|████      | 8/20 [05:08<06:51, 34.31s/it]
Task 4, Epoch 9/20 => Loss 0.211, Train_accy 93.46:  45%|████▌     | 9/20 [05:08<06:17, 34.29s/it]
Task 4, Epoch 10/20 => Loss 0.203, Train_accy 93.81:  45%|████▌     | 9/20 [05:42<06:17, 34.29s/it]
Task 4, Epoch 10/20 => Loss 0.203, Train_accy 93.81:  50%|█████     | 10/20 [05:42<05:42, 34.27s/it]
Task 4, Epoch 11/20 => Loss 0.185, Train_accy 94.14:  50%|█████     | 10/20 [06:17<05:42, 34.27s/it]
Task 4, Epoch 11/20 => Loss 0.185, Train_accy 94.14:  55%|█████▌    | 11/20 [06:17<05:09, 34.38s/it]
Task 4, Epoch 12/20 => Loss 0.183, Train_accy 94.43:  55%|█████▌    | 11/20 [06:51<05:09, 34.38s/it]
Task 4, Epoch 12/20 => Loss 0.183, Train_accy 94.43:  60%|██████    | 12/20 [06:51<04:34, 34.37s/it]
Task 4, Epoch 13/20 => Loss 0.184, Train_accy 94.40:  60%|██████    | 12/20 [07:25<04:34, 34.37s/it]
Task 4, Epoch 13/20 => Loss 0.184, Train_accy 94.40:  65%|██████▌   | 13/20 [07:25<04:00, 34.31s/it]
Task 4, Epoch 14/20 => Loss 0.189, Train_accy 94.04:  65%|██████▌   | 13/20 [07:59<04:00, 34.31s/it]
Task 4, Epoch 14/20 => Loss 0.189, Train_accy 94.04:  70%|███████   | 14/20 [07:59<03:25, 34.28s/it]
Task 4, Epoch 15/20 => Loss 0.183, Train_accy 94.50:  70%|███████   | 14/20 [08:34<03:25, 34.28s/it]
Task 4, Epoch 15/20 => Loss 0.183, Train_accy 94.50:  75%|███████▌  | 15/20 [08:34<02:51, 34.33s/it]
Task 4, Epoch 16/20 => Loss 0.169, Train_accy 94.74:  75%|███████▌  | 15/20 [09:08<02:51, 34.33s/it]
Task 4, Epoch 16/20 => Loss 0.169, Train_accy 94.74:  80%|████████  | 16/20 [09:08<02:17, 34.29s/it]
Task 4, Epoch 17/20 => Loss 0.181, Train_accy 94.30:  80%|████████  | 16/20 [09:42<02:17, 34.29s/it]
Task 4, Epoch 17/20 => Loss 0.181, Train_accy 94.30:  85%|████████▌ | 17/20 [09:42<01:42, 34.27s/it]
Task 4, Epoch 18/20 => Loss 0.170, Train_accy 94.49:  85%|████████▌ | 17/20 [10:17<01:42, 34.27s/it]
Task 4, Epoch 18/20 => Loss 0.170, Train_accy 94.49:  90%|█████████ | 18/20 [10:17<01:08, 34.25s/it]
Task 4, Epoch 19/20 => Loss 0.171, Train_accy 94.61:  90%|█████████ | 18/20 [10:51<01:08, 34.25s/it]
Task 4, Epoch 19/20 => Loss 0.171, Train_accy 94.61:  95%|█████████▌| 19/20 [10:51<00:34, 34.23s/it]
Task 4, Epoch 20/20 => Loss 0.167, Train_accy 94.70:  95%|█████████▌| 19/20 [11:25<00:34, 34.23s/it]
Task 4, Epoch 20/20 => Loss 0.167, Train_accy 94.70: 100%|██████████| 20/20 [11:25<00:00, 34.24s/it]
Task 4, Epoch 20/20 => Loss 0.167, Train_accy 94.70: 100%|██████████| 20/20 [11:25<00:00, 34.27s/it]
2024-08-12 10:32:10,708 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.167, Train_accy 94.70
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 27/768 type remove
Layer 4 : 37/768 type remove
Layer 5 : 54/768 type remove
Layer 6 : 89/768 type remove
Layer 7 : 113/768 type remove
Layer 8 : 170/768 type remove
Layer 9 : 253/768 type remove
Layer 10 : 306/768 type remove
Layer 11 : 192/768 type remove
Layer 12 : 292/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:32:56,240 [trainer.py] => Time:758.4702212810516
10000 10000
10000 10000
2024-08-12 10:33:13,645 [trainer.py] => Time:17.404706478118896
2024-08-12 10:33:13,646 [inflora.py] => Exemplar size: 0
2024-08-12 10:33:13,646 [trainer.py] => CNN: {'total': 89.32, '00-19': 92.35, '20-39': 92.1, '40-59': 86.75, '60-79': 87.95, '80-99': 87.45, 'old': 89.79, 'new': 87.45}
2024-08-12 10:33:13,646 [trainer.py] => CNN top1 curve: [98.15, 95.62, 93.0, 90.62, 89.32]
2024-08-12 10:33:13,646 [trainer.py] => CNN top1 with task curve: [98.15, 98.22, 97.73, 97.38, 97.56]
2024-08-12 10:33:13,646 [trainer.py] => CNN top1 task curve: [1.0, 0.968, 0.9446666666666667, 0.919875, 0.9048]
Average Accuracy (CNN): 93.34
logs/cub/20_20_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 10:33:16,875 [trainer.py] => config: ./configs/cub200_inflora.json
2024-08-12 10:33:16,875 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 10:33:16,875 [trainer.py] => prefix: reproduce
2024-08-12 10:33:16,875 [trainer.py] => dataset: cub
2024-08-12 10:33:16,876 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 10:33:16,876 [trainer.py] => memory_size: 0
2024-08-12 10:33:16,876 [trainer.py] => memory_per_class: 0
2024-08-12 10:33:16,876 [trainer.py] => fixed_memory: True
2024-08-12 10:33:16,876 [trainer.py] => shuffle: True
2024-08-12 10:33:16,876 [trainer.py] => init_cls: 20
2024-08-12 10:33:16,876 [trainer.py] => increment: 20
2024-08-12 10:33:16,876 [trainer.py] => model_name: InfLoRA
2024-08-12 10:33:16,876 [trainer.py] => net_type: sip
2024-08-12 10:33:16,876 [trainer.py] => embd_dim: 768
2024-08-12 10:33:16,876 [trainer.py] => num_heads: 12
2024-08-12 10:33:16,876 [trainer.py] => total_sessions: 10
2024-08-12 10:33:16,876 [trainer.py] => seed: 1993
2024-08-12 10:33:16,876 [trainer.py] => EPSILON: 1e-08
2024-08-12 10:33:16,876 [trainer.py] => init_epoch: 20
2024-08-12 10:33:16,876 [trainer.py] => optim: adam
2024-08-12 10:33:16,876 [trainer.py] => init_lr: 0.0005
2024-08-12 10:33:16,876 [trainer.py] => init_lr_decay: 0.1
2024-08-12 10:33:16,876 [trainer.py] => init_weight_decay: 0.0
2024-08-12 10:33:16,876 [trainer.py] => epochs: 20
2024-08-12 10:33:16,876 [trainer.py] => lrate: 0.0005
2024-08-12 10:33:16,876 [trainer.py] => lrate_decay: 0.1
2024-08-12 10:33:16,876 [trainer.py] => batch_size: 48
2024-08-12 10:33:16,876 [trainer.py] => weight_decay: 0.0
2024-08-12 10:33:16,876 [trainer.py] => rank: 4
2024-08-12 10:33:16,876 [trainer.py] => lamb: 0.95
2024-08-12 10:33:16,876 [trainer.py] => lame: 1.0
2024-08-12 10:33:16,876 [trainer.py] => num_workers: 16
2024-08-12 10:33:16,911 [data_manager.py] => [168, 136, 51, 9, 183, 101, 171, 99, 42, 159, 191, 70, 16, 188, 27, 10, 175, 26, 68, 187, 98, 6, 85, 35, 112, 43, 100, 0, 103, 181, 88, 59, 4, 2, 116, 174, 94, 80, 106, 1, 147, 17, 141, 131, 72, 23, 173, 54, 197, 118, 87, 32, 79, 104, 91, 19, 135, 107, 178, 36, 11, 199, 142, 8, 122, 3, 28, 57, 153, 172, 190, 56, 49, 44, 97, 62, 151, 169, 194, 55, 192, 12, 189, 78, 66, 180, 15, 137, 109, 134, 92, 119, 126, 52, 170, 40, 148, 65, 144, 64, 138, 45, 77, 89, 154, 90, 71, 193, 74, 30, 113, 143, 96, 84, 67, 50, 186, 156, 69, 21, 18, 111, 108, 58, 125, 157, 150, 110, 182, 129, 166, 83, 81, 60, 13, 165, 14, 176, 63, 117, 5, 22, 145, 121, 38, 41, 82, 127, 114, 20, 31, 53, 37, 163, 196, 130, 152, 162, 86, 76, 24, 34, 184, 149, 33, 128, 198, 155, 146, 167, 139, 120, 140, 102, 47, 25, 158, 123, 46, 164, 61, 7, 115, 75, 133, 160, 105, 132, 179, 124, 48, 73, 93, 39, 95, 195, 29, 177, 185, 161]
2024-08-12 10:33:19,549 [trainer.py] => All params: 109136611
2024-08-12 10:33:19,551 [trainer.py] => Trainable params: 109136611
2024-08-12 10:33:19,551 [inflora.py] => Learning on 0-20

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.854, Train_accy 48.94:   0%|          | 0/20 [00:03<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.854, Train_accy 48.94:   5%|▌         | 1/20 [00:03<01:13,  3.86s/it]
Task 0, Epoch 2/20 => Loss 0.458, Train_accy 86.36:   5%|▌         | 1/20 [00:07<01:13,  3.86s/it]
Task 0, Epoch 2/20 => Loss 0.458, Train_accy 86.36:  10%|█         | 2/20 [00:07<01:08,  3.81s/it]
Task 0, Epoch 3/20 => Loss 0.275, Train_accy 91.65:  10%|█         | 2/20 [00:11<01:08,  3.81s/it]
Task 0, Epoch 3/20 => Loss 0.275, Train_accy 91.65:  15%|█▌        | 3/20 [00:11<01:04,  3.80s/it]
Task 0, Epoch 4/20 => Loss 0.216, Train_accy 93.34:  15%|█▌        | 3/20 [00:15<01:04,  3.80s/it]
Task 0, Epoch 4/20 => Loss 0.216, Train_accy 93.34:  20%|██        | 4/20 [00:15<01:00,  3.81s/it]
Task 0, Epoch 5/20 => Loss 0.202, Train_accy 93.45:  20%|██        | 4/20 [00:19<01:00,  3.81s/it]
Task 0, Epoch 5/20 => Loss 0.202, Train_accy 93.45:  25%|██▌       | 5/20 [00:19<00:57,  3.81s/it]
Task 0, Epoch 6/20 => Loss 0.170, Train_accy 95.45:  25%|██▌       | 5/20 [00:22<00:57,  3.81s/it]
Task 0, Epoch 6/20 => Loss 0.170, Train_accy 95.45:  30%|███       | 6/20 [00:22<00:53,  3.81s/it]
Task 0, Epoch 7/20 => Loss 0.188, Train_accy 93.76:  30%|███       | 6/20 [00:26<00:53,  3.81s/it]
Task 0, Epoch 7/20 => Loss 0.188, Train_accy 93.76:  35%|███▌      | 7/20 [00:26<00:49,  3.80s/it]
Task 0, Epoch 8/20 => Loss 0.151, Train_accy 95.45:  35%|███▌      | 7/20 [00:30<00:49,  3.80s/it]
Task 0, Epoch 8/20 => Loss 0.151, Train_accy 95.45:  40%|████      | 8/20 [00:30<00:45,  3.81s/it]
Task 0, Epoch 9/20 => Loss 0.141, Train_accy 95.14:  40%|████      | 8/20 [00:34<00:45,  3.81s/it]
Task 0, Epoch 9/20 => Loss 0.141, Train_accy 95.14:  45%|████▌     | 9/20 [00:34<00:41,  3.81s/it]
Task 0, Epoch 10/20 => Loss 0.151, Train_accy 95.35:  45%|████▌     | 9/20 [00:38<00:41,  3.81s/it]
Task 0, Epoch 10/20 => Loss 0.151, Train_accy 95.35:  50%|█████     | 10/20 [00:38<00:38,  3.81s/it]
Task 0, Epoch 11/20 => Loss 0.166, Train_accy 94.50:  50%|█████     | 10/20 [00:41<00:38,  3.81s/it]
Task 0, Epoch 11/20 => Loss 0.166, Train_accy 94.50:  55%|█████▌    | 11/20 [00:41<00:34,  3.81s/it]
Task 0, Epoch 12/20 => Loss 0.173, Train_accy 94.50:  55%|█████▌    | 11/20 [00:45<00:34,  3.81s/it]
Task 0, Epoch 12/20 => Loss 0.173, Train_accy 94.50:  60%|██████    | 12/20 [00:45<00:30,  3.83s/it]
Task 0, Epoch 13/20 => Loss 0.144, Train_accy 95.56:  60%|██████    | 12/20 [00:49<00:30,  3.83s/it]
Task 0, Epoch 13/20 => Loss 0.144, Train_accy 95.56:  65%|██████▌   | 13/20 [00:49<00:26,  3.85s/it]
Task 0, Epoch 14/20 => Loss 0.152, Train_accy 95.67:  65%|██████▌   | 13/20 [00:53<00:26,  3.85s/it]
Task 0, Epoch 14/20 => Loss 0.152, Train_accy 95.67:  70%|███████   | 14/20 [00:53<00:23,  3.85s/it]
Task 0, Epoch 15/20 => Loss 0.152, Train_accy 95.24:  70%|███████   | 14/20 [00:57<00:23,  3.85s/it]
Task 0, Epoch 15/20 => Loss 0.152, Train_accy 95.24:  75%|███████▌  | 15/20 [00:57<00:19,  3.84s/it]
Task 0, Epoch 16/20 => Loss 0.131, Train_accy 95.88:  75%|███████▌  | 15/20 [01:01<00:19,  3.84s/it]
Task 0, Epoch 16/20 => Loss 0.131, Train_accy 95.88:  80%|████████  | 16/20 [01:01<00:15,  3.83s/it]
Task 0, Epoch 17/20 => Loss 0.126, Train_accy 95.45:  80%|████████  | 16/20 [01:04<00:15,  3.83s/it]
Task 0, Epoch 17/20 => Loss 0.126, Train_accy 95.45:  85%|████████▌ | 17/20 [01:04<00:11,  3.83s/it]
Task 0, Epoch 18/20 => Loss 0.142, Train_accy 95.88:  85%|████████▌ | 17/20 [01:08<00:11,  3.83s/it]
Task 0, Epoch 18/20 => Loss 0.142, Train_accy 95.88:  90%|█████████ | 18/20 [01:08<00:07,  3.82s/it]
Task 0, Epoch 19/20 => Loss 0.105, Train_accy 96.93:  90%|█████████ | 18/20 [01:12<00:07,  3.82s/it]
Task 0, Epoch 19/20 => Loss 0.105, Train_accy 96.93:  95%|█████████▌| 19/20 [01:12<00:03,  3.82s/it]
Task 0, Epoch 20/20 => Loss 0.116, Train_accy 96.19:  95%|█████████▌| 19/20 [01:16<00:03,  3.82s/it]
Task 0, Epoch 20/20 => Loss 0.116, Train_accy 96.19: 100%|██████████| 20/20 [01:16<00:00,  3.83s/it]
Task 0, Epoch 20/20 => Loss 0.116, Train_accy 96.19: 100%|██████████| 20/20 [01:16<00:00,  3.82s/it]
2024-08-12 10:34:41,001 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.116, Train_accy 96.19
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 11/768 type remove
Layer 4 : 11/768 type remove
Layer 5 : 16/768 type remove
Layer 6 : 13/768 type remove
Layer 7 : 12/768 type remove
Layer 8 : 13/768 type remove
Layer 9 : 12/768 type remove
Layer 10 : 9/768 type remove
Layer 11 : 2/768 type remove
Layer 12 : 2/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:34:49,165 [trainer.py] => Time:89.61457848548889
247 247
247 247
2024-08-12 10:34:50,674 [trainer.py] => Time:1.5081417560577393
2024-08-12 10:34:50,674 [inflora.py] => Exemplar size: 0
2024-08-12 10:34:50,675 [trainer.py] => CNN: {'total': 97.98, '00-19': 97.98, 'old': 0, 'new': 97.98}
2024-08-12 10:34:50,675 [trainer.py] => CNN top1 curve: [97.98]
2024-08-12 10:34:50,675 [trainer.py] => CNN top1 with task curve: [97.98]
2024-08-12 10:34:50,675 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 97.98
2024-08-12 10:34:50,680 [trainer.py] => All params: 109136611
2024-08-12 10:34:50,684 [trainer.py] => Trainable params: 89108
2024-08-12 10:34:50,684 [inflora.py] => Learning on 20-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.524, Train_accy 57.67:   0%|          | 0/20 [00:03<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.524, Train_accy 57.67:   5%|▌         | 1/20 [00:03<01:15,  3.95s/it]
Task 1, Epoch 2/20 => Loss 0.376, Train_accy 89.95:   5%|▌         | 1/20 [00:07<01:15,  3.95s/it]
Task 1, Epoch 2/20 => Loss 0.376, Train_accy 89.95:  10%|█         | 2/20 [00:07<01:11,  3.95s/it]
Task 1, Epoch 3/20 => Loss 0.253, Train_accy 92.59:  10%|█         | 2/20 [00:11<01:11,  3.95s/it]
Task 1, Epoch 3/20 => Loss 0.253, Train_accy 92.59:  15%|█▌        | 3/20 [00:11<01:07,  3.96s/it]
Task 1, Epoch 4/20 => Loss 0.237, Train_accy 92.80:  15%|█▌        | 3/20 [00:15<01:07,  3.96s/it]
Task 1, Epoch 4/20 => Loss 0.237, Train_accy 92.80:  20%|██        | 4/20 [00:15<01:03,  4.00s/it]
Task 1, Epoch 5/20 => Loss 0.214, Train_accy 93.02:  20%|██        | 4/20 [00:19<01:03,  4.00s/it]
Task 1, Epoch 5/20 => Loss 0.214, Train_accy 93.02:  25%|██▌       | 5/20 [00:19<01:00,  4.01s/it]
Task 1, Epoch 6/20 => Loss 0.174, Train_accy 94.92:  25%|██▌       | 5/20 [00:23<01:00,  4.01s/it]
Task 1, Epoch 6/20 => Loss 0.174, Train_accy 94.92:  30%|███       | 6/20 [00:23<00:56,  4.02s/it]
Task 1, Epoch 7/20 => Loss 0.155, Train_accy 95.34:  30%|███       | 6/20 [00:28<00:56,  4.02s/it]
Task 1, Epoch 7/20 => Loss 0.155, Train_accy 95.34:  35%|███▌      | 7/20 [00:28<00:52,  4.03s/it]
Task 1, Epoch 8/20 => Loss 0.146, Train_accy 95.45:  35%|███▌      | 7/20 [00:32<00:52,  4.03s/it]
Task 1, Epoch 8/20 => Loss 0.146, Train_accy 95.45:  40%|████      | 8/20 [00:32<00:48,  4.02s/it]
Task 1, Epoch 9/20 => Loss 0.157, Train_accy 95.34:  40%|████      | 8/20 [00:36<00:48,  4.02s/it]
Task 1, Epoch 9/20 => Loss 0.157, Train_accy 95.34:  45%|████▌     | 9/20 [00:36<00:44,  4.01s/it]
Task 1, Epoch 10/20 => Loss 0.127, Train_accy 95.77:  45%|████▌     | 9/20 [00:40<00:44,  4.01s/it]
Task 1, Epoch 10/20 => Loss 0.127, Train_accy 95.77:  50%|█████     | 10/20 [00:40<00:40,  4.00s/it]
Task 1, Epoch 11/20 => Loss 0.165, Train_accy 94.92:  50%|█████     | 10/20 [00:43<00:40,  4.00s/it]
Task 1, Epoch 11/20 => Loss 0.165, Train_accy 94.92:  55%|█████▌    | 11/20 [00:43<00:35,  3.98s/it]
Task 1, Epoch 12/20 => Loss 0.134, Train_accy 96.19:  55%|█████▌    | 11/20 [00:47<00:35,  3.98s/it]
Task 1, Epoch 12/20 => Loss 0.134, Train_accy 96.19:  60%|██████    | 12/20 [00:47<00:31,  3.99s/it]
Task 1, Epoch 13/20 => Loss 0.142, Train_accy 95.66:  60%|██████    | 12/20 [00:51<00:31,  3.99s/it]
Task 1, Epoch 13/20 => Loss 0.142, Train_accy 95.66:  65%|██████▌   | 13/20 [00:51<00:27,  4.00s/it]
Task 1, Epoch 14/20 => Loss 0.158, Train_accy 95.03:  65%|██████▌   | 13/20 [00:55<00:27,  4.00s/it]
Task 1, Epoch 14/20 => Loss 0.158, Train_accy 95.03:  70%|███████   | 14/20 [00:55<00:23,  3.99s/it]
Task 1, Epoch 15/20 => Loss 0.125, Train_accy 96.51:  70%|███████   | 14/20 [00:59<00:23,  3.99s/it]
Task 1, Epoch 15/20 => Loss 0.125, Train_accy 96.51:  75%|███████▌  | 15/20 [00:59<00:19,  3.99s/it]
Task 1, Epoch 16/20 => Loss 0.107, Train_accy 97.04:  75%|███████▌  | 15/20 [01:03<00:19,  3.99s/it]
Task 1, Epoch 16/20 => Loss 0.107, Train_accy 97.04:  80%|████████  | 16/20 [01:03<00:15,  3.98s/it]
Task 1, Epoch 17/20 => Loss 0.134, Train_accy 95.66:  80%|████████  | 16/20 [01:07<00:15,  3.98s/it]
Task 1, Epoch 17/20 => Loss 0.134, Train_accy 95.66:  85%|████████▌ | 17/20 [01:07<00:11,  3.99s/it]
Task 1, Epoch 18/20 => Loss 0.112, Train_accy 96.72:  85%|████████▌ | 17/20 [01:11<00:11,  3.99s/it]
Task 1, Epoch 18/20 => Loss 0.112, Train_accy 96.72:  90%|█████████ | 18/20 [01:11<00:07,  3.99s/it]
Task 1, Epoch 19/20 => Loss 0.121, Train_accy 96.83:  90%|█████████ | 18/20 [01:15<00:07,  3.99s/it]
Task 1, Epoch 19/20 => Loss 0.121, Train_accy 96.83:  95%|█████████▌| 19/20 [01:15<00:03,  3.99s/it]
Task 1, Epoch 20/20 => Loss 0.117, Train_accy 96.08:  95%|█████████▌| 19/20 [01:19<00:03,  3.99s/it]
Task 1, Epoch 20/20 => Loss 0.117, Train_accy 96.08: 100%|██████████| 20/20 [01:19<00:00,  4.00s/it]
Task 1, Epoch 20/20 => Loss 0.117, Train_accy 96.08: 100%|██████████| 20/20 [01:19<00:00,  4.00s/it]
2024-08-12 10:36:15,618 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.117, Train_accy 96.08
Threshold:  0.955
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 13/768 type remove
Layer 5 : 19/768 type remove
Layer 6 : 17/768 type remove
Layer 7 : 16/768 type remove
Layer 8 : 17/768 type remove
Layer 9 : 17/768 type remove
Layer 10 : 15/768 type remove
Layer 11 : 5/768 type remove
Layer 12 : 6/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:36:25,863 [trainer.py] => Time:95.17872905731201
454 454
454 454
2024-08-12 10:36:27,603 [trainer.py] => Time:1.739389419555664
2024-08-12 10:36:27,604 [inflora.py] => Exemplar size: 0
2024-08-12 10:36:27,604 [trainer.py] => CNN: {'total': 94.93, '00-19': 97.17, '20-39': 92.27, 'old': 97.17, 'new': 92.27}
2024-08-12 10:36:27,604 [trainer.py] => CNN top1 curve: [97.98, 94.93]
2024-08-12 10:36:27,604 [trainer.py] => CNN top1 with task curve: [97.98, 97.8]
2024-08-12 10:36:27,604 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952]
Average Accuracy (CNN): 96.46
2024-08-12 10:36:27,607 [trainer.py] => All params: 109136611
2024-08-12 10:36:27,609 [trainer.py] => Trainable params: 89108
2024-08-12 10:36:27,609 [inflora.py] => Learning on 40-60

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.831, Train_accy 53.66:   0%|          | 0/20 [00:04<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.831, Train_accy 53.66:   5%|▌         | 1/20 [00:04<01:17,  4.06s/it]
Task 2, Epoch 2/20 => Loss 0.363, Train_accy 89.08:   5%|▌         | 1/20 [00:08<01:17,  4.06s/it]
Task 2, Epoch 2/20 => Loss 0.363, Train_accy 89.08:  10%|█         | 2/20 [00:08<01:12,  4.04s/it]
Task 2, Epoch 3/20 => Loss 0.259, Train_accy 92.15:  10%|█         | 2/20 [00:12<01:12,  4.04s/it]
Task 2, Epoch 3/20 => Loss 0.259, Train_accy 92.15:  15%|█▌        | 3/20 [00:12<01:08,  4.05s/it]
Task 2, Epoch 4/20 => Loss 0.217, Train_accy 93.64:  15%|█▌        | 3/20 [00:16<01:08,  4.05s/it]
Task 2, Epoch 4/20 => Loss 0.217, Train_accy 93.64:  20%|██        | 4/20 [00:16<01:04,  4.03s/it]
Task 2, Epoch 5/20 => Loss 0.199, Train_accy 94.17:  20%|██        | 4/20 [00:20<01:04,  4.03s/it]
Task 2, Epoch 5/20 => Loss 0.199, Train_accy 94.17:  25%|██▌       | 5/20 [00:20<01:00,  4.04s/it]
Task 2, Epoch 6/20 => Loss 0.189, Train_accy 93.96:  25%|██▌       | 5/20 [00:24<01:00,  4.04s/it]
Task 2, Epoch 6/20 => Loss 0.189, Train_accy 93.96:  30%|███       | 6/20 [00:24<00:56,  4.03s/it]
Task 2, Epoch 7/20 => Loss 0.209, Train_accy 93.64:  30%|███       | 6/20 [00:28<00:56,  4.03s/it]
Task 2, Epoch 7/20 => Loss 0.209, Train_accy 93.64:  35%|███▌      | 7/20 [00:28<00:52,  4.04s/it]
Task 2, Epoch 8/20 => Loss 0.210, Train_accy 93.53:  35%|███▌      | 7/20 [00:32<00:52,  4.04s/it]
Task 2, Epoch 8/20 => Loss 0.210, Train_accy 93.53:  40%|████      | 8/20 [00:32<00:48,  4.04s/it]
Task 2, Epoch 9/20 => Loss 0.150, Train_accy 96.08:  40%|████      | 8/20 [00:36<00:48,  4.04s/it]
Task 2, Epoch 9/20 => Loss 0.150, Train_accy 96.08:  45%|████▌     | 9/20 [00:36<00:44,  4.03s/it]
Task 2, Epoch 10/20 => Loss 0.168, Train_accy 94.91:  45%|████▌     | 9/20 [00:40<00:44,  4.03s/it]
Task 2, Epoch 10/20 => Loss 0.168, Train_accy 94.91:  50%|█████     | 10/20 [00:40<00:40,  4.03s/it]
Task 2, Epoch 11/20 => Loss 0.163, Train_accy 95.76:  50%|█████     | 10/20 [00:44<00:40,  4.03s/it]
Task 2, Epoch 11/20 => Loss 0.163, Train_accy 95.76:  55%|█████▌    | 11/20 [00:44<00:36,  4.03s/it]
Task 2, Epoch 12/20 => Loss 0.166, Train_accy 95.02:  55%|█████▌    | 11/20 [00:48<00:36,  4.03s/it]
Task 2, Epoch 12/20 => Loss 0.166, Train_accy 95.02:  60%|██████    | 12/20 [00:48<00:32,  4.03s/it]
Task 2, Epoch 13/20 => Loss 0.136, Train_accy 96.08:  60%|██████    | 12/20 [00:52<00:32,  4.03s/it]
Task 2, Epoch 13/20 => Loss 0.136, Train_accy 96.08:  65%|██████▌   | 13/20 [00:52<00:28,  4.03s/it]
Task 2, Epoch 14/20 => Loss 0.131, Train_accy 96.50:  65%|██████▌   | 13/20 [00:56<00:28,  4.03s/it]
Task 2, Epoch 14/20 => Loss 0.131, Train_accy 96.50:  70%|███████   | 14/20 [00:56<00:24,  4.04s/it]
Task 2, Epoch 15/20 => Loss 0.169, Train_accy 94.91:  70%|███████   | 14/20 [01:00<00:24,  4.04s/it]
Task 2, Epoch 15/20 => Loss 0.169, Train_accy 94.91:  75%|███████▌  | 15/20 [01:00<00:20,  4.03s/it]
Task 2, Epoch 16/20 => Loss 0.144, Train_accy 95.23:  75%|███████▌  | 15/20 [01:04<00:20,  4.03s/it]
Task 2, Epoch 16/20 => Loss 0.144, Train_accy 95.23:  80%|████████  | 16/20 [01:04<00:16,  4.03s/it]
Task 2, Epoch 17/20 => Loss 0.122, Train_accy 96.18:  80%|████████  | 16/20 [01:08<00:16,  4.03s/it]
Task 2, Epoch 17/20 => Loss 0.122, Train_accy 96.18:  85%|████████▌ | 17/20 [01:08<00:12,  4.04s/it]
Task 2, Epoch 18/20 => Loss 0.138, Train_accy 95.65:  85%|████████▌ | 17/20 [01:12<00:12,  4.04s/it]
Task 2, Epoch 18/20 => Loss 0.138, Train_accy 95.65:  90%|█████████ | 18/20 [01:12<00:08,  4.04s/it]
Task 2, Epoch 19/20 => Loss 0.169, Train_accy 94.91:  90%|█████████ | 18/20 [01:16<00:08,  4.04s/it]
Task 2, Epoch 19/20 => Loss 0.169, Train_accy 94.91:  95%|█████████▌| 19/20 [01:16<00:04,  4.04s/it]
Task 2, Epoch 20/20 => Loss 0.169, Train_accy 95.44:  95%|█████████▌| 19/20 [01:20<00:04,  4.04s/it]
Task 2, Epoch 20/20 => Loss 0.169, Train_accy 95.44: 100%|██████████| 20/20 [01:20<00:00,  4.04s/it]
Task 2, Epoch 20/20 => Loss 0.169, Train_accy 95.44: 100%|██████████| 20/20 [01:20<00:00,  4.04s/it]
2024-08-12 10:37:53,690 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.169, Train_accy 95.44
Threshold:  0.96
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 14/768 type remove
Layer 4 : 16/768 type remove
Layer 5 : 22/768 type remove
Layer 6 : 20/768 type remove
Layer 7 : 19/768 type remove
Layer 8 : 19/768 type remove
Layer 9 : 20/768 type remove
Layer 10 : 19/768 type remove
Layer 11 : 7/768 type remove
Layer 12 : 8/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:38:04,129 [trainer.py] => Time:96.51975584030151
672 672
672 672
2024-08-12 10:38:06,245 [trainer.py] => Time:2.116126298904419
2024-08-12 10:38:06,245 [inflora.py] => Exemplar size: 0
2024-08-12 10:38:06,245 [trainer.py] => CNN: {'total': 92.26, '00-19': 93.52, '20-39': 90.34, '40-59': 92.66, 'old': 92.07, 'new': 92.66}
2024-08-12 10:38:06,245 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26]
2024-08-12 10:38:06,245 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92]
2024-08-12 10:38:06,246 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238]
Average Accuracy (CNN): 95.06
2024-08-12 10:38:06,248 [trainer.py] => All params: 109136611
2024-08-12 10:38:06,249 [trainer.py] => Trainable params: 89108
2024-08-12 10:38:06,250 [inflora.py] => Learning on 60-80

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.495, Train_accy 58.46:   0%|          | 0/20 [00:04<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.495, Train_accy 58.46:   5%|▌         | 1/20 [00:04<01:17,  4.07s/it]
Task 3, Epoch 2/20 => Loss 0.277, Train_accy 91.86:   5%|▌         | 1/20 [00:08<01:17,  4.07s/it]
Task 3, Epoch 2/20 => Loss 0.277, Train_accy 91.86:  10%|█         | 2/20 [00:08<01:13,  4.08s/it]
Task 3, Epoch 3/20 => Loss 0.238, Train_accy 93.13:  10%|█         | 2/20 [00:12<01:13,  4.08s/it]
Task 3, Epoch 3/20 => Loss 0.238, Train_accy 93.13:  15%|█▌        | 3/20 [00:12<01:09,  4.07s/it]
Task 3, Epoch 4/20 => Loss 0.225, Train_accy 92.71:  15%|█▌        | 3/20 [00:16<01:09,  4.07s/it]
Task 3, Epoch 4/20 => Loss 0.225, Train_accy 92.71:  20%|██        | 4/20 [00:16<01:05,  4.07s/it]
Task 3, Epoch 5/20 => Loss 0.200, Train_accy 94.29:  20%|██        | 4/20 [00:20<01:05,  4.07s/it]
Task 3, Epoch 5/20 => Loss 0.200, Train_accy 94.29:  25%|██▌       | 5/20 [00:20<01:01,  4.07s/it]
Task 3, Epoch 6/20 => Loss 0.170, Train_accy 94.40:  25%|██▌       | 5/20 [00:24<01:01,  4.07s/it]
Task 3, Epoch 6/20 => Loss 0.170, Train_accy 94.40:  30%|███       | 6/20 [00:24<00:57,  4.08s/it]
Task 3, Epoch 7/20 => Loss 0.170, Train_accy 94.61:  30%|███       | 6/20 [00:28<00:57,  4.08s/it]
Task 3, Epoch 7/20 => Loss 0.170, Train_accy 94.61:  35%|███▌      | 7/20 [00:28<00:53,  4.09s/it]
Task 3, Epoch 8/20 => Loss 0.194, Train_accy 93.97:  35%|███▌      | 7/20 [00:32<00:53,  4.09s/it]
Task 3, Epoch 8/20 => Loss 0.194, Train_accy 93.97:  40%|████      | 8/20 [00:32<00:49,  4.10s/it]
Task 3, Epoch 9/20 => Loss 0.157, Train_accy 94.40:  40%|████      | 8/20 [00:36<00:49,  4.10s/it]
Task 3, Epoch 9/20 => Loss 0.157, Train_accy 94.40:  45%|████▌     | 9/20 [00:36<00:44,  4.08s/it]
Task 3, Epoch 10/20 => Loss 0.162, Train_accy 94.82:  45%|████▌     | 9/20 [00:40<00:44,  4.08s/it]
Task 3, Epoch 10/20 => Loss 0.162, Train_accy 94.82:  50%|█████     | 10/20 [00:40<00:40,  4.08s/it]
Task 3, Epoch 11/20 => Loss 0.154, Train_accy 94.93:  50%|█████     | 10/20 [00:44<00:40,  4.08s/it]
Task 3, Epoch 11/20 => Loss 0.154, Train_accy 94.93:  55%|█████▌    | 11/20 [00:44<00:36,  4.08s/it]
Task 3, Epoch 12/20 => Loss 0.145, Train_accy 95.45:  55%|█████▌    | 11/20 [00:48<00:36,  4.08s/it]
Task 3, Epoch 12/20 => Loss 0.145, Train_accy 95.45:  60%|██████    | 12/20 [00:48<00:32,  4.08s/it]
Task 3, Epoch 13/20 => Loss 0.120, Train_accy 96.51:  60%|██████    | 12/20 [00:53<00:32,  4.08s/it]
Task 3, Epoch 13/20 => Loss 0.120, Train_accy 96.51:  65%|██████▌   | 13/20 [00:53<00:28,  4.08s/it]
Task 3, Epoch 14/20 => Loss 0.149, Train_accy 94.71:  65%|██████▌   | 13/20 [00:57<00:28,  4.08s/it]
Task 3, Epoch 14/20 => Loss 0.149, Train_accy 94.71:  70%|███████   | 14/20 [00:57<00:24,  4.08s/it]
Task 3, Epoch 15/20 => Loss 0.109, Train_accy 96.72:  70%|███████   | 14/20 [01:01<00:24,  4.08s/it]
Task 3, Epoch 15/20 => Loss 0.109, Train_accy 96.72:  75%|███████▌  | 15/20 [01:01<00:20,  4.10s/it]
Task 3, Epoch 16/20 => Loss 0.113, Train_accy 96.30:  75%|███████▌  | 15/20 [01:05<00:20,  4.10s/it]
Task 3, Epoch 16/20 => Loss 0.113, Train_accy 96.30:  80%|████████  | 16/20 [01:05<00:16,  4.10s/it]
Task 3, Epoch 17/20 => Loss 0.145, Train_accy 95.03:  80%|████████  | 16/20 [01:09<00:16,  4.10s/it]
Task 3, Epoch 17/20 => Loss 0.145, Train_accy 95.03:  85%|████████▌ | 17/20 [01:09<00:12,  4.10s/it]
Task 3, Epoch 18/20 => Loss 0.102, Train_accy 96.72:  85%|████████▌ | 17/20 [01:13<00:12,  4.10s/it]
Task 3, Epoch 18/20 => Loss 0.102, Train_accy 96.72:  90%|█████████ | 18/20 [01:13<00:08,  4.10s/it]
Task 3, Epoch 19/20 => Loss 0.161, Train_accy 94.93:  90%|█████████ | 18/20 [01:17<00:08,  4.10s/it]
Task 3, Epoch 19/20 => Loss 0.161, Train_accy 94.93:  95%|█████████▌| 19/20 [01:17<00:04,  4.10s/it]
Task 3, Epoch 20/20 => Loss 0.116, Train_accy 96.41:  95%|█████████▌| 19/20 [01:21<00:04,  4.10s/it]
Task 3, Epoch 20/20 => Loss 0.116, Train_accy 96.41: 100%|██████████| 20/20 [01:21<00:00,  4.10s/it]
Task 3, Epoch 20/20 => Loss 0.116, Train_accy 96.41: 100%|██████████| 20/20 [01:21<00:00,  4.09s/it]
2024-08-12 10:39:33,337 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.116, Train_accy 96.41
Threshold:  0.965
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 26/768 type remove
Layer 6 : 23/768 type remove
Layer 7 : 22/768 type remove
Layer 8 : 22/768 type remove
Layer 9 : 23/768 type remove
Layer 10 : 21/768 type remove
Layer 11 : 9/768 type remove
Layer 12 : 11/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:39:44,892 [trainer.py] => Time:98.6420509815216
919 919
919 919
2024-08-12 10:39:47,429 [trainer.py] => Time:2.537109851837158
2024-08-12 10:39:47,429 [inflora.py] => Exemplar size: 0
2024-08-12 10:39:47,429 [trainer.py] => CNN: {'total': 89.12, '00-19': 91.09, '20-39': 87.92, '40-59': 90.37, '60-79': 87.04, 'old': 89.88, 'new': 87.04}
2024-08-12 10:39:47,429 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12]
2024-08-12 10:39:47,429 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93]
2024-08-12 10:39:47,430 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172]
Average Accuracy (CNN): 93.57
2024-08-12 10:39:47,432 [trainer.py] => All params: 109136611
2024-08-12 10:39:47,434 [trainer.py] => Trainable params: 89108
2024-08-12 10:39:47,434 [inflora.py] => Learning on 80-100

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.504, Train_accy 56.89:   0%|          | 0/20 [00:04<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.504, Train_accy 56.89:   5%|▌         | 1/20 [00:04<01:16,  4.01s/it]
Task 4, Epoch 2/20 => Loss 0.368, Train_accy 88.18:   5%|▌         | 1/20 [00:08<01:16,  4.01s/it]
Task 4, Epoch 2/20 => Loss 0.368, Train_accy 88.18:  10%|█         | 2/20 [00:08<01:13,  4.06s/it]
Task 4, Epoch 3/20 => Loss 0.279, Train_accy 90.48:  10%|█         | 2/20 [00:12<01:13,  4.06s/it]
Task 4, Epoch 3/20 => Loss 0.279, Train_accy 90.48:  15%|█▌        | 3/20 [00:12<01:08,  4.05s/it]
Task 4, Epoch 4/20 => Loss 0.246, Train_accy 92.01:  15%|█▌        | 3/20 [00:16<01:08,  4.05s/it]
Task 4, Epoch 4/20 => Loss 0.246, Train_accy 92.01:  20%|██        | 4/20 [00:16<01:04,  4.05s/it]
Task 4, Epoch 5/20 => Loss 0.239, Train_accy 92.56:  20%|██        | 4/20 [00:20<01:04,  4.05s/it]
Task 4, Epoch 5/20 => Loss 0.239, Train_accy 92.56:  25%|██▌       | 5/20 [00:20<01:00,  4.05s/it]
Task 4, Epoch 6/20 => Loss 0.333, Train_accy 93.98:  25%|██▌       | 5/20 [00:24<01:00,  4.05s/it]
Task 4, Epoch 6/20 => Loss 0.333, Train_accy 93.98:  30%|███       | 6/20 [00:24<00:57,  4.09s/it]
Task 4, Epoch 7/20 => Loss 0.199, Train_accy 93.33:  30%|███       | 6/20 [00:28<00:57,  4.09s/it]
Task 4, Epoch 7/20 => Loss 0.199, Train_accy 93.33:  35%|███▌      | 7/20 [00:28<00:53,  4.08s/it]
Task 4, Epoch 8/20 => Loss 0.235, Train_accy 93.00:  35%|███▌      | 7/20 [00:32<00:53,  4.08s/it]
Task 4, Epoch 8/20 => Loss 0.235, Train_accy 93.00:  40%|████      | 8/20 [00:32<00:48,  4.08s/it]
Task 4, Epoch 9/20 => Loss 0.171, Train_accy 94.42:  40%|████      | 8/20 [00:36<00:48,  4.08s/it]
Task 4, Epoch 9/20 => Loss 0.171, Train_accy 94.42:  45%|████▌     | 9/20 [00:36<00:44,  4.08s/it]
Task 4, Epoch 10/20 => Loss 0.174, Train_accy 94.09:  45%|████▌     | 9/20 [00:40<00:44,  4.08s/it]
Task 4, Epoch 10/20 => Loss 0.174, Train_accy 94.09:  50%|█████     | 10/20 [00:40<00:40,  4.08s/it]
Task 4, Epoch 11/20 => Loss 0.159, Train_accy 95.51:  50%|█████     | 10/20 [00:44<00:40,  4.08s/it]
Task 4, Epoch 11/20 => Loss 0.159, Train_accy 95.51:  55%|█████▌    | 11/20 [00:44<00:36,  4.07s/it]
Task 4, Epoch 12/20 => Loss 0.305, Train_accy 93.87:  55%|█████▌    | 11/20 [00:49<00:36,  4.07s/it]
Task 4, Epoch 12/20 => Loss 0.305, Train_accy 93.87:  60%|██████    | 12/20 [00:49<00:33,  4.14s/it]
Task 4, Epoch 13/20 => Loss 0.161, Train_accy 94.20:  60%|██████    | 12/20 [00:53<00:33,  4.14s/it]
Task 4, Epoch 13/20 => Loss 0.161, Train_accy 94.20:  65%|██████▌   | 13/20 [00:53<00:28,  4.14s/it]
Task 4, Epoch 14/20 => Loss 0.163, Train_accy 93.87:  65%|██████▌   | 13/20 [00:57<00:28,  4.14s/it]
Task 4, Epoch 14/20 => Loss 0.163, Train_accy 93.87:  70%|███████   | 14/20 [00:57<00:24,  4.15s/it]
Task 4, Epoch 15/20 => Loss 0.208, Train_accy 94.31:  70%|███████   | 14/20 [01:01<00:24,  4.15s/it]
Task 4, Epoch 15/20 => Loss 0.208, Train_accy 94.31:  75%|███████▌  | 15/20 [01:01<00:20,  4.13s/it]
Task 4, Epoch 16/20 => Loss 0.145, Train_accy 95.84:  75%|███████▌  | 15/20 [01:05<00:20,  4.13s/it]
Task 4, Epoch 16/20 => Loss 0.145, Train_accy 95.84:  80%|████████  | 16/20 [01:05<00:16,  4.10s/it]
Task 4, Epoch 17/20 => Loss 0.133, Train_accy 95.84:  80%|████████  | 16/20 [01:09<00:16,  4.10s/it]
Task 4, Epoch 17/20 => Loss 0.133, Train_accy 95.84:  85%|████████▌ | 17/20 [01:09<00:12,  4.07s/it]
Task 4, Epoch 18/20 => Loss 0.126, Train_accy 96.28:  85%|████████▌ | 17/20 [01:13<00:12,  4.07s/it]
Task 4, Epoch 18/20 => Loss 0.126, Train_accy 96.28:  90%|█████████ | 18/20 [01:13<00:08,  4.07s/it]
Task 4, Epoch 19/20 => Loss 0.138, Train_accy 94.97:  90%|█████████ | 18/20 [01:17<00:08,  4.07s/it]
Task 4, Epoch 19/20 => Loss 0.138, Train_accy 94.97:  95%|█████████▌| 19/20 [01:17<00:04,  4.08s/it]
Task 4, Epoch 20/20 => Loss 0.144, Train_accy 95.30:  95%|█████████▌| 19/20 [01:21<00:04,  4.08s/it]
Task 4, Epoch 20/20 => Loss 0.144, Train_accy 95.30: 100%|██████████| 20/20 [01:21<00:00,  4.07s/it]
Task 4, Epoch 20/20 => Loss 0.144, Train_accy 95.30: 100%|██████████| 20/20 [01:21<00:00,  4.09s/it]
2024-08-12 10:41:14,820 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.144, Train_accy 95.30
Threshold:  0.97
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 21/768 type remove
Layer 5 : 29/768 type remove
Layer 6 : 26/768 type remove
Layer 7 : 25/768 type remove
Layer 8 : 24/768 type remove
Layer 9 : 26/768 type remove
Layer 10 : 25/768 type remove
Layer 11 : 12/768 type remove
Layer 12 : 16/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:41:25,372 [trainer.py] => Time:97.93752765655518
1188 1188
1188 1188
2024-08-12 10:41:28,365 [trainer.py] => Time:2.99253249168396
2024-08-12 10:41:28,365 [inflora.py] => Exemplar size: 0
2024-08-12 10:41:28,365 [trainer.py] => CNN: {'total': 85.19, '00-19': 90.28, '20-39': 87.44, '40-59': 88.99, '60-79': 84.62, '80-99': 76.21, 'old': 87.81, 'new': 76.21}
2024-08-12 10:41:28,365 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19]
2024-08-12 10:41:28,365 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23]
2024-08-12 10:41:28,366 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077]
Average Accuracy (CNN): 91.9
2024-08-12 10:41:28,369 [trainer.py] => All params: 109136611
2024-08-12 10:41:28,371 [trainer.py] => Trainable params: 89108
2024-08-12 10:41:28,371 [inflora.py] => Learning on 100-120

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.563, Train_accy 58.40:   0%|          | 0/20 [00:04<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.563, Train_accy 58.40:   5%|▌         | 1/20 [00:04<01:19,  4.17s/it]
Task 5, Epoch 2/20 => Loss 0.271, Train_accy 91.81:   5%|▌         | 1/20 [00:08<01:19,  4.17s/it]
Task 5, Epoch 2/20 => Loss 0.271, Train_accy 91.81:  10%|█         | 2/20 [00:08<01:14,  4.13s/it]
Task 5, Epoch 3/20 => Loss 0.195, Train_accy 94.22:  10%|█         | 2/20 [00:12<01:14,  4.13s/it]
Task 5, Epoch 3/20 => Loss 0.195, Train_accy 94.22:  15%|█▌        | 3/20 [00:12<01:11,  4.18s/it]
Task 5, Epoch 4/20 => Loss 0.151, Train_accy 96.22:  15%|█▌        | 3/20 [00:16<01:11,  4.18s/it]
Task 5, Epoch 4/20 => Loss 0.151, Train_accy 96.22:  20%|██        | 4/20 [00:16<01:07,  4.19s/it]
Task 5, Epoch 5/20 => Loss 0.135, Train_accy 95.06:  20%|██        | 4/20 [00:20<01:07,  4.19s/it]
Task 5, Epoch 5/20 => Loss 0.135, Train_accy 95.06:  25%|██▌       | 5/20 [00:20<01:02,  4.18s/it]
Task 5, Epoch 6/20 => Loss 0.127, Train_accy 96.22:  25%|██▌       | 5/20 [00:25<01:02,  4.18s/it]
Task 5, Epoch 6/20 => Loss 0.127, Train_accy 96.22:  30%|███       | 6/20 [00:25<00:58,  4.18s/it]
Task 5, Epoch 7/20 => Loss 0.159, Train_accy 94.54:  30%|███       | 6/20 [00:29<00:58,  4.18s/it]
Task 5, Epoch 7/20 => Loss 0.159, Train_accy 94.54:  35%|███▌      | 7/20 [00:29<00:54,  4.18s/it]
Task 5, Epoch 8/20 => Loss 0.155, Train_accy 95.17:  35%|███▌      | 7/20 [00:33<00:54,  4.18s/it]
Task 5, Epoch 8/20 => Loss 0.155, Train_accy 95.17:  40%|████      | 8/20 [00:33<00:50,  4.17s/it]
Task 5, Epoch 9/20 => Loss 0.130, Train_accy 95.80:  40%|████      | 8/20 [00:37<00:50,  4.17s/it]
Task 5, Epoch 9/20 => Loss 0.130, Train_accy 95.80:  45%|████▌     | 9/20 [00:37<00:46,  4.18s/it]
Task 5, Epoch 10/20 => Loss 0.133, Train_accy 96.01:  45%|████▌     | 9/20 [00:41<00:46,  4.18s/it]
Task 5, Epoch 10/20 => Loss 0.133, Train_accy 96.01:  50%|█████     | 10/20 [00:41<00:41,  4.18s/it]
Task 5, Epoch 11/20 => Loss 0.127, Train_accy 96.32:  50%|█████     | 10/20 [00:45<00:41,  4.18s/it]
Task 5, Epoch 11/20 => Loss 0.127, Train_accy 96.32:  55%|█████▌    | 11/20 [00:45<00:37,  4.18s/it]
Task 5, Epoch 12/20 => Loss 0.143, Train_accy 95.06:  55%|█████▌    | 11/20 [00:50<00:37,  4.18s/it]
Task 5, Epoch 12/20 => Loss 0.143, Train_accy 95.06:  60%|██████    | 12/20 [00:50<00:33,  4.19s/it]
Task 5, Epoch 13/20 => Loss 0.123, Train_accy 95.90:  60%|██████    | 12/20 [00:54<00:33,  4.19s/it]
Task 5, Epoch 13/20 => Loss 0.123, Train_accy 95.90:  65%|██████▌   | 13/20 [00:54<00:29,  4.20s/it]
Task 5, Epoch 14/20 => Loss 0.089, Train_accy 97.37:  65%|██████▌   | 13/20 [00:58<00:29,  4.20s/it]
Task 5, Epoch 14/20 => Loss 0.089, Train_accy 97.37:  70%|███████   | 14/20 [00:58<00:25,  4.19s/it]
Task 5, Epoch 15/20 => Loss 0.125, Train_accy 95.59:  70%|███████   | 14/20 [01:02<00:25,  4.19s/it]
Task 5, Epoch 15/20 => Loss 0.125, Train_accy 95.59:  75%|███████▌  | 15/20 [01:02<00:20,  4.19s/it]
Task 5, Epoch 16/20 => Loss 0.111, Train_accy 96.64:  75%|███████▌  | 15/20 [01:06<00:20,  4.19s/it]
Task 5, Epoch 16/20 => Loss 0.111, Train_accy 96.64:  80%|████████  | 16/20 [01:06<00:16,  4.19s/it]
Task 5, Epoch 17/20 => Loss 0.120, Train_accy 96.32:  80%|████████  | 16/20 [01:11<00:16,  4.19s/it]
Task 5, Epoch 17/20 => Loss 0.120, Train_accy 96.32:  85%|████████▌ | 17/20 [01:11<00:12,  4.19s/it]
Task 5, Epoch 18/20 => Loss 0.132, Train_accy 95.90:  85%|████████▌ | 17/20 [01:15<00:12,  4.19s/it]
Task 5, Epoch 18/20 => Loss 0.132, Train_accy 95.90:  90%|█████████ | 18/20 [01:15<00:08,  4.22s/it]
Task 5, Epoch 19/20 => Loss 0.115, Train_accy 96.43:  90%|█████████ | 18/20 [01:19<00:08,  4.22s/it]
Task 5, Epoch 19/20 => Loss 0.115, Train_accy 96.43:  95%|█████████▌| 19/20 [01:19<00:04,  4.22s/it]
Task 5, Epoch 20/20 => Loss 0.130, Train_accy 96.11:  95%|█████████▌| 19/20 [01:23<00:04,  4.22s/it]
Task 5, Epoch 20/20 => Loss 0.130, Train_accy 96.11: 100%|██████████| 20/20 [01:23<00:00,  4.21s/it]
Task 5, Epoch 20/20 => Loss 0.130, Train_accy 96.11: 100%|██████████| 20/20 [01:23<00:00,  4.19s/it]
2024-08-12 10:42:58,860 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.130, Train_accy 96.11
Threshold:  0.975
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 24/768 type remove
Layer 5 : 34/768 type remove
Layer 6 : 30/768 type remove
Layer 7 : 31/768 type remove
Layer 8 : 31/768 type remove
Layer 9 : 32/768 type remove
Layer 10 : 31/768 type remove
Layer 11 : 16/768 type remove
Layer 12 : 20/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:43:10,193 [trainer.py] => Time:101.82221245765686
1416 1416
1416 1416
2024-08-12 10:43:13,609 [trainer.py] => Time:3.414719581604004
2024-08-12 10:43:13,609 [inflora.py] => Exemplar size: 0
2024-08-12 10:43:13,609 [trainer.py] => CNN: {'total': 81.29, '00-19': 90.28, '20-39': 86.47, '40-59': 85.78, '60-79': 80.16, '80-99': 73.23, '100-119': 73.25, 'old': 82.83, 'new': 73.25}
2024-08-12 10:43:13,609 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19, 81.29]
2024-08-12 10:43:13,609 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23, 98.16]
2024-08-12 10:43:13,609 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077, 0.818502824858757]
Average Accuracy (CNN): 90.13
2024-08-12 10:43:13,611 [trainer.py] => All params: 109136611
2024-08-12 10:43:13,613 [trainer.py] => Trainable params: 89108
2024-08-12 10:43:13,613 [inflora.py] => Learning on 120-140

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.781, Train_accy 48.95:   0%|          | 0/20 [00:04<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.781, Train_accy 48.95:   5%|▌         | 1/20 [00:04<01:19,  4.17s/it]
Task 6, Epoch 2/20 => Loss 0.553, Train_accy 81.55:   5%|▌         | 1/20 [00:08<01:19,  4.17s/it]
Task 6, Epoch 2/20 => Loss 0.553, Train_accy 81.55:  10%|█         | 2/20 [00:08<01:15,  4.20s/it]
Task 6, Epoch 3/20 => Loss 0.427, Train_accy 84.38:  10%|█         | 2/20 [00:12<01:15,  4.20s/it]
Task 6, Epoch 3/20 => Loss 0.427, Train_accy 84.38:  15%|█▌        | 3/20 [00:12<01:11,  4.20s/it]
Task 6, Epoch 4/20 => Loss 0.346, Train_accy 87.74:  15%|█▌        | 3/20 [00:16<01:11,  4.20s/it]
Task 6, Epoch 4/20 => Loss 0.346, Train_accy 87.74:  20%|██        | 4/20 [00:16<01:07,  4.20s/it]
Task 6, Epoch 5/20 => Loss 0.312, Train_accy 88.99:  20%|██        | 4/20 [00:21<01:07,  4.20s/it]
Task 6, Epoch 5/20 => Loss 0.312, Train_accy 88.99:  25%|██▌       | 5/20 [00:21<01:03,  4.22s/it]
Task 6, Epoch 6/20 => Loss 0.307, Train_accy 88.78:  25%|██▌       | 5/20 [00:25<01:03,  4.22s/it]
Task 6, Epoch 6/20 => Loss 0.307, Train_accy 88.78:  30%|███       | 6/20 [00:25<00:59,  4.24s/it]
Task 6, Epoch 7/20 => Loss 0.240, Train_accy 92.35:  30%|███       | 6/20 [00:29<00:59,  4.24s/it]
Task 6, Epoch 7/20 => Loss 0.240, Train_accy 92.35:  35%|███▌      | 7/20 [00:29<00:54,  4.23s/it]
Task 6, Epoch 8/20 => Loss 0.269, Train_accy 90.88:  35%|███▌      | 7/20 [00:33<00:54,  4.23s/it]
Task 6, Epoch 8/20 => Loss 0.269, Train_accy 90.88:  40%|████      | 8/20 [00:33<00:50,  4.23s/it]
Task 6, Epoch 9/20 => Loss 0.191, Train_accy 94.44:  40%|████      | 8/20 [00:37<00:50,  4.23s/it]
Task 6, Epoch 9/20 => Loss 0.191, Train_accy 94.44:  45%|████▌     | 9/20 [00:37<00:46,  4.22s/it]
Task 6, Epoch 10/20 => Loss 0.257, Train_accy 91.61:  45%|████▌     | 9/20 [00:42<00:46,  4.22s/it]
Task 6, Epoch 10/20 => Loss 0.257, Train_accy 91.61:  50%|█████     | 10/20 [00:42<00:42,  4.22s/it]
Task 6, Epoch 11/20 => Loss 0.234, Train_accy 92.77:  50%|█████     | 10/20 [00:46<00:42,  4.22s/it]
Task 6, Epoch 11/20 => Loss 0.234, Train_accy 92.77:  55%|█████▌    | 11/20 [00:46<00:37,  4.21s/it]
Task 6, Epoch 12/20 => Loss 0.228, Train_accy 92.56:  55%|█████▌    | 11/20 [00:50<00:37,  4.21s/it]
Task 6, Epoch 12/20 => Loss 0.228, Train_accy 92.56:  60%|██████    | 12/20 [00:50<00:33,  4.22s/it]
Task 6, Epoch 13/20 => Loss 0.221, Train_accy 92.87:  60%|██████    | 12/20 [00:54<00:33,  4.22s/it]
Task 6, Epoch 13/20 => Loss 0.221, Train_accy 92.87:  65%|██████▌   | 13/20 [00:54<00:29,  4.22s/it]
Task 6, Epoch 14/20 => Loss 0.193, Train_accy 94.55:  65%|██████▌   | 13/20 [00:59<00:29,  4.22s/it]
Task 6, Epoch 14/20 => Loss 0.193, Train_accy 94.55:  70%|███████   | 14/20 [00:59<00:25,  4.22s/it]
Task 6, Epoch 15/20 => Loss 0.213, Train_accy 92.56:  70%|███████   | 14/20 [01:03<00:25,  4.22s/it]
Task 6, Epoch 15/20 => Loss 0.213, Train_accy 92.56:  75%|███████▌  | 15/20 [01:03<00:21,  4.24s/it]
Task 6, Epoch 16/20 => Loss 0.223, Train_accy 92.14:  75%|███████▌  | 15/20 [01:07<00:21,  4.24s/it]
Task 6, Epoch 16/20 => Loss 0.223, Train_accy 92.14:  80%|████████  | 16/20 [01:07<00:16,  4.22s/it]
Task 6, Epoch 17/20 => Loss 0.183, Train_accy 94.34:  80%|████████  | 16/20 [01:11<00:16,  4.22s/it]
Task 6, Epoch 17/20 => Loss 0.183, Train_accy 94.34:  85%|████████▌ | 17/20 [01:11<00:12,  4.24s/it]
Task 6, Epoch 18/20 => Loss 0.181, Train_accy 94.65:  85%|████████▌ | 17/20 [01:16<00:12,  4.24s/it]
Task 6, Epoch 18/20 => Loss 0.181, Train_accy 94.65:  90%|█████████ | 18/20 [01:16<00:08,  4.28s/it]
Task 6, Epoch 19/20 => Loss 0.180, Train_accy 94.44:  90%|█████████ | 18/20 [01:20<00:08,  4.28s/it]
Task 6, Epoch 19/20 => Loss 0.180, Train_accy 94.44:  95%|█████████▌| 19/20 [01:20<00:04,  4.25s/it]
Task 6, Epoch 20/20 => Loss 0.164, Train_accy 94.65:  95%|█████████▌| 19/20 [01:24<00:04,  4.25s/it]
Task 6, Epoch 20/20 => Loss 0.164, Train_accy 94.65: 100%|██████████| 20/20 [01:24<00:00,  4.25s/it]
Task 6, Epoch 20/20 => Loss 0.164, Train_accy 94.65: 100%|██████████| 20/20 [01:24<00:00,  4.23s/it]
2024-08-12 10:44:44,500 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.164, Train_accy 94.65
Threshold:  0.98
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 26/768 type remove
Layer 4 : 31/768 type remove
Layer 5 : 43/768 type remove
Layer 6 : 40/768 type remove
Layer 7 : 39/768 type remove
Layer 8 : 39/768 type remove
Layer 9 : 40/768 type remove
Layer 10 : 40/768 type remove
Layer 11 : 21/768 type remove
Layer 12 : 23/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:44:55,228 [trainer.py] => Time:101.61535000801086
1641 1641
1641 1641
2024-08-12 10:44:59,018 [trainer.py] => Time:3.7893800735473633
2024-08-12 10:44:59,018 [inflora.py] => Exemplar size: 0
2024-08-12 10:44:59,018 [trainer.py] => CNN: {'total': 79.4, '00-19': 89.47, '20-39': 85.99, '40-59': 85.78, '60-79': 81.78, '80-99': 66.54, '100-119': 72.37, '120-139': 76.0, 'old': 79.94, 'new': 76.0}
2024-08-12 10:44:59,019 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19, 81.29, 79.4]
2024-08-12 10:44:59,019 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23, 98.16, 97.87]
2024-08-12 10:44:59,019 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077, 0.818502824858757, 0.8013406459475929]
Average Accuracy (CNN): 88.6
2024-08-12 10:44:59,021 [trainer.py] => All params: 109136611
2024-08-12 10:44:59,023 [trainer.py] => Trainable params: 89108
2024-08-12 10:44:59,023 [inflora.py] => Learning on 140-160

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.712, Train_accy 51.52:   0%|          | 0/20 [00:04<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.712, Train_accy 51.52:   5%|▌         | 1/20 [00:04<01:19,  4.17s/it]
Task 7, Epoch 2/20 => Loss 0.343, Train_accy 88.70:   5%|▌         | 1/20 [00:08<01:19,  4.17s/it]
Task 7, Epoch 2/20 => Loss 0.343, Train_accy 88.70:  10%|█         | 2/20 [00:08<01:14,  4.15s/it]
Task 7, Epoch 3/20 => Loss 0.331, Train_accy 89.78:  10%|█         | 2/20 [00:12<01:14,  4.15s/it]
Task 7, Epoch 3/20 => Loss 0.331, Train_accy 89.78:  15%|█▌        | 3/20 [00:12<01:10,  4.13s/it]
Task 7, Epoch 4/20 => Loss 0.303, Train_accy 91.41:  15%|█▌        | 3/20 [00:16<01:10,  4.13s/it]
Task 7, Epoch 4/20 => Loss 0.303, Train_accy 91.41:  20%|██        | 4/20 [00:16<01:05,  4.12s/it]
Task 7, Epoch 5/20 => Loss 0.285, Train_accy 91.41:  20%|██        | 4/20 [00:20<01:05,  4.12s/it]
Task 7, Epoch 5/20 => Loss 0.285, Train_accy 91.41:  25%|██▌       | 5/20 [00:20<01:01,  4.11s/it]
Task 7, Epoch 6/20 => Loss 0.265, Train_accy 91.96:  25%|██▌       | 5/20 [00:24<01:01,  4.11s/it]
Task 7, Epoch 6/20 => Loss 0.265, Train_accy 91.96:  30%|███       | 6/20 [00:24<00:57,  4.11s/it]
Task 7, Epoch 7/20 => Loss 0.189, Train_accy 94.67:  30%|███       | 6/20 [00:28<00:57,  4.11s/it]
Task 7, Epoch 7/20 => Loss 0.189, Train_accy 94.67:  35%|███▌      | 7/20 [00:28<00:53,  4.11s/it]
Task 7, Epoch 8/20 => Loss 0.243, Train_accy 92.28:  35%|███▌      | 7/20 [00:32<00:53,  4.11s/it]
Task 7, Epoch 8/20 => Loss 0.243, Train_accy 92.28:  40%|████      | 8/20 [00:32<00:49,  4.12s/it]
Task 7, Epoch 9/20 => Loss 0.209, Train_accy 95.11:  40%|████      | 8/20 [00:37<00:49,  4.12s/it]
Task 7, Epoch 9/20 => Loss 0.209, Train_accy 95.11:  45%|████▌     | 9/20 [00:37<00:45,  4.14s/it]
Task 7, Epoch 10/20 => Loss 0.199, Train_accy 93.37:  45%|████▌     | 9/20 [00:41<00:45,  4.14s/it]
Task 7, Epoch 10/20 => Loss 0.199, Train_accy 93.37:  50%|█████     | 10/20 [00:41<00:41,  4.15s/it]
Task 7, Epoch 11/20 => Loss 0.186, Train_accy 94.46:  50%|█████     | 10/20 [00:45<00:41,  4.15s/it]
Task 7, Epoch 11/20 => Loss 0.186, Train_accy 94.46:  55%|█████▌    | 11/20 [00:45<00:37,  4.14s/it]
Task 7, Epoch 12/20 => Loss 0.227, Train_accy 94.02:  55%|█████▌    | 11/20 [00:49<00:37,  4.14s/it]
Task 7, Epoch 12/20 => Loss 0.227, Train_accy 94.02:  60%|██████    | 12/20 [00:49<00:33,  4.14s/it]
Task 7, Epoch 13/20 => Loss 0.143, Train_accy 95.76:  60%|██████    | 12/20 [00:53<00:33,  4.14s/it]
Task 7, Epoch 13/20 => Loss 0.143, Train_accy 95.76:  65%|██████▌   | 13/20 [00:53<00:28,  4.13s/it]
Task 7, Epoch 14/20 => Loss 0.185, Train_accy 94.67:  65%|██████▌   | 13/20 [00:57<00:28,  4.13s/it]
Task 7, Epoch 14/20 => Loss 0.185, Train_accy 94.67:  70%|███████   | 14/20 [00:57<00:24,  4.14s/it]
Task 7, Epoch 15/20 => Loss 0.191, Train_accy 94.13:  70%|███████   | 14/20 [01:01<00:24,  4.14s/it]
Task 7, Epoch 15/20 => Loss 0.191, Train_accy 94.13:  75%|███████▌  | 15/20 [01:01<00:20,  4.13s/it]
Task 7, Epoch 16/20 => Loss 0.168, Train_accy 95.33:  75%|███████▌  | 15/20 [01:06<00:20,  4.13s/it]
Task 7, Epoch 16/20 => Loss 0.168, Train_accy 95.33:  80%|████████  | 16/20 [01:06<00:16,  4.13s/it]
Task 7, Epoch 17/20 => Loss 0.147, Train_accy 95.76:  80%|████████  | 16/20 [01:10<00:16,  4.13s/it]
Task 7, Epoch 17/20 => Loss 0.147, Train_accy 95.76:  85%|████████▌ | 17/20 [01:10<00:12,  4.12s/it]
Task 7, Epoch 18/20 => Loss 0.175, Train_accy 96.09:  85%|████████▌ | 17/20 [01:14<00:12,  4.12s/it]
Task 7, Epoch 18/20 => Loss 0.175, Train_accy 96.09:  90%|█████████ | 18/20 [01:14<00:08,  4.12s/it]
Task 7, Epoch 19/20 => Loss 0.143, Train_accy 95.43:  90%|█████████ | 18/20 [01:18<00:08,  4.12s/it]
Task 7, Epoch 19/20 => Loss 0.143, Train_accy 95.43:  95%|█████████▌| 19/20 [01:18<00:04,  4.14s/it]
Task 7, Epoch 20/20 => Loss 0.161, Train_accy 96.09:  95%|█████████▌| 19/20 [01:22<00:04,  4.14s/it]
Task 7, Epoch 20/20 => Loss 0.161, Train_accy 96.09: 100%|██████████| 20/20 [01:22<00:00,  4.12s/it]
Task 7, Epoch 20/20 => Loss 0.161, Train_accy 96.09: 100%|██████████| 20/20 [01:22<00:00,  4.13s/it]
2024-08-12 10:46:27,037 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.161, Train_accy 96.09
Threshold:  0.985
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 32/768 type remove
Layer 4 : 40/768 type remove
Layer 5 : 57/768 type remove
Layer 6 : 53/768 type remove
Layer 7 : 52/768 type remove
Layer 8 : 54/768 type remove
Layer 9 : 56/768 type remove
Layer 10 : 55/768 type remove
Layer 11 : 32/768 type remove
Layer 12 : 29/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:46:37,732 [trainer.py] => Time:98.70856094360352
1891 1891
1891 1891
2024-08-12 10:46:42,000 [trainer.py] => Time:4.268095970153809
2024-08-12 10:46:42,000 [inflora.py] => Exemplar size: 0
2024-08-12 10:46:42,001 [trainer.py] => CNN: {'total': 79.16, '00-19': 87.85, '20-39': 83.09, '40-59': 83.49, '60-79': 78.54, '80-99': 68.4, '100-119': 75.0, '120-139': 76.44, '140-159': 82.0, 'old': 78.73, 'new': 82.0}
2024-08-12 10:46:42,001 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19, 81.29, 79.4, 79.16]
2024-08-12 10:46:42,001 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23, 98.16, 97.87, 98.1]
2024-08-12 10:46:42,001 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077, 0.818502824858757, 0.8013406459475929, 0.7974616604970914]
Average Accuracy (CNN): 87.42
2024-08-12 10:46:42,003 [trainer.py] => All params: 109136611
2024-08-12 10:46:42,005 [trainer.py] => Trainable params: 89108
2024-08-12 10:46:42,005 [inflora.py] => Learning on 160-180

  0%|          | 0/20 [00:00<?, ?it/s]
Task 8, Epoch 1/20 => Loss 1.685, Train_accy 55.22:   0%|          | 0/20 [00:04<?, ?it/s]
Task 8, Epoch 1/20 => Loss 1.685, Train_accy 55.22:   5%|▌         | 1/20 [00:04<01:21,  4.27s/it]
Task 8, Epoch 2/20 => Loss 0.382, Train_accy 89.67:   5%|▌         | 1/20 [00:08<01:21,  4.27s/it]
Task 8, Epoch 2/20 => Loss 0.382, Train_accy 89.67:  10%|█         | 2/20 [00:08<01:17,  4.30s/it]
Task 8, Epoch 3/20 => Loss 0.299, Train_accy 91.65:  10%|█         | 2/20 [00:12<01:17,  4.30s/it]
Task 8, Epoch 3/20 => Loss 0.299, Train_accy 91.65:  15%|█▌        | 3/20 [00:12<01:13,  4.30s/it]
Task 8, Epoch 4/20 => Loss 0.243, Train_accy 93.01:  15%|█▌        | 3/20 [00:17<01:13,  4.30s/it]
Task 8, Epoch 4/20 => Loss 0.243, Train_accy 93.01:  20%|██        | 4/20 [00:17<01:08,  4.31s/it]
Task 8, Epoch 5/20 => Loss 0.246, Train_accy 92.28:  20%|██        | 4/20 [00:21<01:08,  4.31s/it]
Task 8, Epoch 5/20 => Loss 0.246, Train_accy 92.28:  25%|██▌       | 5/20 [00:21<01:04,  4.30s/it]
Task 8, Epoch 6/20 => Loss 0.214, Train_accy 94.26:  25%|██▌       | 5/20 [00:25<01:04,  4.30s/it]
Task 8, Epoch 6/20 => Loss 0.214, Train_accy 94.26:  30%|███       | 6/20 [00:25<01:00,  4.30s/it]
Task 8, Epoch 7/20 => Loss 0.210, Train_accy 93.74:  30%|███       | 6/20 [00:30<01:00,  4.30s/it]
Task 8, Epoch 7/20 => Loss 0.210, Train_accy 93.74:  35%|███▌      | 7/20 [00:30<00:56,  4.34s/it]
Task 8, Epoch 8/20 => Loss 0.213, Train_accy 93.63:  35%|███▌      | 7/20 [00:34<00:56,  4.34s/it]
Task 8, Epoch 8/20 => Loss 0.213, Train_accy 93.63:  40%|████      | 8/20 [00:34<00:51,  4.32s/it]
Task 8, Epoch 9/20 => Loss 0.155, Train_accy 95.20:  40%|████      | 8/20 [00:38<00:51,  4.32s/it]
Task 8, Epoch 9/20 => Loss 0.155, Train_accy 95.20:  45%|████▌     | 9/20 [00:38<00:47,  4.32s/it]
Task 8, Epoch 10/20 => Loss 0.176, Train_accy 94.68:  45%|████▌     | 9/20 [00:43<00:47,  4.32s/it]
Task 8, Epoch 10/20 => Loss 0.176, Train_accy 94.68:  50%|█████     | 10/20 [00:43<00:43,  4.32s/it]
Task 8, Epoch 11/20 => Loss 0.196, Train_accy 93.95:  50%|█████     | 10/20 [00:47<00:43,  4.32s/it]
Task 8, Epoch 11/20 => Loss 0.196, Train_accy 93.95:  55%|█████▌    | 11/20 [00:47<00:38,  4.33s/it]
Task 8, Epoch 12/20 => Loss 0.199, Train_accy 93.84:  55%|█████▌    | 11/20 [00:51<00:38,  4.33s/it]
Task 8, Epoch 12/20 => Loss 0.199, Train_accy 93.84:  60%|██████    | 12/20 [00:51<00:34,  4.34s/it]
Task 8, Epoch 13/20 => Loss 0.144, Train_accy 95.82:  60%|██████    | 12/20 [00:56<00:34,  4.34s/it]
Task 8, Epoch 13/20 => Loss 0.144, Train_accy 95.82:  65%|██████▌   | 13/20 [00:56<00:30,  4.32s/it]
Task 8, Epoch 14/20 => Loss 0.173, Train_accy 95.20:  65%|██████▌   | 13/20 [01:00<00:30,  4.32s/it]
Task 8, Epoch 14/20 => Loss 0.173, Train_accy 95.20:  70%|███████   | 14/20 [01:00<00:25,  4.31s/it]
Task 8, Epoch 15/20 => Loss 0.173, Train_accy 93.95:  70%|███████   | 14/20 [01:04<00:25,  4.31s/it]
Task 8, Epoch 15/20 => Loss 0.173, Train_accy 93.95:  75%|███████▌  | 15/20 [01:04<00:21,  4.31s/it]
Task 8, Epoch 16/20 => Loss 0.176, Train_accy 94.57:  75%|███████▌  | 15/20 [01:09<00:21,  4.31s/it]
Task 8, Epoch 16/20 => Loss 0.176, Train_accy 94.57:  80%|████████  | 16/20 [01:09<00:17,  4.32s/it]
Task 8, Epoch 17/20 => Loss 0.174, Train_accy 94.89:  80%|████████  | 16/20 [01:13<00:17,  4.32s/it]
Task 8, Epoch 17/20 => Loss 0.174, Train_accy 94.89:  85%|████████▌ | 17/20 [01:13<00:12,  4.30s/it]
Task 8, Epoch 18/20 => Loss 0.197, Train_accy 94.05:  85%|████████▌ | 17/20 [01:17<00:12,  4.30s/it]
Task 8, Epoch 18/20 => Loss 0.197, Train_accy 94.05:  90%|█████████ | 18/20 [01:17<00:08,  4.30s/it]
Task 8, Epoch 19/20 => Loss 0.142, Train_accy 95.82:  90%|█████████ | 18/20 [01:21<00:08,  4.30s/it]
Task 8, Epoch 19/20 => Loss 0.142, Train_accy 95.82:  95%|█████████▌| 19/20 [01:21<00:04,  4.31s/it]
Task 8, Epoch 20/20 => Loss 0.133, Train_accy 96.03:  95%|█████████▌| 19/20 [01:26<00:04,  4.31s/it]
Task 8, Epoch 20/20 => Loss 0.133, Train_accy 96.03: 100%|██████████| 20/20 [01:26<00:00,  4.31s/it]
Task 8, Epoch 20/20 => Loss 0.133, Train_accy 96.03: 100%|██████████| 20/20 [01:26<00:00,  4.31s/it]
2024-08-12 10:48:13,888 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.133, Train_accy 96.03
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 43/768 type remove
Layer 4 : 56/768 type remove
Layer 5 : 76/768 type remove
Layer 6 : 71/768 type remove
Layer 7 : 71/768 type remove
Layer 8 : 73/768 type remove
Layer 9 : 77/768 type remove
Layer 10 : 77/768 type remove
Layer 11 : 46/768 type remove
Layer 12 : 37/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:48:25,483 [trainer.py] => Time:103.47749495506287
2128 2128
2128 2128
2024-08-12 10:48:30,255 [trainer.py] => Time:4.7713463306427
2024-08-12 10:48:30,255 [inflora.py] => Exemplar size: 0
2024-08-12 10:48:30,255 [trainer.py] => CNN: {'total': 77.96, '00-19': 86.23, '20-39': 83.57, '40-59': 82.57, '60-79': 78.14, '80-99': 71.0, '100-119': 75.0, '120-139': 76.89, '140-159': 79.6, '160-179': 70.04, 'old': 78.95, 'new': 70.04}
2024-08-12 10:48:30,255 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19, 81.29, 79.4, 79.16, 77.96]
2024-08-12 10:48:30,255 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23, 98.16, 97.87, 98.1, 97.98]
2024-08-12 10:48:30,255 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077, 0.818502824858757, 0.8013406459475929, 0.7974616604970914, 0.7847744360902256]
Average Accuracy (CNN): 86.37
2024-08-12 10:48:30,258 [trainer.py] => All params: 109136611
2024-08-12 10:48:30,260 [trainer.py] => Trainable params: 89108
2024-08-12 10:48:30,260 [inflora.py] => Learning on 180-200

  0%|          | 0/20 [00:00<?, ?it/s]
Task 9, Epoch 1/20 => Loss 1.556, Train_accy 57.25:   0%|          | 0/20 [00:04<?, ?it/s]
Task 9, Epoch 1/20 => Loss 1.556, Train_accy 57.25:   5%|▌         | 1/20 [00:04<01:20,  4.24s/it]
Task 9, Epoch 2/20 => Loss 0.371, Train_accy 89.08:   5%|▌         | 1/20 [00:08<01:20,  4.24s/it]
Task 9, Epoch 2/20 => Loss 0.371, Train_accy 89.08:  10%|█         | 2/20 [00:08<01:16,  4.24s/it]
Task 9, Epoch 3/20 => Loss 0.268, Train_accy 91.91:  10%|█         | 2/20 [00:12<01:16,  4.24s/it]
Task 9, Epoch 3/20 => Loss 0.268, Train_accy 91.91:  15%|█▌        | 3/20 [00:12<01:12,  4.24s/it]
Task 9, Epoch 4/20 => Loss 0.230, Train_accy 93.07:  15%|█▌        | 3/20 [00:17<01:12,  4.24s/it]
Task 9, Epoch 4/20 => Loss 0.230, Train_accy 93.07:  20%|██        | 4/20 [00:17<01:08,  4.28s/it]
Task 9, Epoch 5/20 => Loss 0.236, Train_accy 93.07:  20%|██        | 4/20 [00:21<01:08,  4.28s/it]
Task 9, Epoch 5/20 => Loss 0.236, Train_accy 93.07:  25%|██▌       | 5/20 [00:21<01:04,  4.30s/it]
Task 9, Epoch 6/20 => Loss 0.226, Train_accy 92.44:  25%|██▌       | 5/20 [00:25<01:04,  4.30s/it]
Task 9, Epoch 6/20 => Loss 0.226, Train_accy 92.44:  30%|███       | 6/20 [00:25<01:00,  4.29s/it]
Task 9, Epoch 7/20 => Loss 0.200, Train_accy 94.01:  30%|███       | 6/20 [00:29<01:00,  4.29s/it]
Task 9, Epoch 7/20 => Loss 0.200, Train_accy 94.01:  35%|███▌      | 7/20 [00:29<00:55,  4.27s/it]
Task 9, Epoch 8/20 => Loss 0.194, Train_accy 93.80:  35%|███▌      | 7/20 [00:34<00:55,  4.27s/it]
Task 9, Epoch 8/20 => Loss 0.194, Train_accy 93.80:  40%|████      | 8/20 [00:34<00:51,  4.30s/it]
Task 9, Epoch 9/20 => Loss 0.189, Train_accy 94.22:  40%|████      | 8/20 [00:38<00:51,  4.30s/it]
Task 9, Epoch 9/20 => Loss 0.189, Train_accy 94.22:  45%|████▌     | 9/20 [00:38<00:47,  4.30s/it]
Task 9, Epoch 10/20 => Loss 0.165, Train_accy 94.43:  45%|████▌     | 9/20 [00:42<00:47,  4.30s/it]
Task 9, Epoch 10/20 => Loss 0.165, Train_accy 94.43:  50%|█████     | 10/20 [00:42<00:42,  4.28s/it]
Task 9, Epoch 11/20 => Loss 0.155, Train_accy 95.17:  50%|█████     | 10/20 [00:47<00:42,  4.28s/it]
Task 9, Epoch 11/20 => Loss 0.155, Train_accy 95.17:  55%|█████▌    | 11/20 [00:47<00:38,  4.29s/it]
Task 9, Epoch 12/20 => Loss 0.190, Train_accy 93.91:  55%|█████▌    | 11/20 [00:51<00:38,  4.29s/it]
Task 9, Epoch 12/20 => Loss 0.190, Train_accy 93.91:  60%|██████    | 12/20 [00:51<00:34,  4.28s/it]
Task 9, Epoch 13/20 => Loss 0.210, Train_accy 93.91:  60%|██████    | 12/20 [00:55<00:34,  4.28s/it]
Task 9, Epoch 13/20 => Loss 0.210, Train_accy 93.91:  65%|██████▌   | 13/20 [00:55<00:29,  4.28s/it]
Task 9, Epoch 14/20 => Loss 0.146, Train_accy 95.38:  65%|██████▌   | 13/20 [00:59<00:29,  4.28s/it]
Task 9, Epoch 14/20 => Loss 0.146, Train_accy 95.38:  70%|███████   | 14/20 [00:59<00:25,  4.28s/it]
Task 9, Epoch 15/20 => Loss 0.171, Train_accy 94.22:  70%|███████   | 14/20 [01:04<00:25,  4.28s/it]
Task 9, Epoch 15/20 => Loss 0.171, Train_accy 94.22:  75%|███████▌  | 15/20 [01:04<00:21,  4.30s/it]
Task 9, Epoch 16/20 => Loss 0.131, Train_accy 95.48:  75%|███████▌  | 15/20 [01:08<00:21,  4.30s/it]
Task 9, Epoch 16/20 => Loss 0.131, Train_accy 95.48:  80%|████████  | 16/20 [01:08<00:17,  4.30s/it]
Task 9, Epoch 17/20 => Loss 0.149, Train_accy 95.38:  80%|████████  | 16/20 [01:12<00:17,  4.30s/it]
Task 9, Epoch 17/20 => Loss 0.149, Train_accy 95.38:  85%|████████▌ | 17/20 [01:12<00:12,  4.30s/it]
Task 9, Epoch 18/20 => Loss 0.187, Train_accy 94.33:  85%|████████▌ | 17/20 [01:17<00:12,  4.30s/it]
Task 9, Epoch 18/20 => Loss 0.187, Train_accy 94.33:  90%|█████████ | 18/20 [01:17<00:08,  4.29s/it]
Task 9, Epoch 19/20 => Loss 0.176, Train_accy 95.17:  90%|█████████ | 18/20 [01:21<00:08,  4.29s/it]
Task 9, Epoch 19/20 => Loss 0.176, Train_accy 95.17:  95%|█████████▌| 19/20 [01:21<00:04,  4.29s/it]
Task 9, Epoch 20/20 => Loss 0.140, Train_accy 95.48:  95%|█████████▌| 19/20 [01:25<00:04,  4.29s/it]
Task 9, Epoch 20/20 => Loss 0.140, Train_accy 95.48: 100%|██████████| 20/20 [01:25<00:00,  4.29s/it]
Task 9, Epoch 20/20 => Loss 0.140, Train_accy 95.48: 100%|██████████| 20/20 [01:25<00:00,  4.28s/it]
2024-08-12 10:50:01,475 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.140, Train_accy 95.48
Threshold:  0.995
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 72/768 type remove
Layer 4 : 99/768 type remove
Layer 5 : 129/768 type remove
Layer 6 : 120/768 type remove
Layer 7 : 123/768 type remove
Layer 8 : 134/768 type remove
Layer 9 : 147/768 type remove
Layer 10 : 150/768 type remove
Layer 11 : 91/768 type remove
Layer 12 : 57/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:50:12,617 [trainer.py] => Time:102.35705947875977
2358 2358
2358 2358
2024-08-12 10:50:17,895 [trainer.py] => Time:5.277717113494873
2024-08-12 10:50:17,895 [inflora.py] => Exemplar size: 0
2024-08-12 10:50:17,895 [trainer.py] => CNN: {'total': 76.17, '00-19': 86.64, '20-39': 81.16, '40-59': 81.65, '60-79': 76.52, '80-99': 69.52, '100-119': 74.12, '120-139': 73.78, '140-159': 78.8, '160-179': 69.2, '180-199': 71.3, 'old': 76.69, 'new': 71.3}
2024-08-12 10:50:17,895 [trainer.py] => CNN top1 curve: [97.98, 94.93, 92.26, 89.12, 85.19, 81.29, 79.4, 79.16, 77.96, 76.17]
2024-08-12 10:50:17,896 [trainer.py] => CNN top1 with task curve: [97.98, 97.8, 97.92, 97.93, 98.23, 98.16, 97.87, 98.1, 97.98, 97.96]
2024-08-12 10:50:17,896 [trainer.py] => CNN top1 task curve: [1.0, 0.9625550660792952, 0.9300595238095238, 0.8998911860718172, 0.8577441077441077, 0.818502824858757, 0.8013406459475929, 0.7974616604970914, 0.7847744360902256, 0.7675996607294318]
Average Accuracy (CNN): 85.35
logs/imagenet_r/40_40_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 10:50:20,968 [trainer.py] => config: ./configs/inr_inflora.json
2024-08-12 10:50:20,968 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 10:50:20,968 [trainer.py] => prefix: reproduce
2024-08-12 10:50:20,968 [trainer.py] => dataset: imagenet_r
2024-08-12 10:50:20,968 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 10:50:20,968 [trainer.py] => memory_size: 0
2024-08-12 10:50:20,968 [trainer.py] => memory_per_class: 0
2024-08-12 10:50:20,968 [trainer.py] => fixed_memory: True
2024-08-12 10:50:20,968 [trainer.py] => shuffle: True
2024-08-12 10:50:20,968 [trainer.py] => init_cls: 40
2024-08-12 10:50:20,968 [trainer.py] => increment: 40
2024-08-12 10:50:20,968 [trainer.py] => model_name: InfLoRA
2024-08-12 10:50:20,968 [trainer.py] => net_type: sip
2024-08-12 10:50:20,968 [trainer.py] => embd_dim: 768
2024-08-12 10:50:20,968 [trainer.py] => num_heads: 12
2024-08-12 10:50:20,968 [trainer.py] => total_sessions: 5
2024-08-12 10:50:20,968 [trainer.py] => seed: 1993
2024-08-12 10:50:20,968 [trainer.py] => EPSILON: 1e-08
2024-08-12 10:50:20,968 [trainer.py] => init_epoch: 20
2024-08-12 10:50:20,968 [trainer.py] => optim: adam
2024-08-12 10:50:20,968 [trainer.py] => init_lr: 0.0005
2024-08-12 10:50:20,968 [trainer.py] => init_lr_decay: 0.1
2024-08-12 10:50:20,968 [trainer.py] => init_weight_decay: 0.0
2024-08-12 10:50:20,968 [trainer.py] => epochs: 20
2024-08-12 10:50:20,968 [trainer.py] => lrate: 0.0005
2024-08-12 10:50:20,968 [trainer.py] => lrate_decay: 0.1
2024-08-12 10:50:20,968 [trainer.py] => batch_size: 48
2024-08-12 10:50:20,968 [trainer.py] => weight_decay: 0.0
2024-08-12 10:50:20,968 [trainer.py] => rank: 4
2024-08-12 10:50:20,968 [trainer.py] => lamb: 0.95
2024-08-12 10:50:20,969 [trainer.py] => lame: 1.0
2024-08-12 10:50:20,969 [trainer.py] => num_workers: 16
2024-08-12 10:50:21,042 [data_manager.py] => [168, 136, 51, 9, 183, 101, 171, 99, 42, 159, 191, 70, 16, 188, 27, 10, 175, 26, 68, 187, 98, 6, 85, 35, 112, 43, 100, 0, 103, 181, 88, 59, 4, 2, 116, 174, 94, 80, 106, 1, 147, 17, 141, 131, 72, 23, 173, 54, 197, 118, 87, 32, 79, 104, 91, 19, 135, 107, 178, 36, 11, 199, 142, 8, 122, 3, 28, 57, 153, 172, 190, 56, 49, 44, 97, 62, 151, 169, 194, 55, 192, 12, 189, 78, 66, 180, 15, 137, 109, 134, 92, 119, 126, 52, 170, 40, 148, 65, 144, 64, 138, 45, 77, 89, 154, 90, 71, 193, 74, 30, 113, 143, 96, 84, 67, 50, 186, 156, 69, 21, 18, 111, 108, 58, 125, 157, 150, 110, 182, 129, 166, 83, 81, 60, 13, 165, 14, 176, 63, 117, 5, 22, 145, 121, 38, 41, 82, 127, 114, 20, 31, 53, 37, 163, 196, 130, 152, 162, 86, 76, 24, 34, 184, 149, 33, 128, 198, 155, 146, 167, 139, 120, 140, 102, 47, 25, 158, 123, 46, 164, 61, 7, 115, 75, 133, 160, 105, 132, 179, 124, 48, 73, 93, 39, 95, 195, 29, 177, 185, 161]
2024-08-12 10:50:23,115 [trainer.py] => All params: 108399331
2024-08-12 10:50:23,116 [trainer.py] => Trainable params: 108399331
2024-08-12 10:50:23,117 [inflora.py] => Learning on 0-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.848, Train_accy 54.04:   0%|          | 0/20 [00:18<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.848, Train_accy 54.04:   5%|▌         | 1/20 [00:18<05:58, 18.89s/it]
Task 0, Epoch 2/20 => Loss 0.672, Train_accy 82.52:   5%|▌         | 1/20 [00:37<05:58, 18.89s/it]
Task 0, Epoch 2/20 => Loss 0.672, Train_accy 82.52:  10%|█         | 2/20 [00:37<05:37, 18.74s/it]
Task 0, Epoch 3/20 => Loss 0.552, Train_accy 84.57:  10%|█         | 2/20 [00:56<05:37, 18.74s/it]
Task 0, Epoch 3/20 => Loss 0.552, Train_accy 84.57:  15%|█▌        | 3/20 [00:56<05:19, 18.79s/it]
Task 0, Epoch 4/20 => Loss 0.478, Train_accy 86.81:  15%|█▌        | 3/20 [01:14<05:19, 18.79s/it]
Task 0, Epoch 4/20 => Loss 0.478, Train_accy 86.81:  20%|██        | 4/20 [01:14<04:58, 18.68s/it]
Task 0, Epoch 5/20 => Loss 0.433, Train_accy 87.87:  20%|██        | 4/20 [01:33<04:58, 18.68s/it]
Task 0, Epoch 5/20 => Loss 0.433, Train_accy 87.87:  25%|██▌       | 5/20 [01:33<04:39, 18.60s/it]
Task 0, Epoch 6/20 => Loss 0.394, Train_accy 89.58:  25%|██▌       | 5/20 [01:51<04:39, 18.60s/it]
Task 0, Epoch 6/20 => Loss 0.394, Train_accy 89.58:  30%|███       | 6/20 [01:51<04:20, 18.58s/it]
Task 0, Epoch 7/20 => Loss 0.353, Train_accy 90.37:  30%|███       | 6/20 [02:10<04:20, 18.58s/it]
Task 0, Epoch 7/20 => Loss 0.353, Train_accy 90.37:  35%|███▌      | 7/20 [02:10<04:01, 18.58s/it]
Task 0, Epoch 8/20 => Loss 0.330, Train_accy 90.87:  35%|███▌      | 7/20 [02:29<04:01, 18.58s/it]
Task 0, Epoch 8/20 => Loss 0.330, Train_accy 90.87:  40%|████      | 8/20 [02:29<03:42, 18.57s/it]
Task 0, Epoch 9/20 => Loss 0.324, Train_accy 91.15:  40%|████      | 8/20 [02:47<03:42, 18.57s/it]
Task 0, Epoch 9/20 => Loss 0.324, Train_accy 91.15:  45%|████▌     | 9/20 [02:47<03:24, 18.62s/it]
Task 0, Epoch 10/20 => Loss 0.331, Train_accy 90.87:  45%|████▌     | 9/20 [03:06<03:24, 18.62s/it]
Task 0, Epoch 10/20 => Loss 0.331, Train_accy 90.87:  50%|█████     | 10/20 [03:06<03:05, 18.57s/it]
Task 0, Epoch 11/20 => Loss 0.285, Train_accy 91.80:  50%|█████     | 10/20 [03:24<03:05, 18.57s/it]
Task 0, Epoch 11/20 => Loss 0.285, Train_accy 91.80:  55%|█████▌    | 11/20 [03:24<02:46, 18.56s/it]
Task 0, Epoch 12/20 => Loss 0.290, Train_accy 92.14:  55%|█████▌    | 11/20 [03:43<02:46, 18.56s/it]
Task 0, Epoch 12/20 => Loss 0.290, Train_accy 92.14:  60%|██████    | 12/20 [03:43<02:28, 18.56s/it]
Task 0, Epoch 13/20 => Loss 0.276, Train_accy 92.49:  60%|██████    | 12/20 [04:02<02:28, 18.56s/it]
Task 0, Epoch 13/20 => Loss 0.276, Train_accy 92.49:  65%|██████▌   | 13/20 [04:02<02:10, 18.68s/it]
Task 0, Epoch 14/20 => Loss 0.253, Train_accy 93.16:  65%|██████▌   | 13/20 [04:21<02:10, 18.68s/it]
Task 0, Epoch 14/20 => Loss 0.253, Train_accy 93.16:  70%|███████   | 14/20 [04:21<01:52, 18.72s/it]
Task 0, Epoch 15/20 => Loss 0.247, Train_accy 92.99:  70%|███████   | 14/20 [04:39<01:52, 18.72s/it]
Task 0, Epoch 15/20 => Loss 0.247, Train_accy 92.99:  75%|███████▌  | 15/20 [04:39<01:33, 18.74s/it]
Task 0, Epoch 16/20 => Loss 0.240, Train_accy 93.31:  75%|███████▌  | 15/20 [04:58<01:33, 18.74s/it]
Task 0, Epoch 16/20 => Loss 0.240, Train_accy 93.31:  80%|████████  | 16/20 [04:58<01:14, 18.75s/it]
Task 0, Epoch 17/20 => Loss 0.210, Train_accy 94.06:  80%|████████  | 16/20 [05:17<01:14, 18.75s/it]
Task 0, Epoch 17/20 => Loss 0.210, Train_accy 94.06:  85%|████████▌ | 17/20 [05:17<00:56, 18.76s/it]
Task 0, Epoch 18/20 => Loss 0.233, Train_accy 93.79:  85%|████████▌ | 17/20 [05:36<00:56, 18.76s/it]
Task 0, Epoch 18/20 => Loss 0.233, Train_accy 93.79:  90%|█████████ | 18/20 [05:36<00:37, 18.74s/it]
Task 0, Epoch 19/20 => Loss 0.217, Train_accy 94.28:  90%|█████████ | 18/20 [05:54<00:37, 18.74s/it]
Task 0, Epoch 19/20 => Loss 0.217, Train_accy 94.28:  95%|█████████▌| 19/20 [05:54<00:18, 18.76s/it]
Task 0, Epoch 20/20 => Loss 0.232, Train_accy 93.53:  95%|█████████▌| 19/20 [06:13<00:18, 18.76s/it]
Task 0, Epoch 20/20 => Loss 0.232, Train_accy 93.53: 100%|██████████| 20/20 [06:13<00:00, 18.74s/it]
Task 0, Epoch 20/20 => Loss 0.232, Train_accy 93.53: 100%|██████████| 20/20 [06:13<00:00, 18.68s/it]
2024-08-12 10:56:53,842 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.232, Train_accy 93.53
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 10/768 type remove
Layer 4 : 10/768 type remove
Layer 5 : 15/768 type remove
Layer 6 : 13/768 type remove
Layer 7 : 12/768 type remove
Layer 8 : 12/768 type remove
Layer 9 : 17/768 type remove
Layer 10 : 17/768 type remove
Layer 11 : 4/768 type remove
Layer 12 : 22/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 10:57:20,334 [trainer.py] => Time:417.21694684028625
1321 1321
1321 1321
2024-08-12 10:57:23,551 [trainer.py] => Time:3.216843366622925
2024-08-12 10:57:23,551 [inflora.py] => Exemplar size: 0
2024-08-12 10:57:23,551 [trainer.py] => CNN: {'total': 91.07, '00-39': 91.07, 'old': 0, 'new': 91.07}
2024-08-12 10:57:23,551 [trainer.py] => CNN top1 curve: [91.07]
2024-08-12 10:57:23,551 [trainer.py] => CNN top1 with task curve: [91.07]
2024-08-12 10:57:23,551 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 91.07
2024-08-12 10:57:23,553 [trainer.py] => All params: 108399331
2024-08-12 10:57:23,554 [trainer.py] => Trainable params: 104488
2024-08-12 10:57:23,554 [inflora.py] => Learning on 40-80

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.835, Train_accy 56.38:   0%|          | 0/20 [00:16<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.835, Train_accy 56.38:   5%|▌         | 1/20 [00:16<05:10, 16.32s/it]
Task 1, Epoch 2/20 => Loss 0.751, Train_accy 79.70:   5%|▌         | 1/20 [00:32<05:10, 16.32s/it]
Task 1, Epoch 2/20 => Loss 0.751, Train_accy 79.70:  10%|█         | 2/20 [00:32<04:54, 16.35s/it]
Task 1, Epoch 3/20 => Loss 0.640, Train_accy 82.85:  10%|█         | 2/20 [00:49<04:54, 16.35s/it]
Task 1, Epoch 3/20 => Loss 0.640, Train_accy 82.85:  15%|█▌        | 3/20 [00:49<04:39, 16.47s/it]
Task 1, Epoch 4/20 => Loss 0.522, Train_accy 85.44:  15%|█▌        | 3/20 [01:05<04:39, 16.47s/it]
Task 1, Epoch 4/20 => Loss 0.522, Train_accy 85.44:  20%|██        | 4/20 [01:05<04:22, 16.42s/it]
Task 1, Epoch 5/20 => Loss 0.471, Train_accy 86.91:  20%|██        | 4/20 [01:21<04:22, 16.42s/it]
Task 1, Epoch 5/20 => Loss 0.471, Train_accy 86.91:  25%|██▌       | 5/20 [01:21<04:05, 16.38s/it]
Task 1, Epoch 6/20 => Loss 0.431, Train_accy 88.11:  25%|██▌       | 5/20 [01:38<04:05, 16.38s/it]
Task 1, Epoch 6/20 => Loss 0.431, Train_accy 88.11:  30%|███       | 6/20 [01:38<03:49, 16.38s/it]
Task 1, Epoch 7/20 => Loss 0.407, Train_accy 88.46:  30%|███       | 6/20 [01:54<03:49, 16.38s/it]
Task 1, Epoch 7/20 => Loss 0.407, Train_accy 88.46:  35%|███▌      | 7/20 [01:54<03:33, 16.42s/it]
Task 1, Epoch 8/20 => Loss 0.364, Train_accy 90.08:  35%|███▌      | 7/20 [02:11<03:33, 16.42s/it]
Task 1, Epoch 8/20 => Loss 0.364, Train_accy 90.08:  40%|████      | 8/20 [02:11<03:16, 16.40s/it]
Task 1, Epoch 9/20 => Loss 0.370, Train_accy 89.91:  40%|████      | 8/20 [02:27<03:16, 16.40s/it]
Task 1, Epoch 9/20 => Loss 0.370, Train_accy 89.91:  45%|████▌     | 9/20 [02:27<03:00, 16.39s/it]
Task 1, Epoch 10/20 => Loss 0.347, Train_accy 90.40:  45%|████▌     | 9/20 [02:44<03:00, 16.39s/it]
Task 1, Epoch 10/20 => Loss 0.347, Train_accy 90.40:  50%|█████     | 10/20 [02:44<02:44, 16.43s/it]
Task 1, Epoch 11/20 => Loss 0.310, Train_accy 92.04:  50%|█████     | 10/20 [03:00<02:44, 16.43s/it]
Task 1, Epoch 11/20 => Loss 0.310, Train_accy 92.04:  55%|█████▌    | 11/20 [03:00<02:28, 16.49s/it]
Task 1, Epoch 12/20 => Loss 0.294, Train_accy 91.80:  55%|█████▌    | 11/20 [03:17<02:28, 16.49s/it]
Task 1, Epoch 12/20 => Loss 0.294, Train_accy 91.80:  60%|██████    | 12/20 [03:17<02:11, 16.49s/it]
Task 1, Epoch 13/20 => Loss 0.282, Train_accy 92.21:  60%|██████    | 12/20 [03:33<02:11, 16.49s/it]
Task 1, Epoch 13/20 => Loss 0.282, Train_accy 92.21:  65%|██████▌   | 13/20 [03:33<01:55, 16.44s/it]
Task 1, Epoch 14/20 => Loss 0.292, Train_accy 91.98:  65%|██████▌   | 13/20 [03:49<01:55, 16.44s/it]
Task 1, Epoch 14/20 => Loss 0.292, Train_accy 91.98:  70%|███████   | 14/20 [03:49<01:38, 16.42s/it]
Task 1, Epoch 15/20 => Loss 0.284, Train_accy 92.21:  70%|███████   | 14/20 [04:06<01:38, 16.42s/it]
Task 1, Epoch 15/20 => Loss 0.284, Train_accy 92.21:  75%|███████▌  | 15/20 [04:06<01:22, 16.41s/it]
Task 1, Epoch 16/20 => Loss 0.259, Train_accy 92.88:  75%|███████▌  | 15/20 [04:22<01:22, 16.41s/it]
Task 1, Epoch 16/20 => Loss 0.259, Train_accy 92.88:  80%|████████  | 16/20 [04:22<01:05, 16.45s/it]
Task 1, Epoch 17/20 => Loss 0.274, Train_accy 92.36:  80%|████████  | 16/20 [04:39<01:05, 16.45s/it]
Task 1, Epoch 17/20 => Loss 0.274, Train_accy 92.36:  85%|████████▌ | 17/20 [04:39<00:49, 16.46s/it]
Task 1, Epoch 18/20 => Loss 0.250, Train_accy 92.84:  85%|████████▌ | 17/20 [04:55<00:49, 16.46s/it]
Task 1, Epoch 18/20 => Loss 0.250, Train_accy 92.84:  90%|█████████ | 18/20 [04:55<00:32, 16.46s/it]
Task 1, Epoch 19/20 => Loss 0.259, Train_accy 92.86:  90%|█████████ | 18/20 [05:12<00:32, 16.46s/it]
Task 1, Epoch 19/20 => Loss 0.259, Train_accy 92.86:  95%|█████████▌| 19/20 [05:12<00:16, 16.47s/it]
Task 1, Epoch 20/20 => Loss 0.258, Train_accy 93.33:  95%|█████████▌| 19/20 [05:28<00:16, 16.47s/it]
Task 1, Epoch 20/20 => Loss 0.258, Train_accy 93.33: 100%|██████████| 20/20 [05:28<00:00, 16.42s/it]
Task 1, Epoch 20/20 => Loss 0.258, Train_accy 93.33: 100%|██████████| 20/20 [05:28<00:00, 16.43s/it]
2024-08-12 11:03:07,135 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.258, Train_accy 93.33
Threshold:  0.96
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 20/768 type remove
Layer 6 : 19/768 type remove
Layer 7 : 20/768 type remove
Layer 8 : 20/768 type remove
Layer 9 : 31/768 type remove
Layer 10 : 36/768 type remove
Layer 11 : 12/768 type remove
Layer 12 : 53/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:03:33,342 [trainer.py] => Time:369.787237405777
2498 2498
2498 2498
2024-08-12 11:03:38,431 [trainer.py] => Time:5.089325666427612
2024-08-12 11:03:38,432 [inflora.py] => Exemplar size: 0
2024-08-12 11:03:38,432 [trainer.py] => CNN: {'total': 86.19, '00-39': 88.57, '40-79': 83.52, 'old': 88.57, 'new': 83.52}
2024-08-12 11:03:38,432 [trainer.py] => CNN top1 curve: [91.07, 86.19]
2024-08-12 11:03:38,432 [trainer.py] => CNN top1 with task curve: [91.07, 89.99]
2024-08-12 11:03:38,432 [trainer.py] => CNN top1 task curve: [1.0, 0.9247397918334668]
Average Accuracy (CNN): 88.63
2024-08-12 11:03:38,433 [trainer.py] => All params: 108399331
2024-08-12 11:03:38,435 [trainer.py] => Trainable params: 104488
2024-08-12 11:03:38,435 [inflora.py] => Learning on 80-120

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.738, Train_accy 57.23:   0%|          | 0/20 [00:17<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.738, Train_accy 57.23:   5%|▌         | 1/20 [00:17<05:27, 17.23s/it]
Task 2, Epoch 2/20 => Loss 0.728, Train_accy 80.50:   5%|▌         | 1/20 [00:34<05:27, 17.23s/it]
Task 2, Epoch 2/20 => Loss 0.728, Train_accy 80.50:  10%|█         | 2/20 [00:34<05:08, 17.13s/it]
Task 2, Epoch 3/20 => Loss 0.606, Train_accy 83.57:  10%|█         | 2/20 [00:51<05:08, 17.13s/it]
Task 2, Epoch 3/20 => Loss 0.606, Train_accy 83.57:  15%|█▌        | 3/20 [00:51<04:50, 17.12s/it]
Task 2, Epoch 4/20 => Loss 0.514, Train_accy 85.27:  15%|█▌        | 3/20 [01:08<04:50, 17.12s/it]
Task 2, Epoch 4/20 => Loss 0.514, Train_accy 85.27:  20%|██        | 4/20 [01:08<04:34, 17.15s/it]
Task 2, Epoch 5/20 => Loss 0.466, Train_accy 86.53:  20%|██        | 4/20 [01:25<04:34, 17.15s/it]
Task 2, Epoch 5/20 => Loss 0.466, Train_accy 86.53:  25%|██▌       | 5/20 [01:25<04:17, 17.14s/it]
Task 2, Epoch 6/20 => Loss 0.426, Train_accy 88.18:  25%|██▌       | 5/20 [01:42<04:17, 17.14s/it]
Task 2, Epoch 6/20 => Loss 0.426, Train_accy 88.18:  30%|███       | 6/20 [01:42<04:00, 17.18s/it]
Task 2, Epoch 7/20 => Loss 0.352, Train_accy 90.21:  30%|███       | 6/20 [02:00<04:00, 17.18s/it]
Task 2, Epoch 7/20 => Loss 0.352, Train_accy 90.21:  35%|███▌      | 7/20 [02:00<03:42, 17.15s/it]
Task 2, Epoch 8/20 => Loss 0.350, Train_accy 90.41:  35%|███▌      | 7/20 [02:17<03:42, 17.15s/it]
Task 2, Epoch 8/20 => Loss 0.350, Train_accy 90.41:  40%|████      | 8/20 [02:17<03:25, 17.14s/it]
Task 2, Epoch 9/20 => Loss 0.321, Train_accy 90.68:  40%|████      | 8/20 [02:34<03:25, 17.14s/it]
Task 2, Epoch 9/20 => Loss 0.321, Train_accy 90.68:  45%|████▌     | 9/20 [02:34<03:08, 17.16s/it]
Task 2, Epoch 10/20 => Loss 0.336, Train_accy 91.20:  45%|████▌     | 9/20 [02:51<03:08, 17.16s/it]
Task 2, Epoch 10/20 => Loss 0.336, Train_accy 91.20:  50%|█████     | 10/20 [02:51<02:52, 17.20s/it]
Task 2, Epoch 11/20 => Loss 0.332, Train_accy 91.03:  50%|█████     | 10/20 [03:09<02:52, 17.20s/it]
Task 2, Epoch 11/20 => Loss 0.332, Train_accy 91.03:  55%|█████▌    | 11/20 [03:09<02:35, 17.24s/it]
Task 2, Epoch 12/20 => Loss 0.315, Train_accy 91.22:  55%|█████▌    | 11/20 [03:26<02:35, 17.24s/it]
Task 2, Epoch 12/20 => Loss 0.315, Train_accy 91.22:  60%|██████    | 12/20 [03:26<02:18, 17.29s/it]
Task 2, Epoch 13/20 => Loss 0.323, Train_accy 91.01:  60%|██████    | 12/20 [03:43<02:18, 17.29s/it]
Task 2, Epoch 13/20 => Loss 0.323, Train_accy 91.01:  65%|██████▌   | 13/20 [03:43<02:01, 17.30s/it]
Task 2, Epoch 14/20 => Loss 0.291, Train_accy 92.38:  65%|██████▌   | 13/20 [04:01<02:01, 17.30s/it]
Task 2, Epoch 14/20 => Loss 0.291, Train_accy 92.38:  70%|███████   | 14/20 [04:01<01:43, 17.29s/it]
Task 2, Epoch 15/20 => Loss 0.276, Train_accy 92.25:  70%|███████   | 14/20 [04:18<01:43, 17.29s/it]
Task 2, Epoch 15/20 => Loss 0.276, Train_accy 92.25:  75%|███████▌  | 15/20 [04:18<01:26, 17.26s/it]
Task 2, Epoch 16/20 => Loss 0.270, Train_accy 92.73:  75%|███████▌  | 15/20 [04:35<01:26, 17.26s/it]
Task 2, Epoch 16/20 => Loss 0.270, Train_accy 92.73:  80%|████████  | 16/20 [04:35<01:08, 17.19s/it]
Task 2, Epoch 17/20 => Loss 0.249, Train_accy 92.95:  80%|████████  | 16/20 [04:52<01:08, 17.19s/it]
Task 2, Epoch 17/20 => Loss 0.249, Train_accy 92.95:  85%|████████▌ | 17/20 [04:52<00:51, 17.22s/it]
Task 2, Epoch 18/20 => Loss 0.217, Train_accy 93.82:  85%|████████▌ | 17/20 [05:09<00:51, 17.22s/it]
Task 2, Epoch 18/20 => Loss 0.217, Train_accy 93.82:  90%|█████████ | 18/20 [05:09<00:34, 17.24s/it]
Task 2, Epoch 19/20 => Loss 0.252, Train_accy 93.29:  90%|█████████ | 18/20 [05:26<00:34, 17.24s/it]
Task 2, Epoch 19/20 => Loss 0.252, Train_accy 93.29:  95%|█████████▌| 19/20 [05:26<00:17, 17.20s/it]
Task 2, Epoch 20/20 => Loss 0.237, Train_accy 93.33:  95%|█████████▌| 19/20 [05:44<00:17, 17.20s/it]
Task 2, Epoch 20/20 => Loss 0.237, Train_accy 93.33: 100%|██████████| 20/20 [05:44<00:00, 17.17s/it]
Task 2, Epoch 20/20 => Loss 0.237, Train_accy 93.33: 100%|██████████| 20/20 [05:44<00:00, 17.20s/it]
2024-08-12 11:09:37,894 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.237, Train_accy 93.33
Threshold:  0.97
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 19/768 type remove
Layer 5 : 28/768 type remove
Layer 6 : 27/768 type remove
Layer 7 : 31/768 type remove
Layer 8 : 32/768 type remove
Layer 9 : 55/768 type remove
Layer 10 : 67/768 type remove
Layer 11 : 27/768 type remove
Layer 12 : 98/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:10:04,861 [trainer.py] => Time:386.42572379112244
3645 3645
3645 3645
2024-08-12 11:10:11,843 [trainer.py] => Time:6.981845378875732
2024-08-12 11:10:11,843 [inflora.py] => Exemplar size: 0
2024-08-12 11:10:11,843 [trainer.py] => CNN: {'total': 81.34, '00-39': 86.22, '40-79': 79.27, '80-119': 77.86, 'old': 82.95, 'new': 77.86}
2024-08-12 11:10:11,843 [trainer.py] => CNN top1 curve: [91.07, 86.19, 81.34]
2024-08-12 11:10:11,843 [trainer.py] => CNN top1 with task curve: [91.07, 89.99, 89.36]
2024-08-12 11:10:11,843 [trainer.py] => CNN top1 task curve: [1.0, 0.9247397918334668, 0.8655692729766804]
Average Accuracy (CNN): 86.2
2024-08-12 11:10:11,845 [trainer.py] => All params: 108399331
2024-08-12 11:10:11,846 [trainer.py] => Trainable params: 104488
2024-08-12 11:10:11,846 [inflora.py] => Learning on 120-160

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.651, Train_accy 60.02:   0%|          | 0/20 [00:17<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.651, Train_accy 60.02:   5%|▌         | 1/20 [00:17<05:31, 17.45s/it]
Task 3, Epoch 2/20 => Loss 0.705, Train_accy 81.36:   5%|▌         | 1/20 [00:34<05:31, 17.45s/it]
Task 3, Epoch 2/20 => Loss 0.705, Train_accy 81.36:  10%|█         | 2/20 [00:34<05:14, 17.47s/it]
Task 3, Epoch 3/20 => Loss 0.580, Train_accy 84.09:  10%|█         | 2/20 [00:52<05:14, 17.47s/it]
Task 3, Epoch 3/20 => Loss 0.580, Train_accy 84.09:  15%|█▌        | 3/20 [00:52<04:57, 17.48s/it]
Task 3, Epoch 4/20 => Loss 0.466, Train_accy 86.78:  15%|█▌        | 3/20 [01:10<04:57, 17.48s/it]
Task 3, Epoch 4/20 => Loss 0.466, Train_accy 86.78:  20%|██        | 4/20 [01:10<04:41, 17.61s/it]
Task 3, Epoch 5/20 => Loss 0.415, Train_accy 88.97:  20%|██        | 4/20 [01:28<04:41, 17.61s/it]
Task 3, Epoch 5/20 => Loss 0.415, Train_accy 88.97:  25%|██▌       | 5/20 [01:28<04:25, 17.67s/it]
Task 3, Epoch 6/20 => Loss 0.381, Train_accy 89.43:  25%|██▌       | 5/20 [01:45<04:25, 17.67s/it]
Task 3, Epoch 6/20 => Loss 0.381, Train_accy 89.43:  30%|███       | 6/20 [01:45<04:07, 17.65s/it]
Task 3, Epoch 7/20 => Loss 0.343, Train_accy 90.38:  30%|███       | 6/20 [02:03<04:07, 17.65s/it]
Task 3, Epoch 7/20 => Loss 0.343, Train_accy 90.38:  35%|███▌      | 7/20 [02:03<03:48, 17.61s/it]
Task 3, Epoch 8/20 => Loss 0.339, Train_accy 90.83:  35%|███▌      | 7/20 [02:20<03:48, 17.61s/it]
Task 3, Epoch 8/20 => Loss 0.339, Train_accy 90.83:  40%|████      | 8/20 [02:20<03:30, 17.55s/it]
Task 3, Epoch 9/20 => Loss 0.295, Train_accy 91.88:  40%|████      | 8/20 [02:38<03:30, 17.55s/it]
Task 3, Epoch 9/20 => Loss 0.295, Train_accy 91.88:  45%|████▌     | 9/20 [02:38<03:13, 17.58s/it]
Task 3, Epoch 10/20 => Loss 0.322, Train_accy 91.17:  45%|████▌     | 9/20 [02:55<03:13, 17.58s/it]
Task 3, Epoch 10/20 => Loss 0.322, Train_accy 91.17:  50%|█████     | 10/20 [02:55<02:55, 17.53s/it]
Task 3, Epoch 11/20 => Loss 0.264, Train_accy 92.98:  50%|█████     | 10/20 [03:13<02:55, 17.53s/it]
Task 3, Epoch 11/20 => Loss 0.264, Train_accy 92.98:  55%|█████▌    | 11/20 [03:13<02:38, 17.58s/it]
Task 3, Epoch 12/20 => Loss 0.286, Train_accy 92.21:  55%|█████▌    | 11/20 [03:30<02:38, 17.58s/it]
Task 3, Epoch 12/20 => Loss 0.286, Train_accy 92.21:  60%|██████    | 12/20 [03:30<02:20, 17.60s/it]
Task 3, Epoch 13/20 => Loss 0.264, Train_accy 92.89:  60%|██████    | 12/20 [03:48<02:20, 17.60s/it]
Task 3, Epoch 13/20 => Loss 0.264, Train_accy 92.89:  65%|██████▌   | 13/20 [03:48<02:02, 17.57s/it]
Task 3, Epoch 14/20 => Loss 0.272, Train_accy 92.98:  65%|██████▌   | 13/20 [04:06<02:02, 17.57s/it]
Task 3, Epoch 14/20 => Loss 0.272, Train_accy 92.98:  70%|███████   | 14/20 [04:06<01:45, 17.61s/it]
Task 3, Epoch 15/20 => Loss 0.260, Train_accy 93.02:  70%|███████   | 14/20 [04:23<01:45, 17.61s/it]
Task 3, Epoch 15/20 => Loss 0.260, Train_accy 93.02:  75%|███████▌  | 15/20 [04:23<01:27, 17.58s/it]
Task 3, Epoch 16/20 => Loss 0.235, Train_accy 93.46:  75%|███████▌  | 15/20 [04:41<01:27, 17.58s/it]
Task 3, Epoch 16/20 => Loss 0.235, Train_accy 93.46:  80%|████████  | 16/20 [04:41<01:10, 17.61s/it]
Task 3, Epoch 17/20 => Loss 0.227, Train_accy 93.77:  80%|████████  | 16/20 [04:59<01:10, 17.61s/it]
Task 3, Epoch 17/20 => Loss 0.227, Train_accy 93.77:  85%|████████▌ | 17/20 [04:59<00:52, 17.63s/it]
Task 3, Epoch 18/20 => Loss 0.230, Train_accy 93.72:  85%|████████▌ | 17/20 [05:16<00:52, 17.63s/it]
Task 3, Epoch 18/20 => Loss 0.230, Train_accy 93.72:  90%|█████████ | 18/20 [05:16<00:35, 17.62s/it]
Task 3, Epoch 19/20 => Loss 0.214, Train_accy 94.43:  90%|█████████ | 18/20 [05:34<00:35, 17.62s/it]
Task 3, Epoch 19/20 => Loss 0.214, Train_accy 94.43:  95%|█████████▌| 19/20 [05:34<00:17, 17.59s/it]
Task 3, Epoch 20/20 => Loss 0.223, Train_accy 93.85:  95%|█████████▌| 19/20 [05:51<00:17, 17.59s/it]
Task 3, Epoch 20/20 => Loss 0.223, Train_accy 93.85: 100%|██████████| 20/20 [05:51<00:00, 17.56s/it]
Task 3, Epoch 20/20 => Loss 0.223, Train_accy 93.85: 100%|██████████| 20/20 [05:51<00:00, 17.58s/it]
2024-08-12 11:16:19,223 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.223, Train_accy 93.85
Threshold:  0.98
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 21/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 40/768 type remove
Layer 6 : 41/768 type remove
Layer 7 : 46/768 type remove
Layer 8 : 52/768 type remove
Layer 9 : 91/768 type remove
Layer 10 : 115/768 type remove
Layer 11 : 55/768 type remove
Layer 12 : 161/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:16:47,365 [trainer.py] => Time:395.51835322380066
4943 4943
4943 4943
2024-08-12 11:16:56,779 [trainer.py] => Time:9.414243698120117
2024-08-12 11:16:56,779 [inflora.py] => Exemplar size: 0
2024-08-12 11:16:56,779 [trainer.py] => CNN: {'total': 80.52, '00-39': 84.78, '40-79': 79.95, '80-119': 76.81, '120-159': 79.97, 'old': 80.71, 'new': 79.97}
2024-08-12 11:16:56,779 [trainer.py] => CNN top1 curve: [91.07, 86.19, 81.34, 80.52]
2024-08-12 11:16:56,779 [trainer.py] => CNN top1 with task curve: [91.07, 89.99, 89.36, 89.18]
2024-08-12 11:16:56,779 [trainer.py] => CNN top1 task curve: [1.0, 0.9247397918334668, 0.8655692729766804, 0.8492818126643739]
Average Accuracy (CNN): 84.78
2024-08-12 11:16:56,781 [trainer.py] => All params: 108399331
2024-08-12 11:16:56,783 [trainer.py] => Trainable params: 104488
2024-08-12 11:16:56,783 [inflora.py] => Learning on 160-200

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.871, Train_accy 54.58:   0%|          | 0/20 [00:15<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.871, Train_accy 54.58:   5%|▌         | 1/20 [00:15<04:51, 15.34s/it]
Task 4, Epoch 2/20 => Loss 0.805, Train_accy 78.09:   5%|▌         | 1/20 [00:30<04:51, 15.34s/it]
Task 4, Epoch 2/20 => Loss 0.805, Train_accy 78.09:  10%|█         | 2/20 [00:30<04:35, 15.32s/it]
Task 4, Epoch 3/20 => Loss 0.618, Train_accy 83.85:  10%|█         | 2/20 [00:45<04:35, 15.32s/it]
Task 4, Epoch 3/20 => Loss 0.618, Train_accy 83.85:  15%|█▌        | 3/20 [00:45<04:19, 15.29s/it]
Task 4, Epoch 4/20 => Loss 0.542, Train_accy 85.92:  15%|█▌        | 3/20 [01:01<04:19, 15.29s/it]
Task 4, Epoch 4/20 => Loss 0.542, Train_accy 85.92:  20%|██        | 4/20 [01:01<04:05, 15.35s/it]
Task 4, Epoch 5/20 => Loss 0.490, Train_accy 86.37:  20%|██        | 4/20 [01:16<04:05, 15.35s/it]
Task 4, Epoch 5/20 => Loss 0.490, Train_accy 86.37:  25%|██▌       | 5/20 [01:16<03:50, 15.37s/it]
Task 4, Epoch 6/20 => Loss 0.432, Train_accy 88.60:  25%|██▌       | 5/20 [01:31<03:50, 15.37s/it]
Task 4, Epoch 6/20 => Loss 0.432, Train_accy 88.60:  30%|███       | 6/20 [01:31<03:34, 15.31s/it]
Task 4, Epoch 7/20 => Loss 0.430, Train_accy 88.62:  30%|███       | 6/20 [01:47<03:34, 15.31s/it]
Task 4, Epoch 7/20 => Loss 0.430, Train_accy 88.62:  35%|███▌      | 7/20 [01:47<03:19, 15.35s/it]
Task 4, Epoch 8/20 => Loss 0.363, Train_accy 89.73:  35%|███▌      | 7/20 [02:02<03:19, 15.35s/it]
Task 4, Epoch 8/20 => Loss 0.363, Train_accy 89.73:  40%|████      | 8/20 [02:02<03:04, 15.35s/it]
Task 4, Epoch 9/20 => Loss 0.370, Train_accy 90.49:  40%|████      | 8/20 [02:18<03:04, 15.35s/it]
Task 4, Epoch 9/20 => Loss 0.370, Train_accy 90.49:  45%|████▌     | 9/20 [02:18<02:48, 15.33s/it]
Task 4, Epoch 10/20 => Loss 0.340, Train_accy 90.83:  45%|████▌     | 9/20 [02:33<02:48, 15.33s/it]
Task 4, Epoch 10/20 => Loss 0.340, Train_accy 90.83:  50%|█████     | 10/20 [02:33<02:32, 15.29s/it]
Task 4, Epoch 11/20 => Loss 0.309, Train_accy 91.30:  50%|█████     | 10/20 [02:48<02:32, 15.29s/it]
Task 4, Epoch 11/20 => Loss 0.309, Train_accy 91.30:  55%|█████▌    | 11/20 [02:48<02:17, 15.30s/it]
Task 4, Epoch 12/20 => Loss 0.325, Train_accy 91.20:  55%|█████▌    | 11/20 [03:03<02:17, 15.30s/it]
Task 4, Epoch 12/20 => Loss 0.325, Train_accy 91.20:  60%|██████    | 12/20 [03:03<02:02, 15.33s/it]
Task 4, Epoch 13/20 => Loss 0.310, Train_accy 92.34:  60%|██████    | 12/20 [03:19<02:02, 15.33s/it]
Task 4, Epoch 13/20 => Loss 0.310, Train_accy 92.34:  65%|██████▌   | 13/20 [03:19<01:47, 15.37s/it]
Task 4, Epoch 14/20 => Loss 0.306, Train_accy 91.84:  65%|██████▌   | 13/20 [03:34<01:47, 15.37s/it]
Task 4, Epoch 14/20 => Loss 0.306, Train_accy 91.84:  70%|███████   | 14/20 [03:34<01:32, 15.38s/it]
Task 4, Epoch 15/20 => Loss 0.286, Train_accy 92.48:  70%|███████   | 14/20 [03:50<01:32, 15.38s/it]
Task 4, Epoch 15/20 => Loss 0.286, Train_accy 92.48:  75%|███████▌  | 15/20 [03:50<01:16, 15.34s/it]
Task 4, Epoch 16/20 => Loss 0.281, Train_accy 92.67:  75%|███████▌  | 15/20 [04:05<01:16, 15.34s/it]
Task 4, Epoch 16/20 => Loss 0.281, Train_accy 92.67:  80%|████████  | 16/20 [04:05<01:01, 15.34s/it]
Task 4, Epoch 17/20 => Loss 0.272, Train_accy 92.89:  80%|████████  | 16/20 [04:20<01:01, 15.34s/it]
Task 4, Epoch 17/20 => Loss 0.272, Train_accy 92.89:  85%|████████▌ | 17/20 [04:20<00:45, 15.33s/it]
Task 4, Epoch 18/20 => Loss 0.282, Train_accy 92.22:  85%|████████▌ | 17/20 [04:35<00:45, 15.33s/it]
Task 4, Epoch 18/20 => Loss 0.282, Train_accy 92.22:  90%|█████████ | 18/20 [04:35<00:30, 15.30s/it]
Task 4, Epoch 19/20 => Loss 0.251, Train_accy 93.31:  90%|█████████ | 18/20 [04:51<00:30, 15.30s/it]
Task 4, Epoch 19/20 => Loss 0.251, Train_accy 93.31:  95%|█████████▌| 19/20 [04:51<00:15, 15.32s/it]
Task 4, Epoch 20/20 => Loss 0.256, Train_accy 93.34:  95%|█████████▌| 19/20 [05:06<00:15, 15.32s/it]
Task 4, Epoch 20/20 => Loss 0.256, Train_accy 93.34: 100%|██████████| 20/20 [05:06<00:00, 15.30s/it]
Task 4, Epoch 20/20 => Loss 0.256, Train_accy 93.34: 100%|██████████| 20/20 [05:06<00:00, 15.33s/it]
2024-08-12 11:22:17,583 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.256, Train_accy 93.34
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 35/768 type remove
Layer 4 : 45/768 type remove
Layer 5 : 68/768 type remove
Layer 6 : 72/768 type remove
Layer 7 : 86/768 type remove
Layer 8 : 101/768 type remove
Layer 9 : 171/768 type remove
Layer 10 : 218/768 type remove
Layer 11 : 140/768 type remove
Layer 12 : 284/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:22:42,594 [trainer.py] => Time:345.81083154678345
6000 6000
6000 6000
2024-08-12 11:22:53,669 [trainer.py] => Time:11.07457423210144
2024-08-12 11:22:53,669 [inflora.py] => Exemplar size: 0
2024-08-12 11:22:53,669 [trainer.py] => CNN: {'total': 77.87, '00-39': 83.12, '40-79': 77.99, '80-119': 75.24, '120-159': 78.89, '160-199': 72.75, 'old': 78.96, 'new': 72.75}
2024-08-12 11:22:53,669 [trainer.py] => CNN top1 curve: [91.07, 86.19, 81.34, 80.52, 77.87]
2024-08-12 11:22:53,669 [trainer.py] => CNN top1 with task curve: [91.07, 89.99, 89.36, 89.18, 88.92]
2024-08-12 11:22:53,669 [trainer.py] => CNN top1 task curve: [1.0, 0.9247397918334668, 0.8655692729766804, 0.8492818126643739, 0.8166666666666667]
Average Accuracy (CNN): 83.4
logs/imagenet_a/10_10_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 11:22:56,939 [trainer.py] => config: ./configs/ina_inflora.json
2024-08-12 11:22:56,939 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 11:22:56,939 [trainer.py] => prefix: reproduce
2024-08-12 11:22:56,939 [trainer.py] => dataset: imagenet_a
2024-08-12 11:22:56,939 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 11:22:56,939 [trainer.py] => memory_size: 0
2024-08-12 11:22:56,939 [trainer.py] => memory_per_class: 0
2024-08-12 11:22:56,939 [trainer.py] => fixed_memory: True
2024-08-12 11:22:56,939 [trainer.py] => shuffle: True
2024-08-12 11:22:56,939 [trainer.py] => init_cls: 10
2024-08-12 11:22:56,939 [trainer.py] => increment: 10
2024-08-12 11:22:56,939 [trainer.py] => model_name: InfLoRA
2024-08-12 11:22:56,939 [trainer.py] => net_type: sip
2024-08-12 11:22:56,939 [trainer.py] => embd_dim: 768
2024-08-12 11:22:56,939 [trainer.py] => num_heads: 12
2024-08-12 11:22:56,939 [trainer.py] => total_sessions: 20
2024-08-12 11:22:56,939 [trainer.py] => seed: 1993
2024-08-12 11:22:56,939 [trainer.py] => EPSILON: 1e-08
2024-08-12 11:22:56,939 [trainer.py] => init_epoch: 20
2024-08-12 11:22:56,939 [trainer.py] => optim: adam
2024-08-12 11:22:56,939 [trainer.py] => init_lr: 0.0005
2024-08-12 11:22:56,939 [trainer.py] => init_lr_decay: 0.1
2024-08-12 11:22:56,939 [trainer.py] => init_weight_decay: 0.0
2024-08-12 11:22:56,939 [trainer.py] => epochs: 20
2024-08-12 11:22:56,939 [trainer.py] => lrate: 0.0005
2024-08-12 11:22:56,939 [trainer.py] => lrate_decay: 0.1
2024-08-12 11:22:56,939 [trainer.py] => batch_size: 48
2024-08-12 11:22:56,940 [trainer.py] => weight_decay: 0.0
2024-08-12 11:22:56,940 [trainer.py] => rank: 4
2024-08-12 11:22:56,940 [trainer.py] => lamb: 0.95
2024-08-12 11:22:56,940 [trainer.py] => lame: 1.0
2024-08-12 11:22:56,940 [trainer.py] => num_workers: 16
2024-08-12 11:22:56,964 [data_manager.py] => [168, 136, 51, 9, 183, 101, 171, 99, 42, 159, 191, 70, 16, 188, 27, 10, 175, 26, 68, 187, 98, 6, 85, 35, 112, 43, 100, 0, 103, 181, 88, 59, 4, 2, 116, 174, 94, 80, 106, 1, 147, 17, 141, 131, 72, 23, 173, 54, 197, 118, 87, 32, 79, 104, 91, 19, 135, 107, 178, 36, 11, 199, 142, 8, 122, 3, 28, 57, 153, 172, 190, 56, 49, 44, 97, 62, 151, 169, 194, 55, 192, 12, 189, 78, 66, 180, 15, 137, 109, 134, 92, 119, 126, 52, 170, 40, 148, 65, 144, 64, 138, 45, 77, 89, 154, 90, 71, 193, 74, 30, 113, 143, 96, 84, 67, 50, 186, 156, 69, 21, 18, 111, 108, 58, 125, 157, 150, 110, 182, 129, 166, 83, 81, 60, 13, 165, 14, 176, 63, 117, 5, 22, 145, 121, 38, 41, 82, 127, 114, 20, 31, 53, 37, 163, 196, 130, 152, 162, 86, 76, 24, 34, 184, 149, 33, 128, 198, 155, 146, 167, 139, 120, 140, 102, 47, 25, 158, 123, 46, 164, 61, 7, 115, 75, 133, 160, 105, 132, 179, 124, 48, 73, 93, 39, 95, 195, 29, 177, 185, 161]
2024-08-12 11:22:59,229 [trainer.py] => All params: 110611171
2024-08-12 11:22:59,232 [trainer.py] => Trainable params: 110611171
2024-08-12 11:22:59,233 [inflora.py] => Learning on 0-10

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 2.024, Train_accy 29.90:   0%|          | 0/20 [00:01<?, ?it/s]
Task 0, Epoch 1/20 => Loss 2.024, Train_accy 29.90:   5%|▌         | 1/20 [00:01<00:32,  1.73s/it]
Task 0, Epoch 2/20 => Loss 1.449, Train_accy 55.81:   5%|▌         | 1/20 [00:03<00:32,  1.73s/it]
Task 0, Epoch 2/20 => Loss 1.449, Train_accy 55.81:  10%|█         | 2/20 [00:03<00:30,  1.68s/it]
Task 0, Epoch 3/20 => Loss 1.110, Train_accy 67.44:  10%|█         | 2/20 [00:05<00:30,  1.68s/it]
Task 0, Epoch 3/20 => Loss 1.110, Train_accy 67.44:  15%|█▌        | 3/20 [00:05<00:28,  1.66s/it]
Task 0, Epoch 4/20 => Loss 0.798, Train_accy 75.08:  15%|█▌        | 3/20 [00:06<00:28,  1.66s/it]
Task 0, Epoch 4/20 => Loss 0.798, Train_accy 75.08:  20%|██        | 4/20 [00:06<00:26,  1.67s/it]
Task 0, Epoch 5/20 => Loss 0.535, Train_accy 84.72:  20%|██        | 4/20 [00:08<00:26,  1.67s/it]
Task 0, Epoch 5/20 => Loss 0.535, Train_accy 84.72:  25%|██▌       | 5/20 [00:08<00:24,  1.65s/it]
Task 0, Epoch 6/20 => Loss 0.417, Train_accy 86.05:  25%|██▌       | 5/20 [00:09<00:24,  1.65s/it]
Task 0, Epoch 6/20 => Loss 0.417, Train_accy 86.05:  30%|███       | 6/20 [00:09<00:23,  1.66s/it]
Task 0, Epoch 7/20 => Loss 0.317, Train_accy 92.69:  30%|███       | 6/20 [00:11<00:23,  1.66s/it]
Task 0, Epoch 7/20 => Loss 0.317, Train_accy 92.69:  35%|███▌      | 7/20 [00:11<00:21,  1.67s/it]
Task 0, Epoch 8/20 => Loss 0.251, Train_accy 94.68:  35%|███▌      | 7/20 [00:13<00:21,  1.67s/it]
Task 0, Epoch 8/20 => Loss 0.251, Train_accy 94.68:  40%|████      | 8/20 [00:13<00:20,  1.67s/it]
Task 0, Epoch 9/20 => Loss 0.259, Train_accy 91.69:  40%|████      | 8/20 [00:15<00:20,  1.67s/it]
Task 0, Epoch 9/20 => Loss 0.259, Train_accy 91.69:  45%|████▌     | 9/20 [00:15<00:18,  1.68s/it]
Task 0, Epoch 10/20 => Loss 0.188, Train_accy 94.68:  45%|████▌     | 9/20 [00:16<00:18,  1.68s/it]
Task 0, Epoch 10/20 => Loss 0.188, Train_accy 94.68:  50%|█████     | 10/20 [00:16<00:16,  1.67s/it]
Task 0, Epoch 11/20 => Loss 0.188, Train_accy 94.68:  50%|█████     | 10/20 [00:18<00:16,  1.67s/it]
Task 0, Epoch 11/20 => Loss 0.188, Train_accy 94.68:  55%|█████▌    | 11/20 [00:18<00:14,  1.66s/it]
Task 0, Epoch 12/20 => Loss 0.147, Train_accy 95.35:  55%|█████▌    | 11/20 [00:20<00:14,  1.66s/it]
Task 0, Epoch 12/20 => Loss 0.147, Train_accy 95.35:  60%|██████    | 12/20 [00:20<00:13,  1.68s/it]
Task 0, Epoch 13/20 => Loss 0.147, Train_accy 94.35:  60%|██████    | 12/20 [00:21<00:13,  1.68s/it]
Task 0, Epoch 13/20 => Loss 0.147, Train_accy 94.35:  65%|██████▌   | 13/20 [00:21<00:11,  1.67s/it]
Task 0, Epoch 14/20 => Loss 0.123, Train_accy 96.68:  65%|██████▌   | 13/20 [00:23<00:11,  1.67s/it]
Task 0, Epoch 14/20 => Loss 0.123, Train_accy 96.68:  70%|███████   | 14/20 [00:23<00:09,  1.66s/it]
Task 0, Epoch 15/20 => Loss 0.092, Train_accy 97.67:  70%|███████   | 14/20 [00:24<00:09,  1.66s/it]
Task 0, Epoch 15/20 => Loss 0.092, Train_accy 97.67:  75%|███████▌  | 15/20 [00:24<00:08,  1.65s/it]
Task 0, Epoch 16/20 => Loss 0.110, Train_accy 97.34:  75%|███████▌  | 15/20 [00:26<00:08,  1.65s/it]
Task 0, Epoch 16/20 => Loss 0.110, Train_accy 97.34:  80%|████████  | 16/20 [00:26<00:06,  1.65s/it]
Task 0, Epoch 17/20 => Loss 0.124, Train_accy 96.68:  80%|████████  | 16/20 [00:28<00:06,  1.65s/it]
Task 0, Epoch 17/20 => Loss 0.124, Train_accy 96.68:  85%|████████▌ | 17/20 [00:28<00:04,  1.65s/it]
Task 0, Epoch 18/20 => Loss 0.077, Train_accy 98.67:  85%|████████▌ | 17/20 [00:29<00:04,  1.65s/it]
Task 0, Epoch 18/20 => Loss 0.077, Train_accy 98.67:  90%|█████████ | 18/20 [00:29<00:03,  1.66s/it]
Task 0, Epoch 19/20 => Loss 0.106, Train_accy 97.34:  90%|█████████ | 18/20 [00:31<00:03,  1.66s/it]
Task 0, Epoch 19/20 => Loss 0.106, Train_accy 97.34:  95%|█████████▌| 19/20 [00:31<00:01,  1.64s/it]
Task 0, Epoch 20/20 => Loss 0.103, Train_accy 97.01:  95%|█████████▌| 19/20 [00:33<00:01,  1.64s/it]
Task 0, Epoch 20/20 => Loss 0.103, Train_accy 97.01: 100%|██████████| 20/20 [00:33<00:00,  1.64s/it]
Task 0, Epoch 20/20 => Loss 0.103, Train_accy 97.01: 100%|██████████| 20/20 [00:33<00:00,  1.66s/it]
2024-08-12 11:23:36,281 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.103, Train_accy 97.01
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 11/768 type remove
Layer 4 : 12/768 type remove
Layer 5 : 19/768 type remove
Layer 6 : 17/768 type remove
Layer 7 : 15/768 type remove
Layer 8 : 19/768 type remove
Layer 9 : 35/768 type remove
Layer 10 : 47/768 type remove
Layer 11 : 10/768 type remove
Layer 12 : 23/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:23:42,202 [trainer.py] => Time:42.96918487548828
77 77
77 77
2024-08-12 11:23:43,402 [trainer.py] => Time:1.1999645233154297
2024-08-12 11:23:43,402 [inflora.py] => Exemplar size: 0
2024-08-12 11:23:43,402 [trainer.py] => CNN: {'total': 75.32, '00-09': 75.32, 'old': 0, 'new': 75.32}
2024-08-12 11:23:43,402 [trainer.py] => CNN top1 curve: [75.32]
2024-08-12 11:23:43,403 [trainer.py] => CNN top1 with task curve: [75.32]
2024-08-12 11:23:43,403 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 75.32
2024-08-12 11:23:43,407 [trainer.py] => All params: 110611171
2024-08-12 11:23:43,411 [trainer.py] => Trainable params: 81418
2024-08-12 11:23:43,411 [inflora.py] => Learning on 10-20

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 2.589, Train_accy 20.05:   0%|          | 0/20 [00:02<?, ?it/s]
Task 1, Epoch 1/20 => Loss 2.589, Train_accy 20.05:   5%|▌         | 1/20 [00:02<00:41,  2.16s/it]
Task 1, Epoch 2/20 => Loss 1.236, Train_accy 57.92:   5%|▌         | 1/20 [00:04<00:41,  2.16s/it]
Task 1, Epoch 2/20 => Loss 1.236, Train_accy 57.92:  10%|█         | 2/20 [00:04<00:38,  2.15s/it]
Task 1, Epoch 3/20 => Loss 0.822, Train_accy 74.50:  10%|█         | 2/20 [00:06<00:38,  2.15s/it]
Task 1, Epoch 3/20 => Loss 0.822, Train_accy 74.50:  15%|█▌        | 3/20 [00:06<00:36,  2.17s/it]
Task 1, Epoch 4/20 => Loss 0.565, Train_accy 80.69:  15%|█▌        | 3/20 [00:08<00:36,  2.17s/it]
Task 1, Epoch 4/20 => Loss 0.565, Train_accy 80.69:  20%|██        | 4/20 [00:08<00:34,  2.17s/it]
Task 1, Epoch 5/20 => Loss 0.436, Train_accy 84.41:  20%|██        | 4/20 [00:10<00:34,  2.17s/it]
Task 1, Epoch 5/20 => Loss 0.436, Train_accy 84.41:  25%|██▌       | 5/20 [00:10<00:32,  2.16s/it]
Task 1, Epoch 6/20 => Loss 0.322, Train_accy 91.83:  25%|██▌       | 5/20 [00:12<00:32,  2.16s/it]
Task 1, Epoch 6/20 => Loss 0.322, Train_accy 91.83:  30%|███       | 6/20 [00:12<00:30,  2.16s/it]
Task 1, Epoch 7/20 => Loss 0.296, Train_accy 90.35:  30%|███       | 6/20 [00:15<00:30,  2.16s/it]
Task 1, Epoch 7/20 => Loss 0.296, Train_accy 90.35:  35%|███▌      | 7/20 [00:15<00:28,  2.16s/it]
Task 1, Epoch 8/20 => Loss 0.261, Train_accy 93.07:  35%|███▌      | 7/20 [00:17<00:28,  2.16s/it]
Task 1, Epoch 8/20 => Loss 0.261, Train_accy 93.07:  40%|████      | 8/20 [00:17<00:25,  2.16s/it]
Task 1, Epoch 9/20 => Loss 0.239, Train_accy 94.06:  40%|████      | 8/20 [00:19<00:25,  2.16s/it]
Task 1, Epoch 9/20 => Loss 0.239, Train_accy 94.06:  45%|████▌     | 9/20 [00:19<00:23,  2.17s/it]
Task 1, Epoch 10/20 => Loss 0.210, Train_accy 94.80:  45%|████▌     | 9/20 [00:21<00:23,  2.17s/it]
Task 1, Epoch 10/20 => Loss 0.210, Train_accy 94.80:  50%|█████     | 10/20 [00:21<00:21,  2.17s/it]
Task 1, Epoch 11/20 => Loss 0.223, Train_accy 93.07:  50%|█████     | 10/20 [00:23<00:21,  2.17s/it]
Task 1, Epoch 11/20 => Loss 0.223, Train_accy 93.07:  55%|█████▌    | 11/20 [00:23<00:19,  2.17s/it]
Task 1, Epoch 12/20 => Loss 0.260, Train_accy 92.82:  55%|█████▌    | 11/20 [00:25<00:19,  2.17s/it]
Task 1, Epoch 12/20 => Loss 0.260, Train_accy 92.82:  60%|██████    | 12/20 [00:25<00:17,  2.17s/it]
Task 1, Epoch 13/20 => Loss 0.152, Train_accy 95.30:  60%|██████    | 12/20 [00:28<00:17,  2.17s/it]
Task 1, Epoch 13/20 => Loss 0.152, Train_accy 95.30:  65%|██████▌   | 13/20 [00:28<00:15,  2.16s/it]
Task 1, Epoch 14/20 => Loss 0.170, Train_accy 94.55:  65%|██████▌   | 13/20 [00:30<00:15,  2.16s/it]
Task 1, Epoch 14/20 => Loss 0.170, Train_accy 94.55:  70%|███████   | 14/20 [00:30<00:13,  2.18s/it]
Task 1, Epoch 15/20 => Loss 0.153, Train_accy 95.54:  70%|███████   | 14/20 [00:32<00:13,  2.18s/it]
Task 1, Epoch 15/20 => Loss 0.153, Train_accy 95.54:  75%|███████▌  | 15/20 [00:32<00:10,  2.18s/it]
Task 1, Epoch 16/20 => Loss 0.164, Train_accy 94.55:  75%|███████▌  | 15/20 [00:34<00:10,  2.18s/it]
Task 1, Epoch 16/20 => Loss 0.164, Train_accy 94.55:  80%|████████  | 16/20 [00:34<00:08,  2.18s/it]
Task 1, Epoch 17/20 => Loss 0.155, Train_accy 94.80:  80%|████████  | 16/20 [00:36<00:08,  2.18s/it]
Task 1, Epoch 17/20 => Loss 0.155, Train_accy 94.80:  85%|████████▌ | 17/20 [00:36<00:06,  2.18s/it]
Task 1, Epoch 18/20 => Loss 0.120, Train_accy 96.78:  85%|████████▌ | 17/20 [00:39<00:06,  2.18s/it]
Task 1, Epoch 18/20 => Loss 0.120, Train_accy 96.78:  90%|█████████ | 18/20 [00:39<00:04,  2.17s/it]
Task 1, Epoch 19/20 => Loss 0.173, Train_accy 95.79:  90%|█████████ | 18/20 [00:41<00:04,  2.17s/it]
Task 1, Epoch 19/20 => Loss 0.173, Train_accy 95.79:  95%|█████████▌| 19/20 [00:41<00:02,  2.16s/it]
Task 1, Epoch 20/20 => Loss 0.137, Train_accy 96.29:  95%|█████████▌| 19/20 [00:43<00:02,  2.16s/it]
Task 1, Epoch 20/20 => Loss 0.137, Train_accy 96.29: 100%|██████████| 20/20 [00:43<00:00,  2.17s/it]
Task 1, Epoch 20/20 => Loss 0.137, Train_accy 96.29: 100%|██████████| 20/20 [00:43<00:00,  2.17s/it]
2024-08-12 11:24:30,747 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.137, Train_accy 96.29
Threshold:  0.9524999999999999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 22/768 type remove
Layer 6 : 20/768 type remove
Layer 7 : 18/768 type remove
Layer 8 : 26/768 type remove
Layer 9 : 49/768 type remove
Layer 10 : 62/768 type remove
Layer 11 : 15/768 type remove
Layer 12 : 30/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:24:39,046 [trainer.py] => Time:55.63483476638794
175 175
175 175
2024-08-12 11:24:40,383 [trainer.py] => Time:1.3369522094726562
2024-08-12 11:24:40,383 [inflora.py] => Exemplar size: 0
2024-08-12 11:24:40,384 [trainer.py] => CNN: {'total': 64.57, '00-09': 66.23, '10-19': 63.27, 'old': 66.23, 'new': 63.27}
2024-08-12 11:24:40,384 [trainer.py] => CNN top1 curve: [75.32, 64.57]
2024-08-12 11:24:40,384 [trainer.py] => CNN top1 with task curve: [75.32, 82.29]
2024-08-12 11:24:40,384 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571]
Average Accuracy (CNN): 69.94
2024-08-12 11:24:40,389 [trainer.py] => All params: 110611171
2024-08-12 11:24:40,392 [trainer.py] => Trainable params: 895598
2024-08-12 11:24:40,392 [inflora.py] => Learning on 20-30

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 2.887, Train_accy 16.53:   0%|          | 0/20 [00:02<?, ?it/s]
Task 2, Epoch 1/20 => Loss 2.887, Train_accy 16.53:   5%|▌         | 1/20 [00:02<00:39,  2.06s/it]
Task 2, Epoch 2/20 => Loss 1.761, Train_accy 45.18:   5%|▌         | 1/20 [00:04<00:39,  2.06s/it]
Task 2, Epoch 2/20 => Loss 1.761, Train_accy 45.18:  10%|█         | 2/20 [00:04<00:36,  2.05s/it]
Task 2, Epoch 3/20 => Loss 1.165, Train_accy 63.09:  10%|█         | 2/20 [00:06<00:36,  2.05s/it]
Task 2, Epoch 3/20 => Loss 1.165, Train_accy 63.09:  15%|█▌        | 3/20 [00:06<00:35,  2.07s/it]
Task 2, Epoch 4/20 => Loss 0.845, Train_accy 73.00:  15%|█▌        | 3/20 [00:08<00:35,  2.07s/it]
Task 2, Epoch 4/20 => Loss 0.845, Train_accy 73.00:  20%|██        | 4/20 [00:08<00:33,  2.08s/it]
Task 2, Epoch 5/20 => Loss 0.739, Train_accy 77.96:  20%|██        | 4/20 [00:10<00:33,  2.08s/it]
Task 2, Epoch 5/20 => Loss 0.739, Train_accy 77.96:  25%|██▌       | 5/20 [00:10<00:31,  2.09s/it]
Task 2, Epoch 6/20 => Loss 0.624, Train_accy 79.89:  25%|██▌       | 5/20 [00:12<00:31,  2.09s/it]
Task 2, Epoch 6/20 => Loss 0.624, Train_accy 79.89:  30%|███       | 6/20 [00:12<00:29,  2.10s/it]
Task 2, Epoch 7/20 => Loss 0.512, Train_accy 84.85:  30%|███       | 6/20 [00:14<00:29,  2.10s/it]
Task 2, Epoch 7/20 => Loss 0.512, Train_accy 84.85:  35%|███▌      | 7/20 [00:14<00:27,  2.09s/it]
Task 2, Epoch 8/20 => Loss 0.475, Train_accy 85.40:  35%|███▌      | 7/20 [00:16<00:27,  2.09s/it]
Task 2, Epoch 8/20 => Loss 0.475, Train_accy 85.40:  40%|████      | 8/20 [00:16<00:24,  2.08s/it]
Task 2, Epoch 9/20 => Loss 0.368, Train_accy 90.63:  40%|████      | 8/20 [00:18<00:24,  2.08s/it]
Task 2, Epoch 9/20 => Loss 0.368, Train_accy 90.63:  45%|████▌     | 9/20 [00:18<00:22,  2.08s/it]
Task 2, Epoch 10/20 => Loss 0.338, Train_accy 90.36:  45%|████▌     | 9/20 [00:20<00:22,  2.08s/it]
Task 2, Epoch 10/20 => Loss 0.338, Train_accy 90.36:  50%|█████     | 10/20 [00:20<00:20,  2.08s/it]
Task 2, Epoch 11/20 => Loss 0.305, Train_accy 93.11:  50%|█████     | 10/20 [00:22<00:20,  2.08s/it]
Task 2, Epoch 11/20 => Loss 0.305, Train_accy 93.11:  55%|█████▌    | 11/20 [00:22<00:18,  2.08s/it]
Task 2, Epoch 12/20 => Loss 0.256, Train_accy 92.01:  55%|█████▌    | 11/20 [00:24<00:18,  2.08s/it]
Task 2, Epoch 12/20 => Loss 0.256, Train_accy 92.01:  60%|██████    | 12/20 [00:24<00:16,  2.08s/it]
Task 2, Epoch 13/20 => Loss 0.241, Train_accy 95.04:  60%|██████    | 12/20 [00:27<00:16,  2.08s/it]
Task 2, Epoch 13/20 => Loss 0.241, Train_accy 95.04:  65%|██████▌   | 13/20 [00:27<00:14,  2.10s/it]
Task 2, Epoch 14/20 => Loss 0.276, Train_accy 92.01:  65%|██████▌   | 13/20 [00:29<00:14,  2.10s/it]
Task 2, Epoch 14/20 => Loss 0.276, Train_accy 92.01:  70%|███████   | 14/20 [00:29<00:12,  2.12s/it]
Task 2, Epoch 15/20 => Loss 0.274, Train_accy 91.74:  70%|███████   | 14/20 [00:31<00:12,  2.12s/it]
Task 2, Epoch 15/20 => Loss 0.274, Train_accy 91.74:  75%|███████▌  | 15/20 [00:31<00:10,  2.11s/it]
Task 2, Epoch 16/20 => Loss 0.248, Train_accy 94.49:  75%|███████▌  | 15/20 [00:33<00:10,  2.11s/it]
Task 2, Epoch 16/20 => Loss 0.248, Train_accy 94.49:  80%|████████  | 16/20 [00:33<00:08,  2.10s/it]
Task 2, Epoch 17/20 => Loss 0.269, Train_accy 90.91:  80%|████████  | 16/20 [00:35<00:08,  2.10s/it]
Task 2, Epoch 17/20 => Loss 0.269, Train_accy 90.91:  85%|████████▌ | 17/20 [00:35<00:06,  2.10s/it]
Task 2, Epoch 18/20 => Loss 0.191, Train_accy 94.77:  85%|████████▌ | 17/20 [00:37<00:06,  2.10s/it]
Task 2, Epoch 18/20 => Loss 0.191, Train_accy 94.77:  90%|█████████ | 18/20 [00:37<00:04,  2.11s/it]
Task 2, Epoch 19/20 => Loss 0.229, Train_accy 93.39:  90%|█████████ | 18/20 [00:39<00:04,  2.11s/it]
Task 2, Epoch 19/20 => Loss 0.229, Train_accy 93.39:  95%|█████████▌| 19/20 [00:39<00:02,  2.09s/it]
Task 2, Epoch 20/20 => Loss 0.246, Train_accy 92.84:  95%|█████████▌| 19/20 [00:41<00:02,  2.09s/it]
Task 2, Epoch 20/20 => Loss 0.246, Train_accy 92.84: 100%|██████████| 20/20 [00:41<00:00,  2.09s/it]
Task 2, Epoch 20/20 => Loss 0.246, Train_accy 92.84: 100%|██████████| 20/20 [00:41<00:00,  2.09s/it]
2024-08-12 11:25:26,471 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.246, Train_accy 92.84
Threshold:  0.955
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 14/768 type remove
Layer 4 : 15/768 type remove
Layer 5 : 24/768 type remove
Layer 6 : 21/768 type remove
Layer 7 : 19/768 type remove
Layer 8 : 27/768 type remove
Layer 9 : 53/768 type remove
Layer 10 : 74/768 type remove
Layer 11 : 18/768 type remove
Layer 12 : 44/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:25:35,285 [trainer.py] => Time:54.89315724372864
274 274
274 274
2024-08-12 11:25:36,628 [trainer.py] => Time:1.3424320220947266
2024-08-12 11:25:36,628 [inflora.py] => Exemplar size: 0
2024-08-12 11:25:36,628 [trainer.py] => CNN: {'total': 64.23, '00-09': 62.34, '10-19': 58.16, '20-29': 71.72, 'old': 60.0, 'new': 71.72}
2024-08-12 11:25:36,628 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23]
2024-08-12 11:25:36,628 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67]
2024-08-12 11:25:36,628 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029]
Average Accuracy (CNN): 68.04
2024-08-12 11:25:36,632 [trainer.py] => All params: 110611171
2024-08-12 11:25:36,636 [trainer.py] => Trainable params: 81418
2024-08-12 11:25:36,636 [inflora.py] => Learning on 30-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 2.459, Train_accy 22.33:   0%|          | 0/20 [00:02<?, ?it/s]
Task 3, Epoch 1/20 => Loss 2.459, Train_accy 22.33:   5%|▌         | 1/20 [00:02<00:42,  2.22s/it]
Task 3, Epoch 2/20 => Loss 1.253, Train_accy 58.06:   5%|▌         | 1/20 [00:04<00:42,  2.22s/it]
Task 3, Epoch 2/20 => Loss 1.253, Train_accy 58.06:  10%|█         | 2/20 [00:04<00:39,  2.21s/it]
Task 3, Epoch 3/20 => Loss 0.791, Train_accy 72.21:  10%|█         | 2/20 [00:06<00:39,  2.21s/it]
Task 3, Epoch 3/20 => Loss 0.791, Train_accy 72.21:  15%|█▌        | 3/20 [00:06<00:37,  2.22s/it]
Task 3, Epoch 4/20 => Loss 0.633, Train_accy 78.41:  15%|█▌        | 3/20 [00:08<00:37,  2.22s/it]
Task 3, Epoch 4/20 => Loss 0.633, Train_accy 78.41:  20%|██        | 4/20 [00:08<00:35,  2.22s/it]
Task 3, Epoch 5/20 => Loss 0.537, Train_accy 83.37:  20%|██        | 4/20 [00:11<00:35,  2.22s/it]
Task 3, Epoch 5/20 => Loss 0.537, Train_accy 83.37:  25%|██▌       | 5/20 [00:11<00:33,  2.23s/it]
Task 3, Epoch 6/20 => Loss 0.441, Train_accy 87.10:  25%|██▌       | 5/20 [00:13<00:33,  2.23s/it]
Task 3, Epoch 6/20 => Loss 0.441, Train_accy 87.10:  30%|███       | 6/20 [00:13<00:31,  2.22s/it]
Task 3, Epoch 7/20 => Loss 0.417, Train_accy 86.85:  30%|███       | 6/20 [00:15<00:31,  2.22s/it]
Task 3, Epoch 7/20 => Loss 0.417, Train_accy 86.85:  35%|███▌      | 7/20 [00:15<00:29,  2.24s/it]
Task 3, Epoch 8/20 => Loss 0.340, Train_accy 89.58:  35%|███▌      | 7/20 [00:17<00:29,  2.24s/it]
Task 3, Epoch 8/20 => Loss 0.340, Train_accy 89.58:  40%|████      | 8/20 [00:17<00:26,  2.25s/it]
Task 3, Epoch 9/20 => Loss 0.274, Train_accy 93.30:  40%|████      | 8/20 [00:20<00:26,  2.25s/it]
Task 3, Epoch 9/20 => Loss 0.274, Train_accy 93.30:  45%|████▌     | 9/20 [00:20<00:24,  2.25s/it]
Task 3, Epoch 10/20 => Loss 0.304, Train_accy 92.06:  45%|████▌     | 9/20 [00:22<00:24,  2.25s/it]
Task 3, Epoch 10/20 => Loss 0.304, Train_accy 92.06:  50%|█████     | 10/20 [00:22<00:22,  2.26s/it]
Task 3, Epoch 11/20 => Loss 0.241, Train_accy 92.56:  50%|█████     | 10/20 [00:24<00:22,  2.26s/it]
Task 3, Epoch 11/20 => Loss 0.241, Train_accy 92.56:  55%|█████▌    | 11/20 [00:24<00:20,  2.24s/it]
Task 3, Epoch 12/20 => Loss 0.239, Train_accy 93.55:  55%|█████▌    | 11/20 [00:26<00:20,  2.24s/it]
Task 3, Epoch 12/20 => Loss 0.239, Train_accy 93.55:  60%|██████    | 12/20 [00:26<00:17,  2.24s/it]
Task 3, Epoch 13/20 => Loss 0.288, Train_accy 90.57:  60%|██████    | 12/20 [00:29<00:17,  2.24s/it]
Task 3, Epoch 13/20 => Loss 0.288, Train_accy 90.57:  65%|██████▌   | 13/20 [00:29<00:15,  2.23s/it]
Task 3, Epoch 14/20 => Loss 0.217, Train_accy 93.30:  65%|██████▌   | 13/20 [00:31<00:15,  2.23s/it]
Task 3, Epoch 14/20 => Loss 0.217, Train_accy 93.30:  70%|███████   | 14/20 [00:31<00:13,  2.24s/it]
Task 3, Epoch 15/20 => Loss 0.240, Train_accy 91.81:  70%|███████   | 14/20 [00:33<00:13,  2.24s/it]
Task 3, Epoch 15/20 => Loss 0.240, Train_accy 91.81:  75%|███████▌  | 15/20 [00:33<00:11,  2.24s/it]
Task 3, Epoch 16/20 => Loss 0.174, Train_accy 94.04:  75%|███████▌  | 15/20 [00:35<00:11,  2.24s/it]
Task 3, Epoch 16/20 => Loss 0.174, Train_accy 94.04:  80%|████████  | 16/20 [00:35<00:09,  2.25s/it]
Task 3, Epoch 17/20 => Loss 0.169, Train_accy 94.54:  80%|████████  | 16/20 [00:38<00:09,  2.25s/it]
Task 3, Epoch 17/20 => Loss 0.169, Train_accy 94.54:  85%|████████▌ | 17/20 [00:38<00:06,  2.25s/it]
Task 3, Epoch 18/20 => Loss 0.192, Train_accy 93.80:  85%|████████▌ | 17/20 [00:40<00:06,  2.25s/it]
Task 3, Epoch 18/20 => Loss 0.192, Train_accy 93.80:  90%|█████████ | 18/20 [00:40<00:04,  2.25s/it]
Task 3, Epoch 19/20 => Loss 0.229, Train_accy 92.56:  90%|█████████ | 18/20 [00:42<00:04,  2.25s/it]
Task 3, Epoch 19/20 => Loss 0.229, Train_accy 92.56:  95%|█████████▌| 19/20 [00:42<00:02,  2.24s/it]
Task 3, Epoch 20/20 => Loss 0.173, Train_accy 94.79:  95%|█████████▌| 19/20 [00:44<00:02,  2.24s/it]
Task 3, Epoch 20/20 => Loss 0.173, Train_accy 94.79: 100%|██████████| 20/20 [00:44<00:00,  2.24s/it]
Task 3, Epoch 20/20 => Loss 0.173, Train_accy 94.79: 100%|██████████| 20/20 [00:44<00:00,  2.24s/it]
2024-08-12 11:26:25,718 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.173, Train_accy 94.79
Threshold:  0.9575
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 15/768 type remove
Layer 4 : 17/768 type remove
Layer 5 : 26/768 type remove
Layer 6 : 24/768 type remove
Layer 7 : 22/768 type remove
Layer 8 : 31/768 type remove
Layer 9 : 60/768 type remove
Layer 10 : 81/768 type remove
Layer 11 : 20/768 type remove
Layer 12 : 45/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:26:34,471 [trainer.py] => Time:57.83480262756348
360 360
360 360
2024-08-12 11:26:36,050 [trainer.py] => Time:1.5794901847839355
2024-08-12 11:26:36,051 [inflora.py] => Exemplar size: 0
2024-08-12 11:26:36,051 [trainer.py] => CNN: {'total': 58.89, '00-09': 57.14, '10-19': 53.06, '20-29': 65.66, '30-39': 59.3, 'old': 58.76, 'new': 59.3}
2024-08-12 11:26:36,051 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89]
2024-08-12 11:26:36,051 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89]
2024-08-12 11:26:36,051 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445]
Average Accuracy (CNN): 65.75
2024-08-12 11:26:36,055 [trainer.py] => All params: 110611171
2024-08-12 11:26:36,059 [trainer.py] => Trainable params: 81418
2024-08-12 11:26:36,059 [inflora.py] => Learning on 40-50

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 2.713, Train_accy 20.30:   0%|          | 0/20 [00:01<?, ?it/s]
Task 4, Epoch 1/20 => Loss 2.713, Train_accy 20.30:   5%|▌         | 1/20 [00:01<00:34,  1.83s/it]
Task 4, Epoch 2/20 => Loss 1.473, Train_accy 53.51:   5%|▌         | 1/20 [00:03<00:34,  1.83s/it]
Task 4, Epoch 2/20 => Loss 1.473, Train_accy 53.51:  10%|█         | 2/20 [00:03<00:33,  1.85s/it]
Task 4, Epoch 3/20 => Loss 1.013, Train_accy 67.53:  10%|█         | 2/20 [00:05<00:33,  1.85s/it]
Task 4, Epoch 3/20 => Loss 1.013, Train_accy 67.53:  15%|█▌        | 3/20 [00:05<00:31,  1.86s/it]
Task 4, Epoch 4/20 => Loss 0.766, Train_accy 76.01:  15%|█▌        | 3/20 [00:07<00:31,  1.86s/it]
Task 4, Epoch 4/20 => Loss 0.766, Train_accy 76.01:  20%|██        | 4/20 [00:07<00:29,  1.87s/it]
Task 4, Epoch 5/20 => Loss 0.609, Train_accy 79.34:  20%|██        | 4/20 [00:09<00:29,  1.87s/it]
Task 4, Epoch 5/20 => Loss 0.609, Train_accy 79.34:  25%|██▌       | 5/20 [00:09<00:28,  1.89s/it]
Task 4, Epoch 6/20 => Loss 0.456, Train_accy 83.76:  25%|██▌       | 5/20 [00:11<00:28,  1.89s/it]
Task 4, Epoch 6/20 => Loss 0.456, Train_accy 83.76:  30%|███       | 6/20 [00:11<00:26,  1.88s/it]
Task 4, Epoch 7/20 => Loss 0.411, Train_accy 88.56:  30%|███       | 6/20 [00:13<00:26,  1.88s/it]
Task 4, Epoch 7/20 => Loss 0.411, Train_accy 88.56:  35%|███▌      | 7/20 [00:13<00:24,  1.88s/it]
Task 4, Epoch 8/20 => Loss 0.298, Train_accy 91.14:  35%|███▌      | 7/20 [00:14<00:24,  1.88s/it]
Task 4, Epoch 8/20 => Loss 0.298, Train_accy 91.14:  40%|████      | 8/20 [00:14<00:22,  1.87s/it]
Task 4, Epoch 9/20 => Loss 0.290, Train_accy 92.62:  40%|████      | 8/20 [00:16<00:22,  1.87s/it]
Task 4, Epoch 9/20 => Loss 0.290, Train_accy 92.62:  45%|████▌     | 9/20 [00:16<00:20,  1.87s/it]
Task 4, Epoch 10/20 => Loss 0.224, Train_accy 94.10:  45%|████▌     | 9/20 [00:18<00:20,  1.87s/it]
Task 4, Epoch 10/20 => Loss 0.224, Train_accy 94.10:  50%|█████     | 10/20 [00:18<00:18,  1.87s/it]
Task 4, Epoch 11/20 => Loss 0.206, Train_accy 94.46:  50%|█████     | 10/20 [00:20<00:18,  1.87s/it]
Task 4, Epoch 11/20 => Loss 0.206, Train_accy 94.46:  55%|█████▌    | 11/20 [00:20<00:16,  1.87s/it]
Task 4, Epoch 12/20 => Loss 0.172, Train_accy 96.31:  55%|█████▌    | 11/20 [00:22<00:16,  1.87s/it]
Task 4, Epoch 12/20 => Loss 0.172, Train_accy 96.31:  60%|██████    | 12/20 [00:22<00:15,  1.88s/it]
Task 4, Epoch 13/20 => Loss 0.205, Train_accy 93.73:  60%|██████    | 12/20 [00:24<00:15,  1.88s/it]
Task 4, Epoch 13/20 => Loss 0.205, Train_accy 93.73:  65%|██████▌   | 13/20 [00:24<00:13,  1.87s/it]
Task 4, Epoch 14/20 => Loss 0.265, Train_accy 91.14:  65%|██████▌   | 13/20 [00:26<00:13,  1.87s/it]
Task 4, Epoch 14/20 => Loss 0.265, Train_accy 91.14:  70%|███████   | 14/20 [00:26<00:11,  1.87s/it]
Task 4, Epoch 15/20 => Loss 0.233, Train_accy 94.46:  70%|███████   | 14/20 [00:28<00:11,  1.87s/it]
Task 4, Epoch 15/20 => Loss 0.233, Train_accy 94.46:  75%|███████▌  | 15/20 [00:28<00:09,  1.86s/it]
Task 4, Epoch 16/20 => Loss 0.171, Train_accy 95.57:  75%|███████▌  | 15/20 [00:29<00:09,  1.86s/it]
Task 4, Epoch 16/20 => Loss 0.171, Train_accy 95.57:  80%|████████  | 16/20 [00:29<00:07,  1.86s/it]
Task 4, Epoch 17/20 => Loss 0.200, Train_accy 95.94:  80%|████████  | 16/20 [00:31<00:07,  1.86s/it]
Task 4, Epoch 17/20 => Loss 0.200, Train_accy 95.94:  85%|████████▌ | 17/20 [00:31<00:05,  1.86s/it]
Task 4, Epoch 18/20 => Loss 0.243, Train_accy 92.62:  85%|████████▌ | 17/20 [00:33<00:05,  1.86s/it]
Task 4, Epoch 18/20 => Loss 0.243, Train_accy 92.62:  90%|█████████ | 18/20 [00:33<00:03,  1.86s/it]
Task 4, Epoch 19/20 => Loss 0.175, Train_accy 95.20:  90%|█████████ | 18/20 [00:35<00:03,  1.86s/it]
Task 4, Epoch 19/20 => Loss 0.175, Train_accy 95.20:  95%|█████████▌| 19/20 [00:35<00:01,  1.86s/it]
Task 4, Epoch 20/20 => Loss 0.163, Train_accy 94.83:  95%|█████████▌| 19/20 [00:37<00:01,  1.86s/it]
Task 4, Epoch 20/20 => Loss 0.163, Train_accy 94.83: 100%|██████████| 20/20 [00:37<00:00,  1.85s/it]
Task 4, Epoch 20/20 => Loss 0.163, Train_accy 94.83: 100%|██████████| 20/20 [00:37<00:00,  1.87s/it]
2024-08-12 11:27:17,308 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.163, Train_accy 94.83
Threshold:  0.96
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 16/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 29/768 type remove
Layer 6 : 26/768 type remove
Layer 7 : 25/768 type remove
Layer 8 : 36/768 type remove
Layer 9 : 68/768 type remove
Layer 10 : 92/768 type remove
Layer 11 : 23/768 type remove
Layer 12 : 47/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:27:25,873 [trainer.py] => Time:49.813772201538086
424 424
424 424
2024-08-12 11:27:27,556 [trainer.py] => Time:1.6829071044921875
2024-08-12 11:27:27,556 [inflora.py] => Exemplar size: 0
2024-08-12 11:27:27,556 [trainer.py] => CNN: {'total': 58.25, '00-09': 57.14, '10-19': 51.02, '20-29': 64.65, '30-39': 58.14, '40-49': 60.94, 'old': 57.78, 'new': 60.94}
2024-08-12 11:27:27,556 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25]
2024-08-12 11:27:27,556 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49]
2024-08-12 11:27:27,556 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132]
Average Accuracy (CNN): 64.25
2024-08-12 11:27:27,560 [trainer.py] => All params: 110611171
2024-08-12 11:27:27,564 [trainer.py] => Trainable params: 81418
2024-08-12 11:27:27,564 [inflora.py] => Learning on 50-60

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 2.569, Train_accy 22.50:   0%|          | 0/20 [00:01<?, ?it/s]
Task 5, Epoch 1/20 => Loss 2.569, Train_accy 22.50:   5%|▌         | 1/20 [00:01<00:32,  1.70s/it]
Task 5, Epoch 2/20 => Loss 1.618, Train_accy 50.83:   5%|▌         | 1/20 [00:03<00:32,  1.70s/it]
Task 5, Epoch 2/20 => Loss 1.618, Train_accy 50.83:  10%|█         | 2/20 [00:03<00:30,  1.71s/it]
Task 5, Epoch 3/20 => Loss 1.077, Train_accy 68.75:  10%|█         | 2/20 [00:05<00:30,  1.71s/it]
Task 5, Epoch 3/20 => Loss 1.077, Train_accy 68.75:  15%|█▌        | 3/20 [00:05<00:29,  1.72s/it]
Task 5, Epoch 4/20 => Loss 0.830, Train_accy 74.58:  15%|█▌        | 3/20 [00:06<00:29,  1.72s/it]
Task 5, Epoch 4/20 => Loss 0.830, Train_accy 74.58:  20%|██        | 4/20 [00:06<00:27,  1.75s/it]
Task 5, Epoch 5/20 => Loss 0.581, Train_accy 81.67:  20%|██        | 4/20 [00:08<00:27,  1.75s/it]
Task 5, Epoch 5/20 => Loss 0.581, Train_accy 81.67:  25%|██▌       | 5/20 [00:08<00:26,  1.75s/it]
Task 5, Epoch 6/20 => Loss 0.471, Train_accy 86.67:  25%|██▌       | 5/20 [00:10<00:26,  1.75s/it]
Task 5, Epoch 6/20 => Loss 0.471, Train_accy 86.67:  30%|███       | 6/20 [00:10<00:24,  1.73s/it]
Task 5, Epoch 7/20 => Loss 0.413, Train_accy 90.00:  30%|███       | 6/20 [00:12<00:24,  1.73s/it]
Task 5, Epoch 7/20 => Loss 0.413, Train_accy 90.00:  35%|███▌      | 7/20 [00:12<00:22,  1.74s/it]
Task 5, Epoch 8/20 => Loss 0.328, Train_accy 91.67:  35%|███▌      | 7/20 [00:13<00:22,  1.74s/it]
Task 5, Epoch 8/20 => Loss 0.328, Train_accy 91.67:  40%|████      | 8/20 [00:13<00:20,  1.75s/it]
Task 5, Epoch 9/20 => Loss 0.255, Train_accy 95.00:  40%|████      | 8/20 [00:15<00:20,  1.75s/it]
Task 5, Epoch 9/20 => Loss 0.255, Train_accy 95.00:  45%|████▌     | 9/20 [00:15<00:19,  1.74s/it]
Task 5, Epoch 10/20 => Loss 0.253, Train_accy 93.33:  45%|████▌     | 9/20 [00:17<00:19,  1.74s/it]
Task 5, Epoch 10/20 => Loss 0.253, Train_accy 93.33:  50%|█████     | 10/20 [00:17<00:17,  1.75s/it]
Task 5, Epoch 11/20 => Loss 0.263, Train_accy 91.67:  50%|█████     | 10/20 [00:19<00:17,  1.75s/it]
Task 5, Epoch 11/20 => Loss 0.263, Train_accy 91.67:  55%|█████▌    | 11/20 [00:19<00:15,  1.75s/it]
Task 5, Epoch 12/20 => Loss 0.170, Train_accy 96.25:  55%|█████▌    | 11/20 [00:20<00:15,  1.75s/it]
Task 5, Epoch 12/20 => Loss 0.170, Train_accy 96.25:  60%|██████    | 12/20 [00:20<00:13,  1.74s/it]
Task 5, Epoch 13/20 => Loss 0.150, Train_accy 97.92:  60%|██████    | 12/20 [00:22<00:13,  1.74s/it]
Task 5, Epoch 13/20 => Loss 0.150, Train_accy 97.92:  65%|██████▌   | 13/20 [00:22<00:12,  1.74s/it]
Task 5, Epoch 14/20 => Loss 0.197, Train_accy 96.25:  65%|██████▌   | 13/20 [00:24<00:12,  1.74s/it]
Task 5, Epoch 14/20 => Loss 0.197, Train_accy 96.25:  70%|███████   | 14/20 [00:24<00:10,  1.74s/it]
Task 5, Epoch 15/20 => Loss 0.210, Train_accy 94.17:  70%|███████   | 14/20 [00:26<00:10,  1.74s/it]
Task 5, Epoch 15/20 => Loss 0.210, Train_accy 94.17:  75%|███████▌  | 15/20 [00:26<00:08,  1.74s/it]
Task 5, Epoch 16/20 => Loss 0.143, Train_accy 96.25:  75%|███████▌  | 15/20 [00:27<00:08,  1.74s/it]
Task 5, Epoch 16/20 => Loss 0.143, Train_accy 96.25:  80%|████████  | 16/20 [00:27<00:06,  1.74s/it]
Task 5, Epoch 17/20 => Loss 0.114, Train_accy 97.50:  80%|████████  | 16/20 [00:29<00:06,  1.74s/it]
Task 5, Epoch 17/20 => Loss 0.114, Train_accy 97.50:  85%|████████▌ | 17/20 [00:29<00:05,  1.74s/it]
Task 5, Epoch 18/20 => Loss 0.170, Train_accy 95.00:  85%|████████▌ | 17/20 [00:31<00:05,  1.74s/it]
Task 5, Epoch 18/20 => Loss 0.170, Train_accy 95.00:  90%|█████████ | 18/20 [00:31<00:03,  1.74s/it]
Task 5, Epoch 19/20 => Loss 0.170, Train_accy 95.42:  90%|█████████ | 18/20 [00:33<00:03,  1.74s/it]
Task 5, Epoch 19/20 => Loss 0.170, Train_accy 95.42:  95%|█████████▌| 19/20 [00:33<00:01,  1.75s/it]
Task 5, Epoch 20/20 => Loss 0.138, Train_accy 97.92:  95%|█████████▌| 19/20 [00:34<00:01,  1.75s/it]
Task 5, Epoch 20/20 => Loss 0.138, Train_accy 97.92: 100%|██████████| 20/20 [00:34<00:00,  1.74s/it]
Task 5, Epoch 20/20 => Loss 0.138, Train_accy 97.92: 100%|██████████| 20/20 [00:34<00:00,  1.74s/it]
2024-08-12 11:28:06,193 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.138, Train_accy 97.92
Threshold:  0.9624999999999999
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
Skip Updating DualGPM for layer: 4
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 17/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 30/768 type remove
Layer 6 : 27/768 type remove
Layer 7 : 27/768 type remove
Layer 8 : 38/768 type remove
Layer 9 : 69/768 type remove
Layer 10 : 93/768 type remove
Layer 11 : 24/768 type remove
Layer 12 : 49/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:28:14,037 [trainer.py] => Time:46.47324466705322
476 476
476 476
2024-08-12 11:28:15,856 [trainer.py] => Time:1.818260669708252
2024-08-12 11:28:15,856 [inflora.py] => Exemplar size: 0
2024-08-12 11:28:15,856 [trainer.py] => CNN: {'total': 57.35, '00-09': 50.65, '10-19': 53.06, '20-29': 61.62, '30-39': 60.47, '40-49': 62.5, '50-59': 55.77, 'old': 57.55, 'new': 55.77}
2024-08-12 11:28:15,856 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35]
2024-08-12 11:28:15,856 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19]
2024-08-12 11:28:15,856 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639]
Average Accuracy (CNN): 63.1
2024-08-12 11:28:15,860 [trainer.py] => All params: 110611171
2024-08-12 11:28:15,863 [trainer.py] => Trainable params: 81418
2024-08-12 11:28:15,863 [inflora.py] => Learning on 60-70

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 2.224, Train_accy 30.28:   0%|          | 0/20 [00:02<?, ?it/s]
Task 6, Epoch 1/20 => Loss 2.224, Train_accy 30.28:   5%|▌         | 1/20 [00:02<00:47,  2.48s/it]
Task 6, Epoch 2/20 => Loss 1.122, Train_accy 63.30:   5%|▌         | 1/20 [00:04<00:47,  2.48s/it]
Task 6, Epoch 2/20 => Loss 1.122, Train_accy 63.30:  10%|█         | 2/20 [00:04<00:44,  2.47s/it]
Task 6, Epoch 3/20 => Loss 0.659, Train_accy 78.90:  10%|█         | 2/20 [00:07<00:44,  2.47s/it]
Task 6, Epoch 3/20 => Loss 0.659, Train_accy 78.90:  15%|█▌        | 3/20 [00:07<00:41,  2.46s/it]
Task 6, Epoch 4/20 => Loss 0.537, Train_accy 82.57:  15%|█▌        | 3/20 [00:09<00:41,  2.46s/it]
Task 6, Epoch 4/20 => Loss 0.537, Train_accy 82.57:  20%|██        | 4/20 [00:09<00:39,  2.47s/it]
Task 6, Epoch 5/20 => Loss 0.554, Train_accy 85.78:  20%|██        | 4/20 [00:12<00:39,  2.47s/it]
Task 6, Epoch 5/20 => Loss 0.554, Train_accy 85.78:  25%|██▌       | 5/20 [00:12<00:37,  2.47s/it]
Task 6, Epoch 6/20 => Loss 0.357, Train_accy 88.53:  25%|██▌       | 5/20 [00:14<00:37,  2.47s/it]
Task 6, Epoch 6/20 => Loss 0.357, Train_accy 88.53:  30%|███       | 6/20 [00:14<00:34,  2.47s/it]
Task 6, Epoch 7/20 => Loss 0.426, Train_accy 89.91:  30%|███       | 6/20 [00:17<00:34,  2.47s/it]
Task 6, Epoch 7/20 => Loss 0.426, Train_accy 89.91:  35%|███▌      | 7/20 [00:17<00:32,  2.46s/it]
Task 6, Epoch 8/20 => Loss 0.359, Train_accy 88.53:  35%|███▌      | 7/20 [00:19<00:32,  2.46s/it]
Task 6, Epoch 8/20 => Loss 0.359, Train_accy 88.53:  40%|████      | 8/20 [00:19<00:29,  2.46s/it]
Task 6, Epoch 9/20 => Loss 0.293, Train_accy 91.74:  40%|████      | 8/20 [00:22<00:29,  2.46s/it]
Task 6, Epoch 9/20 => Loss 0.293, Train_accy 91.74:  45%|████▌     | 9/20 [00:22<00:27,  2.46s/it]
Task 6, Epoch 10/20 => Loss 0.300, Train_accy 91.28:  45%|████▌     | 9/20 [00:24<00:27,  2.46s/it]
Task 6, Epoch 10/20 => Loss 0.300, Train_accy 91.28:  50%|█████     | 10/20 [00:24<00:24,  2.49s/it]
Task 6, Epoch 11/20 => Loss 0.220, Train_accy 93.12:  50%|█████     | 10/20 [00:27<00:24,  2.49s/it]
Task 6, Epoch 11/20 => Loss 0.220, Train_accy 93.12:  55%|█████▌    | 11/20 [00:27<00:22,  2.49s/it]
Task 6, Epoch 12/20 => Loss 0.227, Train_accy 91.97:  55%|█████▌    | 11/20 [00:29<00:22,  2.49s/it]
Task 6, Epoch 12/20 => Loss 0.227, Train_accy 91.97:  60%|██████    | 12/20 [00:29<00:20,  2.51s/it]
Task 6, Epoch 13/20 => Loss 0.203, Train_accy 94.50:  60%|██████    | 12/20 [00:32<00:20,  2.51s/it]
Task 6, Epoch 13/20 => Loss 0.203, Train_accy 94.50:  65%|██████▌   | 13/20 [00:32<00:17,  2.50s/it]
Task 6, Epoch 14/20 => Loss 0.174, Train_accy 94.04:  65%|██████▌   | 13/20 [00:34<00:17,  2.50s/it]
Task 6, Epoch 14/20 => Loss 0.174, Train_accy 94.04:  70%|███████   | 14/20 [00:34<00:14,  2.48s/it]
Task 6, Epoch 15/20 => Loss 0.175, Train_accy 94.50:  70%|███████   | 14/20 [00:37<00:14,  2.48s/it]
Task 6, Epoch 15/20 => Loss 0.175, Train_accy 94.50:  75%|███████▌  | 15/20 [00:37<00:12,  2.48s/it]
Task 6, Epoch 16/20 => Loss 0.239, Train_accy 93.12:  75%|███████▌  | 15/20 [00:39<00:12,  2.48s/it]
Task 6, Epoch 16/20 => Loss 0.239, Train_accy 93.12:  80%|████████  | 16/20 [00:39<00:09,  2.47s/it]
Task 6, Epoch 17/20 => Loss 0.190, Train_accy 94.27:  80%|████████  | 16/20 [00:42<00:09,  2.47s/it]
Task 6, Epoch 17/20 => Loss 0.190, Train_accy 94.27:  85%|████████▌ | 17/20 [00:42<00:07,  2.46s/it]
Task 6, Epoch 18/20 => Loss 0.142, Train_accy 96.56:  85%|████████▌ | 17/20 [00:44<00:07,  2.46s/it]
Task 6, Epoch 18/20 => Loss 0.142, Train_accy 96.56:  90%|█████████ | 18/20 [00:44<00:04,  2.48s/it]
Task 6, Epoch 19/20 => Loss 0.210, Train_accy 94.27:  90%|█████████ | 18/20 [00:47<00:04,  2.48s/it]
Task 6, Epoch 19/20 => Loss 0.210, Train_accy 94.27:  95%|█████████▌| 19/20 [00:47<00:02,  2.47s/it]
Task 6, Epoch 20/20 => Loss 0.146, Train_accy 95.18:  95%|█████████▌| 19/20 [00:49<00:02,  2.47s/it]
Task 6, Epoch 20/20 => Loss 0.146, Train_accy 95.18: 100%|██████████| 20/20 [00:49<00:00,  2.47s/it]
Task 6, Epoch 20/20 => Loss 0.146, Train_accy 95.18: 100%|██████████| 20/20 [00:49<00:00,  2.48s/it]
2024-08-12 11:29:09,673 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.146, Train_accy 95.18
Threshold:  0.965
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 19/768 type remove
Layer 5 : 33/768 type remove
Layer 6 : 31/768 type remove
Layer 7 : 31/768 type remove
Layer 8 : 44/768 type remove
Layer 9 : 75/768 type remove
Layer 10 : 97/768 type remove
Layer 11 : 25/768 type remove
Layer 12 : 50/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:29:20,189 [trainer.py] => Time:64.32576656341553
602 602
602 602
2024-08-12 11:29:22,270 [trainer.py] => Time:2.0811824798583984
2024-08-12 11:29:22,271 [inflora.py] => Exemplar size: 0
2024-08-12 11:29:22,271 [trainer.py] => CNN: {'total': 56.64, '00-09': 51.95, '10-19': 52.04, '20-29': 59.6, '30-39': 58.14, '40-49': 56.25, '50-59': 57.69, '60-69': 59.52, 'old': 55.88, 'new': 59.52}
2024-08-12 11:29:22,271 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64]
2024-08-12 11:29:22,271 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72]
2024-08-12 11:29:22,271 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914]
Average Accuracy (CNN): 62.18
2024-08-12 11:29:22,275 [trainer.py] => All params: 110611171
2024-08-12 11:29:22,278 [trainer.py] => Trainable params: 81418
2024-08-12 11:29:22,279 [inflora.py] => Learning on 70-80

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 2.222, Train_accy 29.31:   0%|          | 0/20 [00:02<?, ?it/s]
Task 7, Epoch 1/20 => Loss 2.222, Train_accy 29.31:   5%|▌         | 1/20 [00:02<00:41,  2.18s/it]
Task 7, Epoch 2/20 => Loss 1.042, Train_accy 64.08:   5%|▌         | 1/20 [00:04<00:41,  2.18s/it]
Task 7, Epoch 2/20 => Loss 1.042, Train_accy 64.08:  10%|█         | 2/20 [00:04<00:39,  2.18s/it]
Task 7, Epoch 3/20 => Loss 0.659, Train_accy 79.02:  10%|█         | 2/20 [00:06<00:39,  2.18s/it]
Task 7, Epoch 3/20 => Loss 0.659, Train_accy 79.02:  15%|█▌        | 3/20 [00:06<00:37,  2.19s/it]
Task 7, Epoch 4/20 => Loss 0.525, Train_accy 81.61:  15%|█▌        | 3/20 [00:08<00:37,  2.19s/it]
Task 7, Epoch 4/20 => Loss 0.525, Train_accy 81.61:  20%|██        | 4/20 [00:08<00:34,  2.18s/it]
Task 7, Epoch 5/20 => Loss 0.390, Train_accy 89.37:  20%|██        | 4/20 [00:10<00:34,  2.18s/it]
Task 7, Epoch 5/20 => Loss 0.390, Train_accy 89.37:  25%|██▌       | 5/20 [00:10<00:32,  2.17s/it]
Task 7, Epoch 6/20 => Loss 0.295, Train_accy 90.80:  25%|██▌       | 5/20 [00:13<00:32,  2.17s/it]
Task 7, Epoch 6/20 => Loss 0.295, Train_accy 90.80:  30%|███       | 6/20 [00:13<00:30,  2.18s/it]
Task 7, Epoch 7/20 => Loss 0.238, Train_accy 92.82:  30%|███       | 6/20 [00:15<00:30,  2.18s/it]
Task 7, Epoch 7/20 => Loss 0.238, Train_accy 92.82:  35%|███▌      | 7/20 [00:15<00:28,  2.19s/it]
Task 7, Epoch 8/20 => Loss 0.222, Train_accy 92.24:  35%|███▌      | 7/20 [00:17<00:28,  2.19s/it]
Task 7, Epoch 8/20 => Loss 0.222, Train_accy 92.24:  40%|████      | 8/20 [00:17<00:26,  2.18s/it]
Task 7, Epoch 9/20 => Loss 0.223, Train_accy 93.68:  40%|████      | 8/20 [00:19<00:26,  2.18s/it]
Task 7, Epoch 9/20 => Loss 0.223, Train_accy 93.68:  45%|████▌     | 9/20 [00:19<00:24,  2.18s/it]
Task 7, Epoch 10/20 => Loss 0.153, Train_accy 95.40:  45%|████▌     | 9/20 [00:21<00:24,  2.18s/it]
Task 7, Epoch 10/20 => Loss 0.153, Train_accy 95.40:  50%|█████     | 10/20 [00:21<00:21,  2.18s/it]
Task 7, Epoch 11/20 => Loss 0.139, Train_accy 96.55:  50%|█████     | 10/20 [00:23<00:21,  2.18s/it]
Task 7, Epoch 11/20 => Loss 0.139, Train_accy 96.55:  55%|█████▌    | 11/20 [00:23<00:19,  2.16s/it]
Task 7, Epoch 12/20 => Loss 0.226, Train_accy 92.24:  55%|█████▌    | 11/20 [00:26<00:19,  2.16s/it]
Task 7, Epoch 12/20 => Loss 0.226, Train_accy 92.24:  60%|██████    | 12/20 [00:26<00:17,  2.15s/it]
Task 7, Epoch 13/20 => Loss 0.147, Train_accy 95.98:  60%|██████    | 12/20 [00:28<00:17,  2.15s/it]
Task 7, Epoch 13/20 => Loss 0.147, Train_accy 95.98:  65%|██████▌   | 13/20 [00:28<00:15,  2.15s/it]
Task 7, Epoch 14/20 => Loss 0.169, Train_accy 94.54:  65%|██████▌   | 13/20 [00:30<00:15,  2.15s/it]
Task 7, Epoch 14/20 => Loss 0.169, Train_accy 94.54:  70%|███████   | 14/20 [00:30<00:12,  2.15s/it]
Task 7, Epoch 15/20 => Loss 0.202, Train_accy 92.82:  70%|███████   | 14/20 [00:32<00:12,  2.15s/it]
Task 7, Epoch 15/20 => Loss 0.202, Train_accy 92.82:  75%|███████▌  | 15/20 [00:32<00:10,  2.14s/it]
Task 7, Epoch 16/20 => Loss 0.142, Train_accy 96.55:  75%|███████▌  | 15/20 [00:34<00:10,  2.14s/it]
Task 7, Epoch 16/20 => Loss 0.142, Train_accy 96.55:  80%|████████  | 16/20 [00:34<00:08,  2.15s/it]
Task 7, Epoch 17/20 => Loss 0.152, Train_accy 95.11:  80%|████████  | 16/20 [00:36<00:08,  2.15s/it]
Task 7, Epoch 17/20 => Loss 0.152, Train_accy 95.11:  85%|████████▌ | 17/20 [00:36<00:06,  2.15s/it]
Task 7, Epoch 18/20 => Loss 0.140, Train_accy 95.98:  85%|████████▌ | 17/20 [00:38<00:06,  2.15s/it]
Task 7, Epoch 18/20 => Loss 0.140, Train_accy 95.98:  90%|█████████ | 18/20 [00:38<00:04,  2.17s/it]
Task 7, Epoch 19/20 => Loss 0.128, Train_accy 97.41:  90%|█████████ | 18/20 [00:41<00:04,  2.17s/it]
Task 7, Epoch 19/20 => Loss 0.128, Train_accy 97.41:  95%|█████████▌| 19/20 [00:41<00:02,  2.16s/it]
Task 7, Epoch 20/20 => Loss 0.115, Train_accy 96.55:  95%|█████████▌| 19/20 [00:43<00:02,  2.16s/it]
Task 7, Epoch 20/20 => Loss 0.115, Train_accy 96.55: 100%|██████████| 20/20 [00:43<00:00,  2.16s/it]
Task 7, Epoch 20/20 => Loss 0.115, Train_accy 96.55: 100%|██████████| 20/20 [00:43<00:00,  2.17s/it]
2024-08-12 11:30:09,791 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.115, Train_accy 96.55
Threshold:  0.9675
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 19/768 type remove
Layer 4 : 20/768 type remove
Layer 5 : 35/768 type remove
Layer 6 : 33/768 type remove
Layer 7 : 34/768 type remove
Layer 8 : 48/768 type remove
Layer 9 : 83/768 type remove
Layer 10 : 107/768 type remove
Layer 11 : 31/768 type remove
Layer 12 : 53/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:30:18,525 [trainer.py] => Time:56.24649167060852
698 698
698 698
2024-08-12 11:30:20,727 [trainer.py] => Time:2.2014894485473633
2024-08-12 11:30:20,727 [inflora.py] => Exemplar size: 0
2024-08-12 11:30:20,727 [trainer.py] => CNN: {'total': 55.87, '00-09': 46.75, '10-19': 50.0, '20-29': 60.61, '30-39': 55.81, '40-49': 54.69, '50-59': 55.77, '60-69': 59.52, '70-79': 60.42, 'old': 55.15, 'new': 60.42}
2024-08-12 11:30:20,728 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87]
2024-08-12 11:30:20,728 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67]
2024-08-12 11:30:20,728 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195]
Average Accuracy (CNN): 61.39
2024-08-12 11:30:20,733 [trainer.py] => All params: 110611171
2024-08-12 11:30:20,736 [trainer.py] => Trainable params: 81418
2024-08-12 11:30:20,736 [inflora.py] => Learning on 80-90

  0%|          | 0/20 [00:00<?, ?it/s]
Task 8, Epoch 1/20 => Loss 2.446, Train_accy 16.96:   0%|          | 0/20 [00:02<?, ?it/s]
Task 8, Epoch 1/20 => Loss 2.446, Train_accy 16.96:   5%|▌         | 1/20 [00:02<00:38,  2.04s/it]
Task 8, Epoch 2/20 => Loss 1.385, Train_accy 54.33:   5%|▌         | 1/20 [00:04<00:38,  2.04s/it]
Task 8, Epoch 2/20 => Loss 1.385, Train_accy 54.33:  10%|█         | 2/20 [00:04<00:36,  2.01s/it]
Task 8, Epoch 3/20 => Loss 0.765, Train_accy 72.32:  10%|█         | 2/20 [00:06<00:36,  2.01s/it]
Task 8, Epoch 3/20 => Loss 0.765, Train_accy 72.32:  15%|█▌        | 3/20 [00:06<00:34,  2.03s/it]
Task 8, Epoch 4/20 => Loss 0.788, Train_accy 80.97:  15%|█▌        | 3/20 [00:08<00:34,  2.03s/it]
Task 8, Epoch 4/20 => Loss 0.788, Train_accy 80.97:  20%|██        | 4/20 [00:08<00:32,  2.03s/it]
Task 8, Epoch 5/20 => Loss 0.371, Train_accy 87.54:  20%|██        | 4/20 [00:10<00:32,  2.03s/it]
Task 8, Epoch 5/20 => Loss 0.371, Train_accy 87.54:  25%|██▌       | 5/20 [00:10<00:30,  2.03s/it]
Task 8, Epoch 6/20 => Loss 0.347, Train_accy 91.70:  25%|██▌       | 5/20 [00:12<00:30,  2.03s/it]
Task 8, Epoch 6/20 => Loss 0.347, Train_accy 91.70:  30%|███       | 6/20 [00:12<00:28,  2.03s/it]
Task 8, Epoch 7/20 => Loss 0.295, Train_accy 89.97:  30%|███       | 6/20 [00:14<00:28,  2.03s/it]
Task 8, Epoch 7/20 => Loss 0.295, Train_accy 89.97:  35%|███▌      | 7/20 [00:14<00:26,  2.03s/it]
Task 8, Epoch 8/20 => Loss 0.258, Train_accy 92.04:  35%|███▌      | 7/20 [00:16<00:26,  2.03s/it]
Task 8, Epoch 8/20 => Loss 0.258, Train_accy 92.04:  40%|████      | 8/20 [00:16<00:24,  2.02s/it]
Task 8, Epoch 9/20 => Loss 0.221, Train_accy 93.08:  40%|████      | 8/20 [00:18<00:24,  2.02s/it]
Task 8, Epoch 9/20 => Loss 0.221, Train_accy 93.08:  45%|████▌     | 9/20 [00:18<00:22,  2.02s/it]
Task 8, Epoch 10/20 => Loss 0.278, Train_accy 93.43:  45%|████▌     | 9/20 [00:20<00:22,  2.02s/it]
Task 8, Epoch 10/20 => Loss 0.278, Train_accy 93.43:  50%|█████     | 10/20 [00:20<00:20,  2.02s/it]
Task 8, Epoch 11/20 => Loss 0.142, Train_accy 96.89:  50%|█████     | 10/20 [00:22<00:20,  2.02s/it]
Task 8, Epoch 11/20 => Loss 0.142, Train_accy 96.89:  55%|█████▌    | 11/20 [00:22<00:18,  2.02s/it]
Task 8, Epoch 12/20 => Loss 0.161, Train_accy 95.85:  55%|█████▌    | 11/20 [00:24<00:18,  2.02s/it]
Task 8, Epoch 12/20 => Loss 0.161, Train_accy 95.85:  60%|██████    | 12/20 [00:24<00:16,  2.02s/it]
Task 8, Epoch 13/20 => Loss 0.210, Train_accy 92.39:  60%|██████    | 12/20 [00:26<00:16,  2.02s/it]
Task 8, Epoch 13/20 => Loss 0.210, Train_accy 92.39:  65%|██████▌   | 13/20 [00:26<00:14,  2.02s/it]
Task 8, Epoch 14/20 => Loss 0.176, Train_accy 95.85:  65%|██████▌   | 13/20 [00:28<00:14,  2.02s/it]
Task 8, Epoch 14/20 => Loss 0.176, Train_accy 95.85:  70%|███████   | 14/20 [00:28<00:12,  2.02s/it]
Task 8, Epoch 15/20 => Loss 0.145, Train_accy 95.16:  70%|███████   | 14/20 [00:30<00:12,  2.02s/it]
Task 8, Epoch 15/20 => Loss 0.145, Train_accy 95.16:  75%|███████▌  | 15/20 [00:30<00:10,  2.01s/it]
Task 8, Epoch 16/20 => Loss 0.140, Train_accy 95.16:  75%|███████▌  | 15/20 [00:32<00:10,  2.01s/it]
Task 8, Epoch 16/20 => Loss 0.140, Train_accy 95.16:  80%|████████  | 16/20 [00:32<00:08,  2.01s/it]
Task 8, Epoch 17/20 => Loss 0.119, Train_accy 96.89:  80%|████████  | 16/20 [00:34<00:08,  2.01s/it]
Task 8, Epoch 17/20 => Loss 0.119, Train_accy 96.89:  85%|████████▌ | 17/20 [00:34<00:06,  2.01s/it]
Task 8, Epoch 18/20 => Loss 0.130, Train_accy 96.89:  85%|████████▌ | 17/20 [00:36<00:06,  2.01s/it]
Task 8, Epoch 18/20 => Loss 0.130, Train_accy 96.89:  90%|█████████ | 18/20 [00:36<00:04,  2.01s/it]
Task 8, Epoch 19/20 => Loss 0.162, Train_accy 93.08:  90%|█████████ | 18/20 [00:38<00:04,  2.01s/it]
Task 8, Epoch 19/20 => Loss 0.162, Train_accy 93.08:  95%|█████████▌| 19/20 [00:38<00:01,  1.99s/it]
Task 8, Epoch 20/20 => Loss 0.147, Train_accy 95.85:  95%|█████████▌| 19/20 [00:40<00:01,  1.99s/it]
Task 8, Epoch 20/20 => Loss 0.147, Train_accy 95.85: 100%|██████████| 20/20 [00:40<00:00,  2.00s/it]
Task 8, Epoch 20/20 => Loss 0.147, Train_accy 95.85: 100%|██████████| 20/20 [00:40<00:00,  2.02s/it]
2024-08-12 11:31:05,154 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.147, Train_accy 95.85
Threshold:  0.97
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 21/768 type remove
Layer 4 : 23/768 type remove
Layer 5 : 40/768 type remove
Layer 6 : 38/768 type remove
Layer 7 : 38/768 type remove
Layer 8 : 58/768 type remove
Layer 9 : 96/768 type remove
Layer 10 : 122/768 type remove
Layer 11 : 38/768 type remove
Layer 12 : 59/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:31:14,133 [trainer.py] => Time:53.397563219070435
779 779
779 779
2024-08-12 11:31:16,550 [trainer.py] => Time:2.416536331176758
2024-08-12 11:31:16,550 [inflora.py] => Exemplar size: 0
2024-08-12 11:31:16,550 [trainer.py] => CNN: {'total': 54.3, '00-09': 50.65, '10-19': 50.0, '20-29': 56.57, '30-39': 55.81, '40-49': 54.69, '50-59': 53.85, '60-69': 58.73, '70-79': 57.29, '80-89': 48.15, 'old': 55.01, 'new': 48.15}
2024-08-12 11:31:16,550 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3]
2024-08-12 11:31:16,551 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47]
2024-08-12 11:31:16,551 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848]
Average Accuracy (CNN): 60.6
2024-08-12 11:31:16,555 [trainer.py] => All params: 110611171
2024-08-12 11:31:16,559 [trainer.py] => Trainable params: 81418
2024-08-12 11:31:16,559 [inflora.py] => Learning on 90-100

  0%|          | 0/20 [00:00<?, ?it/s]
Task 9, Epoch 1/20 => Loss 2.999, Train_accy 14.89:   0%|          | 0/20 [00:01<?, ?it/s]
Task 9, Epoch 1/20 => Loss 2.999, Train_accy 14.89:   5%|▌         | 1/20 [00:01<00:33,  1.78s/it]
Task 9, Epoch 2/20 => Loss 1.735, Train_accy 43.83:   5%|▌         | 1/20 [00:03<00:33,  1.78s/it]
Task 9, Epoch 2/20 => Loss 1.735, Train_accy 43.83:  10%|█         | 2/20 [00:03<00:32,  1.81s/it]
Task 9, Epoch 3/20 => Loss 1.161, Train_accy 62.98:  10%|█         | 2/20 [00:05<00:32,  1.81s/it]
Task 9, Epoch 3/20 => Loss 1.161, Train_accy 62.98:  15%|█▌        | 3/20 [00:05<00:30,  1.81s/it]
Task 9, Epoch 4/20 => Loss 0.901, Train_accy 69.36:  15%|█▌        | 3/20 [00:07<00:30,  1.81s/it]
Task 9, Epoch 4/20 => Loss 0.901, Train_accy 69.36:  20%|██        | 4/20 [00:07<00:28,  1.81s/it]
Task 9, Epoch 5/20 => Loss 0.659, Train_accy 76.60:  20%|██        | 4/20 [00:09<00:28,  1.81s/it]
Task 9, Epoch 5/20 => Loss 0.659, Train_accy 76.60:  25%|██▌       | 5/20 [00:09<00:27,  1.81s/it]
Task 9, Epoch 6/20 => Loss 0.522, Train_accy 82.55:  25%|██▌       | 5/20 [00:10<00:27,  1.81s/it]
Task 9, Epoch 6/20 => Loss 0.522, Train_accy 82.55:  30%|███       | 6/20 [00:10<00:25,  1.82s/it]
Task 9, Epoch 7/20 => Loss 0.501, Train_accy 83.83:  30%|███       | 6/20 [00:12<00:25,  1.82s/it]
Task 9, Epoch 7/20 => Loss 0.501, Train_accy 83.83:  35%|███▌      | 7/20 [00:12<00:23,  1.82s/it]
Task 9, Epoch 8/20 => Loss 0.399, Train_accy 86.81:  35%|███▌      | 7/20 [00:14<00:23,  1.82s/it]
Task 9, Epoch 8/20 => Loss 0.399, Train_accy 86.81:  40%|████      | 8/20 [00:14<00:21,  1.82s/it]
Task 9, Epoch 9/20 => Loss 0.317, Train_accy 90.64:  40%|████      | 8/20 [00:16<00:21,  1.82s/it]
Task 9, Epoch 9/20 => Loss 0.317, Train_accy 90.64:  45%|████▌     | 9/20 [00:16<00:19,  1.82s/it]
Task 9, Epoch 10/20 => Loss 0.284, Train_accy 91.91:  45%|████▌     | 9/20 [00:18<00:19,  1.82s/it]
Task 9, Epoch 10/20 => Loss 0.284, Train_accy 91.91:  50%|█████     | 10/20 [00:18<00:18,  1.82s/it]
Task 9, Epoch 11/20 => Loss 0.266, Train_accy 92.34:  50%|█████     | 10/20 [00:19<00:18,  1.82s/it]
Task 9, Epoch 11/20 => Loss 0.266, Train_accy 92.34:  55%|█████▌    | 11/20 [00:19<00:16,  1.82s/it]
Task 9, Epoch 12/20 => Loss 0.232, Train_accy 93.62:  55%|█████▌    | 11/20 [00:21<00:16,  1.82s/it]
Task 9, Epoch 12/20 => Loss 0.232, Train_accy 93.62:  60%|██████    | 12/20 [00:21<00:14,  1.82s/it]
Task 9, Epoch 13/20 => Loss 0.257, Train_accy 94.04:  60%|██████    | 12/20 [00:23<00:14,  1.82s/it]
Task 9, Epoch 13/20 => Loss 0.257, Train_accy 94.04:  65%|██████▌   | 13/20 [00:23<00:12,  1.82s/it]
Task 9, Epoch 14/20 => Loss 0.252, Train_accy 93.19:  65%|██████▌   | 13/20 [00:25<00:12,  1.82s/it]
Task 9, Epoch 14/20 => Loss 0.252, Train_accy 93.19:  70%|███████   | 14/20 [00:25<00:10,  1.82s/it]
Task 9, Epoch 15/20 => Loss 0.207, Train_accy 94.47:  70%|███████   | 14/20 [00:27<00:10,  1.82s/it]
Task 9, Epoch 15/20 => Loss 0.207, Train_accy 94.47:  75%|███████▌  | 15/20 [00:27<00:09,  1.83s/it]
Task 9, Epoch 16/20 => Loss 0.197, Train_accy 96.60:  75%|███████▌  | 15/20 [00:29<00:09,  1.83s/it]
Task 9, Epoch 16/20 => Loss 0.197, Train_accy 96.60:  80%|████████  | 16/20 [00:29<00:07,  1.82s/it]
Task 9, Epoch 17/20 => Loss 0.193, Train_accy 94.89:  80%|████████  | 16/20 [00:30<00:07,  1.82s/it]
Task 9, Epoch 17/20 => Loss 0.193, Train_accy 94.89:  85%|████████▌ | 17/20 [00:30<00:05,  1.82s/it]
Task 9, Epoch 18/20 => Loss 0.212, Train_accy 94.47:  85%|████████▌ | 17/20 [00:32<00:05,  1.82s/it]
Task 9, Epoch 18/20 => Loss 0.212, Train_accy 94.47:  90%|█████████ | 18/20 [00:32<00:03,  1.81s/it]
Task 9, Epoch 19/20 => Loss 0.190, Train_accy 94.47:  90%|█████████ | 18/20 [00:34<00:03,  1.81s/it]
Task 9, Epoch 19/20 => Loss 0.190, Train_accy 94.47:  95%|█████████▌| 19/20 [00:34<00:01,  1.82s/it]
Task 9, Epoch 20/20 => Loss 0.194, Train_accy 94.04:  95%|█████████▌| 19/20 [00:36<00:01,  1.82s/it]
Task 9, Epoch 20/20 => Loss 0.194, Train_accy 94.04: 100%|██████████| 20/20 [00:36<00:00,  1.82s/it]
Task 9, Epoch 20/20 => Loss 0.194, Train_accy 94.04: 100%|██████████| 20/20 [00:36<00:00,  1.82s/it]
2024-08-12 11:31:57,119 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.194, Train_accy 94.04
Threshold:  0.9724999999999999
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 23/768 type remove
Layer 4 : 25/768 type remove
Layer 5 : 43/768 type remove
Layer 6 : 41/768 type remove
Layer 7 : 41/768 type remove
Layer 8 : 61/768 type remove
Layer 9 : 102/768 type remove
Layer 10 : 135/768 type remove
Layer 11 : 45/768 type remove
Layer 12 : 68/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:32:05,330 [trainer.py] => Time:48.771429777145386
841 841
841 841
2024-08-12 11:32:07,962 [trainer.py] => Time:2.632103443145752
2024-08-12 11:32:07,963 [inflora.py] => Exemplar size: 0
2024-08-12 11:32:07,963 [trainer.py] => CNN: {'total': 51.25, '00-09': 44.16, '10-19': 47.96, '20-29': 54.55, '30-39': 55.81, '40-49': 54.69, '50-59': 51.92, '60-69': 54.76, '70-79': 52.08, '80-89': 46.91, '90-99': 46.77, 'old': 51.6, 'new': 46.77}
2024-08-12 11:32:07,963 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25]
2024-08-12 11:32:07,963 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19]
2024-08-12 11:32:07,963 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107]
Average Accuracy (CNN): 59.67
2024-08-12 11:32:07,967 [trainer.py] => All params: 110611171
2024-08-12 11:32:07,970 [trainer.py] => Trainable params: 81418
2024-08-12 11:32:07,971 [inflora.py] => Learning on 100-110

  0%|          | 0/20 [00:00<?, ?it/s]
Task 10, Epoch 1/20 => Loss 2.439, Train_accy 22.45:   0%|          | 0/20 [00:01<?, ?it/s]
Task 10, Epoch 1/20 => Loss 2.439, Train_accy 22.45:   5%|▌         | 1/20 [00:01<00:35,  1.88s/it]
Task 10, Epoch 2/20 => Loss 1.576, Train_accy 50.20:   5%|▌         | 1/20 [00:03<00:35,  1.88s/it]
Task 10, Epoch 2/20 => Loss 1.576, Train_accy 50.20:  10%|█         | 2/20 [00:03<00:33,  1.88s/it]
Task 10, Epoch 3/20 => Loss 1.309, Train_accy 66.53:  10%|█         | 2/20 [00:05<00:33,  1.88s/it]
Task 10, Epoch 3/20 => Loss 1.309, Train_accy 66.53:  15%|█▌        | 3/20 [00:05<00:31,  1.87s/it]
Task 10, Epoch 4/20 => Loss 0.877, Train_accy 77.55:  15%|█▌        | 3/20 [00:07<00:31,  1.87s/it]
Task 10, Epoch 4/20 => Loss 0.877, Train_accy 77.55:  20%|██        | 4/20 [00:07<00:30,  1.88s/it]
Task 10, Epoch 5/20 => Loss 0.642, Train_accy 80.41:  20%|██        | 4/20 [00:09<00:30,  1.88s/it]
Task 10, Epoch 5/20 => Loss 0.642, Train_accy 80.41:  25%|██▌       | 5/20 [00:09<00:28,  1.87s/it]
Task 10, Epoch 6/20 => Loss 0.462, Train_accy 88.16:  25%|██▌       | 5/20 [00:11<00:28,  1.87s/it]
Task 10, Epoch 6/20 => Loss 0.462, Train_accy 88.16:  30%|███       | 6/20 [00:11<00:26,  1.87s/it]
Task 10, Epoch 7/20 => Loss 0.343, Train_accy 89.80:  30%|███       | 6/20 [00:13<00:26,  1.87s/it]
Task 10, Epoch 7/20 => Loss 0.343, Train_accy 89.80:  35%|███▌      | 7/20 [00:13<00:24,  1.87s/it]
Task 10, Epoch 8/20 => Loss 0.320, Train_accy 91.84:  35%|███▌      | 7/20 [00:14<00:24,  1.87s/it]
Task 10, Epoch 8/20 => Loss 0.320, Train_accy 91.84:  40%|████      | 8/20 [00:14<00:22,  1.87s/it]
Task 10, Epoch 9/20 => Loss 0.361, Train_accy 92.24:  40%|████      | 8/20 [00:16<00:22,  1.87s/it]
Task 10, Epoch 9/20 => Loss 0.361, Train_accy 92.24:  45%|████▌     | 9/20 [00:16<00:20,  1.88s/it]
Task 10, Epoch 10/20 => Loss 0.269, Train_accy 93.06:  45%|████▌     | 9/20 [00:18<00:20,  1.88s/it]
Task 10, Epoch 10/20 => Loss 0.269, Train_accy 93.06:  50%|█████     | 10/20 [00:18<00:18,  1.89s/it]
Task 10, Epoch 11/20 => Loss 0.234, Train_accy 94.29:  50%|█████     | 10/20 [00:20<00:18,  1.89s/it]
Task 10, Epoch 11/20 => Loss 0.234, Train_accy 94.29:  55%|█████▌    | 11/20 [00:20<00:17,  1.89s/it]
Task 10, Epoch 12/20 => Loss 0.269, Train_accy 91.02:  55%|█████▌    | 11/20 [00:22<00:17,  1.89s/it]
Task 10, Epoch 12/20 => Loss 0.269, Train_accy 91.02:  60%|██████    | 12/20 [00:22<00:15,  1.89s/it]
Task 10, Epoch 13/20 => Loss 0.233, Train_accy 95.10:  60%|██████    | 12/20 [00:24<00:15,  1.89s/it]
Task 10, Epoch 13/20 => Loss 0.233, Train_accy 95.10:  65%|██████▌   | 13/20 [00:24<00:13,  1.90s/it]
Task 10, Epoch 14/20 => Loss 0.191, Train_accy 93.88:  65%|██████▌   | 13/20 [00:26<00:13,  1.90s/it]
Task 10, Epoch 14/20 => Loss 0.191, Train_accy 93.88:  70%|███████   | 14/20 [00:26<00:11,  1.90s/it]
Task 10, Epoch 15/20 => Loss 0.213, Train_accy 93.06:  70%|███████   | 14/20 [00:28<00:11,  1.90s/it]
Task 10, Epoch 15/20 => Loss 0.213, Train_accy 93.06:  75%|███████▌  | 15/20 [00:28<00:09,  1.92s/it]
Task 10, Epoch 16/20 => Loss 0.220, Train_accy 93.88:  75%|███████▌  | 15/20 [00:30<00:09,  1.92s/it]
Task 10, Epoch 16/20 => Loss 0.220, Train_accy 93.88:  80%|████████  | 16/20 [00:30<00:07,  1.90s/it]
Task 10, Epoch 17/20 => Loss 0.204, Train_accy 93.88:  80%|████████  | 16/20 [00:32<00:07,  1.90s/it]
Task 10, Epoch 17/20 => Loss 0.204, Train_accy 93.88:  85%|████████▌ | 17/20 [00:32<00:05,  1.90s/it]
Task 10, Epoch 18/20 => Loss 0.146, Train_accy 97.55:  85%|████████▌ | 17/20 [00:34<00:05,  1.90s/it]
Task 10, Epoch 18/20 => Loss 0.146, Train_accy 97.55:  90%|█████████ | 18/20 [00:34<00:03,  1.91s/it]
Task 10, Epoch 19/20 => Loss 0.192, Train_accy 95.92:  90%|█████████ | 18/20 [00:35<00:03,  1.91s/it]
Task 10, Epoch 19/20 => Loss 0.192, Train_accy 95.92:  95%|█████████▌| 19/20 [00:35<00:01,  1.90s/it]
Task 10, Epoch 20/20 => Loss 0.133, Train_accy 95.51:  95%|█████████▌| 19/20 [00:37<00:01,  1.90s/it]
Task 10, Epoch 20/20 => Loss 0.133, Train_accy 95.51: 100%|██████████| 20/20 [00:37<00:00,  1.90s/it]
Task 10, Epoch 20/20 => Loss 0.133, Train_accy 95.51: 100%|██████████| 20/20 [00:37<00:00,  1.89s/it]
2024-08-12 11:32:49,941 [inflora.py] => Task 10, Epoch 20/20 => Loss 0.133, Train_accy 95.51
Threshold:  0.975
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 24/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 44/768 type remove
Layer 6 : 43/768 type remove
Layer 7 : 44/768 type remove
Layer 8 : 65/768 type remove
Layer 9 : 108/768 type remove
Layer 10 : 142/768 type remove
Layer 11 : 50/768 type remove
Layer 12 : 75/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:32:58,311 [trainer.py] => Time:50.34084939956665
901 901
901 901
2024-08-12 11:33:00,997 [trainer.py] => Time:2.6851189136505127
2024-08-12 11:33:00,997 [inflora.py] => Exemplar size: 0
2024-08-12 11:33:00,997 [trainer.py] => CNN: {'total': 50.28, '00-09': 44.16, '10-19': 47.96, '20-29': 56.57, '30-39': 56.98, '40-49': 53.12, '50-59': 46.15, '60-69': 53.17, '70-79': 51.04, '80-89': 46.91, '90-99': 46.77, '100-109': 43.33, 'old': 50.77, 'new': 43.33}
2024-08-12 11:33:00,997 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28]
2024-08-12 11:33:00,997 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13]
2024-08-12 11:33:00,997 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824]
Average Accuracy (CNN): 58.81
2024-08-12 11:33:01,001 [trainer.py] => All params: 110611171
2024-08-12 11:33:01,005 [trainer.py] => Trainable params: 81418
2024-08-12 11:33:01,005 [inflora.py] => Learning on 110-120

  0%|          | 0/20 [00:00<?, ?it/s]
Task 11, Epoch 1/20 => Loss 2.403, Train_accy 21.94:   0%|          | 0/20 [00:01<?, ?it/s]
Task 11, Epoch 1/20 => Loss 2.403, Train_accy 21.94:   5%|▌         | 1/20 [00:01<00:37,  2.00s/it]
Task 11, Epoch 2/20 => Loss 1.252, Train_accy 60.07:   5%|▌         | 1/20 [00:03<00:37,  2.00s/it]
Task 11, Epoch 2/20 => Loss 1.252, Train_accy 60.07:  10%|█         | 2/20 [00:03<00:35,  2.00s/it]
Task 11, Epoch 3/20 => Loss 0.850, Train_accy 72.66:  10%|█         | 2/20 [00:06<00:35,  2.00s/it]
Task 11, Epoch 3/20 => Loss 0.850, Train_accy 72.66:  15%|█▌        | 3/20 [00:06<00:34,  2.02s/it]
Task 11, Epoch 4/20 => Loss 0.581, Train_accy 82.01:  15%|█▌        | 3/20 [00:08<00:34,  2.02s/it]
Task 11, Epoch 4/20 => Loss 0.581, Train_accy 82.01:  20%|██        | 4/20 [00:08<00:31,  2.00s/it]
Task 11, Epoch 5/20 => Loss 0.480, Train_accy 84.53:  20%|██        | 4/20 [00:10<00:31,  2.00s/it]
Task 11, Epoch 5/20 => Loss 0.480, Train_accy 84.53:  25%|██▌       | 5/20 [00:10<00:30,  2.00s/it]
Task 11, Epoch 6/20 => Loss 0.358, Train_accy 88.49:  25%|██▌       | 5/20 [00:11<00:30,  2.00s/it]
Task 11, Epoch 6/20 => Loss 0.358, Train_accy 88.49:  30%|███       | 6/20 [00:12<00:27,  1.99s/it]
Task 11, Epoch 7/20 => Loss 0.325, Train_accy 91.73:  30%|███       | 6/20 [00:13<00:27,  1.99s/it]
Task 11, Epoch 7/20 => Loss 0.325, Train_accy 91.73:  35%|███▌      | 7/20 [00:13<00:25,  1.99s/it]
Task 11, Epoch 8/20 => Loss 0.310, Train_accy 91.73:  35%|███▌      | 7/20 [00:15<00:25,  1.99s/it]
Task 11, Epoch 8/20 => Loss 0.310, Train_accy 91.73:  40%|████      | 8/20 [00:15<00:23,  1.98s/it]
Task 11, Epoch 9/20 => Loss 0.236, Train_accy 94.60:  40%|████      | 8/20 [00:17<00:23,  1.98s/it]
Task 11, Epoch 9/20 => Loss 0.236, Train_accy 94.60:  45%|████▌     | 9/20 [00:17<00:21,  2.00s/it]
Task 11, Epoch 10/20 => Loss 0.226, Train_accy 93.53:  45%|████▌     | 9/20 [00:19<00:21,  2.00s/it]
Task 11, Epoch 10/20 => Loss 0.226, Train_accy 93.53:  50%|█████     | 10/20 [00:19<00:20,  2.00s/it]
Task 11, Epoch 11/20 => Loss 0.177, Train_accy 96.40:  50%|█████     | 10/20 [00:21<00:20,  2.00s/it]
Task 11, Epoch 11/20 => Loss 0.177, Train_accy 96.40:  55%|█████▌    | 11/20 [00:21<00:17,  1.99s/it]
Task 11, Epoch 12/20 => Loss 0.182, Train_accy 94.60:  55%|█████▌    | 11/20 [00:23<00:17,  1.99s/it]
Task 11, Epoch 12/20 => Loss 0.182, Train_accy 94.60:  60%|██████    | 12/20 [00:23<00:15,  2.00s/it]
Task 11, Epoch 13/20 => Loss 0.192, Train_accy 94.24:  60%|██████    | 12/20 [00:25<00:15,  2.00s/it]
Task 11, Epoch 13/20 => Loss 0.192, Train_accy 94.24:  65%|██████▌   | 13/20 [00:25<00:13,  2.00s/it]
Task 11, Epoch 14/20 => Loss 0.168, Train_accy 96.04:  65%|██████▌   | 13/20 [00:27<00:13,  2.00s/it]
Task 11, Epoch 14/20 => Loss 0.168, Train_accy 96.04:  70%|███████   | 14/20 [00:27<00:11,  1.99s/it]
Task 11, Epoch 15/20 => Loss 0.167, Train_accy 95.68:  70%|███████   | 14/20 [00:29<00:11,  1.99s/it]
Task 11, Epoch 15/20 => Loss 0.167, Train_accy 95.68:  75%|███████▌  | 15/20 [00:29<00:09,  1.99s/it]
Task 11, Epoch 16/20 => Loss 0.152, Train_accy 95.32:  75%|███████▌  | 15/20 [00:31<00:09,  1.99s/it]
Task 11, Epoch 16/20 => Loss 0.152, Train_accy 95.32:  80%|████████  | 16/20 [00:31<00:07,  1.99s/it]
Task 11, Epoch 17/20 => Loss 0.164, Train_accy 95.68:  80%|████████  | 16/20 [00:33<00:07,  1.99s/it]
Task 11, Epoch 17/20 => Loss 0.164, Train_accy 95.68:  85%|████████▌ | 17/20 [00:33<00:05,  1.99s/it]
Task 11, Epoch 18/20 => Loss 0.141, Train_accy 96.76:  85%|████████▌ | 17/20 [00:35<00:05,  1.99s/it]
Task 11, Epoch 18/20 => Loss 0.141, Train_accy 96.76:  90%|█████████ | 18/20 [00:35<00:03,  1.99s/it]
Task 11, Epoch 19/20 => Loss 0.133, Train_accy 97.48:  90%|█████████ | 18/20 [00:37<00:03,  1.99s/it]
Task 11, Epoch 19/20 => Loss 0.133, Train_accy 97.48:  95%|█████████▌| 19/20 [00:37<00:02,  2.01s/it]
Task 11, Epoch 20/20 => Loss 0.152, Train_accy 95.68:  95%|█████████▌| 19/20 [00:39<00:02,  2.01s/it]
Task 11, Epoch 20/20 => Loss 0.152, Train_accy 95.68: 100%|██████████| 20/20 [00:39<00:00,  1.99s/it]
Task 11, Epoch 20/20 => Loss 0.152, Train_accy 95.68: 100%|██████████| 20/20 [00:39<00:00,  2.00s/it]
2024-08-12 11:33:45,299 [inflora.py] => Task 11, Epoch 20/20 => Loss 0.152, Train_accy 95.68
Threshold:  0.9775
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 27/768 type remove
Layer 4 : 30/768 type remove
Layer 5 : 50/768 type remove
Layer 6 : 49/768 type remove
Layer 7 : 49/768 type remove
Layer 8 : 72/768 type remove
Layer 9 : 115/768 type remove
Layer 10 : 152/768 type remove
Layer 11 : 56/768 type remove
Layer 12 : 79/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:33:54,782 [trainer.py] => Time:53.77704215049744
975 975
975 975
2024-08-12 11:33:57,533 [trainer.py] => Time:2.751133680343628
2024-08-12 11:33:57,534 [inflora.py] => Exemplar size: 0
2024-08-12 11:33:57,534 [trainer.py] => CNN: {'total': 49.95, '00-09': 44.16, '10-19': 46.94, '20-29': 58.59, '30-39': 55.81, '40-49': 54.69, '50-59': 46.15, '60-69': 53.17, '70-79': 52.08, '80-89': 46.91, '90-99': 43.55, '100-109': 41.67, '110-119': 47.3, 'old': 50.17, 'new': 47.3}
2024-08-12 11:33:57,534 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95]
2024-08-12 11:33:57,534 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92]
2024-08-12 11:33:57,534 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231]
Average Accuracy (CNN): 58.08
2024-08-12 11:33:57,538 [trainer.py] => All params: 110611171
2024-08-12 11:33:57,541 [trainer.py] => Trainable params: 81418
2024-08-12 11:33:57,541 [inflora.py] => Learning on 120-130

  0%|          | 0/20 [00:00<?, ?it/s]
Task 12, Epoch 1/20 => Loss 2.923, Train_accy 13.04:   0%|          | 0/20 [00:01<?, ?it/s]
Task 12, Epoch 1/20 => Loss 2.923, Train_accy 13.04:   5%|▌         | 1/20 [00:01<00:35,  1.86s/it]
Task 12, Epoch 2/20 => Loss 1.959, Train_accy 36.96:   5%|▌         | 1/20 [00:03<00:35,  1.86s/it]
Task 12, Epoch 2/20 => Loss 1.959, Train_accy 36.96:  10%|█         | 2/20 [00:03<00:34,  1.93s/it]
Task 12, Epoch 3/20 => Loss 1.390, Train_accy 57.83:  10%|█         | 2/20 [00:05<00:34,  1.93s/it]
Task 12, Epoch 3/20 => Loss 1.390, Train_accy 57.83:  15%|█▌        | 3/20 [00:05<00:31,  1.88s/it]
Task 12, Epoch 4/20 => Loss 1.164, Train_accy 64.78:  15%|█▌        | 3/20 [00:07<00:31,  1.88s/it]
Task 12, Epoch 4/20 => Loss 1.164, Train_accy 64.78:  20%|██        | 4/20 [00:07<00:29,  1.87s/it]
Task 12, Epoch 5/20 => Loss 0.806, Train_accy 77.83:  20%|██        | 4/20 [00:09<00:29,  1.87s/it]
Task 12, Epoch 5/20 => Loss 0.806, Train_accy 77.83:  25%|██▌       | 5/20 [00:09<00:27,  1.85s/it]
Task 12, Epoch 6/20 => Loss 0.711, Train_accy 79.57:  25%|██▌       | 5/20 [00:11<00:27,  1.85s/it]
Task 12, Epoch 6/20 => Loss 0.711, Train_accy 79.57:  30%|███       | 6/20 [00:11<00:25,  1.85s/it]
Task 12, Epoch 7/20 => Loss 0.629, Train_accy 82.17:  30%|███       | 6/20 [00:13<00:25,  1.85s/it]
Task 12, Epoch 7/20 => Loss 0.629, Train_accy 82.17:  35%|███▌      | 7/20 [00:13<00:24,  1.86s/it]
Task 12, Epoch 8/20 => Loss 0.533, Train_accy 85.65:  35%|███▌      | 7/20 [00:14<00:24,  1.86s/it]
Task 12, Epoch 8/20 => Loss 0.533, Train_accy 85.65:  40%|████      | 8/20 [00:14<00:22,  1.85s/it]
Task 12, Epoch 9/20 => Loss 0.529, Train_accy 87.39:  40%|████      | 8/20 [00:16<00:22,  1.85s/it]
Task 12, Epoch 9/20 => Loss 0.529, Train_accy 87.39:  45%|████▌     | 9/20 [00:16<00:20,  1.85s/it]
Task 12, Epoch 10/20 => Loss 0.435, Train_accy 87.83:  45%|████▌     | 9/20 [00:18<00:20,  1.85s/it]
Task 12, Epoch 10/20 => Loss 0.435, Train_accy 87.83:  50%|█████     | 10/20 [00:18<00:18,  1.85s/it]
Task 12, Epoch 11/20 => Loss 0.384, Train_accy 88.70:  50%|█████     | 10/20 [00:20<00:18,  1.85s/it]
Task 12, Epoch 11/20 => Loss 0.384, Train_accy 88.70:  55%|█████▌    | 11/20 [00:20<00:16,  1.86s/it]
Task 12, Epoch 12/20 => Loss 0.357, Train_accy 89.13:  55%|█████▌    | 11/20 [00:22<00:16,  1.86s/it]
Task 12, Epoch 12/20 => Loss 0.357, Train_accy 89.13:  60%|██████    | 12/20 [00:22<00:14,  1.85s/it]
Task 12, Epoch 13/20 => Loss 0.391, Train_accy 88.70:  60%|██████    | 12/20 [00:24<00:14,  1.85s/it]
Task 12, Epoch 13/20 => Loss 0.391, Train_accy 88.70:  65%|██████▌   | 13/20 [00:24<00:12,  1.85s/it]
Task 12, Epoch 14/20 => Loss 0.256, Train_accy 94.78:  65%|██████▌   | 13/20 [00:25<00:12,  1.85s/it]
Task 12, Epoch 14/20 => Loss 0.256, Train_accy 94.78:  70%|███████   | 14/20 [00:25<00:10,  1.83s/it]
Task 12, Epoch 15/20 => Loss 0.296, Train_accy 93.91:  70%|███████   | 14/20 [00:27<00:10,  1.83s/it]
Task 12, Epoch 15/20 => Loss 0.296, Train_accy 93.91:  75%|███████▌  | 15/20 [00:27<00:09,  1.84s/it]
Task 12, Epoch 16/20 => Loss 0.285, Train_accy 91.30:  75%|███████▌  | 15/20 [00:29<00:09,  1.84s/it]
Task 12, Epoch 16/20 => Loss 0.285, Train_accy 91.30:  80%|████████  | 16/20 [00:29<00:07,  1.85s/it]
Task 12, Epoch 17/20 => Loss 0.314, Train_accy 90.00:  80%|████████  | 16/20 [00:31<00:07,  1.85s/it]
Task 12, Epoch 17/20 => Loss 0.314, Train_accy 90.00:  85%|████████▌ | 17/20 [00:31<00:05,  1.85s/it]
Task 12, Epoch 18/20 => Loss 0.250, Train_accy 93.48:  85%|████████▌ | 17/20 [00:33<00:05,  1.85s/it]
Task 12, Epoch 18/20 => Loss 0.250, Train_accy 93.48:  90%|█████████ | 18/20 [00:33<00:03,  1.85s/it]
Task 12, Epoch 19/20 => Loss 0.232, Train_accy 93.91:  90%|█████████ | 18/20 [00:35<00:03,  1.85s/it]
Task 12, Epoch 19/20 => Loss 0.232, Train_accy 93.91:  95%|█████████▌| 19/20 [00:35<00:01,  1.85s/it]
Task 12, Epoch 20/20 => Loss 0.295, Train_accy 93.04:  95%|█████████▌| 19/20 [00:37<00:01,  1.85s/it]
Task 12, Epoch 20/20 => Loss 0.295, Train_accy 93.04: 100%|██████████| 20/20 [00:37<00:00,  1.85s/it]
Task 12, Epoch 20/20 => Loss 0.295, Train_accy 93.04: 100%|██████████| 20/20 [00:37<00:00,  1.85s/it]
2024-08-12 11:34:38,531 [inflora.py] => Task 12, Epoch 20/20 => Loss 0.295, Train_accy 93.04
Threshold:  0.98
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 33/768 type remove
Layer 5 : 55/768 type remove
Layer 6 : 55/768 type remove
Layer 7 : 55/768 type remove
Layer 8 : 83/768 type remove
Layer 9 : 139/768 type remove
Layer 10 : 185/768 type remove
Layer 11 : 76/768 type remove
Layer 12 : 103/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:34:47,262 [trainer.py] => Time:49.721203327178955
1035 1035
1035 1035
2024-08-12 11:34:50,321 [trainer.py] => Time:3.058410167694092
2024-08-12 11:34:50,321 [inflora.py] => Exemplar size: 0
2024-08-12 11:34:50,321 [trainer.py] => CNN: {'total': 48.79, '00-09': 44.16, '10-19': 45.92, '20-29': 57.58, '30-39': 56.98, '40-49': 54.69, '50-59': 48.08, '60-69': 53.17, '70-79': 46.88, '80-89': 46.91, '90-99': 45.16, '100-109': 43.33, '110-119': 50.0, '120-129': 31.67, 'old': 49.85, 'new': 31.67}
2024-08-12 11:34:50,321 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79]
2024-08-12 11:34:50,322 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96]
2024-08-12 11:34:50,322 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357]
Average Accuracy (CNN): 57.36
2024-08-12 11:34:50,326 [trainer.py] => All params: 110611171
2024-08-12 11:34:50,329 [trainer.py] => Trainable params: 81418
2024-08-12 11:34:50,329 [inflora.py] => Learning on 130-140

  0%|          | 0/20 [00:00<?, ?it/s]
Task 13, Epoch 1/20 => Loss 2.514, Train_accy 17.80:   0%|          | 0/20 [00:02<?, ?it/s]
Task 13, Epoch 1/20 => Loss 2.514, Train_accy 17.80:   5%|▌         | 1/20 [00:02<00:40,  2.12s/it]
Task 13, Epoch 2/20 => Loss 1.428, Train_accy 54.69:   5%|▌         | 1/20 [00:04<00:40,  2.12s/it]
Task 13, Epoch 2/20 => Loss 1.428, Train_accy 54.69:  10%|█         | 2/20 [00:04<00:38,  2.14s/it]
Task 13, Epoch 3/20 => Loss 0.927, Train_accy 72.82:  10%|█         | 2/20 [00:06<00:38,  2.14s/it]
Task 13, Epoch 3/20 => Loss 0.927, Train_accy 72.82:  15%|█▌        | 3/20 [00:06<00:36,  2.16s/it]
Task 13, Epoch 4/20 => Loss 0.678, Train_accy 77.67:  15%|█▌        | 3/20 [00:08<00:36,  2.16s/it]
Task 13, Epoch 4/20 => Loss 0.678, Train_accy 77.67:  20%|██        | 4/20 [00:08<00:34,  2.16s/it]
Task 13, Epoch 5/20 => Loss 0.594, Train_accy 78.96:  20%|██        | 4/20 [00:10<00:34,  2.16s/it]
Task 13, Epoch 5/20 => Loss 0.594, Train_accy 78.96:  25%|██▌       | 5/20 [00:10<00:32,  2.17s/it]
Task 13, Epoch 6/20 => Loss 0.429, Train_accy 87.38:  25%|██▌       | 5/20 [00:12<00:32,  2.17s/it]
Task 13, Epoch 6/20 => Loss 0.429, Train_accy 87.38:  30%|███       | 6/20 [00:12<00:30,  2.16s/it]
Task 13, Epoch 7/20 => Loss 0.398, Train_accy 87.06:  30%|███       | 6/20 [00:15<00:30,  2.16s/it]
Task 13, Epoch 7/20 => Loss 0.398, Train_accy 87.06:  35%|███▌      | 7/20 [00:15<00:28,  2.17s/it]
Task 13, Epoch 8/20 => Loss 0.358, Train_accy 90.61:  35%|███▌      | 7/20 [00:17<00:28,  2.17s/it]
Task 13, Epoch 8/20 => Loss 0.358, Train_accy 90.61:  40%|████      | 8/20 [00:17<00:26,  2.19s/it]
Task 13, Epoch 9/20 => Loss 0.297, Train_accy 90.94:  40%|████      | 8/20 [00:19<00:26,  2.19s/it]
Task 13, Epoch 9/20 => Loss 0.297, Train_accy 90.94:  45%|████▌     | 9/20 [00:19<00:24,  2.19s/it]
Task 13, Epoch 10/20 => Loss 0.310, Train_accy 89.97:  45%|████▌     | 9/20 [00:21<00:24,  2.19s/it]
Task 13, Epoch 10/20 => Loss 0.310, Train_accy 89.97:  50%|█████     | 10/20 [00:21<00:21,  2.17s/it]
Task 13, Epoch 11/20 => Loss 0.228, Train_accy 94.82:  50%|█████     | 10/20 [00:23<00:21,  2.17s/it]
Task 13, Epoch 11/20 => Loss 0.228, Train_accy 94.82:  55%|█████▌    | 11/20 [00:23<00:19,  2.17s/it]
Task 13, Epoch 12/20 => Loss 0.267, Train_accy 94.17:  55%|█████▌    | 11/20 [00:25<00:19,  2.17s/it]
Task 13, Epoch 12/20 => Loss 0.267, Train_accy 94.17:  60%|██████    | 12/20 [00:25<00:17,  2.16s/it]
Task 13, Epoch 13/20 => Loss 0.204, Train_accy 95.79:  60%|██████    | 12/20 [00:28<00:17,  2.16s/it]
Task 13, Epoch 13/20 => Loss 0.204, Train_accy 95.79:  65%|██████▌   | 13/20 [00:28<00:15,  2.15s/it]
Task 13, Epoch 14/20 => Loss 0.205, Train_accy 95.47:  65%|██████▌   | 13/20 [00:30<00:15,  2.15s/it]
Task 13, Epoch 14/20 => Loss 0.205, Train_accy 95.47:  70%|███████   | 14/20 [00:30<00:12,  2.15s/it]
Task 13, Epoch 15/20 => Loss 0.262, Train_accy 93.53:  70%|███████   | 14/20 [00:32<00:12,  2.15s/it]
Task 13, Epoch 15/20 => Loss 0.262, Train_accy 93.53:  75%|███████▌  | 15/20 [00:32<00:10,  2.14s/it]
Task 13, Epoch 16/20 => Loss 0.268, Train_accy 93.85:  75%|███████▌  | 15/20 [00:34<00:10,  2.14s/it]
Task 13, Epoch 16/20 => Loss 0.268, Train_accy 93.85:  80%|████████  | 16/20 [00:34<00:08,  2.15s/it]
Task 13, Epoch 17/20 => Loss 0.211, Train_accy 93.20:  80%|████████  | 16/20 [00:36<00:08,  2.15s/it]
Task 13, Epoch 17/20 => Loss 0.211, Train_accy 93.20:  85%|████████▌ | 17/20 [00:36<00:06,  2.16s/it]
Task 13, Epoch 18/20 => Loss 0.155, Train_accy 96.44:  85%|████████▌ | 17/20 [00:38<00:06,  2.16s/it]
Task 13, Epoch 18/20 => Loss 0.155, Train_accy 96.44:  90%|█████████ | 18/20 [00:38<00:04,  2.17s/it]
Task 13, Epoch 19/20 => Loss 0.159, Train_accy 95.47:  90%|█████████ | 18/20 [00:41<00:04,  2.17s/it]
Task 13, Epoch 19/20 => Loss 0.159, Train_accy 95.47:  95%|█████████▌| 19/20 [00:41<00:02,  2.16s/it]
Task 13, Epoch 20/20 => Loss 0.190, Train_accy 93.20:  95%|█████████▌| 19/20 [00:43<00:02,  2.16s/it]
Task 13, Epoch 20/20 => Loss 0.190, Train_accy 93.20: 100%|██████████| 20/20 [00:43<00:00,  2.16s/it]
Task 13, Epoch 20/20 => Loss 0.190, Train_accy 93.20: 100%|██████████| 20/20 [00:43<00:00,  2.16s/it]
2024-08-12 11:35:37,866 [inflora.py] => Task 13, Epoch 20/20 => Loss 0.190, Train_accy 93.20
Threshold:  0.9824999999999999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 34/768 type remove
Layer 4 : 39/768 type remove
Layer 5 : 62/768 type remove
Layer 6 : 61/768 type remove
Layer 7 : 62/768 type remove
Layer 8 : 94/768 type remove
Layer 9 : 153/768 type remove
Layer 10 : 202/768 type remove
Layer 11 : 82/768 type remove
Layer 12 : 109/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:35:47,108 [trainer.py] => Time:56.77835988998413
1121 1121
1121 1121
2024-08-12 11:35:50,211 [trainer.py] => Time:3.102907419204712
2024-08-12 11:35:50,211 [inflora.py] => Exemplar size: 0
2024-08-12 11:35:50,211 [trainer.py] => CNN: {'total': 48.35, '00-09': 45.45, '10-19': 45.92, '20-29': 54.55, '30-39': 55.81, '40-49': 53.12, '50-59': 44.23, '60-69': 50.0, '70-79': 48.96, '80-89': 49.38, '90-99': 43.55, '100-109': 45.0, '110-119': 50.0, '120-129': 28.33, '130-139': 52.33, 'old': 48.02, 'new': 52.33}
2024-08-12 11:35:50,211 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35]
2024-08-12 11:35:50,211 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12]
2024-08-12 11:35:50,211 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266]
Average Accuracy (CNN): 56.72
2024-08-12 11:35:50,215 [trainer.py] => All params: 110611171
2024-08-12 11:35:50,218 [trainer.py] => Trainable params: 81418
2024-08-12 11:35:50,218 [inflora.py] => Learning on 140-150

  0%|          | 0/20 [00:00<?, ?it/s]
Task 14, Epoch 1/20 => Loss 2.361, Train_accy 28.05:   0%|          | 0/20 [00:02<?, ?it/s]
Task 14, Epoch 1/20 => Loss 2.361, Train_accy 28.05:   5%|▌         | 1/20 [00:02<00:41,  2.17s/it]
Task 14, Epoch 2/20 => Loss 1.377, Train_accy 57.01:   5%|▌         | 1/20 [00:04<00:41,  2.17s/it]
Task 14, Epoch 2/20 => Loss 1.377, Train_accy 57.01:  10%|█         | 2/20 [00:04<00:39,  2.18s/it]
Task 14, Epoch 3/20 => Loss 0.997, Train_accy 67.07:  10%|█         | 2/20 [00:06<00:39,  2.18s/it]
Task 14, Epoch 3/20 => Loss 0.997, Train_accy 67.07:  15%|█▌        | 3/20 [00:06<00:37,  2.19s/it]
Task 14, Epoch 4/20 => Loss 0.804, Train_accy 72.87:  15%|█▌        | 3/20 [00:08<00:37,  2.19s/it]
Task 14, Epoch 4/20 => Loss 0.804, Train_accy 72.87:  20%|██        | 4/20 [00:08<00:34,  2.19s/it]
Task 14, Epoch 5/20 => Loss 0.568, Train_accy 81.71:  20%|██        | 4/20 [00:10<00:34,  2.19s/it]
Task 14, Epoch 5/20 => Loss 0.568, Train_accy 81.71:  25%|██▌       | 5/20 [00:10<00:33,  2.21s/it]
Task 14, Epoch 6/20 => Loss 0.496, Train_accy 84.45:  25%|██▌       | 5/20 [00:13<00:33,  2.21s/it]
Task 14, Epoch 6/20 => Loss 0.496, Train_accy 84.45:  30%|███       | 6/20 [00:13<00:30,  2.21s/it]
Task 14, Epoch 7/20 => Loss 0.409, Train_accy 88.72:  30%|███       | 6/20 [00:15<00:30,  2.21s/it]
Task 14, Epoch 7/20 => Loss 0.409, Train_accy 88.72:  35%|███▌      | 7/20 [00:15<00:28,  2.20s/it]
Task 14, Epoch 8/20 => Loss 0.423, Train_accy 86.89:  35%|███▌      | 7/20 [00:17<00:28,  2.20s/it]
Task 14, Epoch 8/20 => Loss 0.423, Train_accy 86.89:  40%|████      | 8/20 [00:17<00:26,  2.21s/it]
Task 14, Epoch 9/20 => Loss 0.334, Train_accy 90.24:  40%|████      | 8/20 [00:19<00:26,  2.21s/it]
Task 14, Epoch 9/20 => Loss 0.334, Train_accy 90.24:  45%|████▌     | 9/20 [00:19<00:24,  2.20s/it]
Task 14, Epoch 10/20 => Loss 0.259, Train_accy 93.60:  45%|████▌     | 9/20 [00:21<00:24,  2.20s/it]
Task 14, Epoch 10/20 => Loss 0.259, Train_accy 93.60:  50%|█████     | 10/20 [00:21<00:21,  2.20s/it]
Task 14, Epoch 11/20 => Loss 0.325, Train_accy 89.33:  50%|█████     | 10/20 [00:24<00:21,  2.20s/it]
Task 14, Epoch 11/20 => Loss 0.325, Train_accy 89.33:  55%|█████▌    | 11/20 [00:24<00:19,  2.20s/it]
Task 14, Epoch 12/20 => Loss 0.309, Train_accy 90.24:  55%|█████▌    | 11/20 [00:26<00:19,  2.20s/it]
Task 14, Epoch 12/20 => Loss 0.309, Train_accy 90.24:  60%|██████    | 12/20 [00:26<00:17,  2.20s/it]
Task 14, Epoch 13/20 => Loss 0.270, Train_accy 92.68:  60%|██████    | 12/20 [00:28<00:17,  2.20s/it]
Task 14, Epoch 13/20 => Loss 0.270, Train_accy 92.68:  65%|██████▌   | 13/20 [00:28<00:15,  2.19s/it]
Task 14, Epoch 14/20 => Loss 0.240, Train_accy 94.82:  65%|██████▌   | 13/20 [00:30<00:15,  2.19s/it]
Task 14, Epoch 14/20 => Loss 0.240, Train_accy 94.82:  70%|███████   | 14/20 [00:30<00:13,  2.20s/it]
Task 14, Epoch 15/20 => Loss 0.235, Train_accy 93.60:  70%|███████   | 14/20 [00:32<00:13,  2.20s/it]
Task 14, Epoch 15/20 => Loss 0.235, Train_accy 93.60:  75%|███████▌  | 15/20 [00:32<00:10,  2.19s/it]
Task 14, Epoch 16/20 => Loss 0.214, Train_accy 94.51:  75%|███████▌  | 15/20 [00:35<00:10,  2.19s/it]
Task 14, Epoch 16/20 => Loss 0.214, Train_accy 94.51:  80%|████████  | 16/20 [00:35<00:08,  2.20s/it]
Task 14, Epoch 17/20 => Loss 0.192, Train_accy 94.21:  80%|████████  | 16/20 [00:37<00:08,  2.20s/it]
Task 14, Epoch 17/20 => Loss 0.192, Train_accy 94.21:  85%|████████▌ | 17/20 [00:37<00:06,  2.22s/it]
Task 14, Epoch 18/20 => Loss 0.214, Train_accy 94.21:  85%|████████▌ | 17/20 [00:39<00:06,  2.22s/it]
Task 14, Epoch 18/20 => Loss 0.214, Train_accy 94.21:  90%|█████████ | 18/20 [00:39<00:04,  2.20s/it]
Task 14, Epoch 19/20 => Loss 0.208, Train_accy 92.68:  90%|█████████ | 18/20 [00:41<00:04,  2.20s/it]
Task 14, Epoch 19/20 => Loss 0.208, Train_accy 92.68:  95%|█████████▌| 19/20 [00:41<00:02,  2.22s/it]
Task 14, Epoch 20/20 => Loss 0.245, Train_accy 92.99:  95%|█████████▌| 19/20 [00:44<00:02,  2.22s/it]
Task 14, Epoch 20/20 => Loss 0.245, Train_accy 92.99: 100%|██████████| 20/20 [00:44<00:00,  2.23s/it]
Task 14, Epoch 20/20 => Loss 0.245, Train_accy 92.99: 100%|██████████| 20/20 [00:44<00:00,  2.20s/it]
2024-08-12 11:36:38,478 [inflora.py] => Task 14, Epoch 20/20 => Loss 0.245, Train_accy 92.99
Threshold:  0.985
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 36/768 type remove
Layer 4 : 43/768 type remove
Layer 5 : 68/768 type remove
Layer 6 : 68/768 type remove
Layer 7 : 72/768 type remove
Layer 8 : 105/768 type remove
Layer 9 : 163/768 type remove
Layer 10 : 213/768 type remove
Layer 11 : 90/768 type remove
Layer 12 : 123/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:36:47,592 [trainer.py] => Time:57.373799085617065
1197 1197
1197 1197
2024-08-12 11:36:50,848 [trainer.py] => Time:3.255856990814209
2024-08-12 11:36:50,848 [inflora.py] => Exemplar size: 0
2024-08-12 11:36:50,848 [trainer.py] => CNN: {'total': 47.87, '00-09': 46.75, '10-19': 44.9, '20-29': 53.54, '30-39': 52.33, '40-49': 51.56, '50-59': 40.38, '60-69': 49.21, '70-79': 46.88, '80-89': 49.38, '90-99': 43.55, '100-109': 46.67, '110-119': 51.35, '120-129': 30.0, '130-139': 53.49, '140-149': 48.68, 'old': 47.81, 'new': 48.68}
2024-08-12 11:36:50,848 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87]
2024-08-12 11:36:50,848 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38]
2024-08-12 11:36:50,848 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857]
Average Accuracy (CNN): 56.13
2024-08-12 11:36:50,852 [trainer.py] => All params: 110611171
2024-08-12 11:36:50,856 [trainer.py] => Trainable params: 81418
2024-08-12 11:36:50,856 [inflora.py] => Learning on 150-160

  0%|          | 0/20 [00:00<?, ?it/s]
Task 15, Epoch 1/20 => Loss 2.772, Train_accy 10.84:   0%|          | 0/20 [00:01<?, ?it/s]
Task 15, Epoch 1/20 => Loss 2.772, Train_accy 10.84:   5%|▌         | 1/20 [00:01<00:33,  1.76s/it]
Task 15, Epoch 2/20 => Loss 1.683, Train_accy 45.81:   5%|▌         | 1/20 [00:03<00:33,  1.76s/it]
Task 15, Epoch 2/20 => Loss 1.683, Train_accy 45.81:  10%|█         | 2/20 [00:03<00:31,  1.76s/it]
Task 15, Epoch 3/20 => Loss 1.231, Train_accy 61.58:  10%|█         | 2/20 [00:05<00:31,  1.76s/it]
Task 15, Epoch 3/20 => Loss 1.231, Train_accy 61.58:  15%|█▌        | 3/20 [00:05<00:29,  1.76s/it]
Task 15, Epoch 4/20 => Loss 0.971, Train_accy 68.47:  15%|█▌        | 3/20 [00:07<00:29,  1.76s/it]
Task 15, Epoch 4/20 => Loss 0.971, Train_accy 68.47:  20%|██        | 4/20 [00:07<00:28,  1.78s/it]
Task 15, Epoch 5/20 => Loss 0.787, Train_accy 76.35:  20%|██        | 4/20 [00:08<00:28,  1.78s/it]
Task 15, Epoch 5/20 => Loss 0.787, Train_accy 76.35:  25%|██▌       | 5/20 [00:08<00:26,  1.77s/it]
Task 15, Epoch 6/20 => Loss 0.572, Train_accy 84.24:  25%|██▌       | 5/20 [00:10<00:26,  1.77s/it]
Task 15, Epoch 6/20 => Loss 0.572, Train_accy 84.24:  30%|███       | 6/20 [00:10<00:24,  1.77s/it]
Task 15, Epoch 7/20 => Loss 0.503, Train_accy 86.21:  30%|███       | 6/20 [00:12<00:24,  1.77s/it]
Task 15, Epoch 7/20 => Loss 0.503, Train_accy 86.21:  35%|███▌      | 7/20 [00:12<00:23,  1.77s/it]
Task 15, Epoch 8/20 => Loss 0.344, Train_accy 90.64:  35%|███▌      | 7/20 [00:14<00:23,  1.77s/it]
Task 15, Epoch 8/20 => Loss 0.344, Train_accy 90.64:  40%|████      | 8/20 [00:14<00:21,  1.78s/it]
Task 15, Epoch 9/20 => Loss 0.348, Train_accy 92.61:  40%|████      | 8/20 [00:15<00:21,  1.78s/it]
Task 15, Epoch 9/20 => Loss 0.348, Train_accy 92.61:  45%|████▌     | 9/20 [00:15<00:19,  1.78s/it]
Task 15, Epoch 10/20 => Loss 0.272, Train_accy 95.57:  45%|████▌     | 9/20 [00:17<00:19,  1.78s/it]
Task 15, Epoch 10/20 => Loss 0.272, Train_accy 95.57:  50%|█████     | 10/20 [00:17<00:17,  1.79s/it]
Task 15, Epoch 11/20 => Loss 0.283, Train_accy 93.10:  50%|█████     | 10/20 [00:19<00:17,  1.79s/it]
Task 15, Epoch 11/20 => Loss 0.283, Train_accy 93.10:  55%|█████▌    | 11/20 [00:19<00:16,  1.79s/it]
Task 15, Epoch 12/20 => Loss 0.196, Train_accy 96.06:  55%|█████▌    | 11/20 [00:21<00:16,  1.79s/it]
Task 15, Epoch 12/20 => Loss 0.196, Train_accy 96.06:  60%|██████    | 12/20 [00:21<00:14,  1.79s/it]
Task 15, Epoch 13/20 => Loss 0.222, Train_accy 94.58:  60%|██████    | 12/20 [00:23<00:14,  1.79s/it]
Task 15, Epoch 13/20 => Loss 0.222, Train_accy 94.58:  65%|██████▌   | 13/20 [00:23<00:12,  1.80s/it]
Task 15, Epoch 14/20 => Loss 0.203, Train_accy 94.58:  65%|██████▌   | 13/20 [00:24<00:12,  1.80s/it]
Task 15, Epoch 14/20 => Loss 0.203, Train_accy 94.58:  70%|███████   | 14/20 [00:24<00:10,  1.78s/it]
Task 15, Epoch 15/20 => Loss 0.229, Train_accy 94.09:  70%|███████   | 14/20 [00:26<00:10,  1.78s/it]
Task 15, Epoch 15/20 => Loss 0.229, Train_accy 94.09:  75%|███████▌  | 15/20 [00:26<00:08,  1.79s/it]
Task 15, Epoch 16/20 => Loss 0.250, Train_accy 92.61:  75%|███████▌  | 15/20 [00:28<00:08,  1.79s/it]
Task 15, Epoch 16/20 => Loss 0.250, Train_accy 92.61:  80%|████████  | 16/20 [00:28<00:07,  1.78s/it]
Task 15, Epoch 17/20 => Loss 0.183, Train_accy 94.58:  80%|████████  | 16/20 [00:30<00:07,  1.78s/it]
Task 15, Epoch 17/20 => Loss 0.183, Train_accy 94.58:  85%|████████▌ | 17/20 [00:30<00:05,  1.78s/it]
Task 15, Epoch 18/20 => Loss 0.177, Train_accy 96.06:  85%|████████▌ | 17/20 [00:32<00:05,  1.78s/it]
Task 15, Epoch 18/20 => Loss 0.177, Train_accy 96.06:  90%|█████████ | 18/20 [00:32<00:03,  1.78s/it]
Task 15, Epoch 19/20 => Loss 0.138, Train_accy 97.04:  90%|█████████ | 18/20 [00:33<00:03,  1.78s/it]
Task 15, Epoch 19/20 => Loss 0.138, Train_accy 97.04:  95%|█████████▌| 19/20 [00:33<00:01,  1.78s/it]
Task 15, Epoch 20/20 => Loss 0.172, Train_accy 95.07:  95%|█████████▌| 19/20 [00:35<00:01,  1.78s/it]
Task 15, Epoch 20/20 => Loss 0.172, Train_accy 95.07: 100%|██████████| 20/20 [00:35<00:00,  1.79s/it]
Task 15, Epoch 20/20 => Loss 0.172, Train_accy 95.07: 100%|██████████| 20/20 [00:35<00:00,  1.78s/it]
2024-08-12 11:37:30,497 [inflora.py] => Task 15, Epoch 20/20 => Loss 0.172, Train_accy 95.07
Threshold:  0.9875
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 22/768 type remove
Layer 3 : 44/768 type remove
Layer 4 : 54/768 type remove
Layer 5 : 85/768 type remove
Layer 6 : 84/768 type remove
Layer 7 : 89/768 type remove
Layer 8 : 132/768 type remove
Layer 9 : 211/768 type remove
Layer 10 : 274/768 type remove
Layer 11 : 143/768 type remove
Layer 12 : 178/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:37:39,174 [trainer.py] => Time:48.31762671470642
1248 1248
1248 1248
2024-08-12 11:37:42,715 [trainer.py] => Time:3.541074752807617
2024-08-12 11:37:42,715 [inflora.py] => Exemplar size: 0
2024-08-12 11:37:42,715 [trainer.py] => CNN: {'total': 46.55, '00-09': 45.45, '10-19': 44.9, '20-29': 51.52, '30-39': 51.16, '40-49': 54.69, '50-59': 42.31, '60-69': 47.62, '70-79': 48.96, '80-89': 49.38, '90-99': 41.94, '100-109': 46.67, '110-119': 48.65, '120-129': 30.0, '130-139': 52.33, '140-149': 48.68, '150-159': 25.49, 'old': 47.45, 'new': 25.49}
2024-08-12 11:37:42,715 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87, 46.55]
2024-08-12 11:37:42,715 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38, 83.41]
2024-08-12 11:37:42,715 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857, 0.47836538461538464]
Average Accuracy (CNN): 55.53
2024-08-12 11:37:42,719 [trainer.py] => All params: 110611171
2024-08-12 11:37:42,723 [trainer.py] => Trainable params: 81418
2024-08-12 11:37:42,723 [inflora.py] => Learning on 160-170

  0%|          | 0/20 [00:00<?, ?it/s]
Task 16, Epoch 1/20 => Loss 2.920, Train_accy 12.28:   0%|          | 0/20 [00:02<?, ?it/s]
Task 16, Epoch 1/20 => Loss 2.920, Train_accy 12.28:   5%|▌         | 1/20 [00:02<00:43,  2.27s/it]
Task 16, Epoch 2/20 => Loss 1.836, Train_accy 37.43:   5%|▌         | 1/20 [00:04<00:43,  2.27s/it]
Task 16, Epoch 2/20 => Loss 1.836, Train_accy 37.43:  10%|█         | 2/20 [00:04<00:41,  2.32s/it]
Task 16, Epoch 3/20 => Loss 1.357, Train_accy 55.09:  10%|█         | 2/20 [00:06<00:41,  2.32s/it]
Task 16, Epoch 3/20 => Loss 1.357, Train_accy 55.09:  15%|█▌        | 3/20 [00:06<00:38,  2.29s/it]
Task 16, Epoch 4/20 => Loss 1.015, Train_accy 67.37:  15%|█▌        | 3/20 [00:09<00:38,  2.29s/it]
Task 16, Epoch 4/20 => Loss 1.015, Train_accy 67.37:  20%|██        | 4/20 [00:09<00:36,  2.27s/it]
Task 16, Epoch 5/20 => Loss 0.843, Train_accy 73.65:  20%|██        | 4/20 [00:11<00:36,  2.27s/it]
Task 16, Epoch 5/20 => Loss 0.843, Train_accy 73.65:  25%|██▌       | 5/20 [00:11<00:34,  2.27s/it]
Task 16, Epoch 6/20 => Loss 0.636, Train_accy 79.94:  25%|██▌       | 5/20 [00:13<00:34,  2.27s/it]
Task 16, Epoch 6/20 => Loss 0.636, Train_accy 79.94:  30%|███       | 6/20 [00:13<00:31,  2.26s/it]
Task 16, Epoch 7/20 => Loss 0.565, Train_accy 81.74:  30%|███       | 6/20 [00:15<00:31,  2.26s/it]
Task 16, Epoch 7/20 => Loss 0.565, Train_accy 81.74:  35%|███▌      | 7/20 [00:15<00:29,  2.26s/it]
Task 16, Epoch 8/20 => Loss 0.472, Train_accy 85.03:  35%|███▌      | 7/20 [00:18<00:29,  2.26s/it]
Task 16, Epoch 8/20 => Loss 0.472, Train_accy 85.03:  40%|████      | 8/20 [00:18<00:27,  2.27s/it]
Task 16, Epoch 9/20 => Loss 0.437, Train_accy 86.83:  40%|████      | 8/20 [00:20<00:27,  2.27s/it]
Task 16, Epoch 9/20 => Loss 0.437, Train_accy 86.83:  45%|████▌     | 9/20 [00:20<00:24,  2.26s/it]
Task 16, Epoch 10/20 => Loss 0.434, Train_accy 86.23:  45%|████▌     | 9/20 [00:22<00:24,  2.26s/it]
Task 16, Epoch 10/20 => Loss 0.434, Train_accy 86.23:  50%|█████     | 10/20 [00:22<00:22,  2.25s/it]
Task 16, Epoch 11/20 => Loss 0.362, Train_accy 89.22:  50%|█████     | 10/20 [00:24<00:22,  2.25s/it]
Task 16, Epoch 11/20 => Loss 0.362, Train_accy 89.22:  55%|█████▌    | 11/20 [00:24<00:20,  2.26s/it]
Task 16, Epoch 12/20 => Loss 0.341, Train_accy 89.52:  55%|█████▌    | 11/20 [00:27<00:20,  2.26s/it]
Task 16, Epoch 12/20 => Loss 0.341, Train_accy 89.52:  60%|██████    | 12/20 [00:27<00:18,  2.25s/it]
Task 16, Epoch 13/20 => Loss 0.336, Train_accy 89.82:  60%|██████    | 12/20 [00:29<00:18,  2.25s/it]
Task 16, Epoch 13/20 => Loss 0.336, Train_accy 89.82:  65%|██████▌   | 13/20 [00:29<00:15,  2.25s/it]
Task 16, Epoch 14/20 => Loss 0.289, Train_accy 91.62:  65%|██████▌   | 13/20 [00:31<00:15,  2.25s/it]
Task 16, Epoch 14/20 => Loss 0.289, Train_accy 91.62:  70%|███████   | 14/20 [00:31<00:13,  2.25s/it]
Task 16, Epoch 15/20 => Loss 0.300, Train_accy 90.42:  70%|███████   | 14/20 [00:33<00:13,  2.25s/it]
Task 16, Epoch 15/20 => Loss 0.300, Train_accy 90.42:  75%|███████▌  | 15/20 [00:33<00:11,  2.24s/it]
Task 16, Epoch 16/20 => Loss 0.298, Train_accy 91.62:  75%|███████▌  | 15/20 [00:36<00:11,  2.24s/it]
Task 16, Epoch 16/20 => Loss 0.298, Train_accy 91.62:  80%|████████  | 16/20 [00:36<00:08,  2.25s/it]
Task 16, Epoch 17/20 => Loss 0.263, Train_accy 92.22:  80%|████████  | 16/20 [00:38<00:08,  2.25s/it]
Task 16, Epoch 17/20 => Loss 0.263, Train_accy 92.22:  85%|████████▌ | 17/20 [00:38<00:06,  2.25s/it]
Task 16, Epoch 18/20 => Loss 0.257, Train_accy 94.31:  85%|████████▌ | 17/20 [00:40<00:06,  2.25s/it]
Task 16, Epoch 18/20 => Loss 0.257, Train_accy 94.31:  90%|█████████ | 18/20 [00:40<00:04,  2.24s/it]
Task 16, Epoch 19/20 => Loss 0.240, Train_accy 92.81:  90%|█████████ | 18/20 [00:42<00:04,  2.24s/it]
Task 16, Epoch 19/20 => Loss 0.240, Train_accy 92.81:  95%|█████████▌| 19/20 [00:42<00:02,  2.24s/it]
Task 16, Epoch 20/20 => Loss 0.256, Train_accy 91.92:  95%|█████████▌| 19/20 [00:45<00:02,  2.24s/it]
Task 16, Epoch 20/20 => Loss 0.256, Train_accy 91.92: 100%|██████████| 20/20 [00:45<00:00,  2.24s/it]
Task 16, Epoch 20/20 => Loss 0.256, Train_accy 91.92: 100%|██████████| 20/20 [00:45<00:00,  2.25s/it]
2024-08-12 11:38:31,979 [inflora.py] => Task 16, Epoch 20/20 => Loss 0.256, Train_accy 91.92
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 27/768 type remove
Layer 3 : 52/768 type remove
Layer 4 : 65/768 type remove
Layer 5 : 101/768 type remove
Layer 6 : 100/768 type remove
Layer 7 : 107/768 type remove
Layer 8 : 153/768 type remove
Layer 9 : 242/768 type remove
Layer 10 : 327/768 type remove
Layer 11 : 193/768 type remove
Layer 12 : 243/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:38:40,505 [trainer.py] => Time:57.78228974342346
1333 1333
1333 1333
2024-08-12 11:38:44,027 [trainer.py] => Time:3.521080493927002
2024-08-12 11:38:44,027 [inflora.py] => Exemplar size: 0
2024-08-12 11:38:44,027 [trainer.py] => CNN: {'total': 44.79, '00-09': 44.16, '10-19': 43.88, '20-29': 49.49, '30-39': 50.0, '40-49': 50.0, '50-59': 44.23, '60-69': 46.83, '70-79': 46.88, '80-89': 49.38, '90-99': 41.94, '100-109': 48.33, '110-119': 44.59, '120-129': 31.67, '130-139': 51.16, '140-149': 50.0, '150-159': 27.45, '160-169': 30.59, 'old': 45.75, 'new': 30.59}
2024-08-12 11:38:44,027 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87, 46.55, 44.79]
2024-08-12 11:38:44,027 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38, 83.41, 83.5]
2024-08-12 11:38:44,027 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857, 0.47836538461538464, 0.45911477869467365]
Average Accuracy (CNN): 54.9
2024-08-12 11:38:44,031 [trainer.py] => All params: 110611171
2024-08-12 11:38:44,034 [trainer.py] => Trainable params: 81418
2024-08-12 11:38:44,035 [inflora.py] => Learning on 170-180

  0%|          | 0/20 [00:00<?, ?it/s]
Task 17, Epoch 1/20 => Loss 2.514, Train_accy 19.83:   0%|          | 0/20 [00:01<?, ?it/s]
Task 17, Epoch 1/20 => Loss 2.514, Train_accy 19.83:   5%|▌         | 1/20 [00:01<00:35,  1.86s/it]
Task 17, Epoch 2/20 => Loss 1.605, Train_accy 48.10:   5%|▌         | 1/20 [00:03<00:35,  1.86s/it]
Task 17, Epoch 2/20 => Loss 1.605, Train_accy 48.10:  10%|█         | 2/20 [00:03<00:33,  1.89s/it]
Task 17, Epoch 3/20 => Loss 1.289, Train_accy 58.65:  10%|█         | 2/20 [00:05<00:33,  1.89s/it]
Task 17, Epoch 3/20 => Loss 1.289, Train_accy 58.65:  15%|█▌        | 3/20 [00:05<00:32,  1.89s/it]
Task 17, Epoch 4/20 => Loss 0.998, Train_accy 68.35:  15%|█▌        | 3/20 [00:07<00:32,  1.89s/it]
Task 17, Epoch 4/20 => Loss 0.998, Train_accy 68.35:  20%|██        | 4/20 [00:07<00:30,  1.92s/it]
Task 17, Epoch 5/20 => Loss 0.723, Train_accy 78.06:  20%|██        | 4/20 [00:09<00:30,  1.92s/it]
Task 17, Epoch 5/20 => Loss 0.723, Train_accy 78.06:  25%|██▌       | 5/20 [00:09<00:28,  1.92s/it]
Task 17, Epoch 6/20 => Loss 0.573, Train_accy 81.86:  25%|██▌       | 5/20 [00:11<00:28,  1.92s/it]
Task 17, Epoch 6/20 => Loss 0.573, Train_accy 81.86:  30%|███       | 6/20 [00:11<00:26,  1.92s/it]
Task 17, Epoch 7/20 => Loss 0.480, Train_accy 86.08:  30%|███       | 6/20 [00:13<00:26,  1.92s/it]
Task 17, Epoch 7/20 => Loss 0.480, Train_accy 86.08:  35%|███▌      | 7/20 [00:13<00:24,  1.91s/it]
Task 17, Epoch 8/20 => Loss 0.384, Train_accy 91.14:  35%|███▌      | 7/20 [00:15<00:24,  1.91s/it]
Task 17, Epoch 8/20 => Loss 0.384, Train_accy 91.14:  40%|████      | 8/20 [00:15<00:22,  1.91s/it]
Task 17, Epoch 9/20 => Loss 0.338, Train_accy 89.87:  40%|████      | 8/20 [00:17<00:22,  1.91s/it]
Task 17, Epoch 9/20 => Loss 0.338, Train_accy 89.87:  45%|████▌     | 9/20 [00:17<00:20,  1.90s/it]
Task 17, Epoch 10/20 => Loss 0.333, Train_accy 93.67:  45%|████▌     | 9/20 [00:19<00:20,  1.90s/it]
Task 17, Epoch 10/20 => Loss 0.333, Train_accy 93.67:  50%|█████     | 10/20 [00:19<00:18,  1.90s/it]
Task 17, Epoch 11/20 => Loss 0.295, Train_accy 91.14:  50%|█████     | 10/20 [00:20<00:18,  1.90s/it]
Task 17, Epoch 11/20 => Loss 0.295, Train_accy 91.14:  55%|█████▌    | 11/20 [00:20<00:17,  1.90s/it]
Task 17, Epoch 12/20 => Loss 0.301, Train_accy 91.56:  55%|█████▌    | 11/20 [00:22<00:17,  1.90s/it]
Task 17, Epoch 12/20 => Loss 0.301, Train_accy 91.56:  60%|██████    | 12/20 [00:22<00:15,  1.90s/it]
Task 17, Epoch 13/20 => Loss 0.223, Train_accy 94.09:  60%|██████    | 12/20 [00:24<00:15,  1.90s/it]
Task 17, Epoch 13/20 => Loss 0.223, Train_accy 94.09:  65%|██████▌   | 13/20 [00:24<00:13,  1.89s/it]
Task 17, Epoch 14/20 => Loss 0.212, Train_accy 94.51:  65%|██████▌   | 13/20 [00:26<00:13,  1.89s/it]
Task 17, Epoch 14/20 => Loss 0.212, Train_accy 94.51:  70%|███████   | 14/20 [00:26<00:11,  1.89s/it]
Task 17, Epoch 15/20 => Loss 0.236, Train_accy 92.41:  70%|███████   | 14/20 [00:28<00:11,  1.89s/it]
Task 17, Epoch 15/20 => Loss 0.236, Train_accy 92.41:  75%|███████▌  | 15/20 [00:28<00:09,  1.88s/it]
Task 17, Epoch 16/20 => Loss 0.210, Train_accy 95.36:  75%|███████▌  | 15/20 [00:30<00:09,  1.88s/it]
Task 17, Epoch 16/20 => Loss 0.210, Train_accy 95.36:  80%|████████  | 16/20 [00:30<00:07,  1.89s/it]
Task 17, Epoch 17/20 => Loss 0.218, Train_accy 94.09:  80%|████████  | 16/20 [00:32<00:07,  1.89s/it]
Task 17, Epoch 17/20 => Loss 0.218, Train_accy 94.09:  85%|████████▌ | 17/20 [00:32<00:05,  1.89s/it]
Task 17, Epoch 18/20 => Loss 0.166, Train_accy 96.62:  85%|████████▌ | 17/20 [00:34<00:05,  1.89s/it]
Task 17, Epoch 18/20 => Loss 0.166, Train_accy 96.62:  90%|█████████ | 18/20 [00:34<00:03,  1.89s/it]
Task 17, Epoch 19/20 => Loss 0.220, Train_accy 93.25:  90%|█████████ | 18/20 [00:36<00:03,  1.89s/it]
Task 17, Epoch 19/20 => Loss 0.220, Train_accy 93.25:  95%|█████████▌| 19/20 [00:36<00:01,  1.89s/it]
Task 17, Epoch 20/20 => Loss 0.225, Train_accy 93.67:  95%|█████████▌| 19/20 [00:37<00:01,  1.89s/it]
Task 17, Epoch 20/20 => Loss 0.225, Train_accy 93.67: 100%|██████████| 20/20 [00:37<00:00,  1.89s/it]
Task 17, Epoch 20/20 => Loss 0.225, Train_accy 93.67: 100%|██████████| 20/20 [00:37<00:00,  1.90s/it]
2024-08-12 11:39:26,213 [inflora.py] => Task 17, Epoch 20/20 => Loss 0.225, Train_accy 93.67
Threshold:  0.9924999999999999
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 33/768 type remove
Layer 3 : 64/768 type remove
Layer 4 : 83/768 type remove
Layer 5 : 126/768 type remove
Layer 6 : 126/768 type remove
Layer 7 : 138/768 type remove
Layer 8 : 196/768 type remove
Layer 9 : 295/768 type remove
Layer 10 : 383/768 type remove
Layer 11 : 245/768 type remove
Layer 12 : 295/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:39:35,353 [trainer.py] => Time:51.31832718849182
1395 1395
1395 1395
2024-08-12 11:39:38,957 [trainer.py] => Time:3.6043128967285156
2024-08-12 11:39:38,958 [inflora.py] => Exemplar size: 0
2024-08-12 11:39:38,958 [trainer.py] => CNN: {'total': 43.08, '00-09': 41.56, '10-19': 42.86, '20-29': 47.47, '30-39': 51.16, '40-49': 50.0, '50-59': 46.15, '60-69': 48.41, '70-79': 44.79, '80-89': 43.21, '90-99': 41.94, '100-109': 48.33, '110-119': 47.3, '120-129': 26.67, '130-139': 52.33, '140-149': 48.68, '150-159': 27.45, '160-169': 27.06, '170-179': 25.81, 'old': 43.89, 'new': 25.81}
2024-08-12 11:39:38,958 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87, 46.55, 44.79, 43.08]
2024-08-12 11:39:38,958 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38, 83.41, 83.5, 83.23]
2024-08-12 11:39:38,958 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857, 0.47836538461538464, 0.45911477869467365, 0.443010752688172]
Average Accuracy (CNN): 54.24
2024-08-12 11:39:38,961 [trainer.py] => All params: 110611171
2024-08-12 11:39:38,964 [trainer.py] => Trainable params: 81418
2024-08-12 11:39:38,964 [inflora.py] => Learning on 180-190

  0%|          | 0/20 [00:00<?, ?it/s]
Task 18, Epoch 1/20 => Loss 3.092, Train_accy 12.17:   0%|          | 0/20 [00:01<?, ?it/s]
Task 18, Epoch 1/20 => Loss 3.092, Train_accy 12.17:   5%|▌         | 1/20 [00:01<00:34,  1.79s/it]
Task 18, Epoch 2/20 => Loss 2.009, Train_accy 37.04:   5%|▌         | 1/20 [00:03<00:34,  1.79s/it]
Task 18, Epoch 2/20 => Loss 2.009, Train_accy 37.04:  10%|█         | 2/20 [00:03<00:32,  1.79s/it]
Task 18, Epoch 3/20 => Loss 1.408, Train_accy 56.61:  10%|█         | 2/20 [00:05<00:32,  1.79s/it]
Task 18, Epoch 3/20 => Loss 1.408, Train_accy 56.61:  15%|█▌        | 3/20 [00:05<00:30,  1.80s/it]
Task 18, Epoch 4/20 => Loss 1.055, Train_accy 62.43:  15%|█▌        | 3/20 [00:07<00:30,  1.80s/it]
Task 18, Epoch 4/20 => Loss 1.055, Train_accy 62.43:  20%|██        | 4/20 [00:07<00:29,  1.81s/it]
Task 18, Epoch 5/20 => Loss 0.820, Train_accy 69.84:  20%|██        | 4/20 [00:08<00:29,  1.81s/it]
Task 18, Epoch 5/20 => Loss 0.820, Train_accy 69.84:  25%|██▌       | 5/20 [00:08<00:26,  1.79s/it]
Task 18, Epoch 6/20 => Loss 0.674, Train_accy 79.89:  25%|██▌       | 5/20 [00:10<00:26,  1.79s/it]
Task 18, Epoch 6/20 => Loss 0.674, Train_accy 79.89:  30%|███       | 6/20 [00:10<00:25,  1.79s/it]
Task 18, Epoch 7/20 => Loss 0.529, Train_accy 82.54:  30%|███       | 6/20 [00:12<00:25,  1.79s/it]
Task 18, Epoch 7/20 => Loss 0.529, Train_accy 82.54:  35%|███▌      | 7/20 [00:12<00:23,  1.79s/it]
Task 18, Epoch 8/20 => Loss 0.389, Train_accy 88.36:  35%|███▌      | 7/20 [00:14<00:23,  1.79s/it]
Task 18, Epoch 8/20 => Loss 0.389, Train_accy 88.36:  40%|████      | 8/20 [00:14<00:21,  1.78s/it]
Task 18, Epoch 9/20 => Loss 0.410, Train_accy 87.30:  40%|████      | 8/20 [00:16<00:21,  1.78s/it]
Task 18, Epoch 9/20 => Loss 0.410, Train_accy 87.30:  45%|████▌     | 9/20 [00:16<00:19,  1.78s/it]
Task 18, Epoch 10/20 => Loss 0.306, Train_accy 92.06:  45%|████▌     | 9/20 [00:17<00:19,  1.78s/it]
Task 18, Epoch 10/20 => Loss 0.306, Train_accy 92.06:  50%|█████     | 10/20 [00:17<00:17,  1.76s/it]
Task 18, Epoch 11/20 => Loss 0.327, Train_accy 91.53:  50%|█████     | 10/20 [00:19<00:17,  1.76s/it]
Task 18, Epoch 11/20 => Loss 0.327, Train_accy 91.53:  55%|█████▌    | 11/20 [00:19<00:15,  1.78s/it]
Task 18, Epoch 12/20 => Loss 0.234, Train_accy 95.24:  55%|█████▌    | 11/20 [00:21<00:15,  1.78s/it]
Task 18, Epoch 12/20 => Loss 0.234, Train_accy 95.24:  60%|██████    | 12/20 [00:21<00:14,  1.78s/it]
Task 18, Epoch 13/20 => Loss 0.264, Train_accy 93.65:  60%|██████    | 12/20 [00:23<00:14,  1.78s/it]
Task 18, Epoch 13/20 => Loss 0.264, Train_accy 93.65:  65%|██████▌   | 13/20 [00:23<00:12,  1.78s/it]
Task 18, Epoch 14/20 => Loss 0.222, Train_accy 95.24:  65%|██████▌   | 13/20 [00:24<00:12,  1.78s/it]
Task 18, Epoch 14/20 => Loss 0.222, Train_accy 95.24:  70%|███████   | 14/20 [00:24<00:10,  1.78s/it]
Task 18, Epoch 15/20 => Loss 0.263, Train_accy 95.24:  70%|███████   | 14/20 [00:26<00:10,  1.78s/it]
Task 18, Epoch 15/20 => Loss 0.263, Train_accy 95.24:  75%|███████▌  | 15/20 [00:26<00:08,  1.79s/it]
Task 18, Epoch 16/20 => Loss 0.266, Train_accy 92.59:  75%|███████▌  | 15/20 [00:28<00:08,  1.79s/it]
Task 18, Epoch 16/20 => Loss 0.266, Train_accy 92.59:  80%|████████  | 16/20 [00:28<00:07,  1.81s/it]
Task 18, Epoch 17/20 => Loss 0.225, Train_accy 94.18:  80%|████████  | 16/20 [00:30<00:07,  1.81s/it]
Task 18, Epoch 17/20 => Loss 0.225, Train_accy 94.18:  85%|████████▌ | 17/20 [00:30<00:05,  1.79s/it]
Task 18, Epoch 18/20 => Loss 0.208, Train_accy 94.71:  85%|████████▌ | 17/20 [00:32<00:05,  1.79s/it]
Task 18, Epoch 18/20 => Loss 0.208, Train_accy 94.71:  90%|█████████ | 18/20 [00:32<00:03,  1.80s/it]
Task 18, Epoch 19/20 => Loss 0.186, Train_accy 95.24:  90%|█████████ | 18/20 [00:33<00:03,  1.80s/it]
Task 18, Epoch 19/20 => Loss 0.186, Train_accy 95.24:  95%|█████████▌| 19/20 [00:33<00:01,  1.79s/it]
Task 18, Epoch 20/20 => Loss 0.201, Train_accy 94.18:  95%|█████████▌| 19/20 [00:35<00:01,  1.79s/it]
Task 18, Epoch 20/20 => Loss 0.201, Train_accy 94.18: 100%|██████████| 20/20 [00:35<00:00,  1.79s/it]
Task 18, Epoch 20/20 => Loss 0.201, Train_accy 94.18: 100%|██████████| 20/20 [00:35<00:00,  1.79s/it]
2024-08-12 11:40:18,452 [inflora.py] => Task 18, Epoch 20/20 => Loss 0.201, Train_accy 94.18
Threshold:  0.995
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 11/768 type remove
Layer 2 : 43/768 type remove
Layer 3 : 88/768 type remove
Layer 4 : 115/768 type remove
Layer 5 : 167/768 type remove
Layer 6 : 168/768 type remove
Layer 7 : 186/768 type remove
Layer 8 : 269/768 type remove
Layer 9 : 383/768 type remove
Layer 10 : 308/768 type retain
Layer 11 : 327/768 type remove
Layer 12 : 371/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:40:27,359 [trainer.py] => Time:48.39444637298584
1434 1434
1434 1434
2024-08-12 11:40:31,252 [trainer.py] => Time:3.8928675651550293
2024-08-12 11:40:31,252 [inflora.py] => Exemplar size: 0
2024-08-12 11:40:31,252 [trainer.py] => CNN: {'total': 42.75, '00-09': 45.45, '10-19': 44.9, '20-29': 47.47, '30-39': 51.16, '40-49': 50.0, '50-59': 42.31, '60-69': 49.21, '70-79': 41.67, '80-89': 45.68, '90-99': 38.71, '100-109': 48.33, '110-119': 45.95, '120-129': 26.67, '130-139': 51.16, '140-149': 51.32, '150-159': 27.45, '160-169': 30.59, '170-179': 25.81, '180-189': 20.51, 'old': 43.37, 'new': 20.51}
2024-08-12 11:40:31,252 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87, 46.55, 44.79, 43.08, 42.75]
2024-08-12 11:40:31,252 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38, 83.41, 83.5, 83.23, 83.26]
2024-08-12 11:40:31,252 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857, 0.47836538461538464, 0.45911477869467365, 0.443010752688172, 0.4393305439330544]
Average Accuracy (CNN): 53.64
2024-08-12 11:40:31,256 [trainer.py] => All params: 110611171
2024-08-12 11:40:31,259 [trainer.py] => Trainable params: 81418
2024-08-12 11:40:31,260 [inflora.py] => Learning on 190-200

  0%|          | 0/20 [00:00<?, ?it/s]
Task 19, Epoch 1/20 => Loss 2.651, Train_accy 20.12:   0%|          | 0/20 [00:02<?, ?it/s]
Task 19, Epoch 1/20 => Loss 2.651, Train_accy 20.12:   5%|▌         | 1/20 [00:02<00:43,  2.31s/it]
Task 19, Epoch 2/20 => Loss 1.383, Train_accy 52.07:   5%|▌         | 1/20 [00:04<00:43,  2.31s/it]
Task 19, Epoch 2/20 => Loss 1.383, Train_accy 52.07:  10%|█         | 2/20 [00:04<00:41,  2.31s/it]
Task 19, Epoch 3/20 => Loss 0.877, Train_accy 68.34:  10%|█         | 2/20 [00:06<00:41,  2.31s/it]
Task 19, Epoch 3/20 => Loss 0.877, Train_accy 68.34:  15%|█▌        | 3/20 [00:06<00:39,  2.31s/it]
Task 19, Epoch 4/20 => Loss 0.708, Train_accy 76.92:  15%|█▌        | 3/20 [00:09<00:39,  2.31s/it]
Task 19, Epoch 4/20 => Loss 0.708, Train_accy 76.92:  20%|██        | 4/20 [00:09<00:36,  2.31s/it]
Task 19, Epoch 5/20 => Loss 0.504, Train_accy 80.18:  20%|██        | 4/20 [00:11<00:36,  2.31s/it]
Task 19, Epoch 5/20 => Loss 0.504, Train_accy 80.18:  25%|██▌       | 5/20 [00:11<00:34,  2.31s/it]
Task 19, Epoch 6/20 => Loss 0.655, Train_accy 85.80:  25%|██▌       | 5/20 [00:13<00:34,  2.31s/it]
Task 19, Epoch 6/20 => Loss 0.655, Train_accy 85.80:  30%|███       | 6/20 [00:13<00:32,  2.31s/it]
Task 19, Epoch 7/20 => Loss 0.481, Train_accy 85.80:  30%|███       | 6/20 [00:16<00:32,  2.31s/it]
Task 19, Epoch 7/20 => Loss 0.481, Train_accy 85.80:  35%|███▌      | 7/20 [00:16<00:30,  2.32s/it]
Task 19, Epoch 8/20 => Loss 0.380, Train_accy 87.57:  35%|███▌      | 7/20 [00:18<00:30,  2.32s/it]
Task 19, Epoch 8/20 => Loss 0.380, Train_accy 87.57:  40%|████      | 8/20 [00:18<00:27,  2.32s/it]
Task 19, Epoch 9/20 => Loss 0.434, Train_accy 87.57:  40%|████      | 8/20 [00:20<00:27,  2.32s/it]
Task 19, Epoch 9/20 => Loss 0.434, Train_accy 87.57:  45%|████▌     | 9/20 [00:20<00:25,  2.31s/it]
Task 19, Epoch 10/20 => Loss 0.310, Train_accy 89.64:  45%|████▌     | 9/20 [00:23<00:25,  2.31s/it]
Task 19, Epoch 10/20 => Loss 0.310, Train_accy 89.64:  50%|█████     | 10/20 [00:23<00:23,  2.31s/it]
Task 19, Epoch 11/20 => Loss 0.401, Train_accy 89.64:  50%|█████     | 10/20 [00:25<00:23,  2.31s/it]
Task 19, Epoch 11/20 => Loss 0.401, Train_accy 89.64:  55%|█████▌    | 11/20 [00:25<00:20,  2.32s/it]
Task 19, Epoch 12/20 => Loss 0.237, Train_accy 91.42:  55%|█████▌    | 11/20 [00:27<00:20,  2.32s/it]
Task 19, Epoch 12/20 => Loss 0.237, Train_accy 91.42:  60%|██████    | 12/20 [00:27<00:18,  2.32s/it]
Task 19, Epoch 13/20 => Loss 0.291, Train_accy 92.31:  60%|██████    | 12/20 [00:30<00:18,  2.32s/it]
Task 19, Epoch 13/20 => Loss 0.291, Train_accy 92.31:  65%|██████▌   | 13/20 [00:30<00:16,  2.33s/it]
Task 19, Epoch 14/20 => Loss 0.265, Train_accy 91.42:  65%|██████▌   | 13/20 [00:32<00:16,  2.33s/it]
Task 19, Epoch 14/20 => Loss 0.265, Train_accy 91.42:  70%|███████   | 14/20 [00:32<00:13,  2.32s/it]
Task 19, Epoch 15/20 => Loss 0.260, Train_accy 92.31:  70%|███████   | 14/20 [00:34<00:13,  2.32s/it]
Task 19, Epoch 15/20 => Loss 0.260, Train_accy 92.31:  75%|███████▌  | 15/20 [00:34<00:11,  2.32s/it]
Task 19, Epoch 16/20 => Loss 0.306, Train_accy 91.42:  75%|███████▌  | 15/20 [00:37<00:11,  2.32s/it]
Task 19, Epoch 16/20 => Loss 0.306, Train_accy 91.42:  80%|████████  | 16/20 [00:37<00:09,  2.32s/it]
Task 19, Epoch 17/20 => Loss 0.209, Train_accy 92.90:  80%|████████  | 16/20 [00:39<00:09,  2.32s/it]
Task 19, Epoch 17/20 => Loss 0.209, Train_accy 92.90:  85%|████████▌ | 17/20 [00:39<00:06,  2.33s/it]
Task 19, Epoch 18/20 => Loss 0.240, Train_accy 91.42:  85%|████████▌ | 17/20 [00:41<00:06,  2.33s/it]
Task 19, Epoch 18/20 => Loss 0.240, Train_accy 91.42:  90%|█████████ | 18/20 [00:41<00:04,  2.34s/it]
Task 19, Epoch 19/20 => Loss 0.192, Train_accy 95.56:  90%|█████████ | 18/20 [00:44<00:04,  2.34s/it]
Task 19, Epoch 19/20 => Loss 0.192, Train_accy 95.56:  95%|█████████▌| 19/20 [00:44<00:02,  2.32s/it]
Task 19, Epoch 20/20 => Loss 0.177, Train_accy 94.67:  95%|█████████▌| 19/20 [00:46<00:02,  2.32s/it]
Task 19, Epoch 20/20 => Loss 0.177, Train_accy 94.67: 100%|██████████| 20/20 [00:46<00:00,  2.31s/it]
Task 19, Epoch 20/20 => Loss 0.177, Train_accy 94.67: 100%|██████████| 20/20 [00:46<00:00,  2.32s/it]
2024-08-12 11:41:21,899 [inflora.py] => Task 19, Epoch 20/20 => Loss 0.177, Train_accy 94.67
Threshold:  0.9975
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 13/768 type remove
Layer 2 : 54/768 type remove
Layer 3 : 117/768 type remove
Layer 4 : 164/768 type remove
Layer 5 : 231/768 type remove
Layer 6 : 243/768 type remove
Layer 7 : 274/768 type remove
Layer 8 : 370/768 type remove
Layer 9 : 276/768 type retain
Layer 10 : 197/768 type retain
Layer 11 : 293/768 type retain
Layer 12 : 260/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:41:31,166 [trainer.py] => Time:59.906359910964966
1519 1519
1519 1519
2024-08-12 11:41:34,979 [trainer.py] => Time:3.8130037784576416
2024-08-12 11:41:34,980 [inflora.py] => Exemplar size: 0
2024-08-12 11:41:34,980 [trainer.py] => CNN: {'total': 42.13, '00-09': 45.45, '10-19': 44.9, '20-29': 50.51, '30-39': 50.0, '40-49': 46.88, '50-59': 42.31, '60-69': 48.41, '70-79': 41.67, '80-89': 40.74, '90-99': 38.71, '100-109': 46.67, '110-119': 44.59, '120-129': 28.33, '130-139': 51.16, '140-149': 50.0, '150-159': 27.45, '160-169': 30.59, '170-179': 24.19, '180-189': 15.38, '190-199': 43.53, 'old': 42.05, 'new': 43.53}
2024-08-12 11:41:34,980 [trainer.py] => CNN top1 curve: [75.32, 64.57, 64.23, 58.89, 58.25, 57.35, 56.64, 55.87, 54.3, 51.25, 50.28, 49.95, 48.79, 48.35, 47.87, 46.55, 44.79, 43.08, 42.75, 42.13]
2024-08-12 11:41:34,980 [trainer.py] => CNN top1 with task curve: [75.32, 82.29, 84.67, 83.89, 83.49, 83.19, 84.72, 84.67, 84.47, 84.19, 84.13, 84.92, 83.96, 84.12, 83.38, 83.41, 83.5, 83.23, 83.26, 83.15]
2024-08-12 11:41:34,980 [trainer.py] => CNN top1 task curve: [1.0, 0.7371428571428571, 0.6970802919708029, 0.6444444444444445, 0.6320754716981132, 0.6197478991596639, 0.6029900332225914, 0.5859598853868195, 0.5661103979460848, 0.539833531510107, 0.5294117647058824, 0.5230769230769231, 0.5053140096618357, 0.49866190900981266, 0.49122807017543857, 0.47836538461538464, 0.45911477869467365, 0.443010752688172, 0.4393305439330544, 0.43317972350230416]
Average Accuracy (CNN): 53.06
logs/omnibenchmark/10_10_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 11:41:38,002 [trainer.py] => config: ./configs/omn_inflora.json
2024-08-12 11:41:38,002 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 11:41:38,002 [trainer.py] => prefix: reproduce
2024-08-12 11:41:38,002 [trainer.py] => dataset: omnibenchmark
2024-08-12 11:41:38,002 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 11:41:38,003 [trainer.py] => memory_size: 0
2024-08-12 11:41:38,003 [trainer.py] => memory_per_class: 0
2024-08-12 11:41:38,003 [trainer.py] => fixed_memory: True
2024-08-12 11:41:38,003 [trainer.py] => shuffle: True
2024-08-12 11:41:38,003 [trainer.py] => init_cls: 10
2024-08-12 11:41:38,003 [trainer.py] => increment: 10
2024-08-12 11:41:38,003 [trainer.py] => model_name: InfLoRA
2024-08-12 11:41:38,003 [trainer.py] => net_type: sip
2024-08-12 11:41:38,003 [trainer.py] => embd_dim: 768
2024-08-12 11:41:38,003 [trainer.py] => num_heads: 12
2024-08-12 11:41:38,003 [trainer.py] => total_sessions: 30
2024-08-12 11:41:38,003 [trainer.py] => seed: 1993
2024-08-12 11:41:38,003 [trainer.py] => EPSILON: 1e-08
2024-08-12 11:41:38,003 [trainer.py] => init_epoch: 20
2024-08-12 11:41:38,003 [trainer.py] => optim: adam
2024-08-12 11:41:38,003 [trainer.py] => init_lr: 0.0005
2024-08-12 11:41:38,003 [trainer.py] => init_lr_decay: 0.1
2024-08-12 11:41:38,003 [trainer.py] => init_weight_decay: 0.0
2024-08-12 11:41:38,003 [trainer.py] => epochs: 20
2024-08-12 11:41:38,003 [trainer.py] => lrate: 0.0005
2024-08-12 11:41:38,003 [trainer.py] => lrate_decay: 0.1
2024-08-12 11:41:38,003 [trainer.py] => batch_size: 48
2024-08-12 11:41:38,003 [trainer.py] => weight_decay: 0.0
2024-08-12 11:41:38,003 [trainer.py] => rank: 4
2024-08-12 11:41:38,003 [trainer.py] => lamb: 0.95
2024-08-12 11:41:38,003 [trainer.py] => lame: 1.0
2024-08-12 11:41:38,003 [trainer.py] => num_workers: 16
2024-08-12 11:41:38,227 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2024-08-12 11:41:40,645 [trainer.py] => All params: 112239531
2024-08-12 11:41:40,649 [trainer.py] => Trainable params: 112239531
2024-08-12 11:41:40,649 [inflora.py] => Learning on 0-10

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.518, Train_accy 82.34:   0%|          | 0/20 [00:11<?, ?it/s]
Task 0, Epoch 1/20 => Loss 0.518, Train_accy 82.34:   5%|▌         | 1/20 [00:11<03:30, 11.08s/it]
Task 0, Epoch 2/20 => Loss 0.163, Train_accy 93.17:   5%|▌         | 1/20 [00:22<03:30, 11.08s/it]
Task 0, Epoch 2/20 => Loss 0.163, Train_accy 93.17:  10%|█         | 2/20 [00:22<03:19, 11.07s/it]
Task 0, Epoch 3/20 => Loss 0.137, Train_accy 94.54:  10%|█         | 2/20 [00:33<03:19, 11.07s/it]
Task 0, Epoch 3/20 => Loss 0.137, Train_accy 94.54:  15%|█▌        | 3/20 [00:33<03:08, 11.07s/it]
Task 0, Epoch 4/20 => Loss 0.106, Train_accy 96.40:  15%|█▌        | 3/20 [00:44<03:08, 11.07s/it]
Task 0, Epoch 4/20 => Loss 0.106, Train_accy 96.40:  20%|██        | 4/20 [00:44<02:57, 11.07s/it]
Task 0, Epoch 5/20 => Loss 0.084, Train_accy 96.96:  20%|██        | 4/20 [00:55<02:57, 11.07s/it]
Task 0, Epoch 5/20 => Loss 0.084, Train_accy 96.96:  25%|██▌       | 5/20 [00:55<02:45, 11.06s/it]
Task 0, Epoch 6/20 => Loss 0.099, Train_accy 96.53:  25%|██▌       | 5/20 [01:06<02:45, 11.06s/it]
Task 0, Epoch 6/20 => Loss 0.099, Train_accy 96.53:  30%|███       | 6/20 [01:06<02:34, 11.05s/it]
Task 0, Epoch 7/20 => Loss 0.072, Train_accy 97.42:  30%|███       | 6/20 [01:17<02:34, 11.05s/it]
Task 0, Epoch 7/20 => Loss 0.072, Train_accy 97.42:  35%|███▌      | 7/20 [01:17<02:23, 11.04s/it]
Task 0, Epoch 8/20 => Loss 0.078, Train_accy 97.06:  35%|███▌      | 7/20 [01:28<02:23, 11.04s/it]
Task 0, Epoch 8/20 => Loss 0.078, Train_accy 97.06:  40%|████      | 8/20 [01:28<02:12, 11.03s/it]
Task 0, Epoch 9/20 => Loss 0.085, Train_accy 97.16:  40%|████      | 8/20 [01:39<02:12, 11.03s/it]
Task 0, Epoch 9/20 => Loss 0.085, Train_accy 97.16:  45%|████▌     | 9/20 [01:39<02:01, 11.04s/it]
Task 0, Epoch 10/20 => Loss 0.073, Train_accy 97.42:  45%|████▌     | 9/20 [01:50<02:01, 11.04s/it]
Task 0, Epoch 10/20 => Loss 0.073, Train_accy 97.42:  50%|█████     | 10/20 [01:50<01:50, 11.04s/it]
Task 0, Epoch 11/20 => Loss 0.075, Train_accy 97.42:  50%|█████     | 10/20 [02:01<01:50, 11.04s/it]
Task 0, Epoch 11/20 => Loss 0.075, Train_accy 97.42:  55%|█████▌    | 11/20 [02:01<01:39, 11.05s/it]
Task 0, Epoch 12/20 => Loss 0.063, Train_accy 97.91:  55%|█████▌    | 11/20 [02:12<01:39, 11.05s/it]
Task 0, Epoch 12/20 => Loss 0.063, Train_accy 97.91:  60%|██████    | 12/20 [02:12<01:28, 11.06s/it]
Task 0, Epoch 13/20 => Loss 0.055, Train_accy 98.14:  60%|██████    | 12/20 [02:23<01:28, 11.06s/it]
Task 0, Epoch 13/20 => Loss 0.055, Train_accy 98.14:  65%|██████▌   | 13/20 [02:23<01:17, 11.06s/it]
Task 0, Epoch 14/20 => Loss 0.051, Train_accy 98.10:  65%|██████▌   | 13/20 [02:34<01:17, 11.06s/it]
Task 0, Epoch 14/20 => Loss 0.051, Train_accy 98.10:  70%|███████   | 14/20 [02:34<01:06, 11.07s/it]
Task 0, Epoch 15/20 => Loss 0.052, Train_accy 98.46:  70%|███████   | 14/20 [02:45<01:06, 11.07s/it]
Task 0, Epoch 15/20 => Loss 0.052, Train_accy 98.46:  75%|███████▌  | 15/20 [02:45<00:55, 11.07s/it]
Task 0, Epoch 16/20 => Loss 0.050, Train_accy 97.97:  75%|███████▌  | 15/20 [02:56<00:55, 11.07s/it]
Task 0, Epoch 16/20 => Loss 0.050, Train_accy 97.97:  80%|████████  | 16/20 [02:56<00:44, 11.08s/it]
Task 0, Epoch 17/20 => Loss 0.047, Train_accy 98.17:  80%|████████  | 16/20 [03:08<00:44, 11.08s/it]
Task 0, Epoch 17/20 => Loss 0.047, Train_accy 98.17:  85%|████████▌ | 17/20 [03:08<00:33, 11.09s/it]
Task 0, Epoch 18/20 => Loss 0.045, Train_accy 98.46:  85%|████████▌ | 17/20 [03:19<00:33, 11.09s/it]
Task 0, Epoch 18/20 => Loss 0.045, Train_accy 98.46:  90%|█████████ | 18/20 [03:19<00:22, 11.12s/it]
Task 0, Epoch 19/20 => Loss 0.041, Train_accy 98.59:  90%|█████████ | 18/20 [03:30<00:22, 11.12s/it]
Task 0, Epoch 19/20 => Loss 0.041, Train_accy 98.59:  95%|█████████▌| 19/20 [03:30<00:11, 11.06s/it]
Task 0, Epoch 20/20 => Loss 0.049, Train_accy 98.27:  95%|█████████▌| 19/20 [03:41<00:11, 11.06s/it]
Task 0, Epoch 20/20 => Loss 0.049, Train_accy 98.27: 100%|██████████| 20/20 [03:41<00:00, 11.04s/it]
Task 0, Epoch 20/20 => Loss 0.049, Train_accy 98.27: 100%|██████████| 20/20 [03:41<00:00, 11.06s/it]
2024-08-12 11:45:32,472 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.049, Train_accy 98.27
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 9/768 type remove
Layer 3 : 11/768 type remove
Layer 4 : 10/768 type remove
Layer 5 : 16/768 type remove
Layer 6 : 15/768 type remove
Layer 7 : 13/768 type remove
Layer 8 : 14/768 type remove
Layer 9 : 15/768 type remove
Layer 10 : 13/768 type remove
Layer 11 : 3/768 type remove
Layer 12 : 6/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:45:49,004 [trainer.py] => Time:248.35473346710205
200 200
200 200
2024-08-12 11:45:50,318 [trainer.py] => Time:1.3145160675048828
2024-08-12 11:45:50,319 [inflora.py] => Exemplar size: 0
2024-08-12 11:45:50,319 [trainer.py] => CNN: {'total': 99.0, '00-09': 99.0, 'old': 0, 'new': 99.0}
2024-08-12 11:45:50,319 [trainer.py] => CNN top1 curve: [99.0]
2024-08-12 11:45:50,319 [trainer.py] => CNN top1 with task curve: [99.0]
2024-08-12 11:45:50,319 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 99.0
2024-08-12 11:45:50,325 [trainer.py] => All params: 112239531
2024-08-12 11:45:50,329 [trainer.py] => Trainable params: 81418
2024-08-12 11:45:50,329 [inflora.py] => Learning on 10-20

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.436, Train_accy 86.20:   0%|          | 0/20 [00:10<?, ?it/s]
Task 1, Epoch 1/20 => Loss 0.436, Train_accy 86.20:   5%|▌         | 1/20 [00:10<03:22, 10.65s/it]
Task 1, Epoch 2/20 => Loss 0.102, Train_accy 96.66:   5%|▌         | 1/20 [00:21<03:22, 10.65s/it]
Task 1, Epoch 2/20 => Loss 0.102, Train_accy 96.66:  10%|█         | 2/20 [00:21<03:13, 10.74s/it]
Task 1, Epoch 3/20 => Loss 0.071, Train_accy 97.76:  10%|█         | 2/20 [00:32<03:13, 10.74s/it]
Task 1, Epoch 3/20 => Loss 0.071, Train_accy 97.76:  15%|█▌        | 3/20 [00:32<03:03, 10.79s/it]
Task 1, Epoch 4/20 => Loss 0.064, Train_accy 97.45:  15%|█▌        | 3/20 [00:42<03:03, 10.79s/it]
Task 1, Epoch 4/20 => Loss 0.064, Train_accy 97.45:  20%|██        | 4/20 [00:42<02:52, 10.75s/it]
Task 1, Epoch 5/20 => Loss 0.058, Train_accy 98.11:  20%|██        | 4/20 [00:53<02:52, 10.75s/it]
Task 1, Epoch 5/20 => Loss 0.058, Train_accy 98.11:  25%|██▌       | 5/20 [00:53<02:40, 10.73s/it]
Task 1, Epoch 6/20 => Loss 0.054, Train_accy 98.38:  25%|██▌       | 5/20 [01:04<02:40, 10.73s/it]
Task 1, Epoch 6/20 => Loss 0.054, Train_accy 98.38:  30%|███       | 6/20 [01:04<02:30, 10.75s/it]
Task 1, Epoch 7/20 => Loss 0.047, Train_accy 98.49:  30%|███       | 6/20 [01:15<02:30, 10.75s/it]
Task 1, Epoch 7/20 => Loss 0.047, Train_accy 98.49:  35%|███▌      | 7/20 [01:15<02:19, 10.71s/it]
Task 1, Epoch 8/20 => Loss 0.056, Train_accy 98.07:  35%|███▌      | 7/20 [01:25<02:19, 10.71s/it]
Task 1, Epoch 8/20 => Loss 0.056, Train_accy 98.07:  40%|████      | 8/20 [01:25<02:08, 10.75s/it]
Task 1, Epoch 9/20 => Loss 0.045, Train_accy 98.38:  40%|████      | 8/20 [01:36<02:08, 10.75s/it]
Task 1, Epoch 9/20 => Loss 0.045, Train_accy 98.38:  45%|████▌     | 9/20 [01:36<01:57, 10.71s/it]
Task 1, Epoch 10/20 => Loss 0.046, Train_accy 98.35:  45%|████▌     | 9/20 [01:47<01:57, 10.71s/it]
Task 1, Epoch 10/20 => Loss 0.046, Train_accy 98.35:  50%|█████     | 10/20 [01:47<01:47, 10.72s/it]
Task 1, Epoch 11/20 => Loss 0.053, Train_accy 98.07:  50%|█████     | 10/20 [01:58<01:47, 10.72s/it]
Task 1, Epoch 11/20 => Loss 0.053, Train_accy 98.07:  55%|█████▌    | 11/20 [01:58<01:36, 10.72s/it]
Task 1, Epoch 12/20 => Loss 0.054, Train_accy 98.25:  55%|█████▌    | 11/20 [02:08<01:36, 10.72s/it]
Task 1, Epoch 12/20 => Loss 0.054, Train_accy 98.25:  60%|██████    | 12/20 [02:08<01:25, 10.71s/it]
Task 1, Epoch 13/20 => Loss 0.038, Train_accy 98.49:  60%|██████    | 12/20 [02:19<01:25, 10.71s/it]
Task 1, Epoch 13/20 => Loss 0.038, Train_accy 98.49:  65%|██████▌   | 13/20 [02:19<01:15, 10.75s/it]
Task 1, Epoch 14/20 => Loss 0.033, Train_accy 98.93:  65%|██████▌   | 13/20 [02:30<01:15, 10.75s/it]
Task 1, Epoch 14/20 => Loss 0.033, Train_accy 98.93:  70%|███████   | 14/20 [02:30<01:04, 10.73s/it]
Task 1, Epoch 15/20 => Loss 0.037, Train_accy 98.73:  70%|███████   | 14/20 [02:40<01:04, 10.73s/it]
Task 1, Epoch 15/20 => Loss 0.037, Train_accy 98.73:  75%|███████▌  | 15/20 [02:40<00:53, 10.70s/it]
Task 1, Epoch 16/20 => Loss 0.034, Train_accy 98.69:  75%|███████▌  | 15/20 [02:51<00:53, 10.70s/it]
Task 1, Epoch 16/20 => Loss 0.034, Train_accy 98.69:  80%|████████  | 16/20 [02:51<00:42, 10.69s/it]
Task 1, Epoch 17/20 => Loss 0.032, Train_accy 98.93:  80%|████████  | 16/20 [03:02<00:42, 10.69s/it]
Task 1, Epoch 17/20 => Loss 0.032, Train_accy 98.93:  85%|████████▌ | 17/20 [03:02<00:32, 10.68s/it]
Task 1, Epoch 18/20 => Loss 0.036, Train_accy 98.62:  85%|████████▌ | 17/20 [03:13<00:32, 10.68s/it]
Task 1, Epoch 18/20 => Loss 0.036, Train_accy 98.62:  90%|█████████ | 18/20 [03:13<00:21, 10.73s/it]
Task 1, Epoch 19/20 => Loss 0.029, Train_accy 99.04:  90%|█████████ | 18/20 [03:23<00:21, 10.73s/it]
Task 1, Epoch 19/20 => Loss 0.029, Train_accy 99.04:  95%|█████████▌| 19/20 [03:23<00:10, 10.73s/it]
Task 1, Epoch 20/20 => Loss 0.031, Train_accy 98.97:  95%|█████████▌| 19/20 [03:34<00:10, 10.73s/it]
Task 1, Epoch 20/20 => Loss 0.031, Train_accy 98.97: 100%|██████████| 20/20 [03:34<00:00, 10.72s/it]
Task 1, Epoch 20/20 => Loss 0.031, Train_accy 98.97: 100%|██████████| 20/20 [03:34<00:00, 10.72s/it]
2024-08-12 11:49:34,738 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.031, Train_accy 98.97
Threshold:  0.9516666666666667
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 13/768 type remove
Layer 4 : 14/768 type remove
Layer 5 : 21/768 type remove
Layer 6 : 20/768 type remove
Layer 7 : 19/768 type remove
Layer 8 : 21/768 type remove
Layer 9 : 29/768 type remove
Layer 10 : 30/768 type remove
Layer 11 : 9/768 type remove
Layer 12 : 15/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:49:53,668 [trainer.py] => Time:243.33889174461365
400 400
400 400
2024-08-12 11:49:55,555 [trainer.py] => Time:1.8856091499328613
2024-08-12 11:49:55,555 [inflora.py] => Exemplar size: 0
2024-08-12 11:49:55,555 [trainer.py] => CNN: {'total': 91.75, '00-09': 86.0, '10-19': 97.5, 'old': 86.0, 'new': 97.5}
2024-08-12 11:49:55,555 [trainer.py] => CNN top1 curve: [99.0, 91.75]
2024-08-12 11:49:55,555 [trainer.py] => CNN top1 with task curve: [99.0, 98.5]
2024-08-12 11:49:55,555 [trainer.py] => CNN top1 task curve: [1.0, 0.9275]
Average Accuracy (CNN): 95.38
2024-08-12 11:49:55,561 [trainer.py] => All params: 112239531
2024-08-12 11:49:55,566 [trainer.py] => Trainable params: 895598
2024-08-12 11:49:55,566 [inflora.py] => Learning on 20-30

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.618, Train_accy 78.55:   0%|          | 0/20 [00:11<?, ?it/s]
Task 2, Epoch 1/20 => Loss 0.618, Train_accy 78.55:   5%|▌         | 1/20 [00:11<03:31, 11.14s/it]
Task 2, Epoch 2/20 => Loss 0.244, Train_accy 90.55:   5%|▌         | 1/20 [00:22<03:31, 11.14s/it]
Task 2, Epoch 2/20 => Loss 0.244, Train_accy 90.55:  10%|█         | 2/20 [00:22<03:21, 11.19s/it]
Task 2, Epoch 3/20 => Loss 0.197, Train_accy 92.05:  10%|█         | 2/20 [00:33<03:21, 11.19s/it]
Task 2, Epoch 3/20 => Loss 0.197, Train_accy 92.05:  15%|█▌        | 3/20 [00:33<03:10, 11.18s/it]
Task 2, Epoch 4/20 => Loss 0.168, Train_accy 93.60:  15%|█▌        | 3/20 [00:44<03:10, 11.18s/it]
Task 2, Epoch 4/20 => Loss 0.168, Train_accy 93.60:  20%|██        | 4/20 [00:44<02:58, 11.14s/it]
Task 2, Epoch 5/20 => Loss 0.158, Train_accy 94.20:  20%|██        | 4/20 [00:55<02:58, 11.14s/it]
Task 2, Epoch 5/20 => Loss 0.158, Train_accy 94.20:  25%|██▌       | 5/20 [00:55<02:46, 11.10s/it]
Task 2, Epoch 6/20 => Loss 0.141, Train_accy 94.67:  25%|██▌       | 5/20 [01:06<02:46, 11.10s/it]
Task 2, Epoch 6/20 => Loss 0.141, Train_accy 94.67:  30%|███       | 6/20 [01:06<02:35, 11.13s/it]
Task 2, Epoch 7/20 => Loss 0.134, Train_accy 95.37:  30%|███       | 6/20 [01:18<02:35, 11.13s/it]
Task 2, Epoch 7/20 => Loss 0.134, Train_accy 95.37:  35%|███▌      | 7/20 [01:18<02:25, 11.16s/it]
Task 2, Epoch 8/20 => Loss 0.134, Train_accy 95.34:  35%|███▌      | 7/20 [01:29<02:25, 11.16s/it]
Task 2, Epoch 8/20 => Loss 0.134, Train_accy 95.34:  40%|████      | 8/20 [01:29<02:13, 11.11s/it]
Task 2, Epoch 9/20 => Loss 0.114, Train_accy 95.64:  40%|████      | 8/20 [01:40<02:13, 11.11s/it]
Task 2, Epoch 9/20 => Loss 0.114, Train_accy 95.64:  45%|████▌     | 9/20 [01:40<02:02, 11.09s/it]
Task 2, Epoch 10/20 => Loss 0.114, Train_accy 95.98:  45%|████▌     | 9/20 [01:51<02:02, 11.09s/it]
Task 2, Epoch 10/20 => Loss 0.114, Train_accy 95.98:  50%|█████     | 10/20 [01:51<01:51, 11.11s/it]
Task 2, Epoch 11/20 => Loss 0.109, Train_accy 96.31:  50%|█████     | 10/20 [02:02<01:51, 11.11s/it]
Task 2, Epoch 11/20 => Loss 0.109, Train_accy 96.31:  55%|█████▌    | 11/20 [02:02<01:39, 11.08s/it]
Task 2, Epoch 12/20 => Loss 0.103, Train_accy 96.41:  55%|█████▌    | 11/20 [02:13<01:39, 11.08s/it]
Task 2, Epoch 12/20 => Loss 0.103, Train_accy 96.41:  60%|██████    | 12/20 [02:13<01:28, 11.11s/it]
Task 2, Epoch 13/20 => Loss 0.102, Train_accy 96.41:  60%|██████    | 12/20 [02:24<01:28, 11.11s/it]
Task 2, Epoch 13/20 => Loss 0.102, Train_accy 96.41:  65%|██████▌   | 13/20 [02:24<01:17, 11.13s/it]
Task 2, Epoch 14/20 => Loss 0.097, Train_accy 96.51:  65%|██████▌   | 13/20 [02:35<01:17, 11.13s/it]
Task 2, Epoch 14/20 => Loss 0.097, Train_accy 96.51:  70%|███████   | 14/20 [02:35<01:06, 11.11s/it]
Task 2, Epoch 15/20 => Loss 0.089, Train_accy 96.75:  70%|███████   | 14/20 [02:46<01:06, 11.11s/it]
Task 2, Epoch 15/20 => Loss 0.089, Train_accy 96.75:  75%|███████▌  | 15/20 [02:46<00:55, 11.09s/it]
Task 2, Epoch 16/20 => Loss 0.085, Train_accy 96.92:  75%|███████▌  | 15/20 [02:57<00:55, 11.09s/it]
Task 2, Epoch 16/20 => Loss 0.085, Train_accy 96.92:  80%|████████  | 16/20 [02:57<00:44, 11.13s/it]
Task 2, Epoch 17/20 => Loss 0.079, Train_accy 96.92:  80%|████████  | 16/20 [03:09<00:44, 11.13s/it]
Task 2, Epoch 17/20 => Loss 0.079, Train_accy 96.92:  85%|████████▌ | 17/20 [03:09<00:33, 11.14s/it]
Task 2, Epoch 18/20 => Loss 0.081, Train_accy 97.49:  85%|████████▌ | 17/20 [03:20<00:33, 11.14s/it]
Task 2, Epoch 18/20 => Loss 0.081, Train_accy 97.49:  90%|█████████ | 18/20 [03:20<00:22, 11.10s/it]
Task 2, Epoch 19/20 => Loss 0.079, Train_accy 97.55:  90%|█████████ | 18/20 [03:31<00:22, 11.10s/it]
Task 2, Epoch 19/20 => Loss 0.079, Train_accy 97.55:  95%|█████████▌| 19/20 [03:31<00:11, 11.12s/it]
Task 2, Epoch 20/20 => Loss 0.087, Train_accy 97.18:  95%|█████████▌| 19/20 [03:42<00:11, 11.12s/it]
Task 2, Epoch 20/20 => Loss 0.087, Train_accy 97.18: 100%|██████████| 20/20 [03:42<00:00, 11.10s/it]
Task 2, Epoch 20/20 => Loss 0.087, Train_accy 97.18: 100%|██████████| 20/20 [03:42<00:00, 11.12s/it]
2024-08-12 11:53:48,450 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.087, Train_accy 97.18
Threshold:  0.9533333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 15/768 type remove
Layer 4 : 15/768 type remove
Layer 5 : 24/768 type remove
Layer 6 : 23/768 type remove
Layer 7 : 22/768 type remove
Layer 8 : 24/768 type remove
Layer 9 : 35/768 type remove
Layer 10 : 38/768 type remove
Layer 11 : 13/768 type remove
Layer 12 : 20/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:54:09,128 [trainer.py] => Time:253.5623517036438
600 600
600 600
2024-08-12 11:54:11,349 [trainer.py] => Time:2.2198779582977295
2024-08-12 11:54:11,349 [inflora.py] => Exemplar size: 0
2024-08-12 11:54:11,349 [trainer.py] => CNN: {'total': 86.83, '00-09': 90.0, '10-19': 94.0, '20-29': 76.5, 'old': 92.0, 'new': 76.5}
2024-08-12 11:54:11,349 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83]
2024-08-12 11:54:11,349 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67]
2024-08-12 11:54:11,350 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333]
Average Accuracy (CNN): 92.53
2024-08-12 11:54:11,357 [trainer.py] => All params: 112239531
2024-08-12 11:54:11,362 [trainer.py] => Trainable params: 895598
2024-08-12 11:54:11,362 [inflora.py] => Learning on 30-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.527, Train_accy 82.60:   0%|          | 0/20 [00:11<?, ?it/s]
Task 3, Epoch 1/20 => Loss 0.527, Train_accy 82.60:   5%|▌         | 1/20 [00:11<03:31, 11.15s/it]
Task 3, Epoch 2/20 => Loss 0.152, Train_accy 94.31:   5%|▌         | 1/20 [00:22<03:31, 11.15s/it]
Task 3, Epoch 2/20 => Loss 0.152, Train_accy 94.31:  10%|█         | 2/20 [00:22<03:20, 11.14s/it]
Task 3, Epoch 3/20 => Loss 0.120, Train_accy 95.79:  10%|█         | 2/20 [00:33<03:20, 11.14s/it]
Task 3, Epoch 3/20 => Loss 0.120, Train_accy 95.79:  15%|█▌        | 3/20 [00:33<03:08, 11.10s/it]
Task 3, Epoch 4/20 => Loss 0.125, Train_accy 95.39:  15%|█▌        | 3/20 [00:44<03:08, 11.10s/it]
Task 3, Epoch 4/20 => Loss 0.125, Train_accy 95.39:  20%|██        | 4/20 [00:44<02:56, 11.05s/it]
Task 3, Epoch 5/20 => Loss 0.102, Train_accy 96.40:  20%|██        | 4/20 [00:55<02:56, 11.05s/it]
Task 3, Epoch 5/20 => Loss 0.102, Train_accy 96.40:  25%|██▌       | 5/20 [00:55<02:46, 11.09s/it]
Task 3, Epoch 6/20 => Loss 0.092, Train_accy 96.67:  25%|██▌       | 5/20 [01:06<02:46, 11.09s/it]
Task 3, Epoch 6/20 => Loss 0.092, Train_accy 96.67:  30%|███       | 6/20 [01:06<02:35, 11.08s/it]
Task 3, Epoch 7/20 => Loss 0.079, Train_accy 97.27:  30%|███       | 6/20 [01:17<02:35, 11.08s/it]
Task 3, Epoch 7/20 => Loss 0.079, Train_accy 97.27:  35%|███▌      | 7/20 [01:17<02:23, 11.07s/it]
Task 3, Epoch 8/20 => Loss 0.084, Train_accy 97.24:  35%|███▌      | 7/20 [01:28<02:23, 11.07s/it]
Task 3, Epoch 8/20 => Loss 0.084, Train_accy 97.24:  40%|████      | 8/20 [01:28<02:12, 11.06s/it]
Task 3, Epoch 9/20 => Loss 0.080, Train_accy 97.14:  40%|████      | 8/20 [01:39<02:12, 11.06s/it]
Task 3, Epoch 9/20 => Loss 0.080, Train_accy 97.14:  45%|████▌     | 9/20 [01:39<02:01, 11.08s/it]
Task 3, Epoch 10/20 => Loss 0.072, Train_accy 97.31:  45%|████▌     | 9/20 [01:51<02:01, 11.08s/it]
Task 3, Epoch 10/20 => Loss 0.072, Train_accy 97.31:  50%|█████     | 10/20 [01:51<01:51, 11.14s/it]
Task 3, Epoch 11/20 => Loss 0.065, Train_accy 97.71:  50%|█████     | 10/20 [02:02<01:51, 11.14s/it]
Task 3, Epoch 11/20 => Loss 0.065, Train_accy 97.71:  55%|█████▌    | 11/20 [02:02<01:40, 11.13s/it]
Task 3, Epoch 12/20 => Loss 0.062, Train_accy 97.88:  55%|█████▌    | 11/20 [02:13<01:40, 11.13s/it]
Task 3, Epoch 12/20 => Loss 0.062, Train_accy 97.88:  60%|██████    | 12/20 [02:13<01:28, 11.10s/it]
Task 3, Epoch 13/20 => Loss 0.072, Train_accy 97.51:  60%|██████    | 12/20 [02:24<01:28, 11.10s/it]
Task 3, Epoch 13/20 => Loss 0.072, Train_accy 97.51:  65%|██████▌   | 13/20 [02:24<01:17, 11.06s/it]
Task 3, Epoch 14/20 => Loss 0.068, Train_accy 97.51:  65%|██████▌   | 13/20 [02:35<01:17, 11.06s/it]
Task 3, Epoch 14/20 => Loss 0.068, Train_accy 97.51:  70%|███████   | 14/20 [02:35<01:06, 11.06s/it]
Task 3, Epoch 15/20 => Loss 0.076, Train_accy 97.41:  70%|███████   | 14/20 [02:46<01:06, 11.06s/it]
Task 3, Epoch 15/20 => Loss 0.076, Train_accy 97.41:  75%|███████▌  | 15/20 [02:46<00:55, 11.04s/it]
Task 3, Epoch 16/20 => Loss 0.067, Train_accy 97.58:  75%|███████▌  | 15/20 [02:57<00:55, 11.04s/it]
Task 3, Epoch 16/20 => Loss 0.067, Train_accy 97.58:  80%|████████  | 16/20 [02:57<00:44, 11.05s/it]
Task 3, Epoch 17/20 => Loss 0.063, Train_accy 97.81:  80%|████████  | 16/20 [03:08<00:44, 11.05s/it]
Task 3, Epoch 17/20 => Loss 0.063, Train_accy 97.81:  85%|████████▌ | 17/20 [03:08<00:33, 11.09s/it]
Task 3, Epoch 18/20 => Loss 0.080, Train_accy 97.27:  85%|████████▌ | 17/20 [03:19<00:33, 11.09s/it]
Task 3, Epoch 18/20 => Loss 0.080, Train_accy 97.27:  90%|█████████ | 18/20 [03:19<00:22, 11.08s/it]
Task 3, Epoch 19/20 => Loss 0.060, Train_accy 98.01:  90%|█████████ | 18/20 [03:30<00:22, 11.08s/it]
Task 3, Epoch 19/20 => Loss 0.060, Train_accy 98.01:  95%|█████████▌| 19/20 [03:30<00:11, 11.07s/it]
Task 3, Epoch 20/20 => Loss 0.058, Train_accy 97.81:  95%|█████████▌| 19/20 [03:41<00:11, 11.07s/it]
Task 3, Epoch 20/20 => Loss 0.058, Train_accy 97.81: 100%|██████████| 20/20 [03:41<00:00, 11.11s/it]
Task 3, Epoch 20/20 => Loss 0.058, Train_accy 97.81: 100%|██████████| 20/20 [03:41<00:00, 11.09s/it]
2024-08-12 11:58:03,898 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.058, Train_accy 97.81
Threshold:  0.955
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 28/768 type remove
Layer 6 : 28/768 type remove
Layer 7 : 28/768 type remove
Layer 8 : 33/768 type remove
Layer 9 : 42/768 type remove
Layer 10 : 45/768 type remove
Layer 11 : 15/768 type remove
Layer 12 : 24/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 11:58:23,076 [trainer.py] => Time:251.71425533294678
800 800
800 800
2024-08-12 11:58:25,640 [trainer.py] => Time:2.563459873199463
2024-08-12 11:58:25,640 [inflora.py] => Exemplar size: 0
2024-08-12 11:58:25,640 [trainer.py] => CNN: {'total': 86.62, '00-09': 86.5, '10-19': 92.5, '20-29': 73.5, '30-39': 94.0, 'old': 84.17, 'new': 94.0}
2024-08-12 11:58:25,640 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62]
2024-08-12 11:58:25,640 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75]
2024-08-12 11:58:25,640 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87]
Average Accuracy (CNN): 91.05
2024-08-12 11:58:25,646 [trainer.py] => All params: 112239531
2024-08-12 11:58:25,651 [trainer.py] => Trainable params: 81418
2024-08-12 11:58:25,651 [inflora.py] => Learning on 40-50

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.591, Train_accy 83.12:   0%|          | 0/20 [00:10<?, ?it/s]
Task 4, Epoch 1/20 => Loss 0.591, Train_accy 83.12:   5%|▌         | 1/20 [00:10<03:28, 10.95s/it]
Task 4, Epoch 2/20 => Loss 0.116, Train_accy 95.80:   5%|▌         | 1/20 [00:22<03:28, 10.95s/it]
Task 4, Epoch 2/20 => Loss 0.116, Train_accy 95.80:  10%|█         | 2/20 [00:22<03:19, 11.09s/it]
Task 4, Epoch 3/20 => Loss 0.108, Train_accy 96.44:  10%|█         | 2/20 [00:33<03:19, 11.09s/it]
Task 4, Epoch 3/20 => Loss 0.108, Train_accy 96.44:  15%|█▌        | 3/20 [00:33<03:09, 11.15s/it]
Task 4, Epoch 4/20 => Loss 0.085, Train_accy 97.02:  15%|█▌        | 3/20 [00:44<03:09, 11.15s/it]
Task 4, Epoch 4/20 => Loss 0.085, Train_accy 97.02:  20%|██        | 4/20 [00:44<02:57, 11.08s/it]
Task 4, Epoch 5/20 => Loss 0.073, Train_accy 97.56:  20%|██        | 4/20 [00:55<02:57, 11.08s/it]
Task 4, Epoch 5/20 => Loss 0.073, Train_accy 97.56:  25%|██▌       | 5/20 [00:55<02:45, 11.06s/it]
Task 4, Epoch 6/20 => Loss 0.071, Train_accy 97.63:  25%|██▌       | 5/20 [01:06<02:45, 11.06s/it]
Task 4, Epoch 6/20 => Loss 0.071, Train_accy 97.63:  30%|███       | 6/20 [01:06<02:35, 11.10s/it]
Task 4, Epoch 7/20 => Loss 0.058, Train_accy 97.90:  30%|███       | 6/20 [01:17<02:35, 11.10s/it]
Task 4, Epoch 7/20 => Loss 0.058, Train_accy 97.90:  35%|███▌      | 7/20 [01:17<02:23, 11.07s/it]
Task 4, Epoch 8/20 => Loss 0.069, Train_accy 97.53:  35%|███▌      | 7/20 [01:28<02:23, 11.07s/it]
Task 4, Epoch 8/20 => Loss 0.069, Train_accy 97.53:  40%|████      | 8/20 [01:28<02:12, 11.05s/it]
Task 4, Epoch 9/20 => Loss 0.064, Train_accy 97.53:  40%|████      | 8/20 [01:39<02:12, 11.05s/it]
Task 4, Epoch 9/20 => Loss 0.064, Train_accy 97.53:  45%|████▌     | 9/20 [01:39<02:01, 11.06s/it]
Task 4, Epoch 10/20 => Loss 0.060, Train_accy 97.76:  45%|████▌     | 9/20 [01:50<02:01, 11.06s/it]
Task 4, Epoch 10/20 => Loss 0.060, Train_accy 97.76:  50%|█████     | 10/20 [01:50<01:50, 11.04s/it]
Task 4, Epoch 11/20 => Loss 0.046, Train_accy 98.37:  50%|█████     | 10/20 [02:01<01:50, 11.04s/it]
Task 4, Epoch 11/20 => Loss 0.046, Train_accy 98.37:  55%|█████▌    | 11/20 [02:01<01:39, 11.03s/it]
Task 4, Epoch 12/20 => Loss 0.047, Train_accy 98.27:  55%|█████▌    | 11/20 [02:12<01:39, 11.03s/it]
Task 4, Epoch 12/20 => Loss 0.047, Train_accy 98.27:  60%|██████    | 12/20 [02:12<01:28, 11.01s/it]
Task 4, Epoch 13/20 => Loss 0.050, Train_accy 98.27:  60%|██████    | 12/20 [02:23<01:28, 11.01s/it]
Task 4, Epoch 13/20 => Loss 0.050, Train_accy 98.27:  65%|██████▌   | 13/20 [02:23<01:17, 11.06s/it]
Task 4, Epoch 14/20 => Loss 0.043, Train_accy 98.54:  65%|██████▌   | 13/20 [02:34<01:17, 11.06s/it]
Task 4, Epoch 14/20 => Loss 0.043, Train_accy 98.54:  70%|███████   | 14/20 [02:34<01:06, 11.06s/it]
Task 4, Epoch 15/20 => Loss 0.050, Train_accy 98.27:  70%|███████   | 14/20 [02:45<01:06, 11.06s/it]
Task 4, Epoch 15/20 => Loss 0.050, Train_accy 98.27:  75%|███████▌  | 15/20 [02:45<00:55, 11.04s/it]
Task 4, Epoch 16/20 => Loss 0.048, Train_accy 98.41:  75%|███████▌  | 15/20 [02:56<00:55, 11.04s/it]
Task 4, Epoch 16/20 => Loss 0.048, Train_accy 98.41:  80%|████████  | 16/20 [02:56<00:44, 11.03s/it]
Task 4, Epoch 17/20 => Loss 0.050, Train_accy 98.20:  80%|████████  | 16/20 [03:07<00:44, 11.03s/it]
Task 4, Epoch 17/20 => Loss 0.050, Train_accy 98.20:  85%|████████▌ | 17/20 [03:07<00:33, 11.06s/it]
Task 4, Epoch 18/20 => Loss 0.037, Train_accy 98.58:  85%|████████▌ | 17/20 [03:19<00:33, 11.06s/it]
Task 4, Epoch 18/20 => Loss 0.037, Train_accy 98.58:  90%|█████████ | 18/20 [03:19<00:22, 11.07s/it]
Task 4, Epoch 19/20 => Loss 0.046, Train_accy 98.44:  90%|█████████ | 18/20 [03:30<00:22, 11.07s/it]
Task 4, Epoch 19/20 => Loss 0.046, Train_accy 98.44:  95%|█████████▌| 19/20 [03:30<00:11, 11.09s/it]
Task 4, Epoch 20/20 => Loss 0.044, Train_accy 98.27:  95%|█████████▌| 19/20 [03:41<00:11, 11.09s/it]
Task 4, Epoch 20/20 => Loss 0.044, Train_accy 98.27: 100%|██████████| 20/20 [03:41<00:00, 11.10s/it]
Task 4, Epoch 20/20 => Loss 0.044, Train_accy 98.27: 100%|██████████| 20/20 [03:41<00:00, 11.07s/it]
2024-08-12 12:02:17,449 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.044, Train_accy 98.27
Threshold:  0.9566666666666667
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 19/768 type remove
Layer 4 : 19/768 type remove
Layer 5 : 29/768 type remove
Layer 6 : 29/768 type remove
Layer 7 : 29/768 type remove
Layer 8 : 34/768 type remove
Layer 9 : 43/768 type remove
Layer 10 : 49/768 type remove
Layer 11 : 17/768 type remove
Layer 12 : 30/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:02:37,186 [trainer.py] => Time:251.53552079200745
1000 1000
1000 1000
2024-08-12 12:02:40,127 [trainer.py] => Time:2.94001841545105
2024-08-12 12:02:40,127 [inflora.py] => Exemplar size: 0
2024-08-12 12:02:40,127 [trainer.py] => CNN: {'total': 81.5, '00-09': 84.5, '10-19': 85.5, '20-29': 70.0, '30-39': 84.5, '40-49': 83.0, 'old': 81.12, 'new': 83.0}
2024-08-12 12:02:40,127 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5]
2024-08-12 12:02:40,127 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8]
2024-08-12 12:02:40,127 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819]
Average Accuracy (CNN): 89.14
2024-08-12 12:02:40,133 [trainer.py] => All params: 112239531
2024-08-12 12:02:40,138 [trainer.py] => Trainable params: 81418
2024-08-12 12:02:40,138 [inflora.py] => Learning on 50-60

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 0.570, Train_accy 82.71:   0%|          | 0/20 [00:11<?, ?it/s]
Task 5, Epoch 1/20 => Loss 0.570, Train_accy 82.71:   5%|▌         | 1/20 [00:11<03:39, 11.55s/it]
Task 5, Epoch 2/20 => Loss 0.141, Train_accy 94.82:   5%|▌         | 1/20 [00:23<03:39, 11.55s/it]
Task 5, Epoch 2/20 => Loss 0.141, Train_accy 94.82:  10%|█         | 2/20 [00:23<03:28, 11.59s/it]
Task 5, Epoch 3/20 => Loss 0.109, Train_accy 96.69:  10%|█         | 2/20 [00:34<03:28, 11.59s/it]
Task 5, Epoch 3/20 => Loss 0.109, Train_accy 96.69:  15%|█▌        | 3/20 [00:34<03:16, 11.54s/it]
Task 5, Epoch 4/20 => Loss 0.106, Train_accy 96.59:  15%|█▌        | 3/20 [00:46<03:16, 11.54s/it]
Task 5, Epoch 4/20 => Loss 0.106, Train_accy 96.59:  20%|██        | 4/20 [00:46<03:04, 11.56s/it]
Task 5, Epoch 5/20 => Loss 0.083, Train_accy 97.35:  20%|██        | 4/20 [00:57<03:04, 11.56s/it]
Task 5, Epoch 5/20 => Loss 0.083, Train_accy 97.35:  25%|██▌       | 5/20 [00:57<02:52, 11.51s/it]
Task 5, Epoch 6/20 => Loss 0.089, Train_accy 97.18:  25%|██▌       | 5/20 [01:09<02:52, 11.51s/it]
Task 5, Epoch 6/20 => Loss 0.089, Train_accy 97.18:  30%|███       | 6/20 [01:09<02:41, 11.52s/it]
Task 5, Epoch 7/20 => Loss 0.076, Train_accy 97.45:  30%|███       | 6/20 [01:20<02:41, 11.52s/it]
Task 5, Epoch 7/20 => Loss 0.076, Train_accy 97.45:  35%|███▌      | 7/20 [01:20<02:29, 11.49s/it]
Task 5, Epoch 8/20 => Loss 0.078, Train_accy 97.45:  35%|███▌      | 7/20 [01:31<02:29, 11.49s/it]
Task 5, Epoch 8/20 => Loss 0.078, Train_accy 97.45:  40%|████      | 8/20 [01:31<02:17, 11.45s/it]
Task 5, Epoch 9/20 => Loss 0.072, Train_accy 97.54:  40%|████      | 8/20 [01:43<02:17, 11.45s/it]
Task 5, Epoch 9/20 => Loss 0.072, Train_accy 97.54:  45%|████▌     | 9/20 [01:43<02:05, 11.44s/it]
Task 5, Epoch 10/20 => Loss 0.072, Train_accy 97.51:  45%|████▌     | 9/20 [01:54<02:05, 11.44s/it]
Task 5, Epoch 10/20 => Loss 0.072, Train_accy 97.51:  50%|█████     | 10/20 [01:54<01:54, 11.47s/it]
Task 5, Epoch 11/20 => Loss 0.066, Train_accy 97.38:  50%|█████     | 10/20 [02:06<01:54, 11.47s/it]
Task 5, Epoch 11/20 => Loss 0.066, Train_accy 97.38:  55%|█████▌    | 11/20 [02:06<01:43, 11.47s/it]
Task 5, Epoch 12/20 => Loss 0.072, Train_accy 97.48:  55%|█████▌    | 11/20 [02:17<01:43, 11.47s/it]
Task 5, Epoch 12/20 => Loss 0.072, Train_accy 97.48:  60%|██████    | 12/20 [02:17<01:31, 11.49s/it]
Task 5, Epoch 13/20 => Loss 0.064, Train_accy 97.84:  60%|██████    | 12/20 [02:29<01:31, 11.49s/it]
Task 5, Epoch 13/20 => Loss 0.064, Train_accy 97.84:  65%|██████▌   | 13/20 [02:29<01:20, 11.51s/it]
Task 5, Epoch 14/20 => Loss 0.066, Train_accy 97.48:  65%|██████▌   | 13/20 [02:40<01:20, 11.51s/it]
Task 5, Epoch 14/20 => Loss 0.066, Train_accy 97.48:  70%|███████   | 14/20 [02:40<01:09, 11.50s/it]
Task 5, Epoch 15/20 => Loss 0.056, Train_accy 98.10:  70%|███████   | 14/20 [02:52<01:09, 11.50s/it]
Task 5, Epoch 15/20 => Loss 0.056, Train_accy 98.10:  75%|███████▌  | 15/20 [02:52<00:57, 11.49s/it]
Task 5, Epoch 16/20 => Loss 0.050, Train_accy 98.33:  75%|███████▌  | 15/20 [03:03<00:57, 11.49s/it]
Task 5, Epoch 16/20 => Loss 0.050, Train_accy 98.33:  80%|████████  | 16/20 [03:03<00:45, 11.48s/it]
Task 5, Epoch 17/20 => Loss 0.057, Train_accy 98.07:  80%|████████  | 16/20 [03:15<00:45, 11.48s/it]
Task 5, Epoch 17/20 => Loss 0.057, Train_accy 98.07:  85%|████████▌ | 17/20 [03:15<00:34, 11.44s/it]
Task 5, Epoch 18/20 => Loss 0.050, Train_accy 98.43:  85%|████████▌ | 17/20 [03:26<00:34, 11.44s/it]
Task 5, Epoch 18/20 => Loss 0.050, Train_accy 98.43:  90%|█████████ | 18/20 [03:26<00:22, 11.47s/it]
Task 5, Epoch 19/20 => Loss 0.054, Train_accy 98.33:  90%|█████████ | 18/20 [03:38<00:22, 11.47s/it]
Task 5, Epoch 19/20 => Loss 0.054, Train_accy 98.33:  95%|█████████▌| 19/20 [03:38<00:11, 11.44s/it]
Task 5, Epoch 20/20 => Loss 0.055, Train_accy 98.07:  95%|█████████▌| 19/20 [03:49<00:11, 11.44s/it]
Task 5, Epoch 20/20 => Loss 0.055, Train_accy 98.07: 100%|██████████| 20/20 [03:49<00:00, 11.47s/it]
Task 5, Epoch 20/20 => Loss 0.055, Train_accy 98.07: 100%|██████████| 20/20 [03:49<00:00, 11.48s/it]
2024-08-12 12:06:40,872 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.055, Train_accy 98.07
Threshold:  0.9583333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 11/768 type remove
Layer 3 : 20/768 type remove
Layer 4 : 21/768 type remove
Layer 5 : 32/768 type remove
Layer 6 : 33/768 type remove
Layer 7 : 33/768 type remove
Layer 8 : 36/768 type remove
Layer 9 : 47/768 type remove
Layer 10 : 54/768 type remove
Layer 11 : 20/768 type remove
Layer 12 : 36/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:07:00,393 [trainer.py] => Time:260.25406217575073
1199 1199
1199 1199
2024-08-12 12:07:03,693 [trainer.py] => Time:3.3005151748657227
2024-08-12 12:07:03,694 [inflora.py] => Exemplar size: 0
2024-08-12 12:07:03,694 [trainer.py] => CNN: {'total': 81.32, '00-09': 81.5, '10-19': 87.0, '20-29': 70.5, '30-39': 78.0, '40-49': 82.0, '50-59': 88.94, 'old': 79.8, 'new': 88.94}
2024-08-12 12:07:03,694 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32]
2024-08-12 12:07:03,694 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17]
2024-08-12 12:07:03,694 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258]
Average Accuracy (CNN): 87.84
2024-08-12 12:07:03,699 [trainer.py] => All params: 112239531
2024-08-12 12:07:03,704 [trainer.py] => Trainable params: 81418
2024-08-12 12:07:03,704 [inflora.py] => Learning on 60-70

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 0.506, Train_accy 84.99:   0%|          | 0/20 [00:11<?, ?it/s]
Task 6, Epoch 1/20 => Loss 0.506, Train_accy 84.99:   5%|▌         | 1/20 [00:11<03:32, 11.21s/it]
Task 6, Epoch 2/20 => Loss 0.103, Train_accy 96.59:   5%|▌         | 1/20 [00:22<03:32, 11.21s/it]
Task 6, Epoch 2/20 => Loss 0.103, Train_accy 96.59:  10%|█         | 2/20 [00:22<03:24, 11.33s/it]
Task 6, Epoch 3/20 => Loss 0.072, Train_accy 97.68:  10%|█         | 2/20 [00:33<03:24, 11.33s/it]
Task 6, Epoch 3/20 => Loss 0.072, Train_accy 97.68:  15%|█▌        | 3/20 [00:33<03:12, 11.34s/it]
Task 6, Epoch 4/20 => Loss 0.073, Train_accy 97.78:  15%|█▌        | 3/20 [00:45<03:12, 11.34s/it]
Task 6, Epoch 4/20 => Loss 0.073, Train_accy 97.78:  20%|██        | 4/20 [00:45<03:02, 11.38s/it]
Task 6, Epoch 5/20 => Loss 0.059, Train_accy 98.01:  20%|██        | 4/20 [00:56<03:02, 11.38s/it]
Task 6, Epoch 5/20 => Loss 0.059, Train_accy 98.01:  25%|██▌       | 5/20 [00:56<02:50, 11.38s/it]
Task 6, Epoch 6/20 => Loss 0.059, Train_accy 97.91:  25%|██▌       | 5/20 [01:08<02:50, 11.38s/it]
Task 6, Epoch 6/20 => Loss 0.059, Train_accy 97.91:  30%|███       | 6/20 [01:08<02:39, 11.38s/it]
Task 6, Epoch 7/20 => Loss 0.050, Train_accy 98.05:  30%|███       | 6/20 [01:19<02:39, 11.38s/it]
Task 6, Epoch 7/20 => Loss 0.050, Train_accy 98.05:  35%|███▌      | 7/20 [01:19<02:27, 11.37s/it]
Task 6, Epoch 8/20 => Loss 0.053, Train_accy 98.28:  35%|███▌      | 7/20 [01:30<02:27, 11.37s/it]
Task 6, Epoch 8/20 => Loss 0.053, Train_accy 98.28:  40%|████      | 8/20 [01:30<02:16, 11.35s/it]
Task 6, Epoch 9/20 => Loss 0.057, Train_accy 97.91:  40%|████      | 8/20 [01:42<02:16, 11.35s/it]
Task 6, Epoch 9/20 => Loss 0.057, Train_accy 97.91:  45%|████▌     | 9/20 [01:42<02:04, 11.35s/it]
Task 6, Epoch 10/20 => Loss 0.049, Train_accy 98.24:  45%|████▌     | 9/20 [01:53<02:04, 11.35s/it]
Task 6, Epoch 10/20 => Loss 0.049, Train_accy 98.24:  50%|█████     | 10/20 [01:53<01:53, 11.32s/it]
Task 6, Epoch 11/20 => Loss 0.059, Train_accy 97.95:  50%|█████     | 10/20 [02:04<01:53, 11.32s/it]
Task 6, Epoch 11/20 => Loss 0.059, Train_accy 97.95:  55%|█████▌    | 11/20 [02:04<01:42, 11.36s/it]
Task 6, Epoch 12/20 => Loss 0.045, Train_accy 98.38:  55%|█████▌    | 11/20 [02:16<01:42, 11.36s/it]
Task 6, Epoch 12/20 => Loss 0.045, Train_accy 98.38:  60%|██████    | 12/20 [02:16<01:30, 11.36s/it]
Task 6, Epoch 13/20 => Loss 0.047, Train_accy 98.34:  60%|██████    | 12/20 [02:27<01:30, 11.36s/it]
Task 6, Epoch 13/20 => Loss 0.047, Train_accy 98.34:  65%|██████▌   | 13/20 [02:27<01:19, 11.35s/it]
Task 6, Epoch 14/20 => Loss 0.042, Train_accy 98.38:  65%|██████▌   | 13/20 [02:38<01:19, 11.35s/it]
Task 6, Epoch 14/20 => Loss 0.042, Train_accy 98.38:  70%|███████   | 14/20 [02:38<01:08, 11.37s/it]
Task 6, Epoch 15/20 => Loss 0.042, Train_accy 98.51:  70%|███████   | 14/20 [02:50<01:08, 11.37s/it]
Task 6, Epoch 15/20 => Loss 0.042, Train_accy 98.51:  75%|███████▌  | 15/20 [02:50<00:56, 11.36s/it]
Task 6, Epoch 16/20 => Loss 0.037, Train_accy 98.64:  75%|███████▌  | 15/20 [03:01<00:56, 11.36s/it]
Task 6, Epoch 16/20 => Loss 0.037, Train_accy 98.64:  80%|████████  | 16/20 [03:01<00:45, 11.39s/it]
Task 6, Epoch 17/20 => Loss 0.035, Train_accy 98.94:  80%|████████  | 16/20 [03:13<00:45, 11.39s/it]
Task 6, Epoch 17/20 => Loss 0.035, Train_accy 98.94:  85%|████████▌ | 17/20 [03:13<00:34, 11.36s/it]
Task 6, Epoch 18/20 => Loss 0.041, Train_accy 98.58:  85%|████████▌ | 17/20 [03:24<00:34, 11.36s/it]
Task 6, Epoch 18/20 => Loss 0.041, Train_accy 98.58:  90%|█████████ | 18/20 [03:24<00:22, 11.38s/it]
Task 6, Epoch 19/20 => Loss 0.033, Train_accy 98.91:  90%|█████████ | 18/20 [03:35<00:22, 11.38s/it]
Task 6, Epoch 19/20 => Loss 0.033, Train_accy 98.91:  95%|█████████▌| 19/20 [03:35<00:11, 11.41s/it]
Task 6, Epoch 20/20 => Loss 0.041, Train_accy 98.58:  95%|█████████▌| 19/20 [03:47<00:11, 11.41s/it]
Task 6, Epoch 20/20 => Loss 0.041, Train_accy 98.58: 100%|██████████| 20/20 [03:47<00:00, 11.38s/it]
Task 6, Epoch 20/20 => Loss 0.041, Train_accy 98.58: 100%|██████████| 20/20 [03:47<00:00, 11.36s/it]
2024-08-12 12:11:01,832 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.041, Train_accy 98.58
Threshold:  0.96
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 23/768 type remove
Layer 5 : 36/768 type remove
Layer 6 : 38/768 type remove
Layer 7 : 37/768 type remove
Layer 8 : 41/768 type remove
Layer 9 : 52/768 type remove
Layer 10 : 60/768 type remove
Layer 11 : 22/768 type remove
Layer 12 : 43/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:11:21,891 [trainer.py] => Time:258.18679547309875
1399 1399
1399 1399
2024-08-12 12:11:25,715 [trainer.py] => Time:3.823798894882202
2024-08-12 12:11:25,715 [inflora.py] => Exemplar size: 0
2024-08-12 12:11:25,715 [trainer.py] => CNN: {'total': 80.2, '00-09': 80.0, '10-19': 85.0, '20-29': 70.0, '30-39': 73.5, '40-49': 80.5, '50-59': 84.92, '60-69': 87.5, 'old': 78.98, 'new': 87.5}
2024-08-12 12:11:25,716 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2]
2024-08-12 12:11:25,716 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21]
2024-08-12 12:11:25,716 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442]
Average Accuracy (CNN): 86.75
2024-08-12 12:11:25,723 [trainer.py] => All params: 112239531
2024-08-12 12:11:25,728 [trainer.py] => Trainable params: 81418
2024-08-12 12:11:25,728 [inflora.py] => Learning on 70-80

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 0.527, Train_accy 83.89:   0%|          | 0/20 [00:10<?, ?it/s]
Task 7, Epoch 1/20 => Loss 0.527, Train_accy 83.89:   5%|▌         | 1/20 [00:10<03:28, 10.97s/it]
Task 7, Epoch 2/20 => Loss 0.190, Train_accy 92.97:   5%|▌         | 1/20 [00:21<03:28, 10.97s/it]
Task 7, Epoch 2/20 => Loss 0.190, Train_accy 92.97:  10%|█         | 2/20 [00:21<03:16, 10.91s/it]
Task 7, Epoch 3/20 => Loss 0.137, Train_accy 95.81:  10%|█         | 2/20 [00:32<03:16, 10.91s/it]
Task 7, Epoch 3/20 => Loss 0.137, Train_accy 95.81:  15%|█▌        | 3/20 [00:32<03:05, 10.90s/it]
Task 7, Epoch 4/20 => Loss 0.122, Train_accy 95.81:  15%|█▌        | 3/20 [00:43<03:05, 10.90s/it]
Task 7, Epoch 4/20 => Loss 0.122, Train_accy 95.81:  20%|██        | 4/20 [00:43<02:54, 10.88s/it]
Task 7, Epoch 5/20 => Loss 0.122, Train_accy 95.81:  20%|██        | 4/20 [00:54<02:54, 10.88s/it]
Task 7, Epoch 5/20 => Loss 0.122, Train_accy 95.81:  25%|██▌       | 5/20 [00:54<02:43, 10.91s/it]
Task 7, Epoch 6/20 => Loss 0.106, Train_accy 96.60:  25%|██▌       | 5/20 [01:05<02:43, 10.91s/it]
Task 7, Epoch 6/20 => Loss 0.106, Train_accy 96.60:  30%|███       | 6/20 [01:05<02:32, 10.91s/it]
Task 7, Epoch 7/20 => Loss 0.106, Train_accy 96.29:  30%|███       | 6/20 [01:16<02:32, 10.91s/it]
Task 7, Epoch 7/20 => Loss 0.106, Train_accy 96.29:  35%|███▌      | 7/20 [01:16<02:22, 10.96s/it]
Task 7, Epoch 8/20 => Loss 0.103, Train_accy 96.26:  35%|███▌      | 7/20 [01:27<02:22, 10.96s/it]
Task 7, Epoch 8/20 => Loss 0.103, Train_accy 96.26:  40%|████      | 8/20 [01:27<02:11, 10.98s/it]
Task 7, Epoch 9/20 => Loss 0.080, Train_accy 96.81:  40%|████      | 8/20 [01:38<02:11, 10.98s/it]
Task 7, Epoch 9/20 => Loss 0.080, Train_accy 96.81:  45%|████▌     | 9/20 [01:38<02:01, 11.02s/it]
Task 7, Epoch 10/20 => Loss 0.087, Train_accy 96.78:  45%|████▌     | 9/20 [01:49<02:01, 11.02s/it]
Task 7, Epoch 10/20 => Loss 0.087, Train_accy 96.78:  50%|█████     | 10/20 [01:49<01:49, 10.98s/it]
Task 7, Epoch 11/20 => Loss 0.086, Train_accy 96.92:  50%|█████     | 10/20 [02:00<01:49, 10.98s/it]
Task 7, Epoch 11/20 => Loss 0.086, Train_accy 96.92:  55%|█████▌    | 11/20 [02:00<01:38, 11.00s/it]
Task 7, Epoch 12/20 => Loss 0.085, Train_accy 96.99:  55%|█████▌    | 11/20 [02:11<01:38, 11.00s/it]
Task 7, Epoch 12/20 => Loss 0.085, Train_accy 96.99:  60%|██████    | 12/20 [02:11<01:28, 11.01s/it]
Task 7, Epoch 13/20 => Loss 0.085, Train_accy 96.92:  60%|██████    | 12/20 [02:22<01:28, 11.01s/it]
Task 7, Epoch 13/20 => Loss 0.085, Train_accy 96.92:  65%|██████▌   | 13/20 [02:22<01:16, 10.97s/it]
Task 7, Epoch 14/20 => Loss 0.075, Train_accy 97.23:  65%|██████▌   | 13/20 [02:33<01:16, 10.97s/it]
Task 7, Epoch 14/20 => Loss 0.075, Train_accy 97.23:  70%|███████   | 14/20 [02:33<01:05, 11.00s/it]
Task 7, Epoch 15/20 => Loss 0.065, Train_accy 97.82:  70%|███████   | 14/20 [02:44<01:05, 11.00s/it]
Task 7, Epoch 15/20 => Loss 0.065, Train_accy 97.82:  75%|███████▌  | 15/20 [02:44<00:54, 10.99s/it]
Task 7, Epoch 16/20 => Loss 0.064, Train_accy 97.85:  75%|███████▌  | 15/20 [02:55<00:54, 10.99s/it]
Task 7, Epoch 16/20 => Loss 0.064, Train_accy 97.85:  80%|████████  | 16/20 [02:55<00:43, 10.96s/it]
Task 7, Epoch 17/20 => Loss 0.068, Train_accy 97.54:  80%|████████  | 16/20 [03:06<00:43, 10.96s/it]
Task 7, Epoch 17/20 => Loss 0.068, Train_accy 97.54:  85%|████████▌ | 17/20 [03:06<00:32, 10.99s/it]
Task 7, Epoch 18/20 => Loss 0.062, Train_accy 97.75:  85%|████████▌ | 17/20 [03:17<00:32, 10.99s/it]
Task 7, Epoch 18/20 => Loss 0.062, Train_accy 97.75:  90%|█████████ | 18/20 [03:17<00:21, 10.99s/it]
Task 7, Epoch 19/20 => Loss 0.068, Train_accy 97.26:  90%|█████████ | 18/20 [03:28<00:21, 10.99s/it]
Task 7, Epoch 19/20 => Loss 0.068, Train_accy 97.26:  95%|█████████▌| 19/20 [03:28<00:10, 10.95s/it]
Task 7, Epoch 20/20 => Loss 0.058, Train_accy 98.20:  95%|█████████▌| 19/20 [03:39<00:10, 10.95s/it]
Task 7, Epoch 20/20 => Loss 0.058, Train_accy 98.20: 100%|██████████| 20/20 [03:39<00:00, 10.98s/it]
Task 7, Epoch 20/20 => Loss 0.058, Train_accy 98.20: 100%|██████████| 20/20 [03:39<00:00, 10.97s/it]
2024-08-12 12:15:15,705 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.058, Train_accy 98.20
Threshold:  0.9616666666666667
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 25/768 type remove
Layer 4 : 26/768 type remove
Layer 5 : 42/768 type remove
Layer 6 : 45/768 type remove
Layer 7 : 43/768 type remove
Layer 8 : 49/768 type remove
Layer 9 : 65/768 type remove
Layer 10 : 72/768 type remove
Layer 11 : 28/768 type remove
Layer 12 : 48/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:15:35,275 [trainer.py] => Time:249.54724979400635
1599 1599
1599 1599
2024-08-12 12:15:39,554 [trainer.py] => Time:4.278739929199219
2024-08-12 12:15:39,555 [inflora.py] => Exemplar size: 0
2024-08-12 12:15:39,555 [trainer.py] => CNN: {'total': 80.74, '00-09': 79.5, '10-19': 85.5, '20-29': 72.0, '30-39': 73.0, '40-49': 80.0, '50-59': 86.43, '60-69': 86.0, '70-79': 83.5, 'old': 80.34, 'new': 83.5}
2024-08-12 12:15:39,555 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74]
2024-08-12 12:15:39,555 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25]
2024-08-12 12:15:39,555 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477]
Average Accuracy (CNN): 86.0
2024-08-12 12:15:39,562 [trainer.py] => All params: 112239531
2024-08-12 12:15:39,566 [trainer.py] => Trainable params: 81418
2024-08-12 12:15:39,566 [inflora.py] => Learning on 80-90

  0%|          | 0/20 [00:00<?, ?it/s]
Task 8, Epoch 1/20 => Loss 0.614, Train_accy 79.68:   0%|          | 0/20 [00:10<?, ?it/s]
Task 8, Epoch 1/20 => Loss 0.614, Train_accy 79.68:   5%|▌         | 1/20 [00:10<03:24, 10.76s/it]
Task 8, Epoch 2/20 => Loss 0.197, Train_accy 91.88:   5%|▌         | 1/20 [00:21<03:24, 10.76s/it]
Task 8, Epoch 2/20 => Loss 0.197, Train_accy 91.88:  10%|█         | 2/20 [00:21<03:13, 10.72s/it]
Task 8, Epoch 3/20 => Loss 0.158, Train_accy 93.74:  10%|█         | 2/20 [00:32<03:13, 10.72s/it]
Task 8, Epoch 3/20 => Loss 0.158, Train_accy 93.74:  15%|█▌        | 3/20 [00:32<03:03, 10.81s/it]
Task 8, Epoch 4/20 => Loss 0.139, Train_accy 94.80:  15%|█▌        | 3/20 [00:43<03:03, 10.81s/it]
Task 8, Epoch 4/20 => Loss 0.139, Train_accy 94.80:  20%|██        | 4/20 [00:43<02:52, 10.81s/it]
Task 8, Epoch 5/20 => Loss 0.145, Train_accy 94.55:  20%|██        | 4/20 [00:54<02:52, 10.81s/it]
Task 8, Epoch 5/20 => Loss 0.145, Train_accy 94.55:  25%|██▌       | 5/20 [00:54<02:42, 10.82s/it]
Task 8, Epoch 6/20 => Loss 0.130, Train_accy 95.04:  25%|██▌       | 5/20 [01:04<02:42, 10.82s/it]
Task 8, Epoch 6/20 => Loss 0.130, Train_accy 95.04:  30%|███       | 6/20 [01:04<02:31, 10.83s/it]
Task 8, Epoch 7/20 => Loss 0.114, Train_accy 95.78:  30%|███       | 6/20 [01:15<02:31, 10.83s/it]
Task 8, Epoch 7/20 => Loss 0.114, Train_accy 95.78:  35%|███▌      | 7/20 [01:15<02:20, 10.83s/it]
Task 8, Epoch 8/20 => Loss 0.107, Train_accy 95.47:  35%|███▌      | 7/20 [01:26<02:20, 10.83s/it]
Task 8, Epoch 8/20 => Loss 0.107, Train_accy 95.47:  40%|████      | 8/20 [01:26<02:09, 10.81s/it]
Task 8, Epoch 9/20 => Loss 0.087, Train_accy 96.49:  40%|████      | 8/20 [01:37<02:09, 10.81s/it]
Task 8, Epoch 9/20 => Loss 0.087, Train_accy 96.49:  45%|████▌     | 9/20 [01:37<01:59, 10.85s/it]
Task 8, Epoch 10/20 => Loss 0.085, Train_accy 96.77:  45%|████▌     | 9/20 [01:48<01:59, 10.85s/it]
Task 8, Epoch 10/20 => Loss 0.085, Train_accy 96.77:  50%|█████     | 10/20 [01:48<01:48, 10.82s/it]
Task 8, Epoch 11/20 => Loss 0.105, Train_accy 95.85:  50%|█████     | 10/20 [01:59<01:48, 10.82s/it]
Task 8, Epoch 11/20 => Loss 0.105, Train_accy 95.85:  55%|█████▌    | 11/20 [01:59<01:37, 10.86s/it]
Task 8, Epoch 12/20 => Loss 0.082, Train_accy 96.98:  55%|█████▌    | 11/20 [02:09<01:37, 10.86s/it]
Task 8, Epoch 12/20 => Loss 0.082, Train_accy 96.98:  60%|██████    | 12/20 [02:09<01:26, 10.87s/it]
Task 8, Epoch 13/20 => Loss 0.080, Train_accy 96.59:  60%|██████    | 12/20 [02:20<01:26, 10.87s/it]
Task 8, Epoch 13/20 => Loss 0.080, Train_accy 96.59:  65%|██████▌   | 13/20 [02:20<01:15, 10.85s/it]
Task 8, Epoch 14/20 => Loss 0.081, Train_accy 97.19:  65%|██████▌   | 13/20 [02:31<01:15, 10.85s/it]
Task 8, Epoch 14/20 => Loss 0.081, Train_accy 97.19:  70%|███████   | 14/20 [02:31<01:05, 10.88s/it]
Task 8, Epoch 15/20 => Loss 0.078, Train_accy 96.98:  70%|███████   | 14/20 [02:42<01:05, 10.88s/it]
Task 8, Epoch 15/20 => Loss 0.078, Train_accy 96.98:  75%|███████▌  | 15/20 [02:42<00:54, 10.86s/it]
Task 8, Epoch 16/20 => Loss 0.077, Train_accy 97.47:  75%|███████▌  | 15/20 [02:53<00:54, 10.86s/it]
Task 8, Epoch 16/20 => Loss 0.077, Train_accy 97.47:  80%|████████  | 16/20 [02:53<00:43, 10.85s/it]
Task 8, Epoch 17/20 => Loss 0.067, Train_accy 97.19:  80%|████████  | 16/20 [03:04<00:43, 10.85s/it]
Task 8, Epoch 17/20 => Loss 0.067, Train_accy 97.19:  85%|████████▌ | 17/20 [03:04<00:32, 10.85s/it]
Task 8, Epoch 18/20 => Loss 0.073, Train_accy 97.29:  85%|████████▌ | 17/20 [03:15<00:32, 10.85s/it]
Task 8, Epoch 18/20 => Loss 0.073, Train_accy 97.29:  90%|█████████ | 18/20 [03:15<00:21, 10.87s/it]
Task 8, Epoch 19/20 => Loss 0.071, Train_accy 97.43:  90%|█████████ | 18/20 [03:25<00:21, 10.87s/it]
Task 8, Epoch 19/20 => Loss 0.071, Train_accy 97.43:  95%|█████████▌| 19/20 [03:25<00:10, 10.85s/it]
Task 8, Epoch 20/20 => Loss 0.071, Train_accy 97.36:  95%|█████████▌| 19/20 [03:36<00:10, 10.85s/it]
Task 8, Epoch 20/20 => Loss 0.071, Train_accy 97.36: 100%|██████████| 20/20 [03:36<00:00, 10.88s/it]
Task 8, Epoch 20/20 => Loss 0.071, Train_accy 97.36: 100%|██████████| 20/20 [03:36<00:00, 10.85s/it]
2024-08-12 12:19:26,891 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.071, Train_accy 97.36
Threshold:  0.9633333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 26/768 type remove
Layer 4 : 28/768 type remove
Layer 5 : 44/768 type remove
Layer 6 : 47/768 type remove
Layer 7 : 46/768 type remove
Layer 8 : 52/768 type remove
Layer 9 : 69/768 type remove
Layer 10 : 81/768 type remove
Layer 11 : 35/768 type remove
Layer 12 : 54/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:19:46,115 [trainer.py] => Time:246.54869747161865
1798 1798
1798 1798
2024-08-12 12:19:50,553 [trainer.py] => Time:4.437126874923706
2024-08-12 12:19:50,553 [inflora.py] => Exemplar size: 0
2024-08-12 12:19:50,553 [trainer.py] => CNN: {'total': 78.7, '00-09': 80.5, '10-19': 81.0, '20-29': 69.5, '30-39': 72.0, '40-49': 80.0, '50-59': 85.93, '60-69': 85.0, '70-79': 82.0, '80-89': 72.36, 'old': 79.49, 'new': 72.36}
2024-08-12 12:19:50,553 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7]
2024-08-12 12:19:50,553 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33]
2024-08-12 12:19:50,553 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408]
Average Accuracy (CNN): 85.18
2024-08-12 12:19:50,558 [trainer.py] => All params: 112239531
2024-08-12 12:19:50,563 [trainer.py] => Trainable params: 81418
2024-08-12 12:19:50,563 [inflora.py] => Learning on 90-100

  0%|          | 0/20 [00:00<?, ?it/s]
Task 9, Epoch 1/20 => Loss 0.393, Train_accy 88.04:   0%|          | 0/20 [00:11<?, ?it/s]
Task 9, Epoch 1/20 => Loss 0.393, Train_accy 88.04:   5%|▌         | 1/20 [00:11<03:35, 11.35s/it]
Task 9, Epoch 2/20 => Loss 0.089, Train_accy 97.34:   5%|▌         | 1/20 [00:22<03:35, 11.35s/it]
Task 9, Epoch 2/20 => Loss 0.089, Train_accy 97.34:  10%|█         | 2/20 [00:22<03:24, 11.36s/it]
Task 9, Epoch 3/20 => Loss 0.073, Train_accy 97.64:  10%|█         | 2/20 [00:34<03:24, 11.36s/it]
Task 9, Epoch 3/20 => Loss 0.073, Train_accy 97.64:  15%|█▌        | 3/20 [00:34<03:14, 11.42s/it]
Task 9, Epoch 4/20 => Loss 0.069, Train_accy 97.84:  15%|█▌        | 3/20 [00:45<03:14, 11.42s/it]
Task 9, Epoch 4/20 => Loss 0.069, Train_accy 97.84:  20%|██        | 4/20 [00:45<03:02, 11.43s/it]
Task 9, Epoch 5/20 => Loss 0.063, Train_accy 97.94:  20%|██        | 4/20 [00:57<03:02, 11.43s/it]
Task 9, Epoch 5/20 => Loss 0.063, Train_accy 97.94:  25%|██▌       | 5/20 [00:57<02:51, 11.43s/it]
Task 9, Epoch 6/20 => Loss 0.058, Train_accy 98.14:  25%|██▌       | 5/20 [01:08<02:51, 11.43s/it]
Task 9, Epoch 6/20 => Loss 0.058, Train_accy 98.14:  30%|███       | 6/20 [01:08<02:39, 11.43s/it]
Task 9, Epoch 7/20 => Loss 0.052, Train_accy 98.41:  30%|███       | 6/20 [01:19<02:39, 11.43s/it]
Task 9, Epoch 7/20 => Loss 0.052, Train_accy 98.41:  35%|███▌      | 7/20 [01:19<02:28, 11.40s/it]
Task 9, Epoch 8/20 => Loss 0.051, Train_accy 98.11:  35%|███▌      | 7/20 [01:31<02:28, 11.40s/it]
Task 9, Epoch 8/20 => Loss 0.051, Train_accy 98.11:  40%|████      | 8/20 [01:31<02:17, 11.45s/it]
Task 9, Epoch 9/20 => Loss 0.047, Train_accy 98.47:  40%|████      | 8/20 [01:42<02:17, 11.45s/it]
Task 9, Epoch 9/20 => Loss 0.047, Train_accy 98.47:  45%|████▌     | 9/20 [01:42<02:05, 11.44s/it]
Task 9, Epoch 10/20 => Loss 0.054, Train_accy 98.24:  45%|████▌     | 9/20 [01:54<02:05, 11.44s/it]
Task 9, Epoch 10/20 => Loss 0.054, Train_accy 98.24:  50%|█████     | 10/20 [01:54<01:54, 11.43s/it]
Task 9, Epoch 11/20 => Loss 0.050, Train_accy 98.34:  50%|█████     | 10/20 [02:05<01:54, 11.43s/it]
Task 9, Epoch 11/20 => Loss 0.050, Train_accy 98.34:  55%|█████▌    | 11/20 [02:05<01:42, 11.42s/it]
Task 9, Epoch 12/20 => Loss 0.053, Train_accy 98.17:  55%|█████▌    | 11/20 [02:16<01:42, 11.42s/it]
Task 9, Epoch 12/20 => Loss 0.053, Train_accy 98.17:  60%|██████    | 12/20 [02:16<01:31, 11.40s/it]
Task 9, Epoch 13/20 => Loss 0.041, Train_accy 98.51:  60%|██████    | 12/20 [02:28<01:31, 11.40s/it]
Task 9, Epoch 13/20 => Loss 0.041, Train_accy 98.51:  65%|██████▌   | 13/20 [02:28<01:20, 11.44s/it]
Task 9, Epoch 14/20 => Loss 0.036, Train_accy 98.77:  65%|██████▌   | 13/20 [02:39<01:20, 11.44s/it]
Task 9, Epoch 14/20 => Loss 0.036, Train_accy 98.77:  70%|███████   | 14/20 [02:39<01:08, 11.41s/it]
Task 9, Epoch 15/20 => Loss 0.046, Train_accy 98.37:  70%|███████   | 14/20 [02:51<01:08, 11.41s/it]
Task 9, Epoch 15/20 => Loss 0.046, Train_accy 98.37:  75%|███████▌  | 15/20 [02:51<00:57, 11.45s/it]
Task 9, Epoch 16/20 => Loss 0.032, Train_accy 98.87:  75%|███████▌  | 15/20 [03:02<00:57, 11.45s/it]
Task 9, Epoch 16/20 => Loss 0.032, Train_accy 98.87:  80%|████████  | 16/20 [03:02<00:45, 11.45s/it]
Task 9, Epoch 17/20 => Loss 0.043, Train_accy 98.64:  80%|████████  | 16/20 [03:14<00:45, 11.45s/it]
Task 9, Epoch 17/20 => Loss 0.043, Train_accy 98.64:  85%|████████▌ | 17/20 [03:14<00:34, 11.42s/it]
Task 9, Epoch 18/20 => Loss 0.040, Train_accy 98.57:  85%|████████▌ | 17/20 [03:25<00:34, 11.42s/it]
Task 9, Epoch 18/20 => Loss 0.040, Train_accy 98.57:  90%|█████████ | 18/20 [03:25<00:22, 11.48s/it]
Task 9, Epoch 19/20 => Loss 0.039, Train_accy 98.77:  90%|█████████ | 18/20 [03:37<00:22, 11.48s/it]
Task 9, Epoch 19/20 => Loss 0.039, Train_accy 98.77:  95%|█████████▌| 19/20 [03:37<00:11, 11.60s/it]
Task 9, Epoch 20/20 => Loss 0.031, Train_accy 98.87:  95%|█████████▌| 19/20 [03:49<00:11, 11.60s/it]
Task 9, Epoch 20/20 => Loss 0.031, Train_accy 98.87: 100%|██████████| 20/20 [03:49<00:00, 11.54s/it]
Task 9, Epoch 20/20 => Loss 0.031, Train_accy 98.87: 100%|██████████| 20/20 [03:49<00:00, 11.45s/it]
2024-08-12 12:23:50,379 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.031, Train_accy 98.87
Threshold:  0.965
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 28/768 type remove
Layer 4 : 30/768 type remove
Layer 5 : 46/768 type remove
Layer 6 : 50/768 type remove
Layer 7 : 49/768 type remove
Layer 8 : 56/768 type remove
Layer 9 : 73/768 type remove
Layer 10 : 87/768 type remove
Layer 11 : 38/768 type remove
Layer 12 : 59/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:24:10,250 [trainer.py] => Time:259.6869521141052
1997 1997
1997 1997
2024-08-12 12:24:15,092 [trainer.py] => Time:4.841909408569336
2024-08-12 12:24:15,092 [inflora.py] => Exemplar size: 0
2024-08-12 12:24:15,092 [trainer.py] => CNN: {'total': 76.87, '00-09': 81.0, '10-19': 80.0, '20-29': 66.5, '30-39': 72.5, '40-49': 79.5, '50-59': 85.43, '60-69': 85.0, '70-79': 80.5, '80-89': 70.85, '90-99': 67.34, 'old': 77.92, 'new': 67.34}
2024-08-12 12:24:15,092 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87]
2024-08-12 12:24:15,092 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15]
2024-08-12 12:24:15,092 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739]
Average Accuracy (CNN): 84.35
2024-08-12 12:24:15,098 [trainer.py] => All params: 112239531
2024-08-12 12:24:15,103 [trainer.py] => Trainable params: 81418
2024-08-12 12:24:15,103 [inflora.py] => Learning on 100-110

  0%|          | 0/20 [00:00<?, ?it/s]
Task 10, Epoch 1/20 => Loss 0.504, Train_accy 84.87:   0%|          | 0/20 [00:11<?, ?it/s]
Task 10, Epoch 1/20 => Loss 0.504, Train_accy 84.87:   5%|▌         | 1/20 [00:11<03:39, 11.55s/it]
Task 10, Epoch 2/20 => Loss 0.149, Train_accy 94.72:   5%|▌         | 1/20 [00:22<03:39, 11.55s/it]
Task 10, Epoch 2/20 => Loss 0.149, Train_accy 94.72:  10%|█         | 2/20 [00:22<03:26, 11.49s/it]
Task 10, Epoch 3/20 => Loss 0.156, Train_accy 95.45:  10%|█         | 2/20 [00:34<03:26, 11.49s/it]
Task 10, Epoch 3/20 => Loss 0.156, Train_accy 95.45:  15%|█▌        | 3/20 [00:34<03:15, 11.47s/it]
Task 10, Epoch 4/20 => Loss 0.112, Train_accy 96.11:  15%|█▌        | 3/20 [00:45<03:15, 11.47s/it]
Task 10, Epoch 4/20 => Loss 0.112, Train_accy 96.11:  20%|██        | 4/20 [00:45<03:03, 11.46s/it]
Task 10, Epoch 5/20 => Loss 0.116, Train_accy 96.04:  20%|██        | 4/20 [00:57<03:03, 11.46s/it]
Task 10, Epoch 5/20 => Loss 0.116, Train_accy 96.04:  25%|██▌       | 5/20 [00:57<02:52, 11.51s/it]
Task 10, Epoch 6/20 => Loss 0.107, Train_accy 96.04:  25%|██▌       | 5/20 [01:09<02:52, 11.51s/it]
Task 10, Epoch 6/20 => Loss 0.107, Train_accy 96.04:  30%|███       | 6/20 [01:09<02:41, 11.55s/it]
Task 10, Epoch 7/20 => Loss 0.095, Train_accy 96.90:  30%|███       | 6/20 [01:20<02:41, 11.55s/it]
Task 10, Epoch 7/20 => Loss 0.095, Train_accy 96.90:  35%|███▌      | 7/20 [01:20<02:29, 11.52s/it]
Task 10, Epoch 8/20 => Loss 0.086, Train_accy 96.87:  35%|███▌      | 7/20 [01:32<02:29, 11.52s/it]
Task 10, Epoch 8/20 => Loss 0.086, Train_accy 96.87:  40%|████      | 8/20 [01:32<02:18, 11.51s/it]
Task 10, Epoch 9/20 => Loss 0.091, Train_accy 96.90:  40%|████      | 8/20 [01:43<02:18, 11.51s/it]
Task 10, Epoch 9/20 => Loss 0.091, Train_accy 96.90:  45%|████▌     | 9/20 [01:43<02:06, 11.47s/it]
Task 10, Epoch 10/20 => Loss 0.083, Train_accy 97.30:  45%|████▌     | 9/20 [01:54<02:06, 11.47s/it]
Task 10, Epoch 10/20 => Loss 0.083, Train_accy 97.30:  50%|█████     | 10/20 [01:54<01:54, 11.46s/it]
Task 10, Epoch 11/20 => Loss 0.086, Train_accy 96.97:  50%|█████     | 10/20 [02:06<01:54, 11.46s/it]
Task 10, Epoch 11/20 => Loss 0.086, Train_accy 96.97:  55%|█████▌    | 11/20 [02:06<01:42, 11.43s/it]
Task 10, Epoch 12/20 => Loss 0.083, Train_accy 97.13:  55%|█████▌    | 11/20 [02:17<01:42, 11.43s/it]
Task 10, Epoch 12/20 => Loss 0.083, Train_accy 97.13:  60%|██████    | 12/20 [02:17<01:31, 11.48s/it]
Task 10, Epoch 13/20 => Loss 0.078, Train_accy 97.40:  60%|██████    | 12/20 [02:29<01:31, 11.48s/it]
Task 10, Epoch 13/20 => Loss 0.078, Train_accy 97.40:  65%|██████▌   | 13/20 [02:29<01:20, 11.47s/it]
Task 10, Epoch 14/20 => Loss 0.079, Train_accy 97.46:  65%|██████▌   | 13/20 [02:40<01:20, 11.47s/it]
Task 10, Epoch 14/20 => Loss 0.079, Train_accy 97.46:  70%|███████   | 14/20 [02:40<01:08, 11.46s/it]
Task 10, Epoch 15/20 => Loss 0.051, Train_accy 98.22:  70%|███████   | 14/20 [02:52<01:08, 11.46s/it]
Task 10, Epoch 15/20 => Loss 0.051, Train_accy 98.22:  75%|███████▌  | 15/20 [02:52<00:57, 11.52s/it]
Task 10, Epoch 16/20 => Loss 0.063, Train_accy 97.76:  75%|███████▌  | 15/20 [03:03<00:57, 11.52s/it]
Task 10, Epoch 16/20 => Loss 0.063, Train_accy 97.76:  80%|████████  | 16/20 [03:03<00:46, 11.55s/it]
Task 10, Epoch 17/20 => Loss 0.065, Train_accy 97.46:  80%|████████  | 16/20 [03:15<00:46, 11.55s/it]
Task 10, Epoch 17/20 => Loss 0.065, Train_accy 97.46:  85%|████████▌ | 17/20 [03:15<00:34, 11.58s/it]
Task 10, Epoch 18/20 => Loss 0.058, Train_accy 97.92:  85%|████████▌ | 17/20 [03:27<00:34, 11.58s/it]
Task 10, Epoch 18/20 => Loss 0.058, Train_accy 97.92:  90%|█████████ | 18/20 [03:27<00:23, 11.60s/it]
Task 10, Epoch 19/20 => Loss 0.072, Train_accy 97.59:  90%|█████████ | 18/20 [03:38<00:23, 11.60s/it]
Task 10, Epoch 19/20 => Loss 0.072, Train_accy 97.59:  95%|█████████▌| 19/20 [03:38<00:11, 11.55s/it]
Task 10, Epoch 20/20 => Loss 0.058, Train_accy 98.09:  95%|█████████▌| 19/20 [03:50<00:11, 11.55s/it]
Task 10, Epoch 20/20 => Loss 0.058, Train_accy 98.09: 100%|██████████| 20/20 [03:50<00:00, 11.56s/it]
Task 10, Epoch 20/20 => Loss 0.058, Train_accy 98.09: 100%|██████████| 20/20 [03:50<00:00, 11.52s/it]
2024-08-12 12:28:16,796 [inflora.py] => Task 10, Epoch 20/20 => Loss 0.058, Train_accy 98.09
Threshold:  0.9666666666666667
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 31/768 type remove
Layer 5 : 49/768 type remove
Layer 6 : 53/768 type remove
Layer 7 : 53/768 type remove
Layer 8 : 61/768 type remove
Layer 9 : 78/768 type remove
Layer 10 : 91/768 type remove
Layer 11 : 40/768 type remove
Layer 12 : 65/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:28:36,972 [trainer.py] => Time:261.86909198760986
2196 2196
2196 2196
2024-08-12 12:28:42,070 [trainer.py] => Time:5.0975587368011475
2024-08-12 12:28:42,070 [inflora.py] => Exemplar size: 0
2024-08-12 12:28:42,071 [trainer.py] => CNN: {'total': 77.14, '00-09': 81.0, '10-19': 80.5, '20-29': 68.0, '30-39': 71.5, '40-49': 80.0, '50-59': 84.42, '60-69': 85.5, '70-79': 79.5, '80-89': 70.35, '90-99': 65.33, '100-109': 82.41, 'old': 76.61, 'new': 82.41}
2024-08-12 12:28:42,071 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14]
2024-08-12 12:28:42,071 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13]
2024-08-12 12:28:42,071 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608]
Average Accuracy (CNN): 83.7
2024-08-12 12:28:42,076 [trainer.py] => All params: 112239531
2024-08-12 12:28:42,081 [trainer.py] => Trainable params: 81418
2024-08-12 12:28:42,081 [inflora.py] => Learning on 110-120

  0%|          | 0/20 [00:00<?, ?it/s]
Task 11, Epoch 1/20 => Loss 0.509, Train_accy 82.37:   0%|          | 0/20 [00:11<?, ?it/s]
Task 11, Epoch 1/20 => Loss 0.509, Train_accy 82.37:   5%|▌         | 1/20 [00:11<03:39, 11.55s/it]
Task 11, Epoch 2/20 => Loss 0.215, Train_accy 92.41:   5%|▌         | 1/20 [00:23<03:39, 11.55s/it]
Task 11, Epoch 2/20 => Loss 0.215, Train_accy 92.41:  10%|█         | 2/20 [00:23<03:28, 11.61s/it]
Task 11, Epoch 3/20 => Loss 0.154, Train_accy 94.33:  10%|█         | 2/20 [00:34<03:28, 11.61s/it]
Task 11, Epoch 3/20 => Loss 0.154, Train_accy 94.33:  15%|█▌        | 3/20 [00:34<03:17, 11.61s/it]
Task 11, Epoch 4/20 => Loss 0.131, Train_accy 94.98:  15%|█▌        | 3/20 [00:46<03:17, 11.61s/it]
Task 11, Epoch 4/20 => Loss 0.131, Train_accy 94.98:  20%|██        | 4/20 [00:46<03:06, 11.64s/it]
Task 11, Epoch 5/20 => Loss 0.132, Train_accy 95.28:  20%|██        | 4/20 [00:58<03:06, 11.64s/it]
Task 11, Epoch 5/20 => Loss 0.132, Train_accy 95.28:  25%|██▌       | 5/20 [00:58<02:54, 11.65s/it]
Task 11, Epoch 6/20 => Loss 0.112, Train_accy 95.99:  25%|██▌       | 5/20 [01:09<02:54, 11.65s/it]
Task 11, Epoch 6/20 => Loss 0.112, Train_accy 95.99:  30%|███       | 6/20 [01:09<02:43, 11.68s/it]
Task 11, Epoch 7/20 => Loss 0.113, Train_accy 95.96:  30%|███       | 6/20 [01:21<02:43, 11.68s/it]
Task 11, Epoch 7/20 => Loss 0.113, Train_accy 95.96:  35%|███▌      | 7/20 [01:21<02:31, 11.68s/it]
Task 11, Epoch 8/20 => Loss 0.108, Train_accy 96.06:  35%|███▌      | 7/20 [01:33<02:31, 11.68s/it]
Task 11, Epoch 8/20 => Loss 0.108, Train_accy 96.06:  40%|████      | 8/20 [01:33<02:19, 11.66s/it]
Task 11, Epoch 9/20 => Loss 0.098, Train_accy 96.71:  40%|████      | 8/20 [01:44<02:19, 11.66s/it]
Task 11, Epoch 9/20 => Loss 0.098, Train_accy 96.71:  45%|████▌     | 9/20 [01:44<02:08, 11.67s/it]
Task 11, Epoch 10/20 => Loss 0.087, Train_accy 97.03:  45%|████▌     | 9/20 [01:56<02:08, 11.67s/it]
Task 11, Epoch 10/20 => Loss 0.087, Train_accy 97.03:  50%|█████     | 10/20 [01:56<01:56, 11.66s/it]
Task 11, Epoch 11/20 => Loss 0.100, Train_accy 96.09:  50%|█████     | 10/20 [02:08<01:56, 11.66s/it]
Task 11, Epoch 11/20 => Loss 0.100, Train_accy 96.09:  55%|█████▌    | 11/20 [02:08<01:45, 11.69s/it]
Task 11, Epoch 12/20 => Loss 0.082, Train_accy 96.81:  55%|█████▌    | 11/20 [02:19<01:45, 11.69s/it]
Task 11, Epoch 12/20 => Loss 0.082, Train_accy 96.81:  60%|██████    | 12/20 [02:19<01:33, 11.66s/it]
Task 11, Epoch 13/20 => Loss 0.084, Train_accy 97.10:  60%|██████    | 12/20 [02:31<01:33, 11.66s/it]
Task 11, Epoch 13/20 => Loss 0.084, Train_accy 97.10:  65%|██████▌   | 13/20 [02:31<01:21, 11.64s/it]
Task 11, Epoch 14/20 => Loss 0.083, Train_accy 96.74:  65%|██████▌   | 13/20 [02:43<01:21, 11.64s/it]
Task 11, Epoch 14/20 => Loss 0.083, Train_accy 96.74:  70%|███████   | 14/20 [02:43<01:10, 11.67s/it]
Task 11, Epoch 15/20 => Loss 0.083, Train_accy 97.03:  70%|███████   | 14/20 [02:54<01:10, 11.67s/it]
Task 11, Epoch 15/20 => Loss 0.083, Train_accy 97.03:  75%|███████▌  | 15/20 [02:54<00:58, 11.68s/it]
Task 11, Epoch 16/20 => Loss 0.082, Train_accy 97.03:  75%|███████▌  | 15/20 [03:06<00:58, 11.68s/it]
Task 11, Epoch 16/20 => Loss 0.082, Train_accy 97.03:  80%|████████  | 16/20 [03:06<00:46, 11.71s/it]
Task 11, Epoch 17/20 => Loss 0.082, Train_accy 96.94:  80%|████████  | 16/20 [03:18<00:46, 11.71s/it]
Task 11, Epoch 17/20 => Loss 0.082, Train_accy 96.94:  85%|████████▌ | 17/20 [03:18<00:35, 11.68s/it]
Task 11, Epoch 18/20 => Loss 0.084, Train_accy 96.77:  85%|████████▌ | 17/20 [03:29<00:35, 11.68s/it]
Task 11, Epoch 18/20 => Loss 0.084, Train_accy 96.77:  90%|█████████ | 18/20 [03:29<00:23, 11.68s/it]
Task 11, Epoch 19/20 => Loss 0.077, Train_accy 97.00:  90%|█████████ | 18/20 [03:41<00:23, 11.68s/it]
Task 11, Epoch 19/20 => Loss 0.077, Train_accy 97.00:  95%|█████████▌| 19/20 [03:41<00:11, 11.65s/it]
Task 11, Epoch 20/20 => Loss 0.070, Train_accy 97.33:  95%|█████████▌| 19/20 [03:53<00:11, 11.65s/it]
Task 11, Epoch 20/20 => Loss 0.070, Train_accy 97.33: 100%|██████████| 20/20 [03:53<00:00, 11.69s/it]
Task 11, Epoch 20/20 => Loss 0.070, Train_accy 97.33: 100%|██████████| 20/20 [03:53<00:00, 11.67s/it]
2024-08-12 12:32:46,558 [inflora.py] => Task 11, Epoch 20/20 => Loss 0.070, Train_accy 97.33
Threshold:  0.9683333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 32/768 type remove
Layer 4 : 34/768 type remove
Layer 5 : 52/768 type remove
Layer 6 : 57/768 type remove
Layer 7 : 57/768 type remove
Layer 8 : 68/768 type remove
Layer 9 : 88/768 type remove
Layer 10 : 104/768 type remove
Layer 11 : 46/768 type remove
Layer 12 : 71/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:33:06,666 [trainer.py] => Time:264.5847554206848
2395 2395
2395 2395
2024-08-12 12:33:12,079 [trainer.py] => Time:5.412622690200806
2024-08-12 12:33:12,079 [inflora.py] => Exemplar size: 0
2024-08-12 12:33:12,079 [trainer.py] => CNN: {'total': 75.82, '00-09': 82.5, '10-19': 80.0, '20-29': 68.0, '30-39': 69.5, '40-49': 77.5, '50-59': 85.93, '60-69': 83.5, '70-79': 80.0, '80-89': 70.85, '90-99': 67.34, '100-109': 79.9, '110-119': 64.82, 'old': 76.82, 'new': 64.82}
2024-08-12 12:33:12,079 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82]
2024-08-12 12:33:12,079 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16]
2024-08-12 12:33:12,079 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172]
Average Accuracy (CNN): 83.04
2024-08-12 12:33:12,085 [trainer.py] => All params: 112239531
2024-08-12 12:33:12,089 [trainer.py] => Trainable params: 81418
2024-08-12 12:33:12,090 [inflora.py] => Learning on 120-130

  0%|          | 0/20 [00:00<?, ?it/s]
Task 12, Epoch 1/20 => Loss 0.531, Train_accy 83.41:   0%|          | 0/20 [00:11<?, ?it/s]
Task 12, Epoch 1/20 => Loss 0.531, Train_accy 83.41:   5%|▌         | 1/20 [00:11<03:34, 11.27s/it]
Task 12, Epoch 2/20 => Loss 0.119, Train_accy 95.87:   5%|▌         | 1/20 [00:22<03:34, 11.27s/it]
Task 12, Epoch 2/20 => Loss 0.119, Train_accy 95.87:  10%|█         | 2/20 [00:22<03:22, 11.28s/it]
Task 12, Epoch 3/20 => Loss 0.090, Train_accy 97.02:  10%|█         | 2/20 [00:33<03:22, 11.28s/it]
Task 12, Epoch 3/20 => Loss 0.090, Train_accy 97.02:  15%|█▌        | 3/20 [00:33<03:11, 11.26s/it]
Task 12, Epoch 4/20 => Loss 0.082, Train_accy 97.09:  15%|█▌        | 3/20 [00:45<03:11, 11.26s/it]
Task 12, Epoch 4/20 => Loss 0.082, Train_accy 97.09:  20%|██        | 4/20 [00:45<03:00, 11.27s/it]
Task 12, Epoch 5/20 => Loss 0.076, Train_accy 97.97:  20%|██        | 4/20 [00:56<03:00, 11.27s/it]
Task 12, Epoch 5/20 => Loss 0.076, Train_accy 97.97:  25%|██▌       | 5/20 [00:56<02:48, 11.26s/it]
Task 12, Epoch 6/20 => Loss 0.062, Train_accy 98.17:  25%|██▌       | 5/20 [01:07<02:48, 11.26s/it]
Task 12, Epoch 6/20 => Loss 0.062, Train_accy 98.17:  30%|███       | 6/20 [01:07<02:38, 11.32s/it]
Task 12, Epoch 7/20 => Loss 0.066, Train_accy 97.90:  30%|███       | 6/20 [01:19<02:38, 11.32s/it]
Task 12, Epoch 7/20 => Loss 0.066, Train_accy 97.90:  35%|███▌      | 7/20 [01:19<02:27, 11.32s/it]
Task 12, Epoch 8/20 => Loss 0.051, Train_accy 98.38:  35%|███▌      | 7/20 [01:30<02:27, 11.32s/it]
Task 12, Epoch 8/20 => Loss 0.051, Train_accy 98.38:  40%|████      | 8/20 [01:30<02:16, 11.35s/it]
Task 12, Epoch 9/20 => Loss 0.052, Train_accy 98.38:  40%|████      | 8/20 [01:41<02:16, 11.35s/it]
Task 12, Epoch 9/20 => Loss 0.052, Train_accy 98.38:  45%|████▌     | 9/20 [01:41<02:04, 11.33s/it]
Task 12, Epoch 10/20 => Loss 0.052, Train_accy 98.34:  45%|████▌     | 9/20 [01:53<02:04, 11.33s/it]
Task 12, Epoch 10/20 => Loss 0.052, Train_accy 98.34:  50%|█████     | 10/20 [01:53<01:53, 11.32s/it]
Task 12, Epoch 11/20 => Loss 0.051, Train_accy 98.34:  50%|█████     | 10/20 [02:04<01:53, 11.32s/it]
Task 12, Epoch 11/20 => Loss 0.051, Train_accy 98.34:  55%|█████▌    | 11/20 [02:04<01:42, 11.33s/it]
Task 12, Epoch 12/20 => Loss 0.041, Train_accy 98.68:  55%|█████▌    | 11/20 [02:15<01:42, 11.33s/it]
Task 12, Epoch 12/20 => Loss 0.041, Train_accy 98.68:  60%|██████    | 12/20 [02:15<01:30, 11.29s/it]
Task 12, Epoch 13/20 => Loss 0.042, Train_accy 98.54:  60%|██████    | 12/20 [02:26<01:30, 11.29s/it]
Task 12, Epoch 13/20 => Loss 0.042, Train_accy 98.54:  65%|██████▌   | 13/20 [02:26<01:18, 11.28s/it]
Task 12, Epoch 14/20 => Loss 0.052, Train_accy 98.34:  65%|██████▌   | 13/20 [02:38<01:18, 11.28s/it]
Task 12, Epoch 14/20 => Loss 0.052, Train_accy 98.34:  70%|███████   | 14/20 [02:38<01:07, 11.32s/it]
Task 12, Epoch 15/20 => Loss 0.054, Train_accy 98.04:  70%|███████   | 14/20 [02:49<01:07, 11.32s/it]
Task 12, Epoch 15/20 => Loss 0.054, Train_accy 98.04:  75%|███████▌  | 15/20 [02:49<00:56, 11.29s/it]
Task 12, Epoch 16/20 => Loss 0.043, Train_accy 98.31:  75%|███████▌  | 15/20 [03:00<00:56, 11.29s/it]
Task 12, Epoch 16/20 => Loss 0.043, Train_accy 98.31:  80%|████████  | 16/20 [03:00<00:45, 11.31s/it]
Task 12, Epoch 17/20 => Loss 0.041, Train_accy 98.71:  80%|████████  | 16/20 [03:12<00:45, 11.31s/it]
Task 12, Epoch 17/20 => Loss 0.041, Train_accy 98.71:  85%|████████▌ | 17/20 [03:12<00:33, 11.27s/it]
Task 12, Epoch 18/20 => Loss 0.036, Train_accy 98.61:  85%|████████▌ | 17/20 [03:23<00:33, 11.27s/it]
Task 12, Epoch 18/20 => Loss 0.036, Train_accy 98.61:  90%|█████████ | 18/20 [03:23<00:22, 11.29s/it]
Task 12, Epoch 19/20 => Loss 0.043, Train_accy 98.65:  90%|█████████ | 18/20 [03:34<00:22, 11.29s/it]
Task 12, Epoch 19/20 => Loss 0.043, Train_accy 98.65:  95%|█████████▌| 19/20 [03:34<00:11, 11.30s/it]
Task 12, Epoch 20/20 => Loss 0.041, Train_accy 98.44:  95%|█████████▌| 19/20 [03:46<00:11, 11.30s/it]
Task 12, Epoch 20/20 => Loss 0.041, Train_accy 98.44: 100%|██████████| 20/20 [03:46<00:00, 11.32s/it]
Task 12, Epoch 20/20 => Loss 0.041, Train_accy 98.44: 100%|██████████| 20/20 [03:46<00:00, 11.30s/it]
2024-08-12 12:37:09,143 [inflora.py] => Task 12, Epoch 20/20 => Loss 0.041, Train_accy 98.44
Threshold:  0.97
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 34/768 type remove
Layer 4 : 37/768 type remove
Layer 5 : 56/768 type remove
Layer 6 : 61/768 type remove
Layer 7 : 62/768 type remove
Layer 8 : 73/768 type remove
Layer 9 : 94/768 type remove
Layer 10 : 111/768 type remove
Layer 11 : 51/768 type remove
Layer 12 : 75/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:37:28,882 [trainer.py] => Time:256.7920627593994
2595 2595
2595 2595
2024-08-12 12:37:34,841 [trainer.py] => Time:5.958366870880127
2024-08-12 12:37:34,841 [inflora.py] => Exemplar size: 0
2024-08-12 12:37:34,841 [trainer.py] => CNN: {'total': 75.68, '00-09': 83.0, '10-19': 79.0, '20-29': 70.5, '30-39': 70.0, '40-49': 75.5, '50-59': 80.9, '60-69': 82.5, '70-79': 81.5, '80-89': 69.85, '90-99': 67.84, '100-109': 79.9, '110-119': 65.33, '120-129': 78.0, 'old': 75.49, 'new': 78.0}
2024-08-12 12:37:34,841 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68]
2024-08-12 12:37:34,841 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11]
2024-08-12 12:37:34,841 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734]
Average Accuracy (CNN): 82.47
2024-08-12 12:37:34,846 [trainer.py] => All params: 112239531
2024-08-12 12:37:34,851 [trainer.py] => Trainable params: 81418
2024-08-12 12:37:34,851 [inflora.py] => Learning on 130-140

  0%|          | 0/20 [00:00<?, ?it/s]
Task 13, Epoch 1/20 => Loss 0.595, Train_accy 79.60:   0%|          | 0/20 [00:11<?, ?it/s]
Task 13, Epoch 1/20 => Loss 0.595, Train_accy 79.60:   5%|▌         | 1/20 [00:11<03:40, 11.62s/it]
Task 13, Epoch 2/20 => Loss 0.233, Train_accy 90.88:   5%|▌         | 1/20 [00:23<03:40, 11.62s/it]
Task 13, Epoch 2/20 => Loss 0.233, Train_accy 90.88:  10%|█         | 2/20 [00:23<03:30, 11.69s/it]
Task 13, Epoch 3/20 => Loss 0.198, Train_accy 92.34:  10%|█         | 2/20 [00:34<03:30, 11.69s/it]
Task 13, Epoch 3/20 => Loss 0.198, Train_accy 92.34:  15%|█▌        | 3/20 [00:34<03:18, 11.66s/it]
Task 13, Epoch 4/20 => Loss 0.198, Train_accy 92.15:  15%|█▌        | 3/20 [00:46<03:18, 11.66s/it]
Task 13, Epoch 4/20 => Loss 0.198, Train_accy 92.15:  20%|██        | 4/20 [00:46<03:06, 11.67s/it]
Task 13, Epoch 5/20 => Loss 0.176, Train_accy 93.26:  20%|██        | 4/20 [00:58<03:06, 11.67s/it]
Task 13, Epoch 5/20 => Loss 0.176, Train_accy 93.26:  25%|██▌       | 5/20 [00:58<02:55, 11.73s/it]
Task 13, Epoch 6/20 => Loss 0.143, Train_accy 94.49:  25%|██▌       | 5/20 [01:10<02:55, 11.73s/it]
Task 13, Epoch 6/20 => Loss 0.143, Train_accy 94.49:  30%|███       | 6/20 [01:10<02:44, 11.72s/it]
Task 13, Epoch 7/20 => Loss 0.132, Train_accy 94.85:  30%|███       | 6/20 [01:21<02:44, 11.72s/it]
Task 13, Epoch 7/20 => Loss 0.132, Train_accy 94.85:  35%|███▌      | 7/20 [01:21<02:32, 11.71s/it]
Task 13, Epoch 8/20 => Loss 0.132, Train_accy 94.40:  35%|███▌      | 7/20 [01:33<02:32, 11.71s/it]
Task 13, Epoch 8/20 => Loss 0.132, Train_accy 94.40:  40%|████      | 8/20 [01:33<02:20, 11.72s/it]
Task 13, Epoch 9/20 => Loss 0.135, Train_accy 94.82:  40%|████      | 8/20 [01:45<02:20, 11.72s/it]
Task 13, Epoch 9/20 => Loss 0.135, Train_accy 94.82:  45%|████▌     | 9/20 [01:45<02:08, 11.70s/it]
Task 13, Epoch 10/20 => Loss 0.127, Train_accy 95.11:  45%|████▌     | 9/20 [01:57<02:08, 11.70s/it]
Task 13, Epoch 10/20 => Loss 0.127, Train_accy 95.11:  50%|█████     | 10/20 [01:57<01:57, 11.73s/it]
Task 13, Epoch 11/20 => Loss 0.132, Train_accy 94.69:  50%|█████     | 10/20 [02:08<01:57, 11.73s/it]
Task 13, Epoch 11/20 => Loss 0.132, Train_accy 94.69:  55%|█████▌    | 11/20 [02:08<01:45, 11.71s/it]
Task 13, Epoch 12/20 => Loss 0.121, Train_accy 95.37:  55%|█████▌    | 11/20 [02:20<01:45, 11.71s/it]
Task 13, Epoch 12/20 => Loss 0.121, Train_accy 95.37:  60%|██████    | 12/20 [02:20<01:34, 11.75s/it]
Task 13, Epoch 13/20 => Loss 0.119, Train_accy 95.31:  60%|██████    | 12/20 [02:32<01:34, 11.75s/it]
Task 13, Epoch 13/20 => Loss 0.119, Train_accy 95.31:  65%|██████▌   | 13/20 [02:32<01:22, 11.76s/it]
Task 13, Epoch 14/20 => Loss 0.108, Train_accy 95.70:  65%|██████▌   | 13/20 [02:43<01:22, 11.76s/it]
Task 13, Epoch 14/20 => Loss 0.108, Train_accy 95.70:  70%|███████   | 14/20 [02:43<01:10, 11.71s/it]
Task 13, Epoch 15/20 => Loss 0.114, Train_accy 95.57:  70%|███████   | 14/20 [02:55<01:10, 11.71s/it]
Task 13, Epoch 15/20 => Loss 0.114, Train_accy 95.57:  75%|███████▌  | 15/20 [02:55<00:58, 11.72s/it]
Task 13, Epoch 16/20 => Loss 0.101, Train_accy 95.93:  75%|███████▌  | 15/20 [03:07<00:58, 11.72s/it]
Task 13, Epoch 16/20 => Loss 0.101, Train_accy 95.93:  80%|████████  | 16/20 [03:07<00:47, 11.75s/it]
Task 13, Epoch 17/20 => Loss 0.113, Train_accy 95.54:  80%|████████  | 16/20 [03:19<00:47, 11.75s/it]
Task 13, Epoch 17/20 => Loss 0.113, Train_accy 95.54:  85%|████████▌ | 17/20 [03:19<00:35, 11.72s/it]
Task 13, Epoch 18/20 => Loss 0.098, Train_accy 96.02:  85%|████████▌ | 17/20 [03:30<00:35, 11.72s/it]
Task 13, Epoch 18/20 => Loss 0.098, Train_accy 96.02:  90%|█████████ | 18/20 [03:30<00:23, 11.75s/it]
Task 13, Epoch 19/20 => Loss 0.109, Train_accy 95.93:  90%|█████████ | 18/20 [03:42<00:23, 11.75s/it]
Task 13, Epoch 19/20 => Loss 0.109, Train_accy 95.93:  95%|█████████▌| 19/20 [03:42<00:11, 11.73s/it]
Task 13, Epoch 20/20 => Loss 0.101, Train_accy 96.38:  95%|█████████▌| 19/20 [03:54<00:11, 11.73s/it]
Task 13, Epoch 20/20 => Loss 0.101, Train_accy 96.38: 100%|██████████| 20/20 [03:54<00:00, 11.73s/it]
Task 13, Epoch 20/20 => Loss 0.101, Train_accy 96.38: 100%|██████████| 20/20 [03:54<00:00, 11.72s/it]
2024-08-12 12:41:40,615 [inflora.py] => Task 13, Epoch 20/20 => Loss 0.101, Train_accy 96.38
Threshold:  0.9716666666666667
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 37/768 type remove
Layer 4 : 39/768 type remove
Layer 5 : 59/768 type remove
Layer 6 : 66/768 type remove
Layer 7 : 67/768 type remove
Layer 8 : 79/768 type remove
Layer 9 : 100/768 type remove
Layer 10 : 116/768 type remove
Layer 11 : 54/768 type remove
Layer 12 : 79/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:42:00,951 [trainer.py] => Time:266.09985303878784
2795 2795
2795 2795
2024-08-12 12:42:07,097 [trainer.py] => Time:6.145702123641968
2024-08-12 12:42:07,097 [inflora.py] => Exemplar size: 0
2024-08-12 12:42:07,097 [trainer.py] => CNN: {'total': 74.49, '00-09': 81.0, '10-19': 81.0, '20-29': 67.5, '30-39': 69.5, '40-49': 75.0, '50-59': 77.39, '60-69': 83.0, '70-79': 80.5, '80-89': 68.34, '90-99': 66.83, '100-109': 79.4, '110-119': 64.82, '120-129': 74.5, '130-139': 74.0, 'old': 74.53, 'new': 74.0}
2024-08-12 12:42:07,097 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49]
2024-08-12 12:42:07,097 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89]
2024-08-12 12:42:07,097 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502]
Average Accuracy (CNN): 81.9
2024-08-12 12:42:07,103 [trainer.py] => All params: 112239531
2024-08-12 12:42:07,107 [trainer.py] => Trainable params: 81418
2024-08-12 12:42:07,108 [inflora.py] => Learning on 140-150

  0%|          | 0/20 [00:00<?, ?it/s]
Task 14, Epoch 1/20 => Loss 0.526, Train_accy 82.42:   0%|          | 0/20 [00:11<?, ?it/s]
Task 14, Epoch 1/20 => Loss 0.526, Train_accy 82.42:   5%|▌         | 1/20 [00:11<03:43, 11.77s/it]
Task 14, Epoch 2/20 => Loss 0.173, Train_accy 93.11:   5%|▌         | 1/20 [00:23<03:43, 11.77s/it]
Task 14, Epoch 2/20 => Loss 0.173, Train_accy 93.11:  10%|█         | 2/20 [00:23<03:32, 11.83s/it]
Task 14, Epoch 3/20 => Loss 0.149, Train_accy 94.24:  10%|█         | 2/20 [00:35<03:32, 11.83s/it]
Task 14, Epoch 3/20 => Loss 0.149, Train_accy 94.24:  15%|█▌        | 3/20 [00:35<03:21, 11.84s/it]
Task 14, Epoch 4/20 => Loss 0.132, Train_accy 94.98:  15%|█▌        | 3/20 [00:47<03:21, 11.84s/it]
Task 14, Epoch 4/20 => Loss 0.132, Train_accy 94.98:  20%|██        | 4/20 [00:47<03:09, 11.86s/it]
Task 14, Epoch 5/20 => Loss 0.135, Train_accy 95.07:  20%|██        | 4/20 [00:59<03:09, 11.86s/it]
Task 14, Epoch 5/20 => Loss 0.135, Train_accy 95.07:  25%|██▌       | 5/20 [00:59<02:57, 11.83s/it]
Task 14, Epoch 6/20 => Loss 0.118, Train_accy 95.62:  25%|██▌       | 5/20 [01:11<02:57, 11.83s/it]
Task 14, Epoch 6/20 => Loss 0.118, Train_accy 95.62:  30%|███       | 6/20 [01:11<02:46, 11.88s/it]
Task 14, Epoch 7/20 => Loss 0.115, Train_accy 95.46:  30%|███       | 6/20 [01:23<02:46, 11.88s/it]
Task 14, Epoch 7/20 => Loss 0.115, Train_accy 95.46:  35%|███▌      | 7/20 [01:23<02:34, 11.90s/it]
Task 14, Epoch 8/20 => Loss 0.100, Train_accy 96.36:  35%|███▌      | 7/20 [01:34<02:34, 11.90s/it]
Task 14, Epoch 8/20 => Loss 0.100, Train_accy 96.36:  40%|████      | 8/20 [01:34<02:22, 11.86s/it]
Task 14, Epoch 9/20 => Loss 0.103, Train_accy 96.10:  40%|████      | 8/20 [01:46<02:22, 11.86s/it]
Task 14, Epoch 9/20 => Loss 0.103, Train_accy 96.10:  45%|████▌     | 9/20 [01:46<02:10, 11.89s/it]
Task 14, Epoch 10/20 => Loss 0.092, Train_accy 96.75:  45%|████▌     | 9/20 [01:58<02:10, 11.89s/it]
Task 14, Epoch 10/20 => Loss 0.092, Train_accy 96.75:  50%|█████     | 10/20 [01:58<01:59, 11.91s/it]
Task 14, Epoch 11/20 => Loss 0.090, Train_accy 96.91:  50%|█████     | 10/20 [02:10<01:59, 11.91s/it]
Task 14, Epoch 11/20 => Loss 0.090, Train_accy 96.91:  55%|█████▌    | 11/20 [02:10<01:46, 11.88s/it]
Task 14, Epoch 12/20 => Loss 0.084, Train_accy 97.07:  55%|█████▌    | 11/20 [02:22<01:46, 11.88s/it]
Task 14, Epoch 12/20 => Loss 0.084, Train_accy 97.07:  60%|██████    | 12/20 [02:22<01:34, 11.85s/it]
Task 14, Epoch 13/20 => Loss 0.078, Train_accy 97.17:  60%|██████    | 12/20 [02:34<01:34, 11.85s/it]
Task 14, Epoch 13/20 => Loss 0.078, Train_accy 97.17:  65%|██████▌   | 13/20 [02:34<01:22, 11.83s/it]
Task 14, Epoch 14/20 => Loss 0.090, Train_accy 97.10:  65%|██████▌   | 13/20 [02:46<01:22, 11.83s/it]
Task 14, Epoch 14/20 => Loss 0.090, Train_accy 97.10:  70%|███████   | 14/20 [02:46<01:11, 11.84s/it]
Task 14, Epoch 15/20 => Loss 0.091, Train_accy 96.78:  70%|███████   | 14/20 [02:57<01:11, 11.84s/it]
Task 14, Epoch 15/20 => Loss 0.091, Train_accy 96.78:  75%|███████▌  | 15/20 [02:57<00:59, 11.88s/it]
Task 14, Epoch 16/20 => Loss 0.091, Train_accy 96.94:  75%|███████▌  | 15/20 [03:09<00:59, 11.88s/it]
Task 14, Epoch 16/20 => Loss 0.091, Train_accy 96.94:  80%|████████  | 16/20 [03:09<00:47, 11.91s/it]
Task 14, Epoch 17/20 => Loss 0.082, Train_accy 97.17:  80%|████████  | 16/20 [03:21<00:47, 11.91s/it]
Task 14, Epoch 17/20 => Loss 0.082, Train_accy 97.17:  85%|████████▌ | 17/20 [03:21<00:35, 11.92s/it]
Task 14, Epoch 18/20 => Loss 0.083, Train_accy 96.91:  85%|████████▌ | 17/20 [03:33<00:35, 11.92s/it]
Task 14, Epoch 18/20 => Loss 0.083, Train_accy 96.91:  90%|█████████ | 18/20 [03:33<00:23, 11.89s/it]
Task 14, Epoch 19/20 => Loss 0.077, Train_accy 97.52:  90%|█████████ | 18/20 [03:45<00:23, 11.89s/it]
Task 14, Epoch 19/20 => Loss 0.077, Train_accy 97.52:  95%|█████████▌| 19/20 [03:45<00:11, 11.91s/it]
Task 14, Epoch 20/20 => Loss 0.084, Train_accy 97.10:  95%|█████████▌| 19/20 [03:57<00:11, 11.91s/it]
Task 14, Epoch 20/20 => Loss 0.084, Train_accy 97.10: 100%|██████████| 20/20 [03:57<00:00, 11.89s/it]
Task 14, Epoch 20/20 => Loss 0.084, Train_accy 97.10: 100%|██████████| 20/20 [03:57<00:00, 11.88s/it]
2024-08-12 12:46:16,118 [inflora.py] => Task 14, Epoch 20/20 => Loss 0.084, Train_accy 97.10
Threshold:  0.9733333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 38/768 type remove
Layer 4 : 40/768 type remove
Layer 5 : 60/768 type remove
Layer 6 : 67/768 type remove
Layer 7 : 68/768 type remove
Layer 8 : 80/768 type remove
Layer 9 : 101/768 type remove
Layer 10 : 117/768 type remove
Layer 11 : 56/768 type remove
Layer 12 : 83/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:46:37,875 [trainer.py] => Time:270.76724910736084
2994 2994
2994 2994
2024-08-12 12:46:44,595 [trainer.py] => Time:6.719294548034668
2024-08-12 12:46:44,595 [inflora.py] => Exemplar size: 0
2024-08-12 12:46:44,595 [trainer.py] => CNN: {'total': 73.85, '00-09': 77.0, '10-19': 81.0, '20-29': 68.5, '30-39': 68.5, '40-49': 75.5, '50-59': 78.39, '60-69': 84.0, '70-79': 81.5, '80-89': 68.34, '90-99': 67.84, '100-109': 74.37, '110-119': 63.82, '120-129': 75.0, '130-139': 73.5, '140-149': 70.35, 'old': 74.1, 'new': 70.35}
2024-08-12 12:46:44,595 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85]
2024-08-12 12:46:44,595 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76]
2024-08-12 12:46:44,595 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264]
Average Accuracy (CNN): 81.37
2024-08-12 12:46:44,601 [trainer.py] => All params: 112239531
2024-08-12 12:46:44,605 [trainer.py] => Trainable params: 81418
2024-08-12 12:46:44,605 [inflora.py] => Learning on 150-160

  0%|          | 0/20 [00:00<?, ?it/s]
Task 15, Epoch 1/20 => Loss 0.488, Train_accy 84.38:   0%|          | 0/20 [00:11<?, ?it/s]
Task 15, Epoch 1/20 => Loss 0.488, Train_accy 84.38:   5%|▌         | 1/20 [00:11<03:41, 11.65s/it]
Task 15, Epoch 2/20 => Loss 0.165, Train_accy 94.15:   5%|▌         | 1/20 [00:23<03:41, 11.65s/it]
Task 15, Epoch 2/20 => Loss 0.165, Train_accy 94.15:  10%|█         | 2/20 [00:23<03:32, 11.79s/it]
Task 15, Epoch 3/20 => Loss 0.160, Train_accy 94.25:  10%|█         | 2/20 [00:35<03:32, 11.79s/it]
Task 15, Epoch 3/20 => Loss 0.160, Train_accy 94.25:  15%|█▌        | 3/20 [00:35<03:20, 11.79s/it]
Task 15, Epoch 4/20 => Loss 0.129, Train_accy 95.39:  15%|█▌        | 3/20 [00:47<03:20, 11.79s/it]
Task 15, Epoch 4/20 => Loss 0.129, Train_accy 95.39:  20%|██        | 4/20 [00:47<03:08, 11.76s/it]
Task 15, Epoch 5/20 => Loss 0.127, Train_accy 95.52:  20%|██        | 4/20 [00:58<03:08, 11.76s/it]
Task 15, Epoch 5/20 => Loss 0.127, Train_accy 95.52:  25%|██▌       | 5/20 [00:58<02:56, 11.77s/it]
Task 15, Epoch 6/20 => Loss 0.114, Train_accy 95.85:  25%|██▌       | 5/20 [01:10<02:56, 11.77s/it]
Task 15, Epoch 6/20 => Loss 0.114, Train_accy 95.85:  30%|███       | 6/20 [01:10<02:44, 11.74s/it]
Task 15, Epoch 7/20 => Loss 0.109, Train_accy 96.31:  30%|███       | 6/20 [01:22<02:44, 11.74s/it]
Task 15, Epoch 7/20 => Loss 0.109, Train_accy 96.31:  35%|███▌      | 7/20 [01:22<02:32, 11.76s/it]
Task 15, Epoch 8/20 => Loss 0.096, Train_accy 96.90:  35%|███▌      | 7/20 [01:34<02:32, 11.76s/it]
Task 15, Epoch 8/20 => Loss 0.096, Train_accy 96.90:  40%|████      | 8/20 [01:34<02:20, 11.74s/it]
Task 15, Epoch 9/20 => Loss 0.118, Train_accy 95.88:  40%|████      | 8/20 [01:45<02:20, 11.74s/it]
Task 15, Epoch 9/20 => Loss 0.118, Train_accy 95.88:  45%|████▌     | 9/20 [01:45<02:09, 11.78s/it]
Task 15, Epoch 10/20 => Loss 0.091, Train_accy 96.83:  45%|████▌     | 9/20 [01:57<02:09, 11.78s/it]
Task 15, Epoch 10/20 => Loss 0.091, Train_accy 96.83:  50%|█████     | 10/20 [01:57<01:57, 11.76s/it]
Task 15, Epoch 11/20 => Loss 0.093, Train_accy 96.73:  50%|█████     | 10/20 [02:09<01:57, 11.76s/it]
Task 15, Epoch 11/20 => Loss 0.093, Train_accy 96.73:  55%|█████▌    | 11/20 [02:09<01:45, 11.74s/it]
Task 15, Epoch 12/20 => Loss 0.080, Train_accy 97.06:  55%|█████▌    | 11/20 [02:20<01:45, 11.74s/it]
Task 15, Epoch 12/20 => Loss 0.080, Train_accy 97.06:  60%|██████    | 12/20 [02:20<01:33, 11.73s/it]
Task 15, Epoch 13/20 => Loss 0.102, Train_accy 96.41:  60%|██████    | 12/20 [02:32<01:33, 11.73s/it]
Task 15, Epoch 13/20 => Loss 0.102, Train_accy 96.41:  65%|██████▌   | 13/20 [02:32<01:22, 11.75s/it]
Task 15, Epoch 14/20 => Loss 0.080, Train_accy 97.29:  65%|██████▌   | 13/20 [02:44<01:22, 11.75s/it]
Task 15, Epoch 14/20 => Loss 0.080, Train_accy 97.29:  70%|███████   | 14/20 [02:44<01:10, 11.74s/it]
Task 15, Epoch 15/20 => Loss 0.084, Train_accy 96.99:  70%|███████   | 14/20 [02:56<01:10, 11.74s/it]
Task 15, Epoch 15/20 => Loss 0.084, Train_accy 96.99:  75%|███████▌  | 15/20 [02:56<00:58, 11.76s/it]
Task 15, Epoch 16/20 => Loss 0.083, Train_accy 97.03:  75%|███████▌  | 15/20 [03:08<00:58, 11.76s/it]
Task 15, Epoch 16/20 => Loss 0.083, Train_accy 97.03:  80%|████████  | 16/20 [03:08<00:47, 11.78s/it]
Task 15, Epoch 17/20 => Loss 0.086, Train_accy 96.76:  80%|████████  | 16/20 [03:19<00:47, 11.78s/it]
Task 15, Epoch 17/20 => Loss 0.086, Train_accy 96.76:  85%|████████▌ | 17/20 [03:19<00:35, 11.79s/it]
Task 15, Epoch 18/20 => Loss 0.076, Train_accy 97.12:  85%|████████▌ | 17/20 [03:31<00:35, 11.79s/it]
Task 15, Epoch 18/20 => Loss 0.076, Train_accy 97.12:  90%|█████████ | 18/20 [03:31<00:23, 11.78s/it]
Task 15, Epoch 19/20 => Loss 0.072, Train_accy 97.52:  90%|█████████ | 18/20 [03:43<00:23, 11.78s/it]
Task 15, Epoch 19/20 => Loss 0.072, Train_accy 97.52:  95%|█████████▌| 19/20 [03:43<00:11, 11.75s/it]
Task 15, Epoch 20/20 => Loss 0.082, Train_accy 97.32:  95%|█████████▌| 19/20 [03:55<00:11, 11.75s/it]
Task 15, Epoch 20/20 => Loss 0.082, Train_accy 97.32: 100%|██████████| 20/20 [03:55<00:00, 11.77s/it]
Task 15, Epoch 20/20 => Loss 0.082, Train_accy 97.32: 100%|██████████| 20/20 [03:55<00:00, 11.76s/it]
2024-08-12 12:50:51,128 [inflora.py] => Task 15, Epoch 20/20 => Loss 0.082, Train_accy 97.32
Threshold:  0.975
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 15/768 type remove
Layer 3 : 40/768 type remove
Layer 4 : 43/768 type remove
Layer 5 : 65/768 type remove
Layer 6 : 74/768 type remove
Layer 7 : 76/768 type remove
Layer 8 : 91/768 type remove
Layer 9 : 114/768 type remove
Layer 10 : 126/768 type remove
Layer 11 : 63/768 type remove
Layer 12 : 88/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:51:11,894 [trainer.py] => Time:267.28825211524963
3193 3193
3193 3193
2024-08-12 12:51:18,951 [trainer.py] => Time:7.056885004043579
2024-08-12 12:51:18,951 [inflora.py] => Exemplar size: 0
2024-08-12 12:51:18,951 [trainer.py] => CNN: {'total': 72.44, '00-09': 76.5, '10-19': 80.5, '20-29': 66.0, '30-39': 68.5, '40-49': 71.0, '50-59': 80.4, '60-69': 83.0, '70-79': 80.0, '80-89': 69.85, '90-99': 65.33, '100-109': 71.36, '110-119': 59.8, '120-129': 73.0, '130-139': 73.0, '140-149': 67.34, '150-159': 73.37, 'old': 72.38, 'new': 73.37}
2024-08-12 12:51:18,952 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44]
2024-08-12 12:51:18,952 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56]
2024-08-12 12:51:18,952 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084]
Average Accuracy (CNN): 80.81
2024-08-12 12:51:18,958 [trainer.py] => All params: 112239531
2024-08-12 12:51:18,963 [trainer.py] => Trainable params: 81418
2024-08-12 12:51:18,963 [inflora.py] => Learning on 160-170

  0%|          | 0/20 [00:00<?, ?it/s]
Task 16, Epoch 1/20 => Loss 0.559, Train_accy 81.90:   0%|          | 0/20 [00:11<?, ?it/s]
Task 16, Epoch 1/20 => Loss 0.559, Train_accy 81.90:   5%|▌         | 1/20 [00:11<03:40, 11.59s/it]
Task 16, Epoch 2/20 => Loss 0.159, Train_accy 93.92:   5%|▌         | 1/20 [00:23<03:40, 11.59s/it]
Task 16, Epoch 2/20 => Loss 0.159, Train_accy 93.92:  10%|█         | 2/20 [00:23<03:28, 11.56s/it]
Task 16, Epoch 3/20 => Loss 0.136, Train_accy 94.82:  10%|█         | 2/20 [00:34<03:28, 11.56s/it]
Task 16, Epoch 3/20 => Loss 0.136, Train_accy 94.82:  15%|█▌        | 3/20 [00:34<03:16, 11.55s/it]
Task 16, Epoch 4/20 => Loss 0.109, Train_accy 95.66:  15%|█▌        | 3/20 [00:46<03:16, 11.55s/it]
Task 16, Epoch 4/20 => Loss 0.109, Train_accy 95.66:  20%|██        | 4/20 [00:46<03:04, 11.51s/it]
Task 16, Epoch 5/20 => Loss 0.093, Train_accy 96.73:  20%|██        | 4/20 [00:57<03:04, 11.51s/it]
Task 16, Epoch 5/20 => Loss 0.093, Train_accy 96.73:  25%|██▌       | 5/20 [00:57<02:53, 11.57s/it]
Task 16, Epoch 6/20 => Loss 0.088, Train_accy 96.89:  25%|██▌       | 5/20 [01:09<02:53, 11.57s/it]
Task 16, Epoch 6/20 => Loss 0.088, Train_accy 96.89:  30%|███       | 6/20 [01:09<02:41, 11.55s/it]
Task 16, Epoch 7/20 => Loss 0.088, Train_accy 96.83:  30%|███       | 6/20 [01:20<02:41, 11.55s/it]
Task 16, Epoch 7/20 => Loss 0.088, Train_accy 96.83:  35%|███▌      | 7/20 [01:20<02:29, 11.52s/it]
Task 16, Epoch 8/20 => Loss 0.082, Train_accy 96.73:  35%|███▌      | 7/20 [01:32<02:29, 11.52s/it]
Task 16, Epoch 8/20 => Loss 0.082, Train_accy 96.73:  40%|████      | 8/20 [01:32<02:18, 11.56s/it]
Task 16, Epoch 9/20 => Loss 0.078, Train_accy 96.96:  40%|████      | 8/20 [01:43<02:18, 11.56s/it]
Task 16, Epoch 9/20 => Loss 0.078, Train_accy 96.96:  45%|████▌     | 9/20 [01:43<02:07, 11.56s/it]
Task 16, Epoch 10/20 => Loss 0.064, Train_accy 97.66:  45%|████▌     | 9/20 [01:55<02:07, 11.56s/it]
Task 16, Epoch 10/20 => Loss 0.064, Train_accy 97.66:  50%|█████     | 10/20 [01:55<01:55, 11.59s/it]
Task 16, Epoch 11/20 => Loss 0.065, Train_accy 97.50:  50%|█████     | 10/20 [02:07<01:55, 11.59s/it]
Task 16, Epoch 11/20 => Loss 0.065, Train_accy 97.50:  55%|█████▌    | 11/20 [02:07<01:44, 11.61s/it]
Task 16, Epoch 12/20 => Loss 0.071, Train_accy 97.10:  55%|█████▌    | 11/20 [02:18<01:44, 11.61s/it]
Task 16, Epoch 12/20 => Loss 0.071, Train_accy 97.10:  60%|██████    | 12/20 [02:18<01:32, 11.56s/it]
Task 16, Epoch 13/20 => Loss 0.061, Train_accy 97.90:  60%|██████    | 12/20 [02:30<01:32, 11.56s/it]
Task 16, Epoch 13/20 => Loss 0.061, Train_accy 97.90:  65%|██████▌   | 13/20 [02:30<01:21, 11.59s/it]
Task 16, Epoch 14/20 => Loss 0.071, Train_accy 97.50:  65%|██████▌   | 13/20 [02:42<01:21, 11.59s/it]
Task 16, Epoch 14/20 => Loss 0.071, Train_accy 97.50:  70%|███████   | 14/20 [02:42<01:09, 11.60s/it]
Task 16, Epoch 15/20 => Loss 0.058, Train_accy 97.66:  70%|███████   | 14/20 [02:53<01:09, 11.60s/it]
Task 16, Epoch 15/20 => Loss 0.058, Train_accy 97.66:  75%|███████▌  | 15/20 [02:53<00:57, 11.59s/it]
Task 16, Epoch 16/20 => Loss 0.072, Train_accy 97.10:  75%|███████▌  | 15/20 [03:05<00:57, 11.59s/it]
Task 16, Epoch 16/20 => Loss 0.072, Train_accy 97.10:  80%|████████  | 16/20 [03:05<00:46, 11.56s/it]
Task 16, Epoch 17/20 => Loss 0.056, Train_accy 97.83:  80%|████████  | 16/20 [03:16<00:46, 11.56s/it]
Task 16, Epoch 17/20 => Loss 0.056, Train_accy 97.83:  85%|████████▌ | 17/20 [03:16<00:34, 11.56s/it]
Task 16, Epoch 18/20 => Loss 0.061, Train_accy 97.80:  85%|████████▌ | 17/20 [03:28<00:34, 11.56s/it]
Task 16, Epoch 18/20 => Loss 0.061, Train_accy 97.80:  90%|█████████ | 18/20 [03:28<00:23, 11.53s/it]
Task 16, Epoch 19/20 => Loss 0.053, Train_accy 97.96:  90%|█████████ | 18/20 [03:39<00:23, 11.53s/it]
Task 16, Epoch 19/20 => Loss 0.053, Train_accy 97.96:  95%|█████████▌| 19/20 [03:39<00:11, 11.56s/it]
Task 16, Epoch 20/20 => Loss 0.059, Train_accy 97.96:  95%|█████████▌| 19/20 [03:51<00:11, 11.56s/it]
Task 16, Epoch 20/20 => Loss 0.059, Train_accy 97.96: 100%|██████████| 20/20 [03:51<00:00, 11.52s/it]
Task 16, Epoch 20/20 => Loss 0.059, Train_accy 97.96: 100%|██████████| 20/20 [03:51<00:00, 11.56s/it]
2024-08-12 12:55:21,116 [inflora.py] => Task 16, Epoch 20/20 => Loss 0.059, Train_accy 97.96
Threshold:  0.9766666666666667
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 45/768 type remove
Layer 4 : 48/768 type remove
Layer 5 : 72/768 type remove
Layer 6 : 79/768 type remove
Layer 7 : 81/768 type remove
Layer 8 : 96/768 type remove
Layer 9 : 129/768 type remove
Layer 10 : 147/768 type remove
Layer 11 : 75/768 type remove
Layer 12 : 94/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:55:41,645 [trainer.py] => Time:262.681715965271
3392 3392
3392 3392
2024-08-12 12:55:48,979 [trainer.py] => Time:7.3333282470703125
2024-08-12 12:55:48,979 [inflora.py] => Exemplar size: 0
2024-08-12 12:55:48,979 [trainer.py] => CNN: {'total': 71.08, '00-09': 75.0, '10-19': 78.5, '20-29': 67.0, '30-39': 66.5, '40-49': 72.0, '50-59': 75.88, '60-69': 83.5, '70-79': 74.5, '80-89': 66.33, '90-99': 65.33, '100-109': 73.87, '110-119': 60.8, '120-129': 73.0, '130-139': 71.5, '140-149': 66.33, '150-159': 72.36, '160-169': 65.83, 'old': 71.41, 'new': 65.83}
2024-08-12 12:55:48,979 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08]
2024-08-12 12:55:48,979 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7]
2024-08-12 12:55:48,979 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962]
Average Accuracy (CNN): 80.24
2024-08-12 12:55:48,984 [trainer.py] => All params: 112239531
2024-08-12 12:55:48,988 [trainer.py] => Trainable params: 81418
2024-08-12 12:55:48,989 [inflora.py] => Learning on 170-180

  0%|          | 0/20 [00:00<?, ?it/s]
Task 17, Epoch 1/20 => Loss 0.581, Train_accy 81.42:   0%|          | 0/20 [00:10<?, ?it/s]
Task 17, Epoch 1/20 => Loss 0.581, Train_accy 81.42:   5%|▌         | 1/20 [00:10<03:25, 10.79s/it]
Task 17, Epoch 2/20 => Loss 0.156, Train_accy 94.39:   5%|▌         | 1/20 [00:21<03:25, 10.79s/it]
Task 17, Epoch 2/20 => Loss 0.156, Train_accy 94.39:  10%|█         | 2/20 [00:21<03:15, 10.85s/it]
Task 17, Epoch 3/20 => Loss 0.122, Train_accy 95.60:  10%|█         | 2/20 [00:32<03:15, 10.85s/it]
Task 17, Epoch 3/20 => Loss 0.122, Train_accy 95.60:  15%|█▌        | 3/20 [00:32<03:04, 10.84s/it]
Task 17, Epoch 4/20 => Loss 0.107, Train_accy 96.16:  15%|█▌        | 3/20 [00:43<03:04, 10.84s/it]
Task 17, Epoch 4/20 => Loss 0.107, Train_accy 96.16:  20%|██        | 4/20 [00:43<02:53, 10.84s/it]
Task 17, Epoch 5/20 => Loss 0.086, Train_accy 97.05:  20%|██        | 4/20 [00:54<02:53, 10.84s/it]
Task 17, Epoch 5/20 => Loss 0.086, Train_accy 97.05:  25%|██▌       | 5/20 [00:54<02:42, 10.85s/it]
Task 17, Epoch 6/20 => Loss 0.079, Train_accy 96.98:  25%|██▌       | 5/20 [01:05<02:42, 10.85s/it]
Task 17, Epoch 6/20 => Loss 0.079, Train_accy 96.98:  30%|███       | 6/20 [01:05<02:31, 10.86s/it]
Task 17, Epoch 7/20 => Loss 0.069, Train_accy 97.55:  30%|███       | 6/20 [01:15<02:31, 10.86s/it]
Task 17, Epoch 7/20 => Loss 0.069, Train_accy 97.55:  35%|███▌      | 7/20 [01:15<02:21, 10.85s/it]
Task 17, Epoch 8/20 => Loss 0.062, Train_accy 97.83:  35%|███▌      | 7/20 [01:26<02:21, 10.85s/it]
Task 17, Epoch 8/20 => Loss 0.062, Train_accy 97.83:  40%|████      | 8/20 [01:26<02:10, 10.88s/it]
Task 17, Epoch 9/20 => Loss 0.067, Train_accy 97.76:  40%|████      | 8/20 [01:37<02:10, 10.88s/it]
Task 17, Epoch 9/20 => Loss 0.067, Train_accy 97.76:  45%|████▌     | 9/20 [01:37<01:59, 10.88s/it]
Task 17, Epoch 10/20 => Loss 0.063, Train_accy 97.83:  45%|████▌     | 9/20 [01:48<01:59, 10.88s/it]
Task 17, Epoch 10/20 => Loss 0.063, Train_accy 97.83:  50%|█████     | 10/20 [01:48<01:48, 10.87s/it]
Task 17, Epoch 11/20 => Loss 0.064, Train_accy 97.51:  50%|█████     | 10/20 [01:59<01:48, 10.87s/it]
Task 17, Epoch 11/20 => Loss 0.064, Train_accy 97.51:  55%|█████▌    | 11/20 [01:59<01:37, 10.89s/it]
Task 17, Epoch 12/20 => Loss 0.072, Train_accy 97.62:  55%|█████▌    | 11/20 [02:10<01:37, 10.89s/it]
Task 17, Epoch 12/20 => Loss 0.072, Train_accy 97.62:  60%|██████    | 12/20 [02:10<01:27, 10.88s/it]
Task 17, Epoch 13/20 => Loss 0.054, Train_accy 98.15:  60%|██████    | 12/20 [02:21<01:27, 10.88s/it]
Task 17, Epoch 13/20 => Loss 0.054, Train_accy 98.15:  65%|██████▌   | 13/20 [02:21<01:16, 10.87s/it]
Task 17, Epoch 14/20 => Loss 0.051, Train_accy 98.54:  65%|██████▌   | 13/20 [02:32<01:16, 10.87s/it]
Task 17, Epoch 14/20 => Loss 0.051, Train_accy 98.54:  70%|███████   | 14/20 [02:32<01:05, 10.93s/it]
Task 17, Epoch 15/20 => Loss 0.047, Train_accy 98.40:  70%|███████   | 14/20 [02:43<01:05, 10.93s/it]
Task 17, Epoch 15/20 => Loss 0.047, Train_accy 98.40:  75%|███████▌  | 15/20 [02:43<00:54, 10.93s/it]
Task 17, Epoch 16/20 => Loss 0.048, Train_accy 98.29:  75%|███████▌  | 15/20 [02:54<00:54, 10.93s/it]
Task 17, Epoch 16/20 => Loss 0.048, Train_accy 98.29:  80%|████████  | 16/20 [02:54<00:43, 10.91s/it]
Task 17, Epoch 17/20 => Loss 0.048, Train_accy 98.47:  80%|████████  | 16/20 [03:05<00:43, 10.91s/it]
Task 17, Epoch 17/20 => Loss 0.048, Train_accy 98.47:  85%|████████▌ | 17/20 [03:05<00:32, 10.94s/it]
Task 17, Epoch 18/20 => Loss 0.051, Train_accy 98.19:  85%|████████▌ | 17/20 [03:16<00:32, 10.94s/it]
Task 17, Epoch 18/20 => Loss 0.051, Train_accy 98.19:  90%|█████████ | 18/20 [03:16<00:21, 10.97s/it]
Task 17, Epoch 19/20 => Loss 0.042, Train_accy 98.58:  90%|█████████ | 18/20 [03:27<00:21, 10.97s/it]
Task 17, Epoch 19/20 => Loss 0.042, Train_accy 98.58:  95%|█████████▌| 19/20 [03:27<00:10, 10.96s/it]
Task 17, Epoch 20/20 => Loss 0.052, Train_accy 98.40:  95%|█████████▌| 19/20 [03:38<00:10, 10.96s/it]
Task 17, Epoch 20/20 => Loss 0.052, Train_accy 98.40: 100%|██████████| 20/20 [03:38<00:00, 10.99s/it]
Task 17, Epoch 20/20 => Loss 0.052, Train_accy 98.40: 100%|██████████| 20/20 [03:38<00:00, 10.91s/it]
2024-08-12 12:59:37,501 [inflora.py] => Task 17, Epoch 20/20 => Loss 0.052, Train_accy 98.40
Threshold:  0.9783333333333333
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 46/768 type remove
Layer 4 : 50/768 type remove
Layer 5 : 74/768 type remove
Layer 6 : 82/768 type remove
Layer 7 : 86/768 type remove
Layer 8 : 100/768 type remove
Layer 9 : 136/768 type remove
Layer 10 : 159/768 type remove
Layer 11 : 82/768 type remove
Layer 12 : 100/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 12:59:57,118 [trainer.py] => Time:248.1295018196106
3592 3592
3592 3592
2024-08-12 13:00:04,743 [trainer.py] => Time:7.624432325363159
2024-08-12 13:00:04,743 [inflora.py] => Exemplar size: 0
2024-08-12 13:00:04,743 [trainer.py] => CNN: {'total': 69.46, '00-09': 77.5, '10-19': 76.0, '20-29': 67.0, '30-39': 65.5, '40-49': 72.0, '50-59': 75.38, '60-69': 84.0, '70-79': 73.0, '80-89': 66.33, '90-99': 63.32, '100-109': 72.36, '110-119': 60.3, '120-129': 74.5, '130-139': 72.0, '140-149': 66.33, '150-159': 70.85, '160-169': 64.32, '170-179': 49.5, 'old': 70.64, 'new': 49.5}
2024-08-12 13:00:04,743 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46]
2024-08-12 13:00:04,743 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83]
2024-08-12 13:00:04,743 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311]
Average Accuracy (CNN): 79.64
2024-08-12 13:00:04,748 [trainer.py] => All params: 112239531
2024-08-12 13:00:04,753 [trainer.py] => Trainable params: 81418
2024-08-12 13:00:04,753 [inflora.py] => Learning on 180-190

  0%|          | 0/20 [00:00<?, ?it/s]
Task 18, Epoch 1/20 => Loss 0.435, Train_accy 85.39:   0%|          | 0/20 [00:11<?, ?it/s]
Task 18, Epoch 1/20 => Loss 0.435, Train_accy 85.39:   5%|▌         | 1/20 [00:11<03:37, 11.47s/it]
Task 18, Epoch 2/20 => Loss 0.104, Train_accy 96.52:   5%|▌         | 1/20 [00:22<03:37, 11.47s/it]
Task 18, Epoch 2/20 => Loss 0.104, Train_accy 96.52:  10%|█         | 2/20 [00:22<03:26, 11.48s/it]
Task 18, Epoch 3/20 => Loss 0.066, Train_accy 97.63:  10%|█         | 2/20 [00:34<03:26, 11.48s/it]
Task 18, Epoch 3/20 => Loss 0.066, Train_accy 97.63:  15%|█▌        | 3/20 [00:34<03:15, 11.52s/it]
Task 18, Epoch 4/20 => Loss 0.068, Train_accy 97.53:  15%|█▌        | 3/20 [00:46<03:15, 11.52s/it]
Task 18, Epoch 4/20 => Loss 0.068, Train_accy 97.53:  20%|██        | 4/20 [00:46<03:04, 11.53s/it]
Task 18, Epoch 5/20 => Loss 0.064, Train_accy 97.80:  20%|██        | 4/20 [00:57<03:04, 11.53s/it]
Task 18, Epoch 5/20 => Loss 0.064, Train_accy 97.80:  25%|██▌       | 5/20 [00:57<02:53, 11.54s/it]
Task 18, Epoch 6/20 => Loss 0.068, Train_accy 97.40:  25%|██▌       | 5/20 [01:09<02:53, 11.54s/it]
Task 18, Epoch 6/20 => Loss 0.068, Train_accy 97.40:  30%|███       | 6/20 [01:09<02:41, 11.53s/it]
Task 18, Epoch 7/20 => Loss 0.058, Train_accy 98.14:  30%|███       | 6/20 [01:20<02:41, 11.53s/it]
Task 18, Epoch 7/20 => Loss 0.058, Train_accy 98.14:  35%|███▌      | 7/20 [01:20<02:30, 11.55s/it]
Task 18, Epoch 8/20 => Loss 0.062, Train_accy 97.94:  35%|███▌      | 7/20 [01:32<02:30, 11.55s/it]
Task 18, Epoch 8/20 => Loss 0.062, Train_accy 97.94:  40%|████      | 8/20 [01:32<02:17, 11.50s/it]
Task 18, Epoch 9/20 => Loss 0.052, Train_accy 98.07:  40%|████      | 8/20 [01:43<02:17, 11.50s/it]
Task 18, Epoch 9/20 => Loss 0.052, Train_accy 98.07:  45%|████▌     | 9/20 [01:43<02:06, 11.47s/it]
Task 18, Epoch 10/20 => Loss 0.052, Train_accy 98.14:  45%|████▌     | 9/20 [01:55<02:06, 11.47s/it]
Task 18, Epoch 10/20 => Loss 0.052, Train_accy 98.14:  50%|█████     | 10/20 [01:55<01:54, 11.48s/it]
Task 18, Epoch 11/20 => Loss 0.045, Train_accy 98.44:  50%|█████     | 10/20 [02:06<01:54, 11.48s/it]
Task 18, Epoch 11/20 => Loss 0.045, Train_accy 98.44:  55%|█████▌    | 11/20 [02:06<01:43, 11.52s/it]
Task 18, Epoch 12/20 => Loss 0.046, Train_accy 98.41:  55%|█████▌    | 11/20 [02:18<01:43, 11.52s/it]
Task 18, Epoch 12/20 => Loss 0.046, Train_accy 98.41:  60%|██████    | 12/20 [02:18<01:32, 11.51s/it]
Task 18, Epoch 13/20 => Loss 0.056, Train_accy 97.97:  60%|██████    | 12/20 [02:29<01:32, 11.51s/it]
Task 18, Epoch 13/20 => Loss 0.056, Train_accy 97.97:  65%|██████▌   | 13/20 [02:29<01:20, 11.48s/it]
Task 18, Epoch 14/20 => Loss 0.044, Train_accy 98.48:  65%|██████▌   | 13/20 [02:40<01:20, 11.48s/it]
Task 18, Epoch 14/20 => Loss 0.044, Train_accy 98.48:  70%|███████   | 14/20 [02:40<01:08, 11.45s/it]
Task 18, Epoch 15/20 => Loss 0.042, Train_accy 98.41:  70%|███████   | 14/20 [02:52<01:08, 11.45s/it]
Task 18, Epoch 15/20 => Loss 0.042, Train_accy 98.41:  75%|███████▌  | 15/20 [02:52<00:57, 11.49s/it]
Task 18, Epoch 16/20 => Loss 0.040, Train_accy 98.51:  75%|███████▌  | 15/20 [03:04<00:57, 11.49s/it]
Task 18, Epoch 16/20 => Loss 0.040, Train_accy 98.51:  80%|████████  | 16/20 [03:04<00:46, 11.51s/it]
Task 18, Epoch 17/20 => Loss 0.039, Train_accy 98.58:  80%|████████  | 16/20 [03:15<00:46, 11.51s/it]
Task 18, Epoch 17/20 => Loss 0.039, Train_accy 98.58:  85%|████████▌ | 17/20 [03:15<00:34, 11.49s/it]
Task 18, Epoch 18/20 => Loss 0.039, Train_accy 98.88:  85%|████████▌ | 17/20 [03:27<00:34, 11.49s/it]
Task 18, Epoch 18/20 => Loss 0.039, Train_accy 98.88:  90%|█████████ | 18/20 [03:27<00:23, 11.52s/it]
Task 18, Epoch 19/20 => Loss 0.050, Train_accy 98.34:  90%|█████████ | 18/20 [03:38<00:23, 11.52s/it]
Task 18, Epoch 19/20 => Loss 0.050, Train_accy 98.34:  95%|█████████▌| 19/20 [03:38<00:11, 11.52s/it]
Task 18, Epoch 20/20 => Loss 0.048, Train_accy 98.44:  95%|█████████▌| 19/20 [03:49<00:11, 11.52s/it]
Task 18, Epoch 20/20 => Loss 0.048, Train_accy 98.44: 100%|██████████| 20/20 [03:49<00:00, 11.48s/it]
Task 18, Epoch 20/20 => Loss 0.048, Train_accy 98.44: 100%|██████████| 20/20 [03:49<00:00, 11.50s/it]
2024-08-12 13:04:05,693 [inflora.py] => Task 18, Epoch 20/20 => Loss 0.048, Train_accy 98.44
Threshold:  0.98
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 52/768 type remove
Layer 4 : 57/768 type remove
Layer 5 : 83/768 type remove
Layer 6 : 93/768 type remove
Layer 7 : 97/768 type remove
Layer 8 : 115/768 type remove
Layer 9 : 154/768 type remove
Layer 10 : 174/768 type remove
Layer 11 : 88/768 type remove
Layer 12 : 107/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:04:25,807 [trainer.py] => Time:261.0538716316223
3790 3790
3790 3790
2024-08-12 13:04:34,013 [trainer.py] => Time:8.205997228622437
2024-08-12 13:04:34,014 [inflora.py] => Exemplar size: 0
2024-08-12 13:04:34,014 [trainer.py] => CNN: {'total': 68.42, '00-09': 76.0, '10-19': 76.5, '20-29': 65.0, '30-39': 66.5, '40-49': 71.0, '50-59': 74.37, '60-69': 80.5, '70-79': 72.5, '80-89': 63.82, '90-99': 63.32, '100-109': 70.35, '110-119': 61.31, '120-129': 74.0, '130-139': 73.0, '140-149': 67.34, '150-159': 58.79, '160-169': 60.8, '170-179': 47.5, '180-189': 77.27, 'old': 67.93, 'new': 77.27}
2024-08-12 13:04:34,014 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42]
2024-08-12 13:04:34,014 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78]
2024-08-12 13:04:34,014 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206]
Average Accuracy (CNN): 79.05
2024-08-12 13:04:34,019 [trainer.py] => All params: 112239531
2024-08-12 13:04:34,023 [trainer.py] => Trainable params: 81418
2024-08-12 13:04:34,023 [inflora.py] => Learning on 190-200

  0%|          | 0/20 [00:00<?, ?it/s]
Task 19, Epoch 1/20 => Loss 0.485, Train_accy 85.74:   0%|          | 0/20 [00:11<?, ?it/s]
Task 19, Epoch 1/20 => Loss 0.485, Train_accy 85.74:   5%|▌         | 1/20 [00:11<03:29, 11.05s/it]
Task 19, Epoch 2/20 => Loss 0.098, Train_accy 96.79:   5%|▌         | 1/20 [00:22<03:29, 11.05s/it]
Task 19, Epoch 2/20 => Loss 0.098, Train_accy 96.79:  10%|█         | 2/20 [00:22<03:18, 11.04s/it]
Task 19, Epoch 3/20 => Loss 0.082, Train_accy 97.25:  10%|█         | 2/20 [00:33<03:18, 11.04s/it]
Task 19, Epoch 3/20 => Loss 0.082, Train_accy 97.25:  15%|█▌        | 3/20 [00:33<03:07, 11.04s/it]
Task 19, Epoch 4/20 => Loss 0.056, Train_accy 98.43:  15%|█▌        | 3/20 [00:44<03:07, 11.04s/it]
Task 19, Epoch 4/20 => Loss 0.056, Train_accy 98.43:  20%|██        | 4/20 [00:44<02:57, 11.12s/it]
Task 19, Epoch 5/20 => Loss 0.056, Train_accy 98.26:  20%|██        | 4/20 [00:55<02:57, 11.12s/it]
Task 19, Epoch 5/20 => Loss 0.056, Train_accy 98.26:  25%|██▌       | 5/20 [00:55<02:47, 11.17s/it]
Task 19, Epoch 6/20 => Loss 0.050, Train_accy 98.29:  25%|██▌       | 5/20 [01:06<02:47, 11.17s/it]
Task 19, Epoch 6/20 => Loss 0.050, Train_accy 98.29:  30%|███       | 6/20 [01:06<02:36, 11.16s/it]
Task 19, Epoch 7/20 => Loss 0.058, Train_accy 98.12:  30%|███       | 6/20 [01:17<02:36, 11.16s/it]
Task 19, Epoch 7/20 => Loss 0.058, Train_accy 98.12:  35%|███▌      | 7/20 [01:17<02:25, 11.16s/it]
Task 19, Epoch 8/20 => Loss 0.042, Train_accy 98.43:  35%|███▌      | 7/20 [01:29<02:25, 11.16s/it]
Task 19, Epoch 8/20 => Loss 0.042, Train_accy 98.43:  40%|████      | 8/20 [01:29<02:13, 11.15s/it]
Task 19, Epoch 9/20 => Loss 0.042, Train_accy 98.78:  40%|████      | 8/20 [01:40<02:13, 11.15s/it]
Task 19, Epoch 9/20 => Loss 0.042, Train_accy 98.78:  45%|████▌     | 9/20 [01:40<02:02, 11.14s/it]
Task 19, Epoch 10/20 => Loss 0.040, Train_accy 98.71:  45%|████▌     | 9/20 [01:51<02:02, 11.14s/it]
Task 19, Epoch 10/20 => Loss 0.040, Train_accy 98.71:  50%|█████     | 10/20 [01:51<01:51, 11.16s/it]
Task 19, Epoch 11/20 => Loss 0.050, Train_accy 98.40:  50%|█████     | 10/20 [02:02<01:51, 11.16s/it]
Task 19, Epoch 11/20 => Loss 0.050, Train_accy 98.40:  55%|█████▌    | 11/20 [02:02<01:40, 11.16s/it]
Task 19, Epoch 12/20 => Loss 0.042, Train_accy 98.50:  55%|█████▌    | 11/20 [02:13<01:40, 11.16s/it]
Task 19, Epoch 12/20 => Loss 0.042, Train_accy 98.50:  60%|██████    | 12/20 [02:13<01:29, 11.15s/it]
Task 19, Epoch 13/20 => Loss 0.046, Train_accy 98.36:  60%|██████    | 12/20 [02:24<01:29, 11.15s/it]
Task 19, Epoch 13/20 => Loss 0.046, Train_accy 98.36:  65%|██████▌   | 13/20 [02:24<01:18, 11.16s/it]
Task 19, Epoch 14/20 => Loss 0.048, Train_accy 98.64:  65%|██████▌   | 13/20 [02:35<01:18, 11.16s/it]
Task 19, Epoch 14/20 => Loss 0.048, Train_accy 98.64:  70%|███████   | 14/20 [02:35<01:06, 11.12s/it]
Task 19, Epoch 15/20 => Loss 0.032, Train_accy 98.99:  70%|███████   | 14/20 [02:47<01:06, 11.12s/it]
Task 19, Epoch 15/20 => Loss 0.032, Train_accy 98.99:  75%|███████▌  | 15/20 [02:47<00:55, 11.16s/it]
Task 19, Epoch 16/20 => Loss 0.042, Train_accy 98.57:  75%|███████▌  | 15/20 [02:58<00:55, 11.16s/it]
Task 19, Epoch 16/20 => Loss 0.042, Train_accy 98.57:  80%|████████  | 16/20 [02:58<00:44, 11.21s/it]
Task 19, Epoch 17/20 => Loss 0.045, Train_accy 98.40:  80%|████████  | 16/20 [03:09<00:44, 11.21s/it]
Task 19, Epoch 17/20 => Loss 0.045, Train_accy 98.40:  85%|████████▌ | 17/20 [03:09<00:33, 11.22s/it]
Task 19, Epoch 18/20 => Loss 0.030, Train_accy 99.09:  85%|████████▌ | 17/20 [03:20<00:33, 11.22s/it]
Task 19, Epoch 18/20 => Loss 0.030, Train_accy 99.09:  90%|█████████ | 18/20 [03:20<00:22, 11.20s/it]
Task 19, Epoch 19/20 => Loss 0.039, Train_accy 98.47:  90%|█████████ | 18/20 [03:32<00:22, 11.20s/it]
Task 19, Epoch 19/20 => Loss 0.039, Train_accy 98.47:  95%|█████████▌| 19/20 [03:32<00:11, 11.22s/it]
Task 19, Epoch 20/20 => Loss 0.028, Train_accy 99.27:  95%|█████████▌| 19/20 [03:43<00:11, 11.22s/it]
Task 19, Epoch 20/20 => Loss 0.028, Train_accy 99.27: 100%|██████████| 20/20 [03:43<00:00, 11.21s/it]
Task 19, Epoch 20/20 => Loss 0.028, Train_accy 99.27: 100%|██████████| 20/20 [03:43<00:00, 11.17s/it]
2024-08-12 13:08:28,174 [inflora.py] => Task 19, Epoch 20/20 => Loss 0.028, Train_accy 99.27
Threshold:  0.9816666666666667
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 17/768 type remove
Layer 3 : 56/768 type remove
Layer 4 : 63/768 type remove
Layer 5 : 90/768 type remove
Layer 6 : 103/768 type remove
Layer 7 : 107/768 type remove
Layer 8 : 124/768 type remove
Layer 9 : 168/768 type remove
Layer 10 : 196/768 type remove
Layer 11 : 103/768 type remove
Layer 12 : 120/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:08:48,011 [trainer.py] => Time:253.98777794837952
3990 3990
3990 3990
2024-08-12 13:08:56,544 [trainer.py] => Time:8.532190799713135
2024-08-12 13:08:56,544 [inflora.py] => Exemplar size: 0
2024-08-12 13:08:56,544 [trainer.py] => CNN: {'total': 68.55, '00-09': 74.0, '10-19': 77.5, '20-29': 64.5, '30-39': 64.5, '40-49': 71.5, '50-59': 74.37, '60-69': 77.5, '70-79': 74.5, '80-89': 63.32, '90-99': 62.31, '100-109': 72.86, '110-119': 59.3, '120-129': 75.0, '130-139': 72.5, '140-149': 68.34, '150-159': 57.79, '160-169': 59.3, '170-179': 46.5, '180-189': 77.78, '190-199': 77.5, 'old': 68.07, 'new': 77.5}
2024-08-12 13:08:56,544 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55]
2024-08-12 13:08:56,544 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92]
2024-08-12 13:08:56,544 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338]
Average Accuracy (CNN): 78.52
2024-08-12 13:08:56,550 [trainer.py] => All params: 112239531
2024-08-12 13:08:56,555 [trainer.py] => Trainable params: 81418
2024-08-12 13:08:56,555 [inflora.py] => Learning on 200-210

  0%|          | 0/20 [00:00<?, ?it/s]
Task 20, Epoch 1/20 => Loss 0.605, Train_accy 79.01:   0%|          | 0/20 [00:11<?, ?it/s]
Task 20, Epoch 1/20 => Loss 0.605, Train_accy 79.01:   5%|▌         | 1/20 [00:11<03:39, 11.54s/it]
Task 20, Epoch 2/20 => Loss 0.232, Train_accy 89.74:   5%|▌         | 1/20 [00:23<03:39, 11.54s/it]
Task 20, Epoch 2/20 => Loss 0.232, Train_accy 89.74:  10%|█         | 2/20 [00:23<03:30, 11.68s/it]
Task 20, Epoch 3/20 => Loss 0.197, Train_accy 91.33:  10%|█         | 2/20 [00:35<03:30, 11.68s/it]
Task 20, Epoch 3/20 => Loss 0.197, Train_accy 91.33:  15%|█▌        | 3/20 [00:35<03:19, 11.76s/it]
Task 20, Epoch 4/20 => Loss 0.170, Train_accy 92.96:  15%|█▌        | 3/20 [00:46<03:19, 11.76s/it]
Task 20, Epoch 4/20 => Loss 0.170, Train_accy 92.96:  20%|██        | 4/20 [00:46<03:08, 11.75s/it]
Task 20, Epoch 5/20 => Loss 0.170, Train_accy 92.73:  20%|██        | 4/20 [00:58<03:08, 11.75s/it]
Task 20, Epoch 5/20 => Loss 0.170, Train_accy 92.73:  25%|██▌       | 5/20 [00:58<02:56, 11.78s/it]
Task 20, Epoch 6/20 => Loss 0.152, Train_accy 93.92:  25%|██▌       | 5/20 [01:10<02:56, 11.78s/it]
Task 20, Epoch 6/20 => Loss 0.152, Train_accy 93.92:  30%|███       | 6/20 [01:10<02:44, 11.77s/it]
Task 20, Epoch 7/20 => Loss 0.142, Train_accy 93.56:  30%|███       | 6/20 [01:22<02:44, 11.77s/it]
Task 20, Epoch 7/20 => Loss 0.142, Train_accy 93.56:  35%|███▌      | 7/20 [01:22<02:32, 11.76s/it]
Task 20, Epoch 8/20 => Loss 0.149, Train_accy 93.86:  35%|███▌      | 7/20 [01:33<02:32, 11.76s/it]
Task 20, Epoch 8/20 => Loss 0.149, Train_accy 93.86:  40%|████      | 8/20 [01:33<02:20, 11.73s/it]
Task 20, Epoch 9/20 => Loss 0.129, Train_accy 94.69:  40%|████      | 8/20 [01:45<02:20, 11.73s/it]
Task 20, Epoch 9/20 => Loss 0.129, Train_accy 94.69:  45%|████▌     | 9/20 [01:45<02:09, 11.74s/it]
Task 20, Epoch 10/20 => Loss 0.135, Train_accy 94.39:  45%|████▌     | 9/20 [01:57<02:09, 11.74s/it]
Task 20, Epoch 10/20 => Loss 0.135, Train_accy 94.39:  50%|█████     | 10/20 [01:57<01:57, 11.74s/it]
Task 20, Epoch 11/20 => Loss 0.124, Train_accy 94.55:  50%|█████     | 10/20 [02:09<01:57, 11.74s/it]
Task 20, Epoch 11/20 => Loss 0.124, Train_accy 94.55:  55%|█████▌    | 11/20 [02:09<01:45, 11.73s/it]
Task 20, Epoch 12/20 => Loss 0.116, Train_accy 95.48:  55%|█████▌    | 11/20 [02:20<01:45, 11.73s/it]
Task 20, Epoch 12/20 => Loss 0.116, Train_accy 95.48:  60%|██████    | 12/20 [02:20<01:34, 11.75s/it]
Task 20, Epoch 13/20 => Loss 0.117, Train_accy 95.22:  60%|██████    | 12/20 [02:32<01:34, 11.75s/it]
Task 20, Epoch 13/20 => Loss 0.117, Train_accy 95.22:  65%|██████▌   | 13/20 [02:32<01:22, 11.72s/it]
Task 20, Epoch 14/20 => Loss 0.113, Train_accy 95.62:  65%|██████▌   | 13/20 [02:44<01:22, 11.72s/it]
Task 20, Epoch 14/20 => Loss 0.113, Train_accy 95.62:  70%|███████   | 14/20 [02:44<01:10, 11.70s/it]
Task 20, Epoch 15/20 => Loss 0.110, Train_accy 95.45:  70%|███████   | 14/20 [02:55<01:10, 11.70s/it]
Task 20, Epoch 15/20 => Loss 0.110, Train_accy 95.45:  75%|███████▌  | 15/20 [02:55<00:58, 11.71s/it]
Task 20, Epoch 16/20 => Loss 0.109, Train_accy 95.52:  75%|███████▌  | 15/20 [03:07<00:58, 11.71s/it]
Task 20, Epoch 16/20 => Loss 0.109, Train_accy 95.52:  80%|████████  | 16/20 [03:07<00:47, 11.76s/it]
Task 20, Epoch 17/20 => Loss 0.107, Train_accy 95.55:  80%|████████  | 16/20 [03:19<00:47, 11.76s/it]
Task 20, Epoch 17/20 => Loss 0.107, Train_accy 95.55:  85%|████████▌ | 17/20 [03:19<00:35, 11.76s/it]
Task 20, Epoch 18/20 => Loss 0.095, Train_accy 96.65:  85%|████████▌ | 17/20 [03:31<00:35, 11.76s/it]
Task 20, Epoch 18/20 => Loss 0.095, Train_accy 96.65:  90%|█████████ | 18/20 [03:31<00:23, 11.75s/it]
Task 20, Epoch 19/20 => Loss 0.096, Train_accy 96.25:  90%|█████████ | 18/20 [03:43<00:23, 11.75s/it]
Task 20, Epoch 19/20 => Loss 0.096, Train_accy 96.25:  95%|█████████▌| 19/20 [03:43<00:11, 11.76s/it]
Task 20, Epoch 20/20 => Loss 0.106, Train_accy 96.15:  95%|█████████▌| 19/20 [03:54<00:11, 11.76s/it]
Task 20, Epoch 20/20 => Loss 0.106, Train_accy 96.15: 100%|██████████| 20/20 [03:54<00:00, 11.77s/it]
Task 20, Epoch 20/20 => Loss 0.106, Train_accy 96.15: 100%|██████████| 20/20 [03:54<00:00, 11.74s/it]
2024-08-12 13:13:02,568 [inflora.py] => Task 20, Epoch 20/20 => Loss 0.106, Train_accy 96.15
Threshold:  0.9833333333333333
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 18/768 type remove
Layer 3 : 61/768 type remove
Layer 4 : 68/768 type remove
Layer 5 : 95/768 type remove
Layer 6 : 107/768 type remove
Layer 7 : 112/768 type remove
Layer 8 : 129/768 type remove
Layer 9 : 177/768 type remove
Layer 10 : 211/768 type remove
Layer 11 : 116/768 type remove
Layer 12 : 127/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:13:24,133 [trainer.py] => Time:267.5772979259491
4189 4189
4189 4189
2024-08-12 13:13:33,127 [trainer.py] => Time:8.99424934387207
2024-08-12 13:13:33,127 [inflora.py] => Exemplar size: 0
2024-08-12 13:13:33,128 [trainer.py] => CNN: {'total': 66.96, '00-09': 73.0, '10-19': 77.5, '20-29': 63.0, '30-39': 66.0, '40-49': 68.5, '50-59': 73.87, '60-69': 78.0, '70-79': 73.5, '80-89': 63.32, '90-99': 61.31, '100-109': 70.85, '110-119': 56.28, '120-129': 73.5, '130-139': 72.0, '140-149': 66.33, '150-159': 56.78, '160-169': 57.29, '170-179': 44.0, '180-189': 77.78, '190-199': 72.0, '200-209': 61.31, 'old': 67.24, 'new': 61.31}
2024-08-12 13:13:33,128 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96]
2024-08-12 13:13:33,128 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61]
2024-08-12 13:13:33,128 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169]
Average Accuracy (CNN): 77.97
2024-08-12 13:13:33,133 [trainer.py] => All params: 112239531
2024-08-12 13:13:33,138 [trainer.py] => Trainable params: 81418
2024-08-12 13:13:33,138 [inflora.py] => Learning on 210-220

  0%|          | 0/20 [00:00<?, ?it/s]
Task 21, Epoch 1/20 => Loss 0.978, Train_accy 63.57:   0%|          | 0/20 [00:11<?, ?it/s]
Task 21, Epoch 1/20 => Loss 0.978, Train_accy 63.57:   5%|▌         | 1/20 [00:11<03:44, 11.84s/it]
Task 21, Epoch 2/20 => Loss 0.647, Train_accy 74.60:   5%|▌         | 1/20 [00:23<03:44, 11.84s/it]
Task 21, Epoch 2/20 => Loss 0.647, Train_accy 74.60:  10%|█         | 2/20 [00:23<03:35, 11.99s/it]
Task 21, Epoch 3/20 => Loss 0.552, Train_accy 78.63:  10%|█         | 2/20 [00:35<03:35, 11.99s/it]
Task 21, Epoch 3/20 => Loss 0.552, Train_accy 78.63:  15%|█▌        | 3/20 [00:35<03:24, 12.02s/it]
Task 21, Epoch 4/20 => Loss 0.512, Train_accy 80.30:  15%|█▌        | 3/20 [00:48<03:24, 12.02s/it]
Task 21, Epoch 4/20 => Loss 0.512, Train_accy 80.30:  20%|██        | 4/20 [00:48<03:12, 12.04s/it]
Task 21, Epoch 5/20 => Loss 0.432, Train_accy 83.59:  20%|██        | 4/20 [01:00<03:12, 12.04s/it]
Task 21, Epoch 5/20 => Loss 0.432, Train_accy 83.59:  25%|██▌       | 5/20 [01:00<03:00, 12.04s/it]
Task 21, Epoch 6/20 => Loss 0.424, Train_accy 84.01:  25%|██▌       | 5/20 [01:12<03:00, 12.04s/it]
Task 21, Epoch 6/20 => Loss 0.424, Train_accy 84.01:  30%|███       | 6/20 [01:12<02:49, 12.09s/it]
Task 21, Epoch 7/20 => Loss 0.404, Train_accy 84.56:  30%|███       | 6/20 [01:24<02:49, 12.09s/it]
Task 21, Epoch 7/20 => Loss 0.404, Train_accy 84.56:  35%|███▌      | 7/20 [01:24<02:37, 12.09s/it]
Task 21, Epoch 8/20 => Loss 0.388, Train_accy 85.59:  35%|███▌      | 7/20 [01:36<02:37, 12.09s/it]
Task 21, Epoch 8/20 => Loss 0.388, Train_accy 85.59:  40%|████      | 8/20 [01:36<02:25, 12.10s/it]
Task 21, Epoch 9/20 => Loss 0.382, Train_accy 85.85:  40%|████      | 8/20 [01:48<02:25, 12.10s/it]
Task 21, Epoch 9/20 => Loss 0.382, Train_accy 85.85:  45%|████▌     | 9/20 [01:48<02:13, 12.12s/it]
Task 21, Epoch 10/20 => Loss 0.345, Train_accy 87.36:  45%|████▌     | 9/20 [02:00<02:13, 12.12s/it]
Task 21, Epoch 10/20 => Loss 0.345, Train_accy 87.36:  50%|█████     | 10/20 [02:00<02:00, 12.09s/it]
Task 21, Epoch 11/20 => Loss 0.333, Train_accy 87.49:  50%|█████     | 10/20 [02:12<02:00, 12.09s/it]
Task 21, Epoch 11/20 => Loss 0.333, Train_accy 87.49:  55%|█████▌    | 11/20 [02:12<01:48, 12.09s/it]
Task 21, Epoch 12/20 => Loss 0.325, Train_accy 88.30:  55%|█████▌    | 11/20 [02:24<01:48, 12.09s/it]
Task 21, Epoch 12/20 => Loss 0.325, Train_accy 88.30:  60%|██████    | 12/20 [02:24<01:36, 12.08s/it]
Task 21, Epoch 13/20 => Loss 0.301, Train_accy 89.17:  60%|██████    | 12/20 [02:36<01:36, 12.08s/it]
Task 21, Epoch 13/20 => Loss 0.301, Train_accy 89.17:  65%|██████▌   | 13/20 [02:36<01:24, 12.09s/it]
Task 21, Epoch 14/20 => Loss 0.300, Train_accy 89.10:  65%|██████▌   | 13/20 [02:48<01:24, 12.09s/it]
Task 21, Epoch 14/20 => Loss 0.300, Train_accy 89.10:  70%|███████   | 14/20 [02:48<01:12, 12.07s/it]
Task 21, Epoch 15/20 => Loss 0.311, Train_accy 89.26:  70%|███████   | 14/20 [03:01<01:12, 12.07s/it]
Task 21, Epoch 15/20 => Loss 0.311, Train_accy 89.26:  75%|███████▌  | 15/20 [03:01<01:00, 12.08s/it]
Task 21, Epoch 16/20 => Loss 0.299, Train_accy 88.91:  75%|███████▌  | 15/20 [03:13<01:00, 12.08s/it]
Task 21, Epoch 16/20 => Loss 0.299, Train_accy 88.91:  80%|████████  | 16/20 [03:13<00:48, 12.05s/it]
Task 21, Epoch 17/20 => Loss 0.296, Train_accy 89.14:  80%|████████  | 16/20 [03:25<00:48, 12.05s/it]
Task 21, Epoch 17/20 => Loss 0.296, Train_accy 89.14:  85%|████████▌ | 17/20 [03:25<00:36, 12.04s/it]
Task 21, Epoch 18/20 => Loss 0.272, Train_accy 90.20:  85%|████████▌ | 17/20 [03:37<00:36, 12.04s/it]
Task 21, Epoch 18/20 => Loss 0.272, Train_accy 90.20:  90%|█████████ | 18/20 [03:37<00:24, 12.06s/it]
Task 21, Epoch 19/20 => Loss 0.283, Train_accy 89.49:  90%|█████████ | 18/20 [03:49<00:24, 12.06s/it]
Task 21, Epoch 19/20 => Loss 0.283, Train_accy 89.49:  95%|█████████▌| 19/20 [03:49<00:12, 12.06s/it]
Task 21, Epoch 20/20 => Loss 0.268, Train_accy 90.36:  95%|█████████▌| 19/20 [04:01<00:12, 12.06s/it]
Task 21, Epoch 20/20 => Loss 0.268, Train_accy 90.36: 100%|██████████| 20/20 [04:01<00:00, 12.02s/it]
Task 21, Epoch 20/20 => Loss 0.268, Train_accy 90.36: 100%|██████████| 20/20 [04:01<00:00, 12.06s/it]
2024-08-12 13:17:45,763 [inflora.py] => Task 21, Epoch 20/20 => Loss 0.268, Train_accy 90.36
Threshold:  0.985
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 19/768 type remove
Layer 3 : 63/768 type remove
Layer 4 : 72/768 type remove
Layer 5 : 99/768 type remove
Layer 6 : 113/768 type remove
Layer 7 : 118/768 type remove
Layer 8 : 134/768 type remove
Layer 9 : 182/768 type remove
Layer 10 : 215/768 type remove
Layer 11 : 120/768 type remove
Layer 12 : 130/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:18:07,159 [trainer.py] => Time:274.0210304260254
4389 4389
4389 4389
2024-08-12 13:18:16,446 [trainer.py] => Time:9.28618049621582
2024-08-12 13:18:16,446 [inflora.py] => Exemplar size: 0
2024-08-12 13:18:16,446 [trainer.py] => CNN: {'total': 65.41, '00-09': 72.5, '10-19': 76.0, '20-29': 64.5, '30-39': 66.5, '40-49': 65.0, '50-59': 74.87, '60-69': 76.5, '70-79': 72.5, '80-89': 63.82, '90-99': 61.31, '100-109': 70.85, '110-119': 57.79, '120-129': 76.0, '130-139': 72.0, '140-149': 66.83, '150-159': 56.78, '160-169': 56.28, '170-179': 47.0, '180-189': 78.79, '190-199': 71.0, '200-209': 61.31, '210-219': 31.0, 'old': 67.06, 'new': 31.0}
2024-08-12 13:18:16,446 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41]
2024-08-12 13:18:16,447 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13]
2024-08-12 13:18:16,447 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812]
Average Accuracy (CNN): 77.4
2024-08-12 13:18:16,452 [trainer.py] => All params: 112239531
2024-08-12 13:18:16,457 [trainer.py] => Trainable params: 81418
2024-08-12 13:18:16,457 [inflora.py] => Learning on 220-230

  0%|          | 0/20 [00:00<?, ?it/s]
Task 22, Epoch 1/20 => Loss 0.354, Train_accy 89.04:   0%|          | 0/20 [00:11<?, ?it/s]
Task 22, Epoch 1/20 => Loss 0.354, Train_accy 89.04:   5%|▌         | 1/20 [00:11<03:47, 11.97s/it]
Task 22, Epoch 2/20 => Loss 0.102, Train_accy 96.67:   5%|▌         | 1/20 [00:24<03:47, 11.97s/it]
Task 22, Epoch 2/20 => Loss 0.102, Train_accy 96.67:  10%|█         | 2/20 [00:24<03:36, 12.02s/it]
Task 22, Epoch 3/20 => Loss 0.087, Train_accy 97.29:  10%|█         | 2/20 [00:36<03:36, 12.02s/it]
Task 22, Epoch 3/20 => Loss 0.087, Train_accy 97.29:  15%|█▌        | 3/20 [00:36<03:24, 12.01s/it]
Task 22, Epoch 4/20 => Loss 0.075, Train_accy 97.58:  15%|█▌        | 3/20 [00:48<03:24, 12.01s/it]
Task 22, Epoch 4/20 => Loss 0.075, Train_accy 97.58:  20%|██        | 4/20 [00:48<03:13, 12.07s/it]
Task 22, Epoch 5/20 => Loss 0.069, Train_accy 98.09:  20%|██        | 4/20 [01:00<03:13, 12.07s/it]
Task 22, Epoch 5/20 => Loss 0.069, Train_accy 98.09:  25%|██▌       | 5/20 [01:00<03:01, 12.08s/it]
Task 22, Epoch 6/20 => Loss 0.084, Train_accy 97.45:  25%|██▌       | 5/20 [01:12<03:01, 12.08s/it]
Task 22, Epoch 6/20 => Loss 0.084, Train_accy 97.45:  30%|███       | 6/20 [01:12<02:48, 12.05s/it]
Task 22, Epoch 7/20 => Loss 0.072, Train_accy 97.41:  30%|███       | 6/20 [01:24<02:48, 12.05s/it]
Task 22, Epoch 7/20 => Loss 0.072, Train_accy 97.41:  35%|███▌      | 7/20 [01:24<02:36, 12.08s/it]
Task 22, Epoch 8/20 => Loss 0.062, Train_accy 97.96:  35%|███▌      | 7/20 [01:36<02:36, 12.08s/it]
Task 22, Epoch 8/20 => Loss 0.062, Train_accy 97.96:  40%|████      | 8/20 [01:36<02:24, 12.08s/it]
Task 22, Epoch 9/20 => Loss 0.060, Train_accy 98.03:  40%|████      | 8/20 [01:48<02:24, 12.08s/it]
Task 22, Epoch 9/20 => Loss 0.060, Train_accy 98.03:  45%|████▌     | 9/20 [01:48<02:12, 12.04s/it]
Task 22, Epoch 10/20 => Loss 0.064, Train_accy 97.90:  45%|████▌     | 9/20 [02:00<02:12, 12.04s/it]
Task 22, Epoch 10/20 => Loss 0.064, Train_accy 97.90:  50%|█████     | 10/20 [02:00<02:00, 12.06s/it]
Task 22, Epoch 11/20 => Loss 0.062, Train_accy 97.83:  50%|█████     | 10/20 [02:12<02:00, 12.06s/it]
Task 22, Epoch 11/20 => Loss 0.062, Train_accy 97.83:  55%|█████▌    | 11/20 [02:12<01:48, 12.06s/it]
Task 22, Epoch 12/20 => Loss 0.053, Train_accy 98.35:  55%|█████▌    | 11/20 [02:24<01:48, 12.06s/it]
Task 22, Epoch 12/20 => Loss 0.053, Train_accy 98.35:  60%|██████    | 12/20 [02:24<01:36, 12.05s/it]
Task 22, Epoch 13/20 => Loss 0.055, Train_accy 98.06:  60%|██████    | 12/20 [02:36<01:36, 12.05s/it]
Task 22, Epoch 13/20 => Loss 0.055, Train_accy 98.06:  65%|██████▌   | 13/20 [02:36<01:24, 12.07s/it]
Task 22, Epoch 14/20 => Loss 0.048, Train_accy 98.25:  65%|██████▌   | 13/20 [02:48<01:24, 12.07s/it]
Task 22, Epoch 14/20 => Loss 0.048, Train_accy 98.25:  70%|███████   | 14/20 [02:48<01:12, 12.08s/it]
Task 22, Epoch 15/20 => Loss 0.049, Train_accy 98.32:  70%|███████   | 14/20 [03:00<01:12, 12.08s/it]
Task 22, Epoch 15/20 => Loss 0.049, Train_accy 98.32:  75%|███████▌  | 15/20 [03:00<01:00, 12.09s/it]
Task 22, Epoch 16/20 => Loss 0.058, Train_accy 97.93:  75%|███████▌  | 15/20 [03:12<01:00, 12.09s/it]
Task 22, Epoch 16/20 => Loss 0.058, Train_accy 97.93:  80%|████████  | 16/20 [03:12<00:48, 12.07s/it]
Task 22, Epoch 17/20 => Loss 0.051, Train_accy 98.29:  80%|████████  | 16/20 [03:25<00:48, 12.07s/it]
Task 22, Epoch 17/20 => Loss 0.051, Train_accy 98.29:  85%|████████▌ | 17/20 [03:25<00:36, 12.07s/it]
Task 22, Epoch 18/20 => Loss 0.046, Train_accy 98.25:  85%|████████▌ | 17/20 [03:37<00:36, 12.07s/it]
Task 22, Epoch 18/20 => Loss 0.046, Train_accy 98.25:  90%|█████████ | 18/20 [03:37<00:24, 12.10s/it]
Task 22, Epoch 19/20 => Loss 0.058, Train_accy 97.90:  90%|█████████ | 18/20 [03:49<00:24, 12.10s/it]
Task 22, Epoch 19/20 => Loss 0.058, Train_accy 97.90:  95%|█████████▌| 19/20 [03:49<00:12, 12.09s/it]
Task 22, Epoch 20/20 => Loss 0.042, Train_accy 98.45:  95%|█████████▌| 19/20 [04:01<00:12, 12.09s/it]
Task 22, Epoch 20/20 => Loss 0.042, Train_accy 98.45: 100%|██████████| 20/20 [04:01<00:00, 12.08s/it]
Task 22, Epoch 20/20 => Loss 0.042, Train_accy 98.45: 100%|██████████| 20/20 [04:01<00:00, 12.07s/it]
2024-08-12 13:22:29,432 [inflora.py] => Task 22, Epoch 20/20 => Loss 0.042, Train_accy 98.45
Threshold:  0.9866666666666667
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 24/768 type remove
Layer 3 : 78/768 type remove
Layer 4 : 90/768 type remove
Layer 5 : 120/768 type remove
Layer 6 : 135/768 type remove
Layer 7 : 141/768 type remove
Layer 8 : 162/768 type remove
Layer 9 : 216/768 type remove
Layer 10 : 259/768 type remove
Layer 11 : 145/768 type remove
Layer 12 : 141/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:22:50,949 [trainer.py] => Time:274.4914631843567
4588 4588
4588 4588
2024-08-12 13:23:00,447 [trainer.py] => Time:9.49681806564331
2024-08-12 13:23:00,447 [inflora.py] => Exemplar size: 0
2024-08-12 13:23:00,447 [trainer.py] => CNN: {'total': 64.63, '00-09': 72.5, '10-19': 75.0, '20-29': 65.0, '30-39': 64.5, '40-49': 63.5, '50-59': 73.87, '60-69': 72.5, '70-79': 70.5, '80-89': 63.32, '90-99': 61.81, '100-109': 63.82, '110-119': 58.29, '120-129': 72.5, '130-139': 73.0, '140-149': 66.83, '150-159': 58.79, '160-169': 56.28, '170-179': 46.0, '180-189': 74.75, '190-199': 69.5, '200-209': 61.31, '210-219': 30.5, '220-229': 72.36, 'old': 64.27, 'new': 72.36}
2024-08-12 13:23:00,447 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63]
2024-08-12 13:23:00,447 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19]
2024-08-12 13:23:00,447 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354]
Average Accuracy (CNN): 76.85
2024-08-12 13:23:00,452 [trainer.py] => All params: 112239531
2024-08-12 13:23:00,457 [trainer.py] => Trainable params: 81418
2024-08-12 13:23:00,457 [inflora.py] => Learning on 230-240

  0%|          | 0/20 [00:00<?, ?it/s]
Task 23, Epoch 1/20 => Loss 0.388, Train_accy 87.59:   0%|          | 0/20 [00:12<?, ?it/s]
Task 23, Epoch 1/20 => Loss 0.388, Train_accy 87.59:   5%|▌         | 1/20 [00:12<03:49, 12.10s/it]
Task 23, Epoch 2/20 => Loss 0.092, Train_accy 97.24:   5%|▌         | 1/20 [00:24<03:49, 12.10s/it]
Task 23, Epoch 2/20 => Loss 0.092, Train_accy 97.24:  10%|█         | 2/20 [00:24<03:37, 12.08s/it]
Task 23, Epoch 3/20 => Loss 0.067, Train_accy 97.81:  10%|█         | 2/20 [00:36<03:37, 12.08s/it]
Task 23, Epoch 3/20 => Loss 0.067, Train_accy 97.81:  15%|█▌        | 3/20 [00:36<03:26, 12.16s/it]
Task 23, Epoch 4/20 => Loss 0.058, Train_accy 98.14:  15%|█▌        | 3/20 [00:48<03:26, 12.16s/it]
Task 23, Epoch 4/20 => Loss 0.058, Train_accy 98.14:  20%|██        | 4/20 [00:48<03:14, 12.16s/it]
Task 23, Epoch 5/20 => Loss 0.054, Train_accy 98.10:  20%|██        | 4/20 [01:00<03:14, 12.16s/it]
Task 23, Epoch 5/20 => Loss 0.054, Train_accy 98.10:  25%|██▌       | 5/20 [01:00<03:02, 12.18s/it]
Task 23, Epoch 6/20 => Loss 0.051, Train_accy 98.20:  25%|██▌       | 5/20 [01:12<03:02, 12.18s/it]
Task 23, Epoch 6/20 => Loss 0.051, Train_accy 98.20:  30%|███       | 6/20 [01:12<02:50, 12.18s/it]
Task 23, Epoch 7/20 => Loss 0.039, Train_accy 98.49:  30%|███       | 6/20 [01:25<02:50, 12.18s/it]
Task 23, Epoch 7/20 => Loss 0.039, Train_accy 98.49:  35%|███▌      | 7/20 [01:25<02:37, 12.15s/it]
Task 23, Epoch 8/20 => Loss 0.046, Train_accy 98.33:  35%|███▌      | 7/20 [01:37<02:37, 12.15s/it]
Task 23, Epoch 8/20 => Loss 0.046, Train_accy 98.33:  40%|████      | 8/20 [01:37<02:25, 12.15s/it]
Task 23, Epoch 9/20 => Loss 0.042, Train_accy 98.52:  40%|████      | 8/20 [01:49<02:25, 12.15s/it]
Task 23, Epoch 9/20 => Loss 0.042, Train_accy 98.52:  45%|████▌     | 9/20 [01:49<02:13, 12.15s/it]
Task 23, Epoch 10/20 => Loss 0.043, Train_accy 98.39:  45%|████▌     | 9/20 [02:01<02:13, 12.15s/it]
Task 23, Epoch 10/20 => Loss 0.043, Train_accy 98.39:  50%|█████     | 10/20 [02:01<02:01, 12.16s/it]
Task 23, Epoch 11/20 => Loss 0.033, Train_accy 98.94:  50%|█████     | 10/20 [02:13<02:01, 12.16s/it]
Task 23, Epoch 11/20 => Loss 0.033, Train_accy 98.94:  55%|█████▌    | 11/20 [02:13<01:49, 12.15s/it]
Task 23, Epoch 12/20 => Loss 0.027, Train_accy 98.91:  55%|█████▌    | 11/20 [02:25<01:49, 12.15s/it]
Task 23, Epoch 12/20 => Loss 0.027, Train_accy 98.91:  60%|██████    | 12/20 [02:25<01:37, 12.13s/it]
Task 23, Epoch 13/20 => Loss 0.030, Train_accy 99.07:  60%|██████    | 12/20 [02:37<01:37, 12.13s/it]
Task 23, Epoch 13/20 => Loss 0.030, Train_accy 99.07:  65%|██████▌   | 13/20 [02:37<01:24, 12.13s/it]
Task 23, Epoch 14/20 => Loss 0.025, Train_accy 99.07:  65%|██████▌   | 13/20 [02:50<01:24, 12.13s/it]
Task 23, Epoch 14/20 => Loss 0.025, Train_accy 99.07:  70%|███████   | 14/20 [02:50<01:12, 12.14s/it]
Task 23, Epoch 15/20 => Loss 0.032, Train_accy 99.00:  70%|███████   | 14/20 [03:02<01:12, 12.14s/it]
Task 23, Epoch 15/20 => Loss 0.032, Train_accy 99.00:  75%|███████▌  | 15/20 [03:02<01:00, 12.13s/it]
Task 23, Epoch 16/20 => Loss 0.042, Train_accy 98.39:  75%|███████▌  | 15/20 [03:14<01:00, 12.13s/it]
Task 23, Epoch 16/20 => Loss 0.042, Train_accy 98.39:  80%|████████  | 16/20 [03:14<00:48, 12.15s/it]
Task 23, Epoch 17/20 => Loss 0.036, Train_accy 98.68:  80%|████████  | 16/20 [03:26<00:48, 12.15s/it]
Task 23, Epoch 17/20 => Loss 0.036, Train_accy 98.68:  85%|████████▌ | 17/20 [03:26<00:36, 12.16s/it]
Task 23, Epoch 18/20 => Loss 0.039, Train_accy 98.81:  85%|████████▌ | 17/20 [03:38<00:36, 12.16s/it]
Task 23, Epoch 18/20 => Loss 0.039, Train_accy 98.81:  90%|█████████ | 18/20 [03:38<00:24, 12.14s/it]
Task 23, Epoch 19/20 => Loss 0.038, Train_accy 98.97:  90%|█████████ | 18/20 [03:50<00:24, 12.14s/it]
Task 23, Epoch 19/20 => Loss 0.038, Train_accy 98.97:  95%|█████████▌| 19/20 [03:50<00:12, 12.15s/it]
Task 23, Epoch 20/20 => Loss 0.028, Train_accy 99.10:  95%|█████████▌| 19/20 [04:02<00:12, 12.15s/it]
Task 23, Epoch 20/20 => Loss 0.028, Train_accy 99.10: 100%|██████████| 20/20 [04:02<00:00, 12.11s/it]
Task 23, Epoch 20/20 => Loss 0.028, Train_accy 99.10: 100%|██████████| 20/20 [04:02<00:00, 12.14s/it]
2024-08-12 13:27:15,062 [inflora.py] => Task 23, Epoch 20/20 => Loss 0.028, Train_accy 99.10
Threshold:  0.9883333333333333
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 25/768 type remove
Layer 3 : 80/768 type remove
Layer 4 : 93/768 type remove
Layer 5 : 125/768 type remove
Layer 6 : 144/768 type remove
Layer 7 : 154/768 type remove
Layer 8 : 180/768 type remove
Layer 9 : 241/768 type remove
Layer 10 : 286/768 type remove
Layer 11 : 169/768 type remove
Layer 12 : 162/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:27:36,996 [trainer.py] => Time:276.5389823913574
4788 4788
4788 4788
2024-08-12 13:27:47,006 [trainer.py] => Time:10.009495496749878
2024-08-12 13:27:47,007 [inflora.py] => Exemplar size: 0
2024-08-12 13:27:47,007 [trainer.py] => CNN: {'total': 64.31, '00-09': 73.0, '10-19': 73.5, '20-29': 64.5, '30-39': 63.0, '40-49': 62.5, '50-59': 71.86, '60-69': 74.5, '70-79': 70.5, '80-89': 63.32, '90-99': 60.8, '100-109': 62.81, '110-119': 54.77, '120-129': 72.5, '130-139': 73.5, '140-149': 62.31, '150-159': 56.28, '160-169': 55.28, '170-179': 43.5, '180-189': 73.74, '190-199': 71.5, '200-209': 58.79, '210-219': 30.0, '220-229': 71.36, '230-239': 79.5, 'old': 63.64, 'new': 79.5}
2024-08-12 13:27:47,007 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31]
2024-08-12 13:27:47,007 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1]
2024-08-12 13:27:47,007 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963]
Average Accuracy (CNN): 76.32
2024-08-12 13:27:47,012 [trainer.py] => All params: 112239531
2024-08-12 13:27:47,016 [trainer.py] => Trainable params: 81418
2024-08-12 13:27:47,016 [inflora.py] => Learning on 240-250

  0%|          | 0/20 [00:00<?, ?it/s]
Task 24, Epoch 1/20 => Loss 0.541, Train_accy 82.09:   0%|          | 0/20 [00:12<?, ?it/s]
Task 24, Epoch 1/20 => Loss 0.541, Train_accy 82.09:   5%|▌         | 1/20 [00:12<03:52, 12.24s/it]
Task 24, Epoch 2/20 => Loss 0.198, Train_accy 92.82:   5%|▌         | 1/20 [00:24<03:52, 12.24s/it]
Task 24, Epoch 2/20 => Loss 0.198, Train_accy 92.82:  10%|█         | 2/20 [00:24<03:42, 12.34s/it]
Task 24, Epoch 3/20 => Loss 0.180, Train_accy 93.26:  10%|█         | 2/20 [00:37<03:42, 12.34s/it]
Task 24, Epoch 3/20 => Loss 0.180, Train_accy 93.26:  15%|█▌        | 3/20 [00:37<03:29, 12.35s/it]
Task 24, Epoch 4/20 => Loss 0.143, Train_accy 94.75:  15%|█▌        | 3/20 [00:49<03:29, 12.35s/it]
Task 24, Epoch 4/20 => Loss 0.143, Train_accy 94.75:  20%|██        | 4/20 [00:49<03:17, 12.33s/it]
Task 24, Epoch 5/20 => Loss 0.128, Train_accy 95.03:  20%|██        | 4/20 [01:01<03:17, 12.33s/it]
Task 24, Epoch 5/20 => Loss 0.128, Train_accy 95.03:  25%|██▌       | 5/20 [01:01<03:05, 12.34s/it]
Task 24, Epoch 6/20 => Loss 0.126, Train_accy 95.00:  25%|██▌       | 5/20 [01:14<03:05, 12.34s/it]
Task 24, Epoch 6/20 => Loss 0.126, Train_accy 95.00:  30%|███       | 6/20 [01:14<02:53, 12.36s/it]
Task 24, Epoch 7/20 => Loss 0.108, Train_accy 96.33:  30%|███       | 6/20 [01:26<02:53, 12.36s/it]
Task 24, Epoch 7/20 => Loss 0.108, Train_accy 96.33:  35%|███▌      | 7/20 [01:26<02:40, 12.34s/it]
Task 24, Epoch 8/20 => Loss 0.116, Train_accy 95.60:  35%|███▌      | 7/20 [01:38<02:40, 12.34s/it]
Task 24, Epoch 8/20 => Loss 0.116, Train_accy 95.60:  40%|████      | 8/20 [01:38<02:28, 12.36s/it]
Task 24, Epoch 9/20 => Loss 0.102, Train_accy 96.11:  40%|████      | 8/20 [01:51<02:28, 12.36s/it]
Task 24, Epoch 9/20 => Loss 0.102, Train_accy 96.11:  45%|████▌     | 9/20 [01:51<02:15, 12.36s/it]
Task 24, Epoch 10/20 => Loss 0.101, Train_accy 96.27:  45%|████▌     | 9/20 [02:03<02:15, 12.36s/it]
Task 24, Epoch 10/20 => Loss 0.101, Train_accy 96.27:  50%|█████     | 10/20 [02:03<02:03, 12.36s/it]
Task 24, Epoch 11/20 => Loss 0.104, Train_accy 96.01:  50%|█████     | 10/20 [02:15<02:03, 12.36s/it]
Task 24, Epoch 11/20 => Loss 0.104, Train_accy 96.01:  55%|█████▌    | 11/20 [02:15<01:51, 12.37s/it]
Task 24, Epoch 12/20 => Loss 0.088, Train_accy 96.87:  55%|█████▌    | 11/20 [02:28<01:51, 12.37s/it]
Task 24, Epoch 12/20 => Loss 0.088, Train_accy 96.87:  60%|██████    | 12/20 [02:28<01:38, 12.36s/it]
Task 24, Epoch 13/20 => Loss 0.097, Train_accy 96.68:  60%|██████    | 12/20 [02:40<01:38, 12.36s/it]
Task 24, Epoch 13/20 => Loss 0.097, Train_accy 96.68:  65%|██████▌   | 13/20 [02:40<01:26, 12.34s/it]
Task 24, Epoch 14/20 => Loss 0.097, Train_accy 96.46:  65%|██████▌   | 13/20 [02:52<01:26, 12.34s/it]
Task 24, Epoch 14/20 => Loss 0.097, Train_accy 96.46:  70%|███████   | 14/20 [02:52<01:14, 12.37s/it]
Task 24, Epoch 15/20 => Loss 0.085, Train_accy 96.90:  70%|███████   | 14/20 [03:05<01:14, 12.37s/it]
Task 24, Epoch 15/20 => Loss 0.085, Train_accy 96.90:  75%|███████▌  | 15/20 [03:05<01:01, 12.35s/it]
Task 24, Epoch 16/20 => Loss 0.091, Train_accy 96.80:  75%|███████▌  | 15/20 [03:17<01:01, 12.35s/it]
Task 24, Epoch 16/20 => Loss 0.091, Train_accy 96.80:  80%|████████  | 16/20 [03:17<00:49, 12.35s/it]
Task 24, Epoch 17/20 => Loss 0.082, Train_accy 97.03:  80%|████████  | 16/20 [03:29<00:49, 12.35s/it]
Task 24, Epoch 17/20 => Loss 0.082, Train_accy 97.03:  85%|████████▌ | 17/20 [03:29<00:36, 12.33s/it]
Task 24, Epoch 18/20 => Loss 0.077, Train_accy 97.22:  85%|████████▌ | 17/20 [03:42<00:36, 12.33s/it]
Task 24, Epoch 18/20 => Loss 0.077, Train_accy 97.22:  90%|█████████ | 18/20 [03:42<00:24, 12.37s/it]
Task 24, Epoch 19/20 => Loss 0.081, Train_accy 97.18:  90%|█████████ | 18/20 [03:54<00:24, 12.37s/it]
Task 24, Epoch 19/20 => Loss 0.081, Train_accy 97.18:  95%|█████████▌| 19/20 [03:54<00:12, 12.37s/it]
Task 24, Epoch 20/20 => Loss 0.076, Train_accy 96.96:  95%|█████████▌| 19/20 [04:06<00:12, 12.37s/it]
Task 24, Epoch 20/20 => Loss 0.076, Train_accy 96.96: 100%|██████████| 20/20 [04:06<00:00, 12.34s/it]
Task 24, Epoch 20/20 => Loss 0.076, Train_accy 96.96: 100%|██████████| 20/20 [04:06<00:00, 12.35s/it]
2024-08-12 13:32:05,770 [inflora.py] => Task 24, Epoch 20/20 => Loss 0.076, Train_accy 96.96
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 26/768 type remove
Layer 3 : 84/768 type remove
Layer 4 : 99/768 type remove
Layer 5 : 133/768 type remove
Layer 6 : 154/768 type remove
Layer 7 : 168/768 type remove
Layer 8 : 195/768 type remove
Layer 9 : 257/768 type remove
Layer 10 : 298/768 type remove
Layer 11 : 182/768 type remove
Layer 12 : 173/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:32:27,605 [trainer.py] => Time:280.58875250816345
4988 4988
4988 4988
2024-08-12 13:32:37,950 [trainer.py] => Time:10.34486699104309
2024-08-12 13:32:37,951 [inflora.py] => Exemplar size: 0
2024-08-12 13:32:37,951 [trainer.py] => CNN: {'total': 63.55, '00-09': 72.0, '10-19': 72.5, '20-29': 63.0, '30-39': 63.5, '40-49': 64.0, '50-59': 73.37, '60-69': 75.5, '70-79': 70.5, '80-89': 63.82, '90-99': 60.8, '100-109': 64.32, '110-119': 54.27, '120-129': 64.5, '130-139': 73.0, '140-149': 62.81, '150-159': 56.28, '160-169': 55.28, '170-179': 43.5, '180-189': 72.73, '190-199': 68.5, '200-209': 57.29, '210-219': 28.5, '220-229': 71.86, '230-239': 76.0, '240-249': 61.0, 'old': 63.66, 'new': 61.0}
2024-08-12 13:32:37,951 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55]
2024-08-12 13:32:37,951 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29]
2024-08-12 13:32:37,951 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155]
Average Accuracy (CNN): 75.81
2024-08-12 13:32:37,957 [trainer.py] => All params: 112239531
2024-08-12 13:32:37,961 [trainer.py] => Trainable params: 81418
2024-08-12 13:32:37,961 [inflora.py] => Learning on 250-260

  0%|          | 0/20 [00:00<?, ?it/s]
Task 25, Epoch 1/20 => Loss 0.442, Train_accy 86.41:   0%|          | 0/20 [00:11<?, ?it/s]
Task 25, Epoch 1/20 => Loss 0.442, Train_accy 86.41:   5%|▌         | 1/20 [00:11<03:40, 11.62s/it]
Task 25, Epoch 2/20 => Loss 0.138, Train_accy 95.97:   5%|▌         | 1/20 [00:23<03:40, 11.62s/it]
Task 25, Epoch 2/20 => Loss 0.138, Train_accy 95.97:  10%|█         | 2/20 [00:23<03:29, 11.62s/it]
Task 25, Epoch 3/20 => Loss 0.111, Train_accy 96.24:  10%|█         | 2/20 [00:34<03:29, 11.62s/it]
Task 25, Epoch 3/20 => Loss 0.111, Train_accy 96.24:  15%|█▌        | 3/20 [00:34<03:16, 11.58s/it]
Task 25, Epoch 4/20 => Loss 0.099, Train_accy 96.81:  15%|█▌        | 3/20 [00:46<03:16, 11.58s/it]
Task 25, Epoch 4/20 => Loss 0.099, Train_accy 96.81:  20%|██        | 4/20 [00:46<03:06, 11.64s/it]
Task 25, Epoch 5/20 => Loss 0.102, Train_accy 96.88:  20%|██        | 4/20 [00:58<03:06, 11.64s/it]
Task 25, Epoch 5/20 => Loss 0.102, Train_accy 96.88:  25%|██▌       | 5/20 [00:58<02:54, 11.66s/it]
Task 25, Epoch 6/20 => Loss 0.089, Train_accy 96.81:  25%|██▌       | 5/20 [01:09<02:54, 11.66s/it]
Task 25, Epoch 6/20 => Loss 0.089, Train_accy 96.81:  30%|███       | 6/20 [01:09<02:43, 11.65s/it]
Task 25, Epoch 7/20 => Loss 0.082, Train_accy 97.12:  30%|███       | 6/20 [01:21<02:43, 11.65s/it]
Task 25, Epoch 7/20 => Loss 0.082, Train_accy 97.12:  35%|███▌      | 7/20 [01:21<02:31, 11.65s/it]
Task 25, Epoch 8/20 => Loss 0.068, Train_accy 97.63:  35%|███▌      | 7/20 [01:33<02:31, 11.65s/it]
Task 25, Epoch 8/20 => Loss 0.068, Train_accy 97.63:  40%|████      | 8/20 [01:33<02:20, 11.67s/it]
Task 25, Epoch 9/20 => Loss 0.073, Train_accy 97.70:  40%|████      | 8/20 [01:44<02:20, 11.67s/it]
Task 25, Epoch 9/20 => Loss 0.073, Train_accy 97.70:  45%|████▌     | 9/20 [01:44<02:08, 11.67s/it]
Task 25, Epoch 10/20 => Loss 0.064, Train_accy 97.83:  45%|████▌     | 9/20 [01:56<02:08, 11.67s/it]
Task 25, Epoch 10/20 => Loss 0.064, Train_accy 97.83:  50%|█████     | 10/20 [01:56<01:56, 11.66s/it]
Task 25, Epoch 11/20 => Loss 0.058, Train_accy 97.83:  50%|█████     | 10/20 [02:08<01:56, 11.66s/it]
Task 25, Epoch 11/20 => Loss 0.058, Train_accy 97.83:  55%|█████▌    | 11/20 [02:08<01:44, 11.66s/it]
Task 25, Epoch 12/20 => Loss 0.053, Train_accy 98.00:  55%|█████▌    | 11/20 [02:19<01:44, 11.66s/it]
Task 25, Epoch 12/20 => Loss 0.053, Train_accy 98.00:  60%|██████    | 12/20 [02:19<01:33, 11.68s/it]
Task 25, Epoch 13/20 => Loss 0.058, Train_accy 97.83:  60%|██████    | 12/20 [02:31<01:33, 11.68s/it]
Task 25, Epoch 13/20 => Loss 0.058, Train_accy 97.83:  65%|██████▌   | 13/20 [02:31<01:21, 11.67s/it]
Task 25, Epoch 14/20 => Loss 0.056, Train_accy 98.07:  65%|██████▌   | 13/20 [02:43<01:21, 11.67s/it]
Task 25, Epoch 14/20 => Loss 0.056, Train_accy 98.07:  70%|███████   | 14/20 [02:43<01:09, 11.65s/it]
Task 25, Epoch 15/20 => Loss 0.056, Train_accy 97.93:  70%|███████   | 14/20 [02:54<01:09, 11.65s/it]
Task 25, Epoch 15/20 => Loss 0.056, Train_accy 97.93:  75%|███████▌  | 15/20 [02:54<00:58, 11.65s/it]
Task 25, Epoch 16/20 => Loss 0.056, Train_accy 98.07:  75%|███████▌  | 15/20 [03:06<00:58, 11.65s/it]
Task 25, Epoch 16/20 => Loss 0.056, Train_accy 98.07:  80%|████████  | 16/20 [03:06<00:46, 11.62s/it]
Task 25, Epoch 17/20 => Loss 0.053, Train_accy 98.10:  80%|████████  | 16/20 [03:18<00:46, 11.62s/it]
Task 25, Epoch 17/20 => Loss 0.053, Train_accy 98.10:  85%|████████▌ | 17/20 [03:18<00:35, 11.67s/it]
Task 25, Epoch 18/20 => Loss 0.064, Train_accy 97.63:  85%|████████▌ | 17/20 [03:29<00:35, 11.67s/it]
Task 25, Epoch 18/20 => Loss 0.064, Train_accy 97.63:  90%|█████████ | 18/20 [03:29<00:23, 11.67s/it]
Task 25, Epoch 19/20 => Loss 0.064, Train_accy 97.63:  90%|█████████ | 18/20 [03:41<00:23, 11.67s/it]
Task 25, Epoch 19/20 => Loss 0.064, Train_accy 97.63:  95%|█████████▌| 19/20 [03:41<00:11, 11.64s/it]
Task 25, Epoch 20/20 => Loss 0.050, Train_accy 98.17:  95%|█████████▌| 19/20 [03:53<00:11, 11.64s/it]
Task 25, Epoch 20/20 => Loss 0.050, Train_accy 98.17: 100%|██████████| 20/20 [03:53<00:00, 11.67s/it]
Task 25, Epoch 20/20 => Loss 0.050, Train_accy 98.17: 100%|██████████| 20/20 [03:53<00:00, 11.65s/it]
2024-08-12 13:36:42,366 [inflora.py] => Task 25, Epoch 20/20 => Loss 0.050, Train_accy 98.17
Threshold:  0.9916666666666667
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 31/768 type remove
Layer 3 : 100/768 type remove
Layer 4 : 119/768 type remove
Layer 5 : 157/768 type remove
Layer 6 : 180/768 type remove
Layer 7 : 196/768 type remove
Layer 8 : 230/768 type remove
Layer 9 : 301/768 type remove
Layer 10 : 347/768 type remove
Layer 11 : 225/768 type remove
Layer 12 : 189/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:37:03,066 [trainer.py] => Time:265.1051573753357
5187 5187
5187 5187
2024-08-12 13:37:13,999 [trainer.py] => Time:10.93256425857544
2024-08-12 13:37:13,999 [inflora.py] => Exemplar size: 0
2024-08-12 13:37:13,999 [trainer.py] => CNN: {'total': 63.16, '00-09': 73.5, '10-19': 72.5, '20-29': 63.0, '30-39': 65.0, '40-49': 62.0, '50-59': 74.37, '60-69': 72.5, '70-79': 69.0, '80-89': 63.32, '90-99': 60.8, '100-109': 63.32, '110-119': 51.26, '120-129': 63.0, '130-139': 72.5, '140-149': 63.82, '150-159': 51.26, '160-169': 56.28, '170-179': 43.0, '180-189': 72.22, '190-199': 69.0, '200-209': 57.79, '210-219': 29.0, '220-229': 64.32, '230-239': 77.5, '240-249': 59.5, '250-259': 72.36, 'old': 62.79, 'new': 72.36}
2024-08-12 13:37:14,000 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55, 63.16]
2024-08-12 13:37:14,000 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29, 97.36]
2024-08-12 13:37:14,000 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155, 0.6321573163678427]
Average Accuracy (CNN): 75.33
2024-08-12 13:37:14,005 [trainer.py] => All params: 112239531
2024-08-12 13:37:14,009 [trainer.py] => Trainable params: 81418
2024-08-12 13:37:14,009 [inflora.py] => Learning on 260-270

  0%|          | 0/20 [00:00<?, ?it/s]
Task 26, Epoch 1/20 => Loss 0.390, Train_accy 89.06:   0%|          | 0/20 [00:12<?, ?it/s]
Task 26, Epoch 1/20 => Loss 0.390, Train_accy 89.06:   5%|▌         | 1/20 [00:12<03:52, 12.24s/it]
Task 26, Epoch 2/20 => Loss 0.039, Train_accy 98.95:   5%|▌         | 1/20 [00:24<03:52, 12.24s/it]
Task 26, Epoch 2/20 => Loss 0.039, Train_accy 98.95:  10%|█         | 2/20 [00:24<03:36, 12.03s/it]
Task 26, Epoch 3/20 => Loss 0.031, Train_accy 99.28:  10%|█         | 2/20 [00:36<03:36, 12.03s/it]
Task 26, Epoch 3/20 => Loss 0.031, Train_accy 99.28:  15%|█▌        | 3/20 [00:36<03:23, 11.98s/it]
Task 26, Epoch 4/20 => Loss 0.036, Train_accy 99.01:  15%|█▌        | 3/20 [00:47<03:23, 11.98s/it]
Task 26, Epoch 4/20 => Loss 0.036, Train_accy 99.01:  20%|██        | 4/20 [00:47<03:11, 11.96s/it]
Task 26, Epoch 5/20 => Loss 0.019, Train_accy 99.51:  20%|██        | 4/20 [00:59<03:11, 11.96s/it]
Task 26, Epoch 5/20 => Loss 0.019, Train_accy 99.51:  25%|██▌       | 5/20 [00:59<02:59, 11.97s/it]
Task 26, Epoch 6/20 => Loss 0.021, Train_accy 99.38:  25%|██▌       | 5/20 [01:11<02:59, 11.97s/it]
Task 26, Epoch 6/20 => Loss 0.021, Train_accy 99.38:  30%|███       | 6/20 [01:11<02:46, 11.92s/it]
Task 26, Epoch 7/20 => Loss 0.029, Train_accy 99.24:  30%|███       | 6/20 [01:23<02:46, 11.92s/it]
Task 26, Epoch 7/20 => Loss 0.029, Train_accy 99.24:  35%|███▌      | 7/20 [01:23<02:35, 11.95s/it]
Task 26, Epoch 8/20 => Loss 0.015, Train_accy 99.54:  35%|███▌      | 7/20 [01:35<02:35, 11.95s/it]
Task 26, Epoch 8/20 => Loss 0.015, Train_accy 99.54:  40%|████      | 8/20 [01:35<02:23, 11.97s/it]
Task 26, Epoch 9/20 => Loss 0.017, Train_accy 99.61:  40%|████      | 8/20 [01:47<02:23, 11.97s/it]
Task 26, Epoch 9/20 => Loss 0.017, Train_accy 99.61:  45%|████▌     | 9/20 [01:47<02:11, 11.94s/it]
Task 26, Epoch 10/20 => Loss 0.021, Train_accy 99.34:  45%|████▌     | 9/20 [01:59<02:11, 11.94s/it]
Task 26, Epoch 10/20 => Loss 0.021, Train_accy 99.34:  50%|█████     | 10/20 [01:59<01:59, 11.96s/it]
Task 26, Epoch 11/20 => Loss 0.022, Train_accy 99.24:  50%|█████     | 10/20 [02:11<01:59, 11.96s/it]
Task 26, Epoch 11/20 => Loss 0.022, Train_accy 99.24:  55%|█████▌    | 11/20 [02:11<01:47, 11.97s/it]
Task 26, Epoch 12/20 => Loss 0.012, Train_accy 99.74:  55%|█████▌    | 11/20 [02:23<01:47, 11.97s/it]
Task 26, Epoch 12/20 => Loss 0.012, Train_accy 99.74:  60%|██████    | 12/20 [02:23<01:35, 11.95s/it]
Task 26, Epoch 13/20 => Loss 0.021, Train_accy 99.41:  60%|██████    | 12/20 [02:35<01:35, 11.95s/it]
Task 26, Epoch 13/20 => Loss 0.021, Train_accy 99.41:  65%|██████▌   | 13/20 [02:35<01:23, 11.98s/it]
Task 26, Epoch 14/20 => Loss 0.014, Train_accy 99.51:  65%|██████▌   | 13/20 [02:47<01:23, 11.98s/it]
Task 26, Epoch 14/20 => Loss 0.014, Train_accy 99.51:  70%|███████   | 14/20 [02:47<01:11, 11.99s/it]
Task 26, Epoch 15/20 => Loss 0.017, Train_accy 99.57:  70%|███████   | 14/20 [02:59<01:11, 11.99s/it]
Task 26, Epoch 15/20 => Loss 0.017, Train_accy 99.57:  75%|███████▌  | 15/20 [02:59<00:59, 11.98s/it]
Task 26, Epoch 16/20 => Loss 0.012, Train_accy 99.64:  75%|███████▌  | 15/20 [03:11<00:59, 11.98s/it]
Task 26, Epoch 16/20 => Loss 0.012, Train_accy 99.64:  80%|████████  | 16/20 [03:11<00:47, 11.98s/it]
Task 26, Epoch 17/20 => Loss 0.017, Train_accy 99.57:  80%|████████  | 16/20 [03:23<00:47, 11.98s/it]
Task 26, Epoch 17/20 => Loss 0.017, Train_accy 99.57:  85%|████████▌ | 17/20 [03:23<00:35, 11.97s/it]
Task 26, Epoch 18/20 => Loss 0.013, Train_accy 99.64:  85%|████████▌ | 17/20 [03:35<00:35, 11.97s/it]
Task 26, Epoch 18/20 => Loss 0.013, Train_accy 99.64:  90%|█████████ | 18/20 [03:35<00:23, 11.98s/it]
Task 26, Epoch 19/20 => Loss 0.014, Train_accy 99.54:  90%|█████████ | 18/20 [03:47<00:23, 11.98s/it]
Task 26, Epoch 19/20 => Loss 0.014, Train_accy 99.54:  95%|█████████▌| 19/20 [03:47<00:11, 11.97s/it]
Task 26, Epoch 20/20 => Loss 0.021, Train_accy 99.41:  95%|█████████▌| 19/20 [03:59<00:11, 11.97s/it]
Task 26, Epoch 20/20 => Loss 0.021, Train_accy 99.41: 100%|██████████| 20/20 [03:59<00:00, 12.00s/it]
Task 26, Epoch 20/20 => Loss 0.021, Train_accy 99.41: 100%|██████████| 20/20 [03:59<00:00, 11.98s/it]
2024-08-12 13:41:25,418 [inflora.py] => Task 26, Epoch 20/20 => Loss 0.021, Train_accy 99.41
Threshold:  0.9933333333333333
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 35/768 type remove
Layer 3 : 109/768 type remove
Layer 4 : 134/768 type remove
Layer 5 : 176/768 type remove
Layer 6 : 204/768 type remove
Layer 7 : 227/768 type remove
Layer 8 : 273/768 type remove
Layer 9 : 361/768 type remove
Layer 10 : 351/768 type retain
Layer 11 : 290/768 type remove
Layer 12 : 245/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:41:46,605 [trainer.py] => Time:272.59551072120667
5387 5387
5387 5387
2024-08-12 13:41:57,728 [trainer.py] => Time:11.122897148132324
2024-08-12 13:41:57,729 [inflora.py] => Exemplar size: 0
2024-08-12 13:41:57,729 [trainer.py] => CNN: {'total': 62.41, '00-09': 73.0, '10-19': 72.0, '20-29': 62.5, '30-39': 64.0, '40-49': 62.5, '50-59': 73.37, '60-69': 70.5, '70-79': 68.0, '80-89': 62.81, '90-99': 60.8, '100-109': 58.79, '110-119': 50.75, '120-129': 63.5, '130-139': 72.5, '140-149': 59.3, '150-159': 46.73, '160-169': 54.77, '170-179': 40.5, '180-189': 73.23, '190-199': 67.0, '200-209': 55.78, '210-219': 28.5, '220-229': 62.81, '230-239': 78.5, '240-249': 56.5, '250-259': 72.36, '260-269': 74.0, 'old': 61.96, 'new': 74.0}
2024-08-12 13:41:57,729 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55, 63.16, 62.41]
2024-08-12 13:41:57,729 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29, 97.36, 97.31]
2024-08-12 13:41:57,729 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155, 0.6321573163678427, 0.6242806757007611]
Average Accuracy (CNN): 74.85
2024-08-12 13:41:57,734 [trainer.py] => All params: 112239531
2024-08-12 13:41:57,739 [trainer.py] => Trainable params: 81418
2024-08-12 13:41:57,739 [inflora.py] => Learning on 270-280

  0%|          | 0/20 [00:00<?, ?it/s]
Task 27, Epoch 1/20 => Loss 0.497, Train_accy 85.64:   0%|          | 0/20 [00:11<?, ?it/s]
Task 27, Epoch 1/20 => Loss 0.497, Train_accy 85.64:   5%|▌         | 1/20 [00:11<03:29, 11.01s/it]
Task 27, Epoch 2/20 => Loss 0.082, Train_accy 97.26:   5%|▌         | 1/20 [00:22<03:29, 11.01s/it]
Task 27, Epoch 2/20 => Loss 0.082, Train_accy 97.26:  10%|█         | 2/20 [00:22<03:18, 11.02s/it]
Task 27, Epoch 3/20 => Loss 0.065, Train_accy 97.84:  10%|█         | 2/20 [00:33<03:18, 11.02s/it]
Task 27, Epoch 3/20 => Loss 0.065, Train_accy 97.84:  15%|█▌        | 3/20 [00:33<03:07, 11.03s/it]
Task 27, Epoch 4/20 => Loss 0.047, Train_accy 98.49:  15%|█▌        | 3/20 [00:44<03:07, 11.03s/it]
Task 27, Epoch 4/20 => Loss 0.047, Train_accy 98.49:  20%|██        | 4/20 [00:44<02:56, 11.03s/it]
Task 27, Epoch 5/20 => Loss 0.049, Train_accy 98.56:  20%|██        | 4/20 [00:55<02:56, 11.03s/it]
Task 27, Epoch 5/20 => Loss 0.049, Train_accy 98.56:  25%|██▌       | 5/20 [00:55<02:46, 11.08s/it]
Task 27, Epoch 6/20 => Loss 0.034, Train_accy 98.96:  25%|██▌       | 5/20 [01:06<02:46, 11.08s/it]
Task 27, Epoch 6/20 => Loss 0.034, Train_accy 98.96:  30%|███       | 6/20 [01:06<02:34, 11.07s/it]
Task 27, Epoch 7/20 => Loss 0.041, Train_accy 98.63:  30%|███       | 6/20 [01:17<02:34, 11.07s/it]
Task 27, Epoch 7/20 => Loss 0.041, Train_accy 98.63:  35%|███▌      | 7/20 [01:17<02:23, 11.06s/it]
Task 27, Epoch 8/20 => Loss 0.028, Train_accy 99.17:  35%|███▌      | 7/20 [01:28<02:23, 11.06s/it]
Task 27, Epoch 8/20 => Loss 0.028, Train_accy 99.17:  40%|████      | 8/20 [01:28<02:12, 11.04s/it]
Task 27, Epoch 9/20 => Loss 0.037, Train_accy 98.81:  40%|████      | 8/20 [01:39<02:12, 11.04s/it]
Task 27, Epoch 9/20 => Loss 0.037, Train_accy 98.81:  45%|████▌     | 9/20 [01:39<02:01, 11.06s/it]
Task 27, Epoch 10/20 => Loss 0.035, Train_accy 98.92:  45%|████▌     | 9/20 [01:50<02:01, 11.06s/it]
Task 27, Epoch 10/20 => Loss 0.035, Train_accy 98.92:  50%|█████     | 10/20 [01:50<01:50, 11.07s/it]
Task 27, Epoch 11/20 => Loss 0.035, Train_accy 98.96:  50%|█████     | 10/20 [02:01<01:50, 11.07s/it]
Task 27, Epoch 11/20 => Loss 0.035, Train_accy 98.96:  55%|█████▌    | 11/20 [02:01<01:39, 11.07s/it]
Task 27, Epoch 12/20 => Loss 0.038, Train_accy 98.60:  55%|█████▌    | 11/20 [02:12<01:39, 11.07s/it]
Task 27, Epoch 12/20 => Loss 0.038, Train_accy 98.60:  60%|██████    | 12/20 [02:12<01:28, 11.08s/it]
Task 27, Epoch 13/20 => Loss 0.028, Train_accy 99.21:  60%|██████    | 12/20 [02:23<01:28, 11.08s/it]
Task 27, Epoch 13/20 => Loss 0.028, Train_accy 99.21:  65%|██████▌   | 13/20 [02:23<01:17, 11.06s/it]
Task 27, Epoch 14/20 => Loss 0.034, Train_accy 98.88:  65%|██████▌   | 13/20 [02:34<01:17, 11.06s/it]
Task 27, Epoch 14/20 => Loss 0.034, Train_accy 98.88:  70%|███████   | 14/20 [02:34<01:06, 11.10s/it]
Task 27, Epoch 15/20 => Loss 0.029, Train_accy 99.03:  70%|███████   | 14/20 [02:46<01:06, 11.10s/it]
Task 27, Epoch 15/20 => Loss 0.029, Train_accy 99.03:  75%|███████▌  | 15/20 [02:46<00:55, 11.10s/it]
Task 27, Epoch 16/20 => Loss 0.038, Train_accy 98.85:  75%|███████▌  | 15/20 [02:57<00:55, 11.10s/it]
Task 27, Epoch 16/20 => Loss 0.038, Train_accy 98.85:  80%|████████  | 16/20 [02:57<00:44, 11.08s/it]
Task 27, Epoch 17/20 => Loss 0.030, Train_accy 98.99:  80%|████████  | 16/20 [03:08<00:44, 11.08s/it]
Task 27, Epoch 17/20 => Loss 0.030, Train_accy 98.99:  85%|████████▌ | 17/20 [03:08<00:33, 11.09s/it]
Task 27, Epoch 18/20 => Loss 0.023, Train_accy 99.28:  85%|████████▌ | 17/20 [03:19<00:33, 11.09s/it]
Task 27, Epoch 18/20 => Loss 0.023, Train_accy 99.28:  90%|█████████ | 18/20 [03:19<00:22, 11.06s/it]
Task 27, Epoch 19/20 => Loss 0.024, Train_accy 99.10:  90%|█████████ | 18/20 [03:30<00:22, 11.06s/it]
Task 27, Epoch 19/20 => Loss 0.024, Train_accy 99.10:  95%|█████████▌| 19/20 [03:30<00:11, 11.07s/it]
Task 27, Epoch 20/20 => Loss 0.026, Train_accy 99.21:  95%|█████████▌| 19/20 [03:41<00:11, 11.07s/it]
Task 27, Epoch 20/20 => Loss 0.026, Train_accy 99.21: 100%|██████████| 20/20 [03:41<00:00, 11.08s/it]
Task 27, Epoch 20/20 => Loss 0.026, Train_accy 99.21: 100%|██████████| 20/20 [03:41<00:00, 11.07s/it]
2024-08-12 13:45:49,878 [inflora.py] => Task 27, Epoch 20/20 => Loss 0.026, Train_accy 99.21
Threshold:  0.995
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 41/768 type remove
Layer 3 : 120/768 type remove
Layer 4 : 152/768 type remove
Layer 5 : 197/768 type remove
Layer 6 : 228/768 type remove
Layer 7 : 259/768 type remove
Layer 8 : 309/768 type remove
Layer 9 : 369/768 type retain
Layer 10 : 311/768 type retain
Layer 11 : 340/768 type remove
Layer 12 : 290/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:46:10,664 [trainer.py] => Time:252.92533564567566
5586 5586
5586 5586
2024-08-12 13:46:22,366 [trainer.py] => Time:11.700939416885376
2024-08-12 13:46:22,366 [inflora.py] => Exemplar size: 0
2024-08-12 13:46:22,366 [trainer.py] => CNN: {'total': 62.41, '00-09': 72.5, '10-19': 71.5, '20-29': 62.0, '30-39': 62.5, '40-49': 54.5, '50-59': 71.36, '60-69': 71.0, '70-79': 67.0, '80-89': 62.81, '90-99': 61.31, '100-109': 60.8, '110-119': 51.76, '120-129': 63.5, '130-139': 72.0, '140-149': 58.29, '150-159': 46.23, '160-169': 55.28, '170-179': 41.5, '180-189': 72.22, '190-199': 67.0, '200-209': 55.28, '210-219': 28.5, '220-229': 62.31, '230-239': 78.0, '240-249': 55.5, '250-259': 72.36, '260-269': 75.0, '270-279': 75.38, 'old': 61.93, 'new': 75.38}
2024-08-12 13:46:22,366 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55, 63.16, 62.41, 62.41]
2024-08-12 13:46:22,366 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29, 97.36, 97.31, 97.4]
2024-08-12 13:46:22,366 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155, 0.6321573163678427, 0.6242806757007611, 0.6244181883279628]
Average Accuracy (CNN): 74.4
2024-08-12 13:46:22,372 [trainer.py] => All params: 112239531
2024-08-12 13:46:22,377 [trainer.py] => Trainable params: 81418
2024-08-12 13:46:22,377 [inflora.py] => Learning on 280-290

  0%|          | 0/20 [00:00<?, ?it/s]
Task 28, Epoch 1/20 => Loss 0.482, Train_accy 83.07:   0%|          | 0/20 [00:11<?, ?it/s]
Task 28, Epoch 1/20 => Loss 0.482, Train_accy 83.07:   5%|▌         | 1/20 [00:11<03:37, 11.42s/it]
Task 28, Epoch 2/20 => Loss 0.163, Train_accy 93.55:   5%|▌         | 1/20 [00:22<03:37, 11.42s/it]
Task 28, Epoch 2/20 => Loss 0.163, Train_accy 93.55:  10%|█         | 2/20 [00:22<03:26, 11.45s/it]
Task 28, Epoch 3/20 => Loss 0.133, Train_accy 94.87:  10%|█         | 2/20 [00:34<03:26, 11.45s/it]
Task 28, Epoch 3/20 => Loss 0.133, Train_accy 94.87:  15%|█▌        | 3/20 [00:34<03:14, 11.46s/it]
Task 28, Epoch 4/20 => Loss 0.118, Train_accy 95.46:  15%|█▌        | 3/20 [00:45<03:14, 11.46s/it]
Task 28, Epoch 4/20 => Loss 0.118, Train_accy 95.46:  20%|██        | 4/20 [00:45<03:03, 11.47s/it]
Task 28, Epoch 5/20 => Loss 0.109, Train_accy 95.66:  20%|██        | 4/20 [00:57<03:03, 11.47s/it]
Task 28, Epoch 5/20 => Loss 0.109, Train_accy 95.66:  25%|██▌       | 5/20 [00:57<02:51, 11.46s/it]
Task 28, Epoch 6/20 => Loss 0.103, Train_accy 96.08:  25%|██▌       | 5/20 [01:08<02:51, 11.46s/it]
Task 28, Epoch 6/20 => Loss 0.103, Train_accy 96.08:  30%|███       | 6/20 [01:08<02:40, 11.50s/it]
Task 28, Epoch 7/20 => Loss 0.087, Train_accy 96.67:  30%|███       | 6/20 [01:20<02:40, 11.50s/it]
Task 28, Epoch 7/20 => Loss 0.087, Train_accy 96.67:  35%|███▌      | 7/20 [01:20<02:29, 11.50s/it]
Task 28, Epoch 8/20 => Loss 0.095, Train_accy 96.53:  35%|███▌      | 7/20 [01:31<02:29, 11.50s/it]
Task 28, Epoch 8/20 => Loss 0.095, Train_accy 96.53:  40%|████      | 8/20 [01:31<02:17, 11.49s/it]
Task 28, Epoch 9/20 => Loss 0.075, Train_accy 96.84:  40%|████      | 8/20 [01:43<02:17, 11.49s/it]
Task 28, Epoch 9/20 => Loss 0.075, Train_accy 96.84:  45%|████▌     | 9/20 [01:43<02:06, 11.48s/it]
Task 28, Epoch 10/20 => Loss 0.080, Train_accy 96.95:  45%|████▌     | 9/20 [01:54<02:06, 11.48s/it]
Task 28, Epoch 10/20 => Loss 0.080, Train_accy 96.95:  50%|█████     | 10/20 [01:54<01:54, 11.49s/it]
Task 28, Epoch 11/20 => Loss 0.072, Train_accy 97.19:  50%|█████     | 10/20 [02:06<01:54, 11.49s/it]
Task 28, Epoch 11/20 => Loss 0.072, Train_accy 97.19:  55%|█████▌    | 11/20 [02:06<01:43, 11.50s/it]
Task 28, Epoch 12/20 => Loss 0.078, Train_accy 97.29:  55%|█████▌    | 11/20 [02:17<01:43, 11.50s/it]
Task 28, Epoch 12/20 => Loss 0.078, Train_accy 97.29:  60%|██████    | 12/20 [02:17<01:31, 11.48s/it]
Task 28, Epoch 13/20 => Loss 0.060, Train_accy 97.71:  60%|██████    | 12/20 [02:29<01:31, 11.48s/it]
Task 28, Epoch 13/20 => Loss 0.060, Train_accy 97.71:  65%|██████▌   | 13/20 [02:29<01:20, 11.53s/it]
Task 28, Epoch 14/20 => Loss 0.065, Train_accy 97.50:  65%|██████▌   | 13/20 [02:40<01:20, 11.53s/it]
Task 28, Epoch 14/20 => Loss 0.065, Train_accy 97.50:  70%|███████   | 14/20 [02:40<01:09, 11.53s/it]
Task 28, Epoch 15/20 => Loss 0.060, Train_accy 97.88:  70%|███████   | 14/20 [02:52<01:09, 11.53s/it]
Task 28, Epoch 15/20 => Loss 0.060, Train_accy 97.88:  75%|███████▌  | 15/20 [02:52<00:57, 11.55s/it]
Task 28, Epoch 16/20 => Loss 0.061, Train_accy 97.75:  75%|███████▌  | 15/20 [03:04<00:57, 11.55s/it]
Task 28, Epoch 16/20 => Loss 0.061, Train_accy 97.75:  80%|████████  | 16/20 [03:04<00:46, 11.56s/it]
Task 28, Epoch 17/20 => Loss 0.063, Train_accy 97.57:  80%|████████  | 16/20 [03:15<00:46, 11.56s/it]
Task 28, Epoch 17/20 => Loss 0.063, Train_accy 97.57:  85%|████████▌ | 17/20 [03:15<00:34, 11.54s/it]
Task 28, Epoch 18/20 => Loss 0.064, Train_accy 97.43:  85%|████████▌ | 17/20 [03:27<00:34, 11.54s/it]
Task 28, Epoch 18/20 => Loss 0.064, Train_accy 97.43:  90%|█████████ | 18/20 [03:27<00:23, 11.53s/it]
Task 28, Epoch 19/20 => Loss 0.064, Train_accy 98.09:  90%|█████████ | 18/20 [03:38<00:23, 11.53s/it]
Task 28, Epoch 19/20 => Loss 0.064, Train_accy 98.09:  95%|█████████▌| 19/20 [03:38<00:11, 11.56s/it]
Task 28, Epoch 20/20 => Loss 0.051, Train_accy 98.16:  95%|█████████▌| 19/20 [03:50<00:11, 11.56s/it]
Task 28, Epoch 20/20 => Loss 0.051, Train_accy 98.16: 100%|██████████| 20/20 [03:50<00:00, 11.54s/it]
Task 28, Epoch 20/20 => Loss 0.051, Train_accy 98.16: 100%|██████████| 20/20 [03:50<00:00, 11.51s/it]
2024-08-12 13:50:23,723 [inflora.py] => Task 28, Epoch 20/20 => Loss 0.051, Train_accy 98.16
Threshold:  0.9966666666666667
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 13/768 type remove
Layer 2 : 50/768 type remove
Layer 3 : 149/768 type remove
Layer 4 : 193/768 type remove
Layer 5 : 243/768 type remove
Layer 6 : 277/768 type remove
Layer 7 : 312/768 type remove
Layer 8 : 368/768 type remove
Layer 9 : 297/768 type retain
Layer 10 : 231/768 type retain
Layer 11 : 343/768 type retain
Layer 12 : 339/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:50:44,944 [trainer.py] => Time:262.5676534175873
5786 5786
5786 5786
2024-08-12 13:50:56,920 [trainer.py] => Time:11.975411176681519
2024-08-12 13:50:56,920 [inflora.py] => Exemplar size: 0
2024-08-12 13:50:56,920 [trainer.py] => CNN: {'total': 62.39, '00-09': 72.0, '10-19': 73.0, '20-29': 61.5, '30-39': 63.5, '40-49': 57.0, '50-59': 73.37, '60-69': 72.0, '70-79': 68.0, '80-89': 61.81, '90-99': 60.8, '100-109': 57.79, '110-119': 51.76, '120-129': 64.5, '130-139': 72.5, '140-149': 58.29, '150-159': 47.74, '160-169': 55.78, '170-179': 43.0, '180-189': 71.21, '190-199': 67.5, '200-209': 56.28, '210-219': 27.0, '220-229': 68.34, '230-239': 74.5, '240-249': 56.5, '250-259': 72.86, '260-269': 74.5, '270-279': 75.88, '280-289': 50.5, 'old': 62.82, 'new': 50.5}
2024-08-12 13:50:56,920 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55, 63.16, 62.41, 62.41, 62.39]
2024-08-12 13:50:56,921 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29, 97.36, 97.31, 97.4, 97.42]
2024-08-12 13:50:56,921 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155, 0.6321573163678427, 0.6242806757007611, 0.6244181883279628, 0.6242654683719322]
Average Accuracy (CNN): 73.99
2024-08-12 13:50:56,926 [trainer.py] => All params: 112239531
2024-08-12 13:50:56,931 [trainer.py] => Trainable params: 81418
2024-08-12 13:50:56,931 [inflora.py] => Learning on 290-300

  0%|          | 0/20 [00:00<?, ?it/s]
Task 29, Epoch 1/20 => Loss 0.512, Train_accy 84.10:   0%|          | 0/20 [00:11<?, ?it/s]
Task 29, Epoch 1/20 => Loss 0.512, Train_accy 84.10:   5%|▌         | 1/20 [00:11<03:40, 11.60s/it]
Task 29, Epoch 2/20 => Loss 0.154, Train_accy 94.42:   5%|▌         | 1/20 [00:23<03:40, 11.60s/it]
Task 29, Epoch 2/20 => Loss 0.154, Train_accy 94.42:  10%|█         | 2/20 [00:23<03:30, 11.68s/it]
Task 29, Epoch 3/20 => Loss 0.134, Train_accy 94.89:  10%|█         | 2/20 [00:35<03:30, 11.68s/it]
Task 29, Epoch 3/20 => Loss 0.134, Train_accy 94.89:  15%|█▌        | 3/20 [00:35<03:19, 11.76s/it]
Task 29, Epoch 4/20 => Loss 0.125, Train_accy 95.30:  15%|█▌        | 3/20 [00:46<03:19, 11.76s/it]
Task 29, Epoch 4/20 => Loss 0.125, Train_accy 95.30:  20%|██        | 4/20 [00:46<03:08, 11.77s/it]
Task 29, Epoch 5/20 => Loss 0.117, Train_accy 95.84:  20%|██        | 4/20 [00:58<03:08, 11.77s/it]
Task 29, Epoch 5/20 => Loss 0.117, Train_accy 95.84:  25%|██▌       | 5/20 [00:58<02:56, 11.80s/it]
Task 29, Epoch 6/20 => Loss 0.097, Train_accy 96.79:  25%|██▌       | 5/20 [01:10<02:56, 11.80s/it]
Task 29, Epoch 6/20 => Loss 0.097, Train_accy 96.79:  30%|███       | 6/20 [01:10<02:44, 11.78s/it]
Task 29, Epoch 7/20 => Loss 0.089, Train_accy 96.79:  30%|███       | 6/20 [01:22<02:44, 11.78s/it]
Task 29, Epoch 7/20 => Loss 0.089, Train_accy 96.79:  35%|███▌      | 7/20 [01:22<02:32, 11.75s/it]
Task 29, Epoch 8/20 => Loss 0.091, Train_accy 97.19:  35%|███▌      | 7/20 [01:34<02:32, 11.75s/it]
Task 29, Epoch 8/20 => Loss 0.091, Train_accy 97.19:  40%|████      | 8/20 [01:34<02:21, 11.76s/it]
Task 29, Epoch 9/20 => Loss 0.082, Train_accy 97.12:  40%|████      | 8/20 [01:45<02:21, 11.76s/it]
Task 29, Epoch 9/20 => Loss 0.082, Train_accy 97.12:  45%|████▌     | 9/20 [01:45<02:09, 11.75s/it]
Task 29, Epoch 10/20 => Loss 0.075, Train_accy 97.19:  45%|████▌     | 9/20 [01:57<02:09, 11.75s/it]
Task 29, Epoch 10/20 => Loss 0.075, Train_accy 97.19:  50%|█████     | 10/20 [01:57<01:57, 11.75s/it]
Task 29, Epoch 11/20 => Loss 0.090, Train_accy 96.85:  50%|█████     | 10/20 [02:09<01:57, 11.75s/it]
Task 29, Epoch 11/20 => Loss 0.090, Train_accy 96.85:  55%|█████▌    | 11/20 [02:09<01:45, 11.75s/it]
Task 29, Epoch 12/20 => Loss 0.085, Train_accy 97.06:  55%|█████▌    | 11/20 [02:21<01:45, 11.75s/it]
Task 29, Epoch 12/20 => Loss 0.085, Train_accy 97.06:  60%|██████    | 12/20 [02:21<01:34, 11.80s/it]
Task 29, Epoch 13/20 => Loss 0.070, Train_accy 97.50:  60%|██████    | 12/20 [02:32<01:34, 11.80s/it]
Task 29, Epoch 13/20 => Loss 0.070, Train_accy 97.50:  65%|██████▌   | 13/20 [02:32<01:22, 11.78s/it]
Task 29, Epoch 14/20 => Loss 0.078, Train_accy 97.16:  65%|██████▌   | 13/20 [02:44<01:22, 11.78s/it]
Task 29, Epoch 14/20 => Loss 0.078, Train_accy 97.16:  70%|███████   | 14/20 [02:44<01:10, 11.77s/it]
Task 29, Epoch 15/20 => Loss 0.086, Train_accy 96.82:  70%|███████   | 14/20 [02:56<01:10, 11.77s/it]
Task 29, Epoch 15/20 => Loss 0.086, Train_accy 96.82:  75%|███████▌  | 15/20 [02:56<00:58, 11.73s/it]
Task 29, Epoch 16/20 => Loss 0.080, Train_accy 97.23:  75%|███████▌  | 15/20 [03:08<00:58, 11.73s/it]
Task 29, Epoch 16/20 => Loss 0.080, Train_accy 97.23:  80%|████████  | 16/20 [03:08<00:47, 11.77s/it]
Task 29, Epoch 17/20 => Loss 0.068, Train_accy 97.90:  80%|████████  | 16/20 [03:19<00:47, 11.77s/it]
Task 29, Epoch 17/20 => Loss 0.068, Train_accy 97.90:  85%|████████▌ | 17/20 [03:19<00:35, 11.76s/it]
Task 29, Epoch 18/20 => Loss 0.066, Train_accy 97.36:  85%|████████▌ | 17/20 [03:31<00:35, 11.76s/it]
Task 29, Epoch 18/20 => Loss 0.066, Train_accy 97.36:  90%|█████████ | 18/20 [03:31<00:23, 11.75s/it]
Task 29, Epoch 19/20 => Loss 0.067, Train_accy 98.07:  90%|█████████ | 18/20 [03:43<00:23, 11.75s/it]
Task 29, Epoch 19/20 => Loss 0.067, Train_accy 98.07:  95%|█████████▌| 19/20 [03:43<00:11, 11.74s/it]
Task 29, Epoch 20/20 => Loss 0.061, Train_accy 97.90:  95%|█████████▌| 19/20 [03:55<00:11, 11.74s/it]
Task 29, Epoch 20/20 => Loss 0.061, Train_accy 97.90: 100%|██████████| 20/20 [03:55<00:00, 11.75s/it]
Task 29, Epoch 20/20 => Loss 0.061, Train_accy 97.90: 100%|██████████| 20/20 [03:55<00:00, 11.76s/it]
2024-08-12 13:55:03,500 [inflora.py] => Task 29, Epoch 20/20 => Loss 0.061, Train_accy 97.90
Threshold:  0.9983333333333333
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 14/768 type remove
Layer 2 : 67/768 type remove
Layer 3 : 178/768 type remove
Layer 4 : 240/768 type remove
Layer 5 : 299/768 type remove
Layer 6 : 335/768 type remove
Layer 7 : 376/768 type remove
Layer 8 : 342/768 type retain
Layer 9 : 253/768 type retain
Layer 10 : 193/768 type retain
Layer 11 : 283/768 type retain
Layer 12 : 358/768 type retain
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:55:25,582 [trainer.py] => Time:268.6509485244751
5985 5985
5985 5985
2024-08-12 13:55:37,975 [trainer.py] => Time:12.392643690109253
2024-08-12 13:55:37,975 [inflora.py] => Exemplar size: 0
2024-08-12 13:55:37,975 [trainer.py] => CNN: {'total': 61.95, '00-09': 71.0, '10-19': 72.5, '20-29': 61.5, '30-39': 62.5, '40-49': 56.5, '50-59': 72.36, '60-69': 70.5, '70-79': 67.5, '80-89': 61.81, '90-99': 59.3, '100-109': 60.8, '110-119': 52.26, '120-129': 65.0, '130-139': 72.0, '140-149': 57.29, '150-159': 45.23, '160-169': 55.28, '170-179': 43.0, '180-189': 71.72, '190-199': 68.0, '200-209': 56.28, '210-219': 27.5, '220-229': 67.34, '230-239': 74.5, '240-249': 55.0, '250-259': 70.35, '260-269': 73.5, '270-279': 74.87, '280-289': 50.5, '290-299': 62.81, 'old': 61.93, 'new': 62.81}
2024-08-12 13:55:37,975 [trainer.py] => CNN top1 curve: [99.0, 91.75, 86.83, 86.62, 81.5, 81.32, 80.2, 80.74, 78.7, 76.87, 77.14, 75.82, 75.68, 74.49, 73.85, 72.44, 71.08, 69.46, 68.42, 68.55, 66.96, 65.41, 64.63, 64.31, 63.55, 63.16, 62.41, 62.41, 62.39, 61.95]
2024-08-12 13:55:37,976 [trainer.py] => CNN top1 with task curve: [99.0, 98.5, 97.67, 97.75, 97.8, 98.17, 98.21, 98.25, 98.33, 98.15, 98.13, 98.16, 98.11, 97.89, 97.76, 97.56, 97.7, 97.83, 97.78, 97.92, 97.61, 97.13, 97.19, 97.1, 97.29, 97.36, 97.31, 97.4, 97.42, 97.44]
2024-08-12 13:55:37,976 [trainer.py] => CNN top1 task curve: [1.0, 0.9275, 0.8733333333333333, 0.87, 0.819, 0.8156797331109258, 0.8041458184417442, 0.8086303939962477, 0.7886540600667408, 0.7701552328492739, 0.7723132969034608, 0.7590814196242172, 0.7583815028901734, 0.7456171735241502, 0.7391449565798264, 0.7256498590667084, 0.7122641509433962, 0.6959910913140311, 0.6857519788918206, 0.6864661654135338, 0.6708044879446169, 0.6548188653451812, 0.6466870095902354, 0.6436925647451963, 0.6361267040898155, 0.6321573163678427, 0.6242806757007611, 0.6244181883279628, 0.6242654683719322, 0.6198830409356725]
Average Accuracy (CNN): 73.59
logs/vtab/5_5_sip/InfLoRA/adam/4/0.95_1.0-0.0005/1993
2024-08-12 13:55:41,211 [trainer.py] => config: ./configs/vtab_inflora.json
2024-08-12 13:55:41,211 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-12 13:55:41,211 [trainer.py] => prefix: reproduce
2024-08-12 13:55:41,211 [trainer.py] => dataset: vtab
2024-08-12 13:55:41,211 [trainer.py] => data_path: /mnt/mydisk/ruoheng.li/lrh/Dataset
2024-08-12 13:55:41,211 [trainer.py] => memory_size: 0
2024-08-12 13:55:41,211 [trainer.py] => memory_per_class: 0
2024-08-12 13:55:41,211 [trainer.py] => fixed_memory: True
2024-08-12 13:55:41,211 [trainer.py] => shuffle: True
2024-08-12 13:55:41,211 [trainer.py] => init_cls: 5
2024-08-12 13:55:41,211 [trainer.py] => increment: 5
2024-08-12 13:55:41,211 [trainer.py] => model_name: InfLoRA
2024-08-12 13:55:41,211 [trainer.py] => net_type: sip
2024-08-12 13:55:41,211 [trainer.py] => embd_dim: 768
2024-08-12 13:55:41,211 [trainer.py] => num_heads: 12
2024-08-12 13:55:41,211 [trainer.py] => total_sessions: 10
2024-08-12 13:55:41,211 [trainer.py] => seed: 1993
2024-08-12 13:55:41,211 [trainer.py] => EPSILON: 1e-08
2024-08-12 13:55:41,211 [trainer.py] => init_epoch: 20
2024-08-12 13:55:41,211 [trainer.py] => optim: adam
2024-08-12 13:55:41,211 [trainer.py] => init_lr: 0.0005
2024-08-12 13:55:41,211 [trainer.py] => init_lr_decay: 0.1
2024-08-12 13:55:41,211 [trainer.py] => init_weight_decay: 0.0
2024-08-12 13:55:41,211 [trainer.py] => epochs: 20
2024-08-12 13:55:41,211 [trainer.py] => lrate: 0.0005
2024-08-12 13:55:41,212 [trainer.py] => lrate_decay: 0.1
2024-08-12 13:55:41,212 [trainer.py] => batch_size: 48
2024-08-12 13:55:41,212 [trainer.py] => weight_decay: 0.0
2024-08-12 13:55:41,212 [trainer.py] => rank: 4
2024-08-12 13:55:41,212 [trainer.py] => lamb: 0.95
2024-08-12 13:55:41,212 [trainer.py] => lame: 1.0
2024-08-12 13:55:41,212 [trainer.py] => num_workers: 16
{'10': 0, '11': 1, '12': 2, '13': 3, '14': 4, '15': 5, '16': 6, '17': 7, '18': 8, '19': 9, '20': 10, '21': 11, '22': 12, '23': 13, '24': 14, '25': 15, '26': 16, '27': 17, '28': 18, '29': 19, '30': 20, '31': 21, '32': 22, '33': 23, '34': 24, '35': 25, '36': 26, '37': 27, '38': 28, '39': 29, '40': 30, '41': 31, '42': 32, '43': 33, '44': 34, '45': 35, '46': 36, '47': 37, '48': 38, '49': 39, '50': 40, '51': 41, '52': 42, '53': 43, '54': 44, '55': 45, '56': 46, '57': 47, '58': 48, '59': 49}
{'10': 0, '11': 1, '12': 2, '13': 3, '14': 4, '15': 5, '16': 6, '17': 7, '18': 8, '19': 9, '20': 10, '21': 11, '22': 12, '23': 13, '24': 14, '25': 15, '26': 16, '27': 17, '28': 18, '29': 19, '30': 20, '31': 21, '32': 22, '33': 23, '34': 24, '35': 25, '36': 26, '37': 27, '38': 28, '39': 29, '40': 30, '41': 31, '42': 32, '43': 33, '44': 34, '45': 35, '46': 36, '47': 37, '48': 38, '49': 39, '50': 40, '51': 41, '52': 42, '53': 43, '54': 44, '55': 45, '56': 46, '57': 47, '58': 48, '59': 49}
2024-08-12 13:55:41,236 [data_manager.py] => [43, 41, 23, 14, 13, 40, 42, 22, 16, 45, 17, 10, 27, 46, 35, 8, 2, 34, 1, 37, 21, 0, 18, 36, 38, 24, 12, 6, 15, 20, 25, 48, 30, 19, 44, 26, 7, 28, 11, 5, 32, 4, 9, 47, 39, 31, 3, 29, 49, 33]
2024-08-12 13:55:43,485 [trainer.py] => All params: 108905911
2024-08-12 13:55:43,487 [trainer.py] => Trainable params: 108905911
2024-08-12 13:55:43,487 [inflora.py] => Learning on 0-5

  0%|          | 0/20 [00:00<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.451, Train_accy 42.86:   0%|          | 0/20 [00:01<?, ?it/s]
Task 0, Epoch 1/20 => Loss 1.451, Train_accy 42.86:   5%|▌         | 1/20 [00:01<00:20,  1.07s/it]
Task 0, Epoch 2/20 => Loss 0.821, Train_accy 73.63:   5%|▌         | 1/20 [00:01<00:20,  1.07s/it]
Task 0, Epoch 2/20 => Loss 0.821, Train_accy 73.63:  10%|█         | 2/20 [00:01<00:17,  1.03it/s]
Task 0, Epoch 3/20 => Loss 0.555, Train_accy 86.81:  10%|█         | 2/20 [00:02<00:17,  1.03it/s]
Task 0, Epoch 3/20 => Loss 0.555, Train_accy 86.81:  15%|█▌        | 3/20 [00:02<00:16,  1.06it/s]
Task 0, Epoch 4/20 => Loss 0.360, Train_accy 92.31:  15%|█▌        | 3/20 [00:03<00:16,  1.06it/s]
Task 0, Epoch 4/20 => Loss 0.360, Train_accy 92.31:  20%|██        | 4/20 [00:03<00:15,  1.05it/s]
Task 0, Epoch 5/20 => Loss 0.218, Train_accy 95.60:  20%|██        | 4/20 [00:04<00:15,  1.05it/s]
Task 0, Epoch 5/20 => Loss 0.218, Train_accy 95.60:  25%|██▌       | 5/20 [00:04<00:14,  1.07it/s]
Task 0, Epoch 6/20 => Loss 0.151, Train_accy 95.60:  25%|██▌       | 5/20 [00:05<00:14,  1.07it/s]
Task 0, Epoch 6/20 => Loss 0.151, Train_accy 95.60:  30%|███       | 6/20 [00:05<00:13,  1.07it/s]
Task 0, Epoch 7/20 => Loss 0.091, Train_accy 98.90:  30%|███       | 6/20 [00:06<00:13,  1.07it/s]
Task 0, Epoch 7/20 => Loss 0.091, Train_accy 98.90:  35%|███▌      | 7/20 [00:06<00:12,  1.08it/s]
Task 0, Epoch 8/20 => Loss 0.110, Train_accy 97.80:  35%|███▌      | 7/20 [00:07<00:12,  1.08it/s]
Task 0, Epoch 8/20 => Loss 0.110, Train_accy 97.80:  40%|████      | 8/20 [00:07<00:11,  1.07it/s]
Task 0, Epoch 9/20 => Loss 0.033, Train_accy 100.00:  40%|████      | 8/20 [00:08<00:11,  1.07it/s]
Task 0, Epoch 9/20 => Loss 0.033, Train_accy 100.00:  45%|████▌     | 9/20 [00:08<00:10,  1.08it/s]
Task 0, Epoch 10/20 => Loss 0.018, Train_accy 100.00:  45%|████▌     | 9/20 [00:09<00:10,  1.08it/s]
Task 0, Epoch 10/20 => Loss 0.018, Train_accy 100.00:  50%|█████     | 10/20 [00:09<00:09,  1.08it/s]
Task 0, Epoch 11/20 => Loss 0.013, Train_accy 100.00:  50%|█████     | 10/20 [00:10<00:09,  1.08it/s]
Task 0, Epoch 11/20 => Loss 0.013, Train_accy 100.00:  55%|█████▌    | 11/20 [00:10<00:08,  1.09it/s]
Task 0, Epoch 12/20 => Loss 0.082, Train_accy 97.80:  55%|█████▌    | 11/20 [00:11<00:08,  1.09it/s] 
Task 0, Epoch 12/20 => Loss 0.082, Train_accy 97.80:  60%|██████    | 12/20 [00:11<00:07,  1.08it/s]
Task 0, Epoch 13/20 => Loss 0.017, Train_accy 100.00:  60%|██████    | 12/20 [00:12<00:07,  1.08it/s]
Task 0, Epoch 13/20 => Loss 0.017, Train_accy 100.00:  65%|██████▌   | 13/20 [00:12<00:06,  1.08it/s]
Task 0, Epoch 14/20 => Loss 0.007, Train_accy 100.00:  65%|██████▌   | 13/20 [00:13<00:06,  1.08it/s]
Task 0, Epoch 14/20 => Loss 0.007, Train_accy 100.00:  70%|███████   | 14/20 [00:13<00:05,  1.09it/s]
Task 0, Epoch 15/20 => Loss 0.011, Train_accy 100.00:  70%|███████   | 14/20 [00:13<00:05,  1.09it/s]
Task 0, Epoch 15/20 => Loss 0.011, Train_accy 100.00:  75%|███████▌  | 15/20 [00:13<00:04,  1.08it/s]
Task 0, Epoch 16/20 => Loss 0.051, Train_accy 97.80:  75%|███████▌  | 15/20 [00:14<00:04,  1.08it/s] 
Task 0, Epoch 16/20 => Loss 0.051, Train_accy 97.80:  80%|████████  | 16/20 [00:14<00:03,  1.09it/s]
Task 0, Epoch 17/20 => Loss 0.020, Train_accy 98.90:  80%|████████  | 16/20 [00:15<00:03,  1.09it/s]
Task 0, Epoch 17/20 => Loss 0.020, Train_accy 98.90:  85%|████████▌ | 17/20 [00:15<00:02,  1.08it/s]
Task 0, Epoch 18/20 => Loss 0.023, Train_accy 98.90:  85%|████████▌ | 17/20 [00:16<00:02,  1.08it/s]
Task 0, Epoch 18/20 => Loss 0.023, Train_accy 98.90:  90%|█████████ | 18/20 [00:16<00:01,  1.08it/s]
Task 0, Epoch 19/20 => Loss 0.038, Train_accy 98.90:  90%|█████████ | 18/20 [00:17<00:01,  1.08it/s]
Task 0, Epoch 19/20 => Loss 0.038, Train_accy 98.90:  95%|█████████▌| 19/20 [00:17<00:00,  1.08it/s]
Task 0, Epoch 20/20 => Loss 0.017, Train_accy 98.90:  95%|█████████▌| 19/20 [00:18<00:00,  1.08it/s]
Task 0, Epoch 20/20 => Loss 0.017, Train_accy 98.90: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]
Task 0, Epoch 20/20 => Loss 0.017, Train_accy 98.90: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s]
2024-08-12 13:56:05,283 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.017, Train_accy 98.90
Threshold:  0.95
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 6/768 type remove
Layer 2 : 10/768 type remove
Layer 3 : 12/768 type remove
Layer 4 : 13/768 type remove
Layer 5 : 21/768 type remove
Layer 6 : 21/768 type remove
Layer 7 : 21/768 type remove
Layer 8 : 28/768 type remove
Layer 9 : 39/768 type remove
Layer 10 : 30/768 type remove
Layer 11 : 17/768 type remove
Layer 12 : 8/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:56:10,697 [trainer.py] => Time:27.209877729415894
286 286
286 286
2024-08-12 13:56:12,109 [trainer.py] => Time:1.4114015102386475
2024-08-12 13:56:12,109 [inflora.py] => Exemplar size: 0
2024-08-12 13:56:12,109 [trainer.py] => CNN: {'total': 97.9, '00-04': 97.9, 'old': 0, 'new': 97.9}
2024-08-12 13:56:12,109 [trainer.py] => CNN top1 curve: [97.9]
2024-08-12 13:56:12,109 [trainer.py] => CNN top1 with task curve: [97.9]
2024-08-12 13:56:12,109 [trainer.py] => CNN top1 task curve: [1.0]
Average Accuracy (CNN): 97.9
2024-08-12 13:56:12,112 [trainer.py] => All params: 108905911
2024-08-12 13:56:12,114 [trainer.py] => Trainable params: 77573
2024-08-12 13:56:12,114 [inflora.py] => Learning on 5-10

  0%|          | 0/20 [00:00<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.902, Train_accy 22.86:   0%|          | 0/20 [00:01<?, ?it/s]
Task 1, Epoch 1/20 => Loss 1.902, Train_accy 22.86:   5%|▌         | 1/20 [00:01<00:19,  1.05s/it]
Task 1, Epoch 2/20 => Loss 1.068, Train_accy 54.29:   5%|▌         | 1/20 [00:02<00:19,  1.05s/it]
Task 1, Epoch 2/20 => Loss 1.068, Train_accy 54.29:  10%|█         | 2/20 [00:02<00:18,  1.05s/it]
Task 1, Epoch 3/20 => Loss 0.628, Train_accy 84.29:  10%|█         | 2/20 [00:03<00:18,  1.05s/it]
Task 1, Epoch 3/20 => Loss 0.628, Train_accy 84.29:  15%|█▌        | 3/20 [00:03<00:17,  1.02s/it]
Task 1, Epoch 4/20 => Loss 0.278, Train_accy 98.57:  15%|█▌        | 3/20 [00:04<00:17,  1.02s/it]
Task 1, Epoch 4/20 => Loss 0.278, Train_accy 98.57:  20%|██        | 4/20 [00:04<00:16,  1.05s/it]
Task 1, Epoch 5/20 => Loss 0.140, Train_accy 100.00:  20%|██        | 4/20 [00:05<00:16,  1.05s/it]
Task 1, Epoch 5/20 => Loss 0.140, Train_accy 100.00:  25%|██▌       | 5/20 [00:05<00:15,  1.04s/it]
Task 1, Epoch 6/20 => Loss 0.065, Train_accy 100.00:  25%|██▌       | 5/20 [00:06<00:15,  1.04s/it]
Task 1, Epoch 6/20 => Loss 0.065, Train_accy 100.00:  30%|███       | 6/20 [00:06<00:14,  1.04s/it]
Task 1, Epoch 7/20 => Loss 0.038, Train_accy 100.00:  30%|███       | 6/20 [00:07<00:14,  1.04s/it]
Task 1, Epoch 7/20 => Loss 0.038, Train_accy 100.00:  35%|███▌      | 7/20 [00:07<00:13,  1.04s/it]
Task 1, Epoch 8/20 => Loss 0.093, Train_accy 95.71:  35%|███▌      | 7/20 [00:08<00:13,  1.04s/it] 
Task 1, Epoch 8/20 => Loss 0.093, Train_accy 95.71:  40%|████      | 8/20 [00:08<00:12,  1.04s/it]
Task 1, Epoch 9/20 => Loss 0.069, Train_accy 97.14:  40%|████      | 8/20 [00:09<00:12,  1.04s/it]
Task 1, Epoch 9/20 => Loss 0.069, Train_accy 97.14:  45%|████▌     | 9/20 [00:09<00:11,  1.04s/it]
Task 1, Epoch 10/20 => Loss 0.026, Train_accy 100.00:  45%|████▌     | 9/20 [00:10<00:11,  1.04s/it]
Task 1, Epoch 10/20 => Loss 0.026, Train_accy 100.00:  50%|█████     | 10/20 [00:10<00:10,  1.03s/it]
Task 1, Epoch 11/20 => Loss 0.057, Train_accy 97.14:  50%|█████     | 10/20 [00:11<00:10,  1.03s/it] 
Task 1, Epoch 11/20 => Loss 0.057, Train_accy 97.14:  55%|█████▌    | 11/20 [00:11<00:09,  1.03s/it]
Task 1, Epoch 12/20 => Loss 0.010, Train_accy 100.00:  55%|█████▌    | 11/20 [00:12<00:09,  1.03s/it]
Task 1, Epoch 12/20 => Loss 0.010, Train_accy 100.00:  60%|██████    | 12/20 [00:12<00:08,  1.03s/it]
Task 1, Epoch 13/20 => Loss 0.017, Train_accy 100.00:  60%|██████    | 12/20 [00:13<00:08,  1.03s/it]
Task 1, Epoch 13/20 => Loss 0.017, Train_accy 100.00:  65%|██████▌   | 13/20 [00:13<00:07,  1.03s/it]
Task 1, Epoch 14/20 => Loss 0.014, Train_accy 100.00:  65%|██████▌   | 13/20 [00:14<00:07,  1.03s/it]
Task 1, Epoch 14/20 => Loss 0.014, Train_accy 100.00:  70%|███████   | 14/20 [00:14<00:06,  1.03s/it]
Task 1, Epoch 15/20 => Loss 0.029, Train_accy 98.57:  70%|███████   | 14/20 [00:15<00:06,  1.03s/it] 
Task 1, Epoch 15/20 => Loss 0.029, Train_accy 98.57:  75%|███████▌  | 15/20 [00:15<00:05,  1.04s/it]
Task 1, Epoch 16/20 => Loss 0.016, Train_accy 100.00:  75%|███████▌  | 15/20 [00:16<00:05,  1.04s/it]
Task 1, Epoch 16/20 => Loss 0.016, Train_accy 100.00:  80%|████████  | 16/20 [00:16<00:04,  1.05s/it]
Task 1, Epoch 17/20 => Loss 0.008, Train_accy 100.00:  80%|████████  | 16/20 [00:17<00:04,  1.05s/it]
Task 1, Epoch 17/20 => Loss 0.008, Train_accy 100.00:  85%|████████▌ | 17/20 [00:17<00:03,  1.05s/it]
Task 1, Epoch 18/20 => Loss 0.035, Train_accy 98.57:  85%|████████▌ | 17/20 [00:18<00:03,  1.05s/it] 
Task 1, Epoch 18/20 => Loss 0.035, Train_accy 98.57:  90%|█████████ | 18/20 [00:18<00:02,  1.05s/it]
Task 1, Epoch 19/20 => Loss 0.009, Train_accy 100.00:  90%|█████████ | 18/20 [00:19<00:02,  1.05s/it]
Task 1, Epoch 19/20 => Loss 0.009, Train_accy 100.00:  95%|█████████▌| 19/20 [00:19<00:01,  1.04s/it]
Task 1, Epoch 20/20 => Loss 0.024, Train_accy 100.00:  95%|█████████▌| 19/20 [00:20<00:01,  1.04s/it]
Task 1, Epoch 20/20 => Loss 0.024, Train_accy 100.00: 100%|██████████| 20/20 [00:20<00:00,  1.05s/it]
Task 1, Epoch 20/20 => Loss 0.024, Train_accy 100.00: 100%|██████████| 20/20 [00:20<00:00,  1.04s/it]
2024-08-12 13:56:36,064 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.024, Train_accy 100.00
Threshold:  0.955
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 12/768 type remove
Layer 3 : 17/768 type remove
Layer 4 : 18/768 type remove
Layer 5 : 29/768 type remove
Layer 6 : 29/768 type remove
Layer 7 : 32/768 type remove
Layer 8 : 46/768 type remove
Layer 9 : 67/768 type remove
Layer 10 : 52/768 type remove
Layer 11 : 28/768 type remove
Layer 12 : 14/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:56:43,409 [trainer.py] => Time:31.294327974319458
826 826
826 826
2024-08-12 13:56:45,770 [trainer.py] => Time:2.3614726066589355
2024-08-12 13:56:45,771 [inflora.py] => Exemplar size: 0
2024-08-12 13:56:45,771 [trainer.py] => CNN: {'total': 95.76, '00-04': 96.5, '05-09': 95.37, 'old': 96.5, 'new': 95.37}
2024-08-12 13:56:45,771 [trainer.py] => CNN top1 curve: [97.9, 95.76]
2024-08-12 13:56:45,771 [trainer.py] => CNN top1 with task curve: [97.9, 99.15]
2024-08-12 13:56:45,771 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542]
Average Accuracy (CNN): 96.83
2024-08-12 13:56:45,773 [trainer.py] => All params: 108905911
2024-08-12 13:56:45,775 [trainer.py] => Trainable params: 77573
2024-08-12 13:56:45,775 [inflora.py] => Learning on 10-15

  0%|          | 0/20 [00:00<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.411, Train_accy 44.93:   0%|          | 0/20 [00:01<?, ?it/s]
Task 2, Epoch 1/20 => Loss 1.411, Train_accy 44.93:   5%|▌         | 1/20 [00:01<00:23,  1.26s/it]
Task 2, Epoch 2/20 => Loss 0.577, Train_accy 82.61:   5%|▌         | 1/20 [00:02<00:23,  1.26s/it]
Task 2, Epoch 2/20 => Loss 0.577, Train_accy 82.61:  10%|█         | 2/20 [00:02<00:23,  1.28s/it]
Task 2, Epoch 3/20 => Loss 0.283, Train_accy 92.03:  10%|█         | 2/20 [00:03<00:23,  1.28s/it]
Task 2, Epoch 3/20 => Loss 0.283, Train_accy 92.03:  15%|█▌        | 3/20 [00:03<00:21,  1.27s/it]
Task 2, Epoch 4/20 => Loss 0.134, Train_accy 95.65:  15%|█▌        | 3/20 [00:05<00:21,  1.27s/it]
Task 2, Epoch 4/20 => Loss 0.134, Train_accy 95.65:  20%|██        | 4/20 [00:05<00:20,  1.26s/it]
Task 2, Epoch 5/20 => Loss 0.086, Train_accy 96.38:  20%|██        | 4/20 [00:06<00:20,  1.26s/it]
Task 2, Epoch 5/20 => Loss 0.086, Train_accy 96.38:  25%|██▌       | 5/20 [00:06<00:18,  1.27s/it]
Task 2, Epoch 6/20 => Loss 0.074, Train_accy 97.10:  25%|██▌       | 5/20 [00:07<00:18,  1.27s/it]
Task 2, Epoch 6/20 => Loss 0.074, Train_accy 97.10:  30%|███       | 6/20 [00:07<00:17,  1.26s/it]
Task 2, Epoch 7/20 => Loss 0.017, Train_accy 100.00:  30%|███       | 6/20 [00:08<00:17,  1.26s/it]
Task 2, Epoch 7/20 => Loss 0.017, Train_accy 100.00:  35%|███▌      | 7/20 [00:08<00:16,  1.27s/it]
Task 2, Epoch 8/20 => Loss 0.027, Train_accy 99.28:  35%|███▌      | 7/20 [00:10<00:16,  1.27s/it] 
Task 2, Epoch 8/20 => Loss 0.027, Train_accy 99.28:  40%|████      | 8/20 [00:10<00:15,  1.28s/it]
Task 2, Epoch 9/20 => Loss 0.054, Train_accy 98.55:  40%|████      | 8/20 [00:11<00:15,  1.28s/it]
Task 2, Epoch 9/20 => Loss 0.054, Train_accy 98.55:  45%|████▌     | 9/20 [00:11<00:14,  1.28s/it]
Task 2, Epoch 10/20 => Loss 0.030, Train_accy 99.28:  45%|████▌     | 9/20 [00:12<00:14,  1.28s/it]
Task 2, Epoch 10/20 => Loss 0.030, Train_accy 99.28:  50%|█████     | 10/20 [00:12<00:12,  1.29s/it]
Task 2, Epoch 11/20 => Loss 0.005, Train_accy 100.00:  50%|█████     | 10/20 [00:14<00:12,  1.29s/it]
Task 2, Epoch 11/20 => Loss 0.005, Train_accy 100.00:  55%|█████▌    | 11/20 [00:14<00:11,  1.29s/it]
Task 2, Epoch 12/20 => Loss 0.004, Train_accy 100.00:  55%|█████▌    | 11/20 [00:15<00:11,  1.29s/it]
Task 2, Epoch 12/20 => Loss 0.004, Train_accy 100.00:  60%|██████    | 12/20 [00:15<00:10,  1.28s/it]
Task 2, Epoch 13/20 => Loss 0.032, Train_accy 99.28:  60%|██████    | 12/20 [00:16<00:10,  1.28s/it] 
Task 2, Epoch 13/20 => Loss 0.032, Train_accy 99.28:  65%|██████▌   | 13/20 [00:16<00:08,  1.28s/it]
Task 2, Epoch 14/20 => Loss 0.061, Train_accy 98.55:  65%|██████▌   | 13/20 [00:17<00:08,  1.28s/it]
Task 2, Epoch 14/20 => Loss 0.061, Train_accy 98.55:  70%|███████   | 14/20 [00:17<00:07,  1.28s/it]
Task 2, Epoch 15/20 => Loss 0.030, Train_accy 99.28:  70%|███████   | 14/20 [00:19<00:07,  1.28s/it]
Task 2, Epoch 15/20 => Loss 0.030, Train_accy 99.28:  75%|███████▌  | 15/20 [00:19<00:06,  1.28s/it]
Task 2, Epoch 16/20 => Loss 0.013, Train_accy 100.00:  75%|███████▌  | 15/20 [00:20<00:06,  1.28s/it]
Task 2, Epoch 16/20 => Loss 0.013, Train_accy 100.00:  80%|████████  | 16/20 [00:20<00:05,  1.28s/it]
Task 2, Epoch 17/20 => Loss 0.014, Train_accy 100.00:  80%|████████  | 16/20 [00:21<00:05,  1.28s/it]
Task 2, Epoch 17/20 => Loss 0.014, Train_accy 100.00:  85%|████████▌ | 17/20 [00:21<00:03,  1.29s/it]
Task 2, Epoch 18/20 => Loss 0.022, Train_accy 99.28:  85%|████████▌ | 17/20 [00:23<00:03,  1.29s/it] 
Task 2, Epoch 18/20 => Loss 0.022, Train_accy 99.28:  90%|█████████ | 18/20 [00:23<00:02,  1.29s/it]
Task 2, Epoch 19/20 => Loss 0.010, Train_accy 99.28:  90%|█████████ | 18/20 [00:24<00:02,  1.29s/it]
Task 2, Epoch 19/20 => Loss 0.010, Train_accy 99.28:  95%|█████████▌| 19/20 [00:24<00:01,  1.29s/it]
Task 2, Epoch 20/20 => Loss 0.006, Train_accy 100.00:  95%|█████████▌| 19/20 [00:25<00:01,  1.29s/it]
Task 2, Epoch 20/20 => Loss 0.006, Train_accy 100.00: 100%|██████████| 20/20 [00:25<00:00,  1.30s/it]
Task 2, Epoch 20/20 => Loss 0.006, Train_accy 100.00: 100%|██████████| 20/20 [00:25<00:00,  1.28s/it]
2024-08-12 13:57:15,016 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.006, Train_accy 100.00
Threshold:  0.96
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 13/768 type remove
Layer 3 : 18/768 type remove
Layer 4 : 22/768 type remove
Layer 5 : 33/768 type remove
Layer 6 : 34/768 type remove
Layer 7 : 41/768 type remove
Layer 8 : 57/768 type remove
Layer 9 : 77/768 type remove
Layer 10 : 59/768 type remove
Layer 11 : 33/768 type remove
Layer 12 : 30/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:57:23,141 [trainer.py] => Time:37.36566114425659
1438 1438
1438 1438
2024-08-12 13:57:26,536 [trainer.py] => Time:3.394388437271118
2024-08-12 13:57:26,536 [inflora.py] => Exemplar size: 0
2024-08-12 13:57:26,536 [trainer.py] => CNN: {'total': 95.48, '00-04': 93.71, '05-09': 93.15, '10-14': 98.37, 'old': 93.34, 'new': 98.37}
2024-08-12 13:57:26,536 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48]
2024-08-12 13:57:26,536 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37]
2024-08-12 13:57:26,536 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607]
Average Accuracy (CNN): 96.38
2024-08-12 13:57:26,539 [trainer.py] => All params: 108905911
2024-08-12 13:57:26,541 [trainer.py] => Trainable params: 77573
2024-08-12 13:57:26,541 [inflora.py] => Learning on 15-20

  0%|          | 0/20 [00:00<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.688, Train_accy 39.49:   0%|          | 0/20 [00:01<?, ?it/s]
Task 3, Epoch 1/20 => Loss 1.688, Train_accy 39.49:   5%|▌         | 1/20 [00:01<00:32,  1.71s/it]
Task 3, Epoch 2/20 => Loss 0.560, Train_accy 81.88:   5%|▌         | 1/20 [00:03<00:32,  1.71s/it]
Task 3, Epoch 2/20 => Loss 0.560, Train_accy 81.88:  10%|█         | 2/20 [00:03<00:30,  1.71s/it]
Task 3, Epoch 3/20 => Loss 0.336, Train_accy 87.32:  10%|█         | 2/20 [00:05<00:30,  1.71s/it]
Task 3, Epoch 3/20 => Loss 0.336, Train_accy 87.32:  15%|█▌        | 3/20 [00:05<00:29,  1.71s/it]
Task 3, Epoch 4/20 => Loss 0.223, Train_accy 92.75:  15%|█▌        | 3/20 [00:06<00:29,  1.71s/it]
Task 3, Epoch 4/20 => Loss 0.223, Train_accy 92.75:  20%|██        | 4/20 [00:06<00:27,  1.71s/it]
Task 3, Epoch 5/20 => Loss 0.194, Train_accy 94.20:  20%|██        | 4/20 [00:08<00:27,  1.71s/it]
Task 3, Epoch 5/20 => Loss 0.194, Train_accy 94.20:  25%|██▌       | 5/20 [00:08<00:25,  1.71s/it]
Task 3, Epoch 6/20 => Loss 0.171, Train_accy 94.20:  25%|██▌       | 5/20 [00:10<00:25,  1.71s/it]
Task 3, Epoch 6/20 => Loss 0.171, Train_accy 94.20:  30%|███       | 6/20 [00:10<00:24,  1.72s/it]
Task 3, Epoch 7/20 => Loss 0.129, Train_accy 94.57:  30%|███       | 6/20 [00:11<00:24,  1.72s/it]
Task 3, Epoch 7/20 => Loss 0.129, Train_accy 94.57:  35%|███▌      | 7/20 [00:11<00:22,  1.71s/it]
Task 3, Epoch 8/20 => Loss 0.114, Train_accy 96.74:  35%|███▌      | 7/20 [00:13<00:22,  1.71s/it]
Task 3, Epoch 8/20 => Loss 0.114, Train_accy 96.74:  40%|████      | 8/20 [00:13<00:20,  1.72s/it]
Task 3, Epoch 9/20 => Loss 0.121, Train_accy 96.38:  40%|████      | 8/20 [00:15<00:20,  1.72s/it]
Task 3, Epoch 9/20 => Loss 0.121, Train_accy 96.38:  45%|████▌     | 9/20 [00:15<00:18,  1.71s/it]
Task 3, Epoch 10/20 => Loss 0.121, Train_accy 96.01:  45%|████▌     | 9/20 [00:17<00:18,  1.71s/it]
Task 3, Epoch 10/20 => Loss 0.121, Train_accy 96.01:  50%|█████     | 10/20 [00:17<00:17,  1.71s/it]
Task 3, Epoch 11/20 => Loss 0.110, Train_accy 96.01:  50%|█████     | 10/20 [00:18<00:17,  1.71s/it]
Task 3, Epoch 11/20 => Loss 0.110, Train_accy 96.01:  55%|█████▌    | 11/20 [00:18<00:15,  1.71s/it]
Task 3, Epoch 12/20 => Loss 0.071, Train_accy 98.55:  55%|█████▌    | 11/20 [00:20<00:15,  1.71s/it]
Task 3, Epoch 12/20 => Loss 0.071, Train_accy 98.55:  60%|██████    | 12/20 [00:20<00:13,  1.72s/it]
Task 3, Epoch 13/20 => Loss 0.056, Train_accy 98.19:  60%|██████    | 12/20 [00:22<00:13,  1.72s/it]
Task 3, Epoch 13/20 => Loss 0.056, Train_accy 98.19:  65%|██████▌   | 13/20 [00:22<00:12,  1.73s/it]
Task 3, Epoch 14/20 => Loss 0.093, Train_accy 97.10:  65%|██████▌   | 13/20 [00:24<00:12,  1.73s/it]
Task 3, Epoch 14/20 => Loss 0.093, Train_accy 97.10:  70%|███████   | 14/20 [00:24<00:10,  1.72s/it]
Task 3, Epoch 15/20 => Loss 0.070, Train_accy 98.91:  70%|███████   | 14/20 [00:25<00:10,  1.72s/it]
Task 3, Epoch 15/20 => Loss 0.070, Train_accy 98.91:  75%|███████▌  | 15/20 [00:25<00:08,  1.73s/it]
Task 3, Epoch 16/20 => Loss 0.066, Train_accy 98.55:  75%|███████▌  | 15/20 [00:27<00:08,  1.73s/it]
Task 3, Epoch 16/20 => Loss 0.066, Train_accy 98.55:  80%|████████  | 16/20 [00:27<00:06,  1.74s/it]
Task 3, Epoch 17/20 => Loss 0.084, Train_accy 97.46:  80%|████████  | 16/20 [00:29<00:06,  1.74s/it]
Task 3, Epoch 17/20 => Loss 0.084, Train_accy 97.46:  85%|████████▌ | 17/20 [00:29<00:05,  1.73s/it]
Task 3, Epoch 18/20 => Loss 0.078, Train_accy 97.83:  85%|████████▌ | 17/20 [00:30<00:05,  1.73s/it]
Task 3, Epoch 18/20 => Loss 0.078, Train_accy 97.83:  90%|█████████ | 18/20 [00:30<00:03,  1.73s/it]
Task 3, Epoch 19/20 => Loss 0.074, Train_accy 97.10:  90%|█████████ | 18/20 [00:32<00:03,  1.73s/it]
Task 3, Epoch 19/20 => Loss 0.074, Train_accy 97.10:  95%|█████████▌| 19/20 [00:32<00:01,  1.73s/it]
Task 3, Epoch 20/20 => Loss 0.104, Train_accy 97.10:  95%|█████████▌| 19/20 [00:34<00:01,  1.73s/it]
Task 3, Epoch 20/20 => Loss 0.104, Train_accy 97.10: 100%|██████████| 20/20 [00:34<00:00,  1.72s/it]
Task 3, Epoch 20/20 => Loss 0.104, Train_accy 97.10: 100%|██████████| 20/20 [00:34<00:00,  1.72s/it]
2024-08-12 13:58:04,694 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.104, Train_accy 97.10
Threshold:  0.965
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 20/768 type remove
Layer 4 : 27/768 type remove
Layer 5 : 38/768 type remove
Layer 6 : 43/768 type remove
Layer 7 : 49/768 type remove
Layer 8 : 74/768 type remove
Layer 9 : 86/768 type remove
Layer 10 : 65/768 type remove
Layer 11 : 37/768 type remove
Layer 12 : 46/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:58:12,719 [trainer.py] => Time:46.17851185798645
2847 2847
2847 2847
2024-08-12 13:58:18,497 [trainer.py] => Time:5.777122974395752
2024-08-12 13:58:18,497 [inflora.py] => Exemplar size: 0
2024-08-12 13:58:18,497 [trainer.py] => CNN: {'total': 88.58, '00-04': 93.01, '05-09': 92.96, '10-14': 98.04, '15-19': 81.9, 'old': 95.13, 'new': 81.9}
2024-08-12 13:58:18,497 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58]
2024-08-12 13:58:18,497 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24]
2024-08-12 13:58:18,497 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141]
Average Accuracy (CNN): 94.43
2024-08-12 13:58:18,500 [trainer.py] => All params: 108905911
2024-08-12 13:58:18,502 [trainer.py] => Trainable params: 77573
2024-08-12 13:58:18,502 [inflora.py] => Learning on 20-25

  0%|          | 0/20 [00:00<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.469, Train_accy 42.00:   0%|          | 0/20 [00:01<?, ?it/s]
Task 4, Epoch 1/20 => Loss 1.469, Train_accy 42.00:   5%|▌         | 1/20 [00:01<00:31,  1.64s/it]
Task 4, Epoch 2/20 => Loss 0.522, Train_accy 78.80:   5%|▌         | 1/20 [00:03<00:31,  1.64s/it]
Task 4, Epoch 2/20 => Loss 0.522, Train_accy 78.80:  10%|█         | 2/20 [00:03<00:29,  1.65s/it]
Task 4, Epoch 3/20 => Loss 0.266, Train_accy 89.60:  10%|█         | 2/20 [00:04<00:29,  1.65s/it]
Task 4, Epoch 3/20 => Loss 0.266, Train_accy 89.60:  15%|█▌        | 3/20 [00:04<00:28,  1.65s/it]
Task 4, Epoch 4/20 => Loss 0.161, Train_accy 94.00:  15%|█▌        | 3/20 [00:06<00:28,  1.65s/it]
Task 4, Epoch 4/20 => Loss 0.161, Train_accy 94.00:  20%|██        | 4/20 [00:06<00:26,  1.66s/it]
Task 4, Epoch 5/20 => Loss 0.099, Train_accy 97.20:  20%|██        | 4/20 [00:08<00:26,  1.66s/it]
Task 4, Epoch 5/20 => Loss 0.099, Train_accy 97.20:  25%|██▌       | 5/20 [00:08<00:24,  1.66s/it]
Task 4, Epoch 6/20 => Loss 0.155, Train_accy 97.20:  25%|██▌       | 5/20 [00:09<00:24,  1.66s/it]
Task 4, Epoch 6/20 => Loss 0.155, Train_accy 97.20:  30%|███       | 6/20 [00:09<00:23,  1.65s/it]
Task 4, Epoch 7/20 => Loss 0.089, Train_accy 97.60:  30%|███       | 6/20 [00:11<00:23,  1.65s/it]
Task 4, Epoch 7/20 => Loss 0.089, Train_accy 97.60:  35%|███▌      | 7/20 [00:11<00:21,  1.65s/it]
Task 4, Epoch 8/20 => Loss 0.058, Train_accy 97.60:  35%|███▌      | 7/20 [00:13<00:21,  1.65s/it]
Task 4, Epoch 8/20 => Loss 0.058, Train_accy 97.60:  40%|████      | 8/20 [00:13<00:19,  1.66s/it]
Task 4, Epoch 9/20 => Loss 0.118, Train_accy 95.20:  40%|████      | 8/20 [00:14<00:19,  1.66s/it]
Task 4, Epoch 9/20 => Loss 0.118, Train_accy 95.20:  45%|████▌     | 9/20 [00:14<00:18,  1.67s/it]
Task 4, Epoch 10/20 => Loss 0.088, Train_accy 97.20:  45%|████▌     | 9/20 [00:16<00:18,  1.67s/it]
Task 4, Epoch 10/20 => Loss 0.088, Train_accy 97.20:  50%|█████     | 10/20 [00:16<00:16,  1.66s/it]
Task 4, Epoch 11/20 => Loss 0.047, Train_accy 98.00:  50%|█████     | 10/20 [00:18<00:16,  1.66s/it]
Task 4, Epoch 11/20 => Loss 0.047, Train_accy 98.00:  55%|█████▌    | 11/20 [00:18<00:14,  1.67s/it]
Task 4, Epoch 12/20 => Loss 0.082, Train_accy 96.80:  55%|█████▌    | 11/20 [00:19<00:14,  1.67s/it]
Task 4, Epoch 12/20 => Loss 0.082, Train_accy 96.80:  60%|██████    | 12/20 [00:19<00:13,  1.67s/it]
Task 4, Epoch 13/20 => Loss 0.065, Train_accy 97.60:  60%|██████    | 12/20 [00:21<00:13,  1.67s/it]
Task 4, Epoch 13/20 => Loss 0.065, Train_accy 97.60:  65%|██████▌   | 13/20 [00:21<00:11,  1.68s/it]
Task 4, Epoch 14/20 => Loss 0.028, Train_accy 99.20:  65%|██████▌   | 13/20 [00:23<00:11,  1.68s/it]
Task 4, Epoch 14/20 => Loss 0.028, Train_accy 99.20:  70%|███████   | 14/20 [00:23<00:10,  1.68s/it]
Task 4, Epoch 15/20 => Loss 0.029, Train_accy 98.80:  70%|███████   | 14/20 [00:24<00:10,  1.68s/it]
Task 4, Epoch 15/20 => Loss 0.029, Train_accy 98.80:  75%|███████▌  | 15/20 [00:24<00:08,  1.67s/it]
Task 4, Epoch 16/20 => Loss 0.042, Train_accy 99.20:  75%|███████▌  | 15/20 [00:26<00:08,  1.67s/it]
Task 4, Epoch 16/20 => Loss 0.042, Train_accy 99.20:  80%|████████  | 16/20 [00:26<00:06,  1.66s/it]
Task 4, Epoch 17/20 => Loss 0.071, Train_accy 97.20:  80%|████████  | 16/20 [00:28<00:06,  1.66s/it]
Task 4, Epoch 17/20 => Loss 0.071, Train_accy 97.20:  85%|████████▌ | 17/20 [00:28<00:04,  1.66s/it]
Task 4, Epoch 18/20 => Loss 0.065, Train_accy 97.60:  85%|████████▌ | 17/20 [00:29<00:04,  1.66s/it]
Task 4, Epoch 18/20 => Loss 0.065, Train_accy 97.60:  90%|█████████ | 18/20 [00:29<00:03,  1.65s/it]
Task 4, Epoch 19/20 => Loss 0.041, Train_accy 98.40:  90%|█████████ | 18/20 [00:31<00:03,  1.65s/it]
Task 4, Epoch 19/20 => Loss 0.041, Train_accy 98.40:  95%|█████████▌| 19/20 [00:31<00:01,  1.65s/it]
Task 4, Epoch 20/20 => Loss 0.050, Train_accy 97.60:  95%|█████████▌| 19/20 [00:33<00:01,  1.65s/it]
Task 4, Epoch 20/20 => Loss 0.050, Train_accy 97.60: 100%|██████████| 20/20 [00:33<00:00,  1.66s/it]
Task 4, Epoch 20/20 => Loss 0.050, Train_accy 97.60: 100%|██████████| 20/20 [00:33<00:00,  1.66s/it]
2024-08-12 13:58:55,580 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.050, Train_accy 97.60
Threshold:  0.97
Skip Updating DualGPM for layer: 1
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 14/768 type remove
Layer 3 : 22/768 type remove
Layer 4 : 30/768 type remove
Layer 5 : 41/768 type remove
Layer 6 : 48/768 type remove
Layer 7 : 60/768 type remove
Layer 8 : 90/768 type remove
Layer 9 : 101/768 type remove
Layer 10 : 75/768 type remove
Layer 11 : 42/768 type remove
Layer 12 : 83/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:59:03,753 [trainer.py] => Time:45.25158381462097
4102 4102
4102 4102
2024-08-12 13:59:11,659 [trainer.py] => Time:7.9055821895599365
2024-08-12 13:59:11,659 [inflora.py] => Exemplar size: 0
2024-08-12 13:59:11,659 [trainer.py] => CNN: {'total': 85.06, '00-04': 93.36, '05-09': 88.52, '10-14': 94.61, '15-19': 80.2, '20-24': 82.47, 'old': 86.2, 'new': 82.47}
2024-08-12 13:59:11,659 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06]
2024-08-12 13:59:11,660 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24]
2024-08-12 13:59:11,660 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807]
Average Accuracy (CNN): 92.56
2024-08-12 13:59:11,662 [trainer.py] => All params: 108905911
2024-08-12 13:59:11,664 [trainer.py] => Trainable params: 77573
2024-08-12 13:59:11,664 [inflora.py] => Learning on 25-30

  0%|          | 0/20 [00:00<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.406, Train_accy 42.61:   0%|          | 0/20 [00:01<?, ?it/s]
Task 5, Epoch 1/20 => Loss 1.406, Train_accy 42.61:   5%|▌         | 1/20 [00:01<00:24,  1.30s/it]
Task 5, Epoch 2/20 => Loss 0.646, Train_accy 71.30:   5%|▌         | 1/20 [00:02<00:24,  1.30s/it]
Task 5, Epoch 2/20 => Loss 0.646, Train_accy 71.30:  10%|█         | 2/20 [00:02<00:23,  1.29s/it]
Task 5, Epoch 3/20 => Loss 0.314, Train_accy 91.30:  10%|█         | 2/20 [00:03<00:23,  1.29s/it]
Task 5, Epoch 3/20 => Loss 0.314, Train_accy 91.30:  15%|█▌        | 3/20 [00:03<00:22,  1.30s/it]
Task 5, Epoch 4/20 => Loss 0.126, Train_accy 99.13:  15%|█▌        | 3/20 [00:05<00:22,  1.30s/it]
Task 5, Epoch 4/20 => Loss 0.126, Train_accy 99.13:  20%|██        | 4/20 [00:05<00:20,  1.30s/it]
Task 5, Epoch 5/20 => Loss 0.088, Train_accy 99.13:  20%|██        | 4/20 [00:06<00:20,  1.30s/it]
Task 5, Epoch 5/20 => Loss 0.088, Train_accy 99.13:  25%|██▌       | 5/20 [00:06<00:19,  1.31s/it]
Task 5, Epoch 6/20 => Loss 0.065, Train_accy 99.13:  25%|██▌       | 5/20 [00:07<00:19,  1.31s/it]
Task 5, Epoch 6/20 => Loss 0.065, Train_accy 99.13:  30%|███       | 6/20 [00:07<00:18,  1.30s/it]
Task 5, Epoch 7/20 => Loss 0.103, Train_accy 99.13:  30%|███       | 6/20 [00:09<00:18,  1.30s/it]
Task 5, Epoch 7/20 => Loss 0.103, Train_accy 99.13:  35%|███▌      | 7/20 [00:09<00:16,  1.30s/it]
Task 5, Epoch 8/20 => Loss 0.045, Train_accy 98.26:  35%|███▌      | 7/20 [00:10<00:16,  1.30s/it]
Task 5, Epoch 8/20 => Loss 0.045, Train_accy 98.26:  40%|████      | 8/20 [00:10<00:15,  1.30s/it]
Task 5, Epoch 9/20 => Loss 0.080, Train_accy 98.26:  40%|████      | 8/20 [00:11<00:15,  1.30s/it]
Task 5, Epoch 9/20 => Loss 0.080, Train_accy 98.26:  45%|████▌     | 9/20 [00:11<00:14,  1.30s/it]
Task 5, Epoch 10/20 => Loss 0.020, Train_accy 99.13:  45%|████▌     | 9/20 [00:13<00:14,  1.30s/it]
Task 5, Epoch 10/20 => Loss 0.020, Train_accy 99.13:  50%|█████     | 10/20 [00:13<00:13,  1.30s/it]
Task 5, Epoch 11/20 => Loss 0.017, Train_accy 100.00:  50%|█████     | 10/20 [00:14<00:13,  1.30s/it]
Task 5, Epoch 11/20 => Loss 0.017, Train_accy 100.00:  55%|█████▌    | 11/20 [00:14<00:11,  1.30s/it]
Task 5, Epoch 12/20 => Loss 0.021, Train_accy 100.00:  55%|█████▌    | 11/20 [00:15<00:11,  1.30s/it]
Task 5, Epoch 12/20 => Loss 0.021, Train_accy 100.00:  60%|██████    | 12/20 [00:15<00:10,  1.30s/it]
Task 5, Epoch 13/20 => Loss 0.019, Train_accy 99.13:  60%|██████    | 12/20 [00:16<00:10,  1.30s/it] 
Task 5, Epoch 13/20 => Loss 0.019, Train_accy 99.13:  65%|██████▌   | 13/20 [00:16<00:09,  1.30s/it]
Task 5, Epoch 14/20 => Loss 0.021, Train_accy 100.00:  65%|██████▌   | 13/20 [00:18<00:09,  1.30s/it]
Task 5, Epoch 14/20 => Loss 0.021, Train_accy 100.00:  70%|███████   | 14/20 [00:18<00:07,  1.30s/it]
Task 5, Epoch 15/20 => Loss 0.033, Train_accy 99.13:  70%|███████   | 14/20 [00:19<00:07,  1.30s/it] 
Task 5, Epoch 15/20 => Loss 0.033, Train_accy 99.13:  75%|███████▌  | 15/20 [00:19<00:06,  1.31s/it]
Task 5, Epoch 16/20 => Loss 0.061, Train_accy 98.26:  75%|███████▌  | 15/20 [00:20<00:06,  1.31s/it]
Task 5, Epoch 16/20 => Loss 0.061, Train_accy 98.26:  80%|████████  | 16/20 [00:20<00:05,  1.30s/it]
Task 5, Epoch 17/20 => Loss 0.036, Train_accy 98.26:  80%|████████  | 16/20 [00:22<00:05,  1.30s/it]
Task 5, Epoch 17/20 => Loss 0.036, Train_accy 98.26:  85%|████████▌ | 17/20 [00:22<00:03,  1.30s/it]
Task 5, Epoch 18/20 => Loss 0.024, Train_accy 100.00:  85%|████████▌ | 17/20 [00:23<00:03,  1.30s/it]
Task 5, Epoch 18/20 => Loss 0.024, Train_accy 100.00:  90%|█████████ | 18/20 [00:23<00:02,  1.30s/it]
Task 5, Epoch 19/20 => Loss 0.021, Train_accy 99.13:  90%|█████████ | 18/20 [00:24<00:02,  1.30s/it] 
Task 5, Epoch 19/20 => Loss 0.021, Train_accy 99.13:  95%|█████████▌| 19/20 [00:24<00:01,  1.30s/it]
Task 5, Epoch 20/20 => Loss 0.034, Train_accy 99.13:  95%|█████████▌| 19/20 [00:26<00:01,  1.30s/it]
Task 5, Epoch 20/20 => Loss 0.034, Train_accy 99.13: 100%|██████████| 20/20 [00:26<00:00,  1.31s/it]
Task 5, Epoch 20/20 => Loss 0.034, Train_accy 99.13: 100%|██████████| 20/20 [00:26<00:00,  1.30s/it]
2024-08-12 13:59:41,319 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.034, Train_accy 99.13
Threshold:  0.975
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 7/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 29/768 type remove
Layer 4 : 38/768 type remove
Layer 5 : 55/768 type remove
Layer 6 : 63/768 type remove
Layer 7 : 75/768 type remove
Layer 8 : 108/768 type remove
Layer 9 : 126/768 type remove
Layer 10 : 102/768 type remove
Layer 11 : 61/768 type remove
Layer 12 : 96/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 13:59:49,518 [trainer.py] => Time:37.853453397750854
4480 4480
4480 4480
2024-08-12 13:59:58,095 [trainer.py] => Time:8.577071189880371
2024-08-12 13:59:58,095 [inflora.py] => Exemplar size: 0
2024-08-12 13:59:58,095 [trainer.py] => CNN: {'total': 82.19, '00-04': 91.96, '05-09': 87.96, '10-14': 95.1, '15-19': 79.7, '20-24': 81.35, '25-29': 57.67, 'old': 84.45, 'new': 57.67}
2024-08-12 13:59:58,095 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06, 82.19]
2024-08-12 13:59:58,095 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24, 98.46]
2024-08-12 13:59:58,095 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807, 0.8247767857142857]
Average Accuracy (CNN): 90.83
2024-08-12 13:59:58,098 [trainer.py] => All params: 108905911
2024-08-12 13:59:58,100 [trainer.py] => Trainable params: 77573
2024-08-12 13:59:58,100 [inflora.py] => Learning on 30-35

  0%|          | 0/20 [00:00<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.133, Train_accy 58.05:   0%|          | 0/20 [00:01<?, ?it/s]
Task 6, Epoch 1/20 => Loss 1.133, Train_accy 58.05:   5%|▌         | 1/20 [00:01<00:27,  1.47s/it]
Task 6, Epoch 2/20 => Loss 0.405, Train_accy 87.93:   5%|▌         | 1/20 [00:02<00:27,  1.47s/it]
Task 6, Epoch 2/20 => Loss 0.405, Train_accy 87.93:  10%|█         | 2/20 [00:02<00:26,  1.46s/it]
Task 6, Epoch 3/20 => Loss 0.144, Train_accy 95.98:  10%|█         | 2/20 [00:04<00:26,  1.46s/it]
Task 6, Epoch 3/20 => Loss 0.144, Train_accy 95.98:  15%|█▌        | 3/20 [00:04<00:25,  1.47s/it]
Task 6, Epoch 4/20 => Loss 0.070, Train_accy 98.85:  15%|█▌        | 3/20 [00:05<00:25,  1.47s/it]
Task 6, Epoch 4/20 => Loss 0.070, Train_accy 98.85:  20%|██        | 4/20 [00:05<00:23,  1.48s/it]
Task 6, Epoch 5/20 => Loss 0.052, Train_accy 98.85:  20%|██        | 4/20 [00:07<00:23,  1.48s/it]
Task 6, Epoch 5/20 => Loss 0.052, Train_accy 98.85:  25%|██▌       | 5/20 [00:07<00:22,  1.48s/it]
Task 6, Epoch 6/20 => Loss 0.021, Train_accy 100.00:  25%|██▌       | 5/20 [00:08<00:22,  1.48s/it]
Task 6, Epoch 6/20 => Loss 0.021, Train_accy 100.00:  30%|███       | 6/20 [00:08<00:20,  1.48s/it]
Task 6, Epoch 7/20 => Loss 0.017, Train_accy 99.43:  30%|███       | 6/20 [00:10<00:20,  1.48s/it] 
Task 6, Epoch 7/20 => Loss 0.017, Train_accy 99.43:  35%|███▌      | 7/20 [00:10<00:19,  1.48s/it]
Task 6, Epoch 8/20 => Loss 0.017, Train_accy 99.43:  35%|███▌      | 7/20 [00:11<00:19,  1.48s/it]
Task 6, Epoch 8/20 => Loss 0.017, Train_accy 99.43:  40%|████      | 8/20 [00:11<00:17,  1.47s/it]
Task 6, Epoch 9/20 => Loss 0.009, Train_accy 100.00:  40%|████      | 8/20 [00:13<00:17,  1.47s/it]
Task 6, Epoch 9/20 => Loss 0.009, Train_accy 100.00:  45%|████▌     | 9/20 [00:13<00:16,  1.49s/it]
Task 6, Epoch 10/20 => Loss 0.022, Train_accy 99.43:  45%|████▌     | 9/20 [00:14<00:16,  1.49s/it]
Task 6, Epoch 10/20 => Loss 0.022, Train_accy 99.43:  50%|█████     | 10/20 [00:14<00:15,  1.55s/it]
Task 6, Epoch 11/20 => Loss 0.007, Train_accy 100.00:  50%|█████     | 10/20 [00:16<00:15,  1.55s/it]
Task 6, Epoch 11/20 => Loss 0.007, Train_accy 100.00:  55%|█████▌    | 11/20 [00:16<00:13,  1.54s/it]
Task 6, Epoch 12/20 => Loss 0.005, Train_accy 100.00:  55%|█████▌    | 11/20 [00:17<00:13,  1.54s/it]
Task 6, Epoch 12/20 => Loss 0.005, Train_accy 100.00:  60%|██████    | 12/20 [00:17<00:12,  1.52s/it]
Task 6, Epoch 13/20 => Loss 0.012, Train_accy 99.43:  60%|██████    | 12/20 [00:19<00:12,  1.52s/it] 
Task 6, Epoch 13/20 => Loss 0.012, Train_accy 99.43:  65%|██████▌   | 13/20 [00:19<00:10,  1.51s/it]
Task 6, Epoch 14/20 => Loss 0.028, Train_accy 99.43:  65%|██████▌   | 13/20 [00:20<00:10,  1.51s/it]
Task 6, Epoch 14/20 => Loss 0.028, Train_accy 99.43:  70%|███████   | 14/20 [00:20<00:08,  1.49s/it]
Task 6, Epoch 15/20 => Loss 0.007, Train_accy 100.00:  70%|███████   | 14/20 [00:22<00:08,  1.49s/it]
Task 6, Epoch 15/20 => Loss 0.007, Train_accy 100.00:  75%|███████▌  | 15/20 [00:22<00:07,  1.50s/it]
Task 6, Epoch 16/20 => Loss 0.028, Train_accy 98.85:  75%|███████▌  | 15/20 [00:23<00:07,  1.50s/it] 
Task 6, Epoch 16/20 => Loss 0.028, Train_accy 98.85:  80%|████████  | 16/20 [00:23<00:05,  1.49s/it]
Task 6, Epoch 17/20 => Loss 0.022, Train_accy 99.43:  80%|████████  | 16/20 [00:25<00:05,  1.49s/it]
Task 6, Epoch 17/20 => Loss 0.022, Train_accy 99.43:  85%|████████▌ | 17/20 [00:25<00:04,  1.50s/it]
Task 6, Epoch 18/20 => Loss 0.005, Train_accy 100.00:  85%|████████▌ | 17/20 [00:26<00:04,  1.50s/it]
Task 6, Epoch 18/20 => Loss 0.005, Train_accy 100.00:  90%|█████████ | 18/20 [00:26<00:02,  1.49s/it]
Task 6, Epoch 19/20 => Loss 0.016, Train_accy 99.43:  90%|█████████ | 18/20 [00:28<00:02,  1.49s/it] 
Task 6, Epoch 19/20 => Loss 0.016, Train_accy 99.43:  95%|█████████▌| 19/20 [00:28<00:01,  1.50s/it]
Task 6, Epoch 20/20 => Loss 0.010, Train_accy 100.00:  95%|█████████▌| 19/20 [00:29<00:01,  1.50s/it]
Task 6, Epoch 20/20 => Loss 0.010, Train_accy 100.00: 100%|██████████| 20/20 [00:29<00:00,  1.50s/it]
Task 6, Epoch 20/20 => Loss 0.010, Train_accy 100.00: 100%|██████████| 20/20 [00:29<00:00,  1.50s/it]
2024-08-12 14:00:32,039 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.010, Train_accy 100.00
Threshold:  0.98
Skip Updating DualGPM for layer: 2
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 16/768 type remove
Layer 3 : 30/768 type remove
Layer 4 : 43/768 type remove
Layer 5 : 64/768 type remove
Layer 6 : 76/768 type remove
Layer 7 : 91/768 type remove
Layer 8 : 136/768 type remove
Layer 9 : 156/768 type remove
Layer 10 : 122/768 type remove
Layer 11 : 75/768 type remove
Layer 12 : 135/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 14:00:40,621 [trainer.py] => Time:42.52150774002075
5291 5291
5291 5291
2024-08-12 14:00:50,551 [trainer.py] => Time:9.928867101669312
2024-08-12 14:00:50,551 [inflora.py] => Exemplar size: 0
2024-08-12 14:00:50,551 [trainer.py] => CNN: {'total': 80.42, '00-04': 90.56, '05-09': 88.15, '10-14': 91.01, '15-19': 76.3, '20-24': 73.07, '25-29': 54.5, '30-34': 94.33, 'old': 77.9, 'new': 94.33}
2024-08-12 14:00:50,551 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06, 82.19, 80.42]
2024-08-12 14:00:50,551 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24, 98.46, 98.47]
2024-08-12 14:00:50,551 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807, 0.8247767857142857, 0.8058968058968059]
Average Accuracy (CNN): 89.34
2024-08-12 14:00:50,555 [trainer.py] => All params: 108905911
2024-08-12 14:00:50,557 [trainer.py] => Trainable params: 77573
2024-08-12 14:00:50,557 [inflora.py] => Learning on 35-40

  0%|          | 0/20 [00:00<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.639, Train_accy 33.33:   0%|          | 0/20 [00:01<?, ?it/s]
Task 7, Epoch 1/20 => Loss 1.639, Train_accy 33.33:   5%|▌         | 1/20 [00:01<00:25,  1.35s/it]
Task 7, Epoch 2/20 => Loss 0.858, Train_accy 65.12:   5%|▌         | 1/20 [00:02<00:25,  1.35s/it]
Task 7, Epoch 2/20 => Loss 0.858, Train_accy 65.12:  10%|█         | 2/20 [00:02<00:24,  1.35s/it]
Task 7, Epoch 3/20 => Loss 0.362, Train_accy 88.37:  10%|█         | 2/20 [00:04<00:24,  1.35s/it]
Task 7, Epoch 3/20 => Loss 0.362, Train_accy 88.37:  15%|█▌        | 3/20 [00:04<00:22,  1.35s/it]
Task 7, Epoch 4/20 => Loss 0.281, Train_accy 91.47:  15%|█▌        | 3/20 [00:05<00:22,  1.35s/it]
Task 7, Epoch 4/20 => Loss 0.281, Train_accy 91.47:  20%|██        | 4/20 [00:05<00:21,  1.36s/it]
Task 7, Epoch 5/20 => Loss 0.109, Train_accy 98.45:  20%|██        | 4/20 [00:06<00:21,  1.36s/it]
Task 7, Epoch 5/20 => Loss 0.109, Train_accy 98.45:  25%|██▌       | 5/20 [00:06<00:20,  1.38s/it]
Task 7, Epoch 6/20 => Loss 0.100, Train_accy 96.90:  25%|██▌       | 5/20 [00:08<00:20,  1.38s/it]
Task 7, Epoch 6/20 => Loss 0.100, Train_accy 96.90:  30%|███       | 6/20 [00:08<00:19,  1.38s/it]
Task 7, Epoch 7/20 => Loss 0.075, Train_accy 98.45:  30%|███       | 6/20 [00:09<00:19,  1.38s/it]
Task 7, Epoch 7/20 => Loss 0.075, Train_accy 98.45:  35%|███▌      | 7/20 [00:09<00:17,  1.37s/it]
Task 7, Epoch 8/20 => Loss 0.066, Train_accy 97.67:  35%|███▌      | 7/20 [00:10<00:17,  1.37s/it]
Task 7, Epoch 8/20 => Loss 0.066, Train_accy 97.67:  40%|████      | 8/20 [00:10<00:16,  1.38s/it]
Task 7, Epoch 9/20 => Loss 0.062, Train_accy 97.67:  40%|████      | 8/20 [00:12<00:16,  1.38s/it]
Task 7, Epoch 9/20 => Loss 0.062, Train_accy 97.67:  45%|████▌     | 9/20 [00:12<00:15,  1.40s/it]
Task 7, Epoch 10/20 => Loss 0.027, Train_accy 99.22:  45%|████▌     | 9/20 [00:13<00:15,  1.40s/it]
Task 7, Epoch 10/20 => Loss 0.027, Train_accy 99.22:  50%|█████     | 10/20 [00:13<00:13,  1.39s/it]
Task 7, Epoch 11/20 => Loss 0.069, Train_accy 99.22:  50%|█████     | 10/20 [00:15<00:13,  1.39s/it]
Task 7, Epoch 11/20 => Loss 0.069, Train_accy 99.22:  55%|█████▌    | 11/20 [00:15<00:12,  1.40s/it]
Task 7, Epoch 12/20 => Loss 0.061, Train_accy 98.45:  55%|█████▌    | 11/20 [00:16<00:12,  1.40s/it]
Task 7, Epoch 12/20 => Loss 0.061, Train_accy 98.45:  60%|██████    | 12/20 [00:16<00:11,  1.39s/it]
Task 7, Epoch 13/20 => Loss 0.053, Train_accy 98.45:  60%|██████    | 12/20 [00:17<00:11,  1.39s/it]
Task 7, Epoch 13/20 => Loss 0.053, Train_accy 98.45:  65%|██████▌   | 13/20 [00:17<00:09,  1.39s/it]
Task 7, Epoch 14/20 => Loss 0.055, Train_accy 98.45:  65%|██████▌   | 13/20 [00:19<00:09,  1.39s/it]
Task 7, Epoch 14/20 => Loss 0.055, Train_accy 98.45:  70%|███████   | 14/20 [00:19<00:08,  1.39s/it]
Task 7, Epoch 15/20 => Loss 0.039, Train_accy 98.45:  70%|███████   | 14/20 [00:20<00:08,  1.39s/it]
Task 7, Epoch 15/20 => Loss 0.039, Train_accy 98.45:  75%|███████▌  | 15/20 [00:20<00:06,  1.39s/it]
Task 7, Epoch 16/20 => Loss 0.061, Train_accy 98.45:  75%|███████▌  | 15/20 [00:22<00:06,  1.39s/it]
Task 7, Epoch 16/20 => Loss 0.061, Train_accy 98.45:  80%|████████  | 16/20 [00:22<00:05,  1.40s/it]
Task 7, Epoch 17/20 => Loss 0.103, Train_accy 98.45:  80%|████████  | 16/20 [00:23<00:05,  1.40s/it]
Task 7, Epoch 17/20 => Loss 0.103, Train_accy 98.45:  85%|████████▌ | 17/20 [00:23<00:04,  1.42s/it]
Task 7, Epoch 18/20 => Loss 0.047, Train_accy 98.45:  85%|████████▌ | 17/20 [00:25<00:04,  1.42s/it]
Task 7, Epoch 18/20 => Loss 0.047, Train_accy 98.45:  90%|█████████ | 18/20 [00:25<00:02,  1.42s/it]
Task 7, Epoch 19/20 => Loss 0.028, Train_accy 99.22:  90%|█████████ | 18/20 [00:26<00:02,  1.42s/it]
Task 7, Epoch 19/20 => Loss 0.028, Train_accy 99.22:  95%|█████████▌| 19/20 [00:26<00:01,  1.41s/it]
Task 7, Epoch 20/20 => Loss 0.019, Train_accy 100.00:  95%|█████████▌| 19/20 [00:27<00:01,  1.41s/it]
Task 7, Epoch 20/20 => Loss 0.019, Train_accy 100.00: 100%|██████████| 20/20 [00:27<00:00,  1.40s/it]
Task 7, Epoch 20/20 => Loss 0.019, Train_accy 100.00: 100%|██████████| 20/20 [00:27<00:00,  1.39s/it]
2024-08-12 14:01:22,075 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.019, Train_accy 100.00
Threshold:  0.985
Skip Updating DualGPM for layer: 1
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 8/768 type remove
Layer 2 : 20/768 type remove
Layer 3 : 43/768 type remove
Layer 4 : 61/768 type remove
Layer 5 : 91/768 type remove
Layer 6 : 106/768 type remove
Layer 7 : 124/768 type remove
Layer 8 : 184/768 type remove
Layer 9 : 238/768 type remove
Layer 10 : 198/768 type remove
Layer 11 : 108/768 type remove
Layer 12 : 152/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 14:01:30,171 [trainer.py] => Time:39.61446952819824
5730 5730
5730 5730
2024-08-12 14:01:40,961 [trainer.py] => Time:10.790045738220215
2024-08-12 14:01:40,962 [inflora.py] => Exemplar size: 0
2024-08-12 14:01:40,962 [trainer.py] => CNN: {'total': 77.38, '00-04': 89.16, '05-09': 84.07, '10-14': 90.69, '15-19': 70.26, '20-24': 72.19, '25-29': 55.03, '30-34': 94.33, '35-39': 68.56, 'old': 78.11, 'new': 68.56}
2024-08-12 14:01:40,962 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06, 82.19, 80.42, 77.38]
2024-08-12 14:01:40,962 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24, 98.46, 98.47, 98.57]
2024-08-12 14:01:40,962 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807, 0.8247767857142857, 0.8058968058968059, 0.77521815008726]
Average Accuracy (CNN): 87.85
2024-08-12 14:01:40,964 [trainer.py] => All params: 108905911
2024-08-12 14:01:40,966 [trainer.py] => Trainable params: 77573
2024-08-12 14:01:40,966 [inflora.py] => Learning on 40-45

  0%|          | 0/20 [00:00<?, ?it/s]
Task 8, Epoch 1/20 => Loss 1.444, Train_accy 41.58:   0%|          | 0/20 [00:01<?, ?it/s]
Task 8, Epoch 1/20 => Loss 1.444, Train_accy 41.58:   5%|▌         | 1/20 [00:01<00:35,  1.89s/it]
Task 8, Epoch 2/20 => Loss 0.535, Train_accy 80.41:   5%|▌         | 1/20 [00:03<00:35,  1.89s/it]
Task 8, Epoch 2/20 => Loss 0.535, Train_accy 80.41:  10%|█         | 2/20 [00:03<00:34,  1.90s/it]
Task 8, Epoch 3/20 => Loss 0.289, Train_accy 91.75:  10%|█         | 2/20 [00:05<00:34,  1.90s/it]
Task 8, Epoch 3/20 => Loss 0.289, Train_accy 91.75:  15%|█▌        | 3/20 [00:05<00:32,  1.90s/it]
Task 8, Epoch 4/20 => Loss 0.150, Train_accy 95.88:  15%|█▌        | 3/20 [00:07<00:32,  1.90s/it]
Task 8, Epoch 4/20 => Loss 0.150, Train_accy 95.88:  20%|██        | 4/20 [00:07<00:30,  1.92s/it]
Task 8, Epoch 5/20 => Loss 0.107, Train_accy 97.59:  20%|██        | 4/20 [00:09<00:30,  1.92s/it]
Task 8, Epoch 5/20 => Loss 0.107, Train_accy 97.59:  25%|██▌       | 5/20 [00:09<00:28,  1.93s/it]
Task 8, Epoch 6/20 => Loss 0.173, Train_accy 96.22:  25%|██▌       | 5/20 [00:11<00:28,  1.93s/it]
Task 8, Epoch 6/20 => Loss 0.173, Train_accy 96.22:  30%|███       | 6/20 [00:11<00:26,  1.92s/it]
Task 8, Epoch 7/20 => Loss 0.058, Train_accy 97.94:  30%|███       | 6/20 [00:13<00:26,  1.92s/it]
Task 8, Epoch 7/20 => Loss 0.058, Train_accy 97.94:  35%|███▌      | 7/20 [00:13<00:25,  1.93s/it]
Task 8, Epoch 8/20 => Loss 0.173, Train_accy 97.94:  35%|███▌      | 7/20 [00:15<00:25,  1.93s/it]
Task 8, Epoch 8/20 => Loss 0.173, Train_accy 97.94:  40%|████      | 8/20 [00:15<00:23,  1.94s/it]
Task 8, Epoch 9/20 => Loss 0.159, Train_accy 98.28:  40%|████      | 8/20 [00:17<00:23,  1.94s/it]
Task 8, Epoch 9/20 => Loss 0.159, Train_accy 98.28:  45%|████▌     | 9/20 [00:17<00:21,  1.92s/it]
Task 8, Epoch 10/20 => Loss 0.097, Train_accy 96.56:  45%|████▌     | 9/20 [00:19<00:21,  1.92s/it]
Task 8, Epoch 10/20 => Loss 0.097, Train_accy 96.56:  50%|█████     | 10/20 [00:19<00:19,  1.92s/it]
Task 8, Epoch 11/20 => Loss 0.084, Train_accy 97.59:  50%|█████     | 10/20 [00:21<00:19,  1.92s/it]
Task 8, Epoch 11/20 => Loss 0.084, Train_accy 97.59:  55%|█████▌    | 11/20 [00:21<00:17,  1.92s/it]
Task 8, Epoch 12/20 => Loss 0.067, Train_accy 97.25:  55%|█████▌    | 11/20 [00:23<00:17,  1.92s/it]
Task 8, Epoch 12/20 => Loss 0.067, Train_accy 97.25:  60%|██████    | 12/20 [00:23<00:15,  1.92s/it]
Task 8, Epoch 13/20 => Loss 0.053, Train_accy 99.31:  60%|██████    | 12/20 [00:24<00:15,  1.92s/it]
Task 8, Epoch 13/20 => Loss 0.053, Train_accy 99.31:  65%|██████▌   | 13/20 [00:24<00:13,  1.91s/it]
Task 8, Epoch 14/20 => Loss 0.057, Train_accy 98.63:  65%|██████▌   | 13/20 [00:26<00:13,  1.91s/it]
Task 8, Epoch 14/20 => Loss 0.057, Train_accy 98.63:  70%|███████   | 14/20 [00:26<00:11,  1.92s/it]
Task 8, Epoch 15/20 => Loss 0.045, Train_accy 98.28:  70%|███████   | 14/20 [00:28<00:11,  1.92s/it]
Task 8, Epoch 15/20 => Loss 0.045, Train_accy 98.28:  75%|███████▌  | 15/20 [00:28<00:09,  1.91s/it]
Task 8, Epoch 16/20 => Loss 0.032, Train_accy 99.31:  75%|███████▌  | 15/20 [00:30<00:09,  1.91s/it]
Task 8, Epoch 16/20 => Loss 0.032, Train_accy 99.31:  80%|████████  | 16/20 [00:30<00:07,  1.93s/it]
Task 8, Epoch 17/20 => Loss 0.024, Train_accy 99.31:  80%|████████  | 16/20 [00:32<00:07,  1.93s/it]
Task 8, Epoch 17/20 => Loss 0.024, Train_accy 99.31:  85%|████████▌ | 17/20 [00:32<00:05,  1.92s/it]
Task 8, Epoch 18/20 => Loss 0.047, Train_accy 99.31:  85%|████████▌ | 17/20 [00:34<00:05,  1.92s/it]
Task 8, Epoch 18/20 => Loss 0.047, Train_accy 99.31:  90%|█████████ | 18/20 [00:34<00:03,  1.92s/it]
Task 8, Epoch 19/20 => Loss 0.047, Train_accy 97.94:  90%|█████████ | 18/20 [00:36<00:03,  1.92s/it]
Task 8, Epoch 19/20 => Loss 0.047, Train_accy 97.94:  95%|█████████▌| 19/20 [00:36<00:01,  1.92s/it]
Task 8, Epoch 20/20 => Loss 0.049, Train_accy 98.28:  95%|█████████▌| 19/20 [00:38<00:01,  1.92s/it]
Task 8, Epoch 20/20 => Loss 0.049, Train_accy 98.28: 100%|██████████| 20/20 [00:38<00:00,  1.92s/it]
Task 8, Epoch 20/20 => Loss 0.049, Train_accy 98.28: 100%|██████████| 20/20 [00:38<00:00,  1.92s/it]
2024-08-12 14:02:23,615 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.049, Train_accy 98.28
Threshold:  0.99
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 9/768 type remove
Layer 2 : 21/768 type remove
Layer 3 : 44/768 type remove
Layer 4 : 65/768 type remove
Layer 5 : 95/768 type remove
Layer 6 : 111/768 type remove
Layer 7 : 133/768 type remove
Layer 8 : 190/768 type remove
Layer 9 : 241/768 type remove
Layer 10 : 202/768 type remove
Layer 11 : 112/768 type remove
Layer 12 : 168/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 14:02:31,928 [trainer.py] => Time:50.96164131164551
7251 7251
7251 7251
2024-08-12 14:02:45,212 [trainer.py] => Time:13.284005165100098
2024-08-12 14:02:45,213 [inflora.py] => Exemplar size: 0
2024-08-12 14:02:45,213 [trainer.py] => CNN: {'total': 75.16, '00-04': 88.81, '05-09': 83.89, '10-14': 88.56, '15-19': 69.84, '20-24': 73.39, '25-29': 54.5, '30-34': 92.48, '35-39': 69.93, '40-44': 67.92, 'old': 77.09, 'new': 67.92}
2024-08-12 14:02:45,213 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06, 82.19, 80.42, 77.38, 75.16]
2024-08-12 14:02:45,213 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24, 98.46, 98.47, 98.57, 98.39]
2024-08-12 14:02:45,213 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807, 0.8247767857142857, 0.8058968058968059, 0.77521815008726, 0.7531374982760999]
Average Accuracy (CNN): 86.44
2024-08-12 14:02:45,215 [trainer.py] => All params: 108905911
2024-08-12 14:02:45,216 [trainer.py] => Trainable params: 77573
2024-08-12 14:02:45,217 [inflora.py] => Learning on 45-50

  0%|          | 0/20 [00:00<?, ?it/s]
Task 9, Epoch 1/20 => Loss 1.265, Train_accy 54.96:   0%|          | 0/20 [00:01<?, ?it/s]
Task 9, Epoch 1/20 => Loss 1.265, Train_accy 54.96:   5%|▌         | 1/20 [00:01<00:34,  1.80s/it]
Task 9, Epoch 2/20 => Loss 0.279, Train_accy 91.22:   5%|▌         | 1/20 [00:03<00:34,  1.80s/it]
Task 9, Epoch 2/20 => Loss 0.279, Train_accy 91.22:  10%|█         | 2/20 [00:03<00:32,  1.81s/it]
Task 9, Epoch 3/20 => Loss 0.129, Train_accy 96.18:  10%|█         | 2/20 [00:05<00:32,  1.81s/it]
Task 9, Epoch 3/20 => Loss 0.129, Train_accy 96.18:  15%|█▌        | 3/20 [00:05<00:30,  1.82s/it]
Task 9, Epoch 4/20 => Loss 0.065, Train_accy 98.85:  15%|█▌        | 3/20 [00:07<00:30,  1.82s/it]
Task 9, Epoch 4/20 => Loss 0.065, Train_accy 98.85:  20%|██        | 4/20 [00:07<00:29,  1.81s/it]
Task 9, Epoch 5/20 => Loss 0.060, Train_accy 98.09:  20%|██        | 4/20 [00:09<00:29,  1.81s/it]
Task 9, Epoch 5/20 => Loss 0.060, Train_accy 98.09:  25%|██▌       | 5/20 [00:09<00:27,  1.82s/it]
Task 9, Epoch 6/20 => Loss 0.040, Train_accy 98.85:  25%|██▌       | 5/20 [00:10<00:27,  1.82s/it]
Task 9, Epoch 6/20 => Loss 0.040, Train_accy 98.85:  30%|███       | 6/20 [00:10<00:25,  1.82s/it]
Task 9, Epoch 7/20 => Loss 0.034, Train_accy 99.24:  30%|███       | 6/20 [00:12<00:25,  1.82s/it]
Task 9, Epoch 7/20 => Loss 0.034, Train_accy 99.24:  35%|███▌      | 7/20 [00:12<00:23,  1.83s/it]
Task 9, Epoch 8/20 => Loss 0.042, Train_accy 98.47:  35%|███▌      | 7/20 [00:14<00:23,  1.83s/it]
Task 9, Epoch 8/20 => Loss 0.042, Train_accy 98.47:  40%|████      | 8/20 [00:14<00:21,  1.83s/it]
Task 9, Epoch 9/20 => Loss 0.025, Train_accy 99.62:  40%|████      | 8/20 [00:16<00:21,  1.83s/it]
Task 9, Epoch 9/20 => Loss 0.025, Train_accy 99.62:  45%|████▌     | 9/20 [00:16<00:20,  1.82s/it]
Task 9, Epoch 10/20 => Loss 0.026, Train_accy 99.62:  45%|████▌     | 9/20 [00:18<00:20,  1.82s/it]
Task 9, Epoch 10/20 => Loss 0.026, Train_accy 99.62:  50%|█████     | 10/20 [00:18<00:18,  1.83s/it]
Task 9, Epoch 11/20 => Loss 0.020, Train_accy 99.24:  50%|█████     | 10/20 [00:20<00:18,  1.83s/it]
Task 9, Epoch 11/20 => Loss 0.020, Train_accy 99.24:  55%|█████▌    | 11/20 [00:20<00:16,  1.82s/it]
Task 9, Epoch 12/20 => Loss 0.061, Train_accy 99.24:  55%|█████▌    | 11/20 [00:21<00:16,  1.82s/it]
Task 9, Epoch 12/20 => Loss 0.061, Train_accy 99.24:  60%|██████    | 12/20 [00:21<00:14,  1.82s/it]
Task 9, Epoch 13/20 => Loss 0.044, Train_accy 98.47:  60%|██████    | 12/20 [00:23<00:14,  1.82s/it]
Task 9, Epoch 13/20 => Loss 0.044, Train_accy 98.47:  65%|██████▌   | 13/20 [00:23<00:12,  1.81s/it]
Task 9, Epoch 14/20 => Loss 0.057, Train_accy 97.71:  65%|██████▌   | 13/20 [00:25<00:12,  1.81s/it]
Task 9, Epoch 14/20 => Loss 0.057, Train_accy 97.71:  70%|███████   | 14/20 [00:25<00:10,  1.81s/it]
Task 9, Epoch 15/20 => Loss 0.034, Train_accy 99.24:  70%|███████   | 14/20 [00:27<00:10,  1.81s/it]
Task 9, Epoch 15/20 => Loss 0.034, Train_accy 99.24:  75%|███████▌  | 15/20 [00:27<00:09,  1.81s/it]
Task 9, Epoch 16/20 => Loss 0.021, Train_accy 99.62:  75%|███████▌  | 15/20 [00:29<00:09,  1.81s/it]
Task 9, Epoch 16/20 => Loss 0.021, Train_accy 99.62:  80%|████████  | 16/20 [00:29<00:07,  1.80s/it]
Task 9, Epoch 17/20 => Loss 0.024, Train_accy 99.24:  80%|████████  | 16/20 [00:30<00:07,  1.80s/it]
Task 9, Epoch 17/20 => Loss 0.024, Train_accy 99.24:  85%|████████▌ | 17/20 [00:30<00:05,  1.82s/it]
Task 9, Epoch 18/20 => Loss 0.033, Train_accy 98.85:  85%|████████▌ | 17/20 [00:32<00:05,  1.82s/it]
Task 9, Epoch 18/20 => Loss 0.033, Train_accy 98.85:  90%|█████████ | 18/20 [00:32<00:03,  1.81s/it]
Task 9, Epoch 19/20 => Loss 0.067, Train_accy 98.47:  90%|█████████ | 18/20 [00:34<00:03,  1.81s/it]
Task 9, Epoch 19/20 => Loss 0.067, Train_accy 98.47:  95%|█████████▌| 19/20 [00:34<00:01,  1.81s/it]
Task 9, Epoch 20/20 => Loss 0.040, Train_accy 98.47:  95%|█████████▌| 19/20 [00:36<00:01,  1.81s/it]
Task 9, Epoch 20/20 => Loss 0.040, Train_accy 98.47: 100%|██████████| 20/20 [00:36<00:00,  1.82s/it]
Task 9, Epoch 20/20 => Loss 0.040, Train_accy 98.47: 100%|██████████| 20/20 [00:36<00:00,  1.82s/it]
2024-08-12 14:03:25,579 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.040, Train_accy 98.47
Threshold:  0.995
----------------------------------------
Gradient Constraints Summary
----------------------------------------
Layer 1 : 10/768 type remove
Layer 2 : 22/768 type remove
Layer 3 : 52/768 type remove
Layer 4 : 81/768 type remove
Layer 5 : 113/768 type remove
Layer 6 : 133/768 type remove
Layer 7 : 171/768 type remove
Layer 8 : 227/768 type remove
Layer 9 : 257/768 type remove
Layer 10 : 217/768 type remove
Layer 11 : 129/768 type remove
Layer 12 : 215/768 type remove
----------------------------------------
Layer 1 - Projection Matrix shape: torch.Size([768, 768])
Layer 2 - Projection Matrix shape: torch.Size([768, 768])
Layer 3 - Projection Matrix shape: torch.Size([768, 768])
Layer 4 - Projection Matrix shape: torch.Size([768, 768])
Layer 5 - Projection Matrix shape: torch.Size([768, 768])
Layer 6 - Projection Matrix shape: torch.Size([768, 768])
Layer 7 - Projection Matrix shape: torch.Size([768, 768])
Layer 8 - Projection Matrix shape: torch.Size([768, 768])
Layer 9 - Projection Matrix shape: torch.Size([768, 768])
Layer 10 - Projection Matrix shape: torch.Size([768, 768])
Layer 11 - Projection Matrix shape: torch.Size([768, 768])
Layer 12 - Projection Matrix shape: torch.Size([768, 768])
2024-08-12 14:03:34,223 [trainer.py] => Time:49.006144285202026
8619 8619
8619 8619
2024-08-12 14:03:49,835 [trainer.py] => Time:15.612333297729492
2024-08-12 14:03:49,836 [inflora.py] => Exemplar size: 0
2024-08-12 14:03:49,836 [trainer.py] => CNN: {'total': 71.06, '00-04': 88.46, '05-09': 83.15, '10-14': 83.99, '15-19': 57.35, '20-24': 70.76, '25-29': 53.97, '30-34': 91.62, '35-39': 54.44, '40-44': 69.56, '45-49': 70.83, 'old': 71.11, 'new': 70.83}
2024-08-12 14:03:49,836 [trainer.py] => CNN top1 curve: [97.9, 95.76, 95.48, 88.58, 85.06, 82.19, 80.42, 77.38, 75.16, 71.06]
2024-08-12 14:03:49,836 [trainer.py] => CNN top1 with task curve: [97.9, 99.15, 99.37, 98.24, 98.24, 98.46, 98.47, 98.57, 98.39, 98.45]
2024-08-12 14:03:49,836 [trainer.py] => CNN top1 task curve: [1.0, 0.9661016949152542, 0.9582753824756607, 0.8935721812434141, 0.8537298878595807, 0.8247767857142857, 0.8058968058968059, 0.77521815008726, 0.7531374982760999, 0.7111033762617474]
Average Accuracy (CNN): 84.9
