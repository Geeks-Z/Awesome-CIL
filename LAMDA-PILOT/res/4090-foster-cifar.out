nohup: ignoring input
2024-08-19 22:58:41,253 [trainer.py] => config: ./exps/foster_cifar_B0_Inc5.json
2024-08-19 22:58:41,253 [trainer.py] => prefix: cil
2024-08-19 22:58:41,253 [trainer.py] => dataset: cifar224
2024-08-19 22:58:41,253 [trainer.py] => memory_size: 2000
2024-08-19 22:58:41,253 [trainer.py] => memory_per_class: 20
2024-08-19 22:58:41,253 [trainer.py] => fixed_memory: False
2024-08-19 22:58:41,253 [trainer.py] => shuffle: True
2024-08-19 22:58:41,253 [trainer.py] => init_cls: 20
2024-08-19 22:58:41,253 [trainer.py] => increment: 20
2024-08-19 22:58:41,253 [trainer.py] => model_name: foster
2024-08-19 22:58:41,253 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-08-19 22:58:41,253 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-19 22:58:41,253 [trainer.py] => seed: 1993
2024-08-19 22:58:41,253 [trainer.py] => beta1: 0.96
2024-08-19 22:58:41,253 [trainer.py] => beta2: 0.97
2024-08-19 22:58:41,253 [trainer.py] => oofc: ft
2024-08-19 22:58:41,253 [trainer.py] => is_teacher_wa: False
2024-08-19 22:58:41,253 [trainer.py] => is_student_wa: False
2024-08-19 22:58:41,253 [trainer.py] => lambda_okd: 1
2024-08-19 22:58:41,253 [trainer.py] => wa_value: 1
2024-08-19 22:58:41,253 [trainer.py] => init_epochs: 1
2024-08-19 22:58:41,253 [trainer.py] => init_lr: 0.001
2024-08-19 22:58:41,253 [trainer.py] => init_weight_decay: 0.0005
2024-08-19 22:58:41,253 [trainer.py] => boosting_epochs: 1
2024-08-19 22:58:41,253 [trainer.py] => compression_epochs: 1
2024-08-19 22:58:41,253 [trainer.py] => lr: 0.001
2024-08-19 22:58:41,253 [trainer.py] => batch_size: 48
2024-08-19 22:58:41,253 [trainer.py] => weight_decay: 0.0005
2024-08-19 22:58:41,253 [trainer.py] => num_workers: 8
2024-08-19 22:58:41,253 [trainer.py] => T: 2
2024-08-19 22:58:42,189 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-19 22:58:42,810 [trainer.py] => All params: 0
2024-08-19 22:58:42,810 [trainer.py] => Trainable params: 0
2024-08-19 22:58:44,219 [foster.py] => Learning on 0-20
2024-08-19 22:58:44,219 [foster.py] => All params: 85829416
2024-08-19 22:58:44,220 [foster.py] => Trainable params: 85829416
  0%|          | 0/1 [00:00<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.967, Train_accy 9.64, Test_accy 17.80:   0%|          | 0/1 [00:37<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.967, Train_accy 9.64, Test_accy 17.80: 100%|██████████| 1/1 [00:37<00:00, 37.03s/it]Task 0, Epoch 1/1 => Loss 2.967, Train_accy 9.64, Test_accy 17.80: 100%|██████████| 1/1 [00:37<00:00, 37.03s/it]
2024-08-19 22:59:21,569 [foster.py] => Task 0, Epoch 1/1 => Loss 2.967, Train_accy 9.64, Test_accy 17.80
2024-08-19 22:59:21,570 [base.py] => Reducing exemplars...(100 per classes)
2024-08-19 22:59:21,570 [base.py] => Constructing exemplars...(100 per classes)
2024-08-19 22:59:55,471 [foster.py] => Exemplar size: 2000
2024-08-19 22:59:55,471 [trainer.py] => CNN: {'total': 17.8, '00-19': 17.8, 'old': 0, 'new': 17.8}
2024-08-19 22:59:55,472 [trainer.py] => NME: {'total': 23.85, '00-19': 23.85, 'old': 0, 'new': 23.85}
2024-08-19 22:59:55,472 [trainer.py] => CNN top1 curve: [17.8]
2024-08-19 22:59:55,472 [trainer.py] => CNN top5 curve: [51.45]
2024-08-19 22:59:55,472 [trainer.py] => NME top1 curve: [23.85]
2024-08-19 22:59:55,472 [trainer.py] => NME top5 curve: [58.5]

Average Accuracy (CNN): 17.8
Average Accuracy (NME): 23.85
2024-08-19 22:59:55,472 [trainer.py] => Average Accuracy (CNN): 17.8
2024-08-19 22:59:55,472 [trainer.py] => Average Accuracy (NME): 23.85
2024-08-19 22:59:55,472 [trainer.py] => Train Time: 37.33
2024-08-19 22:59:55,472 [trainer.py] => Test Time: 6.17 

2024-08-19 22:59:55,473 [trainer.py] => All params: 85829416
2024-08-19 22:59:55,473 [trainer.py] => Trainable params: 85829416
2024-08-19 22:59:57,087 [foster.py] => Learning on 20-40
2024-08-19 22:59:57,089 [foster.py] => All params: 171704932
2024-08-19 22:59:57,089 [foster.py] => Trainable params: 85890896
2024-08-19 22:59:57,266 [foster.py] => per cls weights : [1.00850692 1.00850692 1.00850692 1.00850692 1.00850692 1.00850692
 1.00850692 1.00850692 1.00850692 1.00850692 1.00850692 1.00850692
 1.00850692 1.00850692 1.00850692 1.00850692 1.00850692 1.00850692
 1.00850692 1.00850692 0.99149308 0.99149308 0.99149308 0.99149308
 0.99149308 0.99149308 0.99149308 0.99149308 0.99149308 0.99149308
 0.99149308 0.99149308 0.99149308 0.99149308 0.99149308 0.99149308
 0.99149308 0.99149308 0.99149308 0.99149308]
  0%|          | 0/1 [00:00<?, ?it/s]Task 1, Epoch 1/1 => Loss 8.209, Loss_clf 2.632, Loss_fe 2.657, Loss_kd 1.460, Train_accy 27.67, Test_accy 54.70:   0%|          | 0/1 [01:05<?, ?it/s]Task 1, Epoch 1/1 => Loss 8.209, Loss_clf 2.632, Loss_fe 2.657, Loss_kd 1.460, Train_accy 27.67, Test_accy 54.70: 100%|██████████| 1/1 [01:05<00:00, 65.58s/it]Task 1, Epoch 1/1 => Loss 8.209, Loss_clf 2.632, Loss_fe 2.657, Loss_kd 1.460, Train_accy 27.67, Test_accy 54.70: 100%|██████████| 1/1 [01:05<00:00, 65.58s/it]
2024-08-19 23:01:02,848 [foster.py] => Task 1, Epoch 1/1 => Loss 8.209, Loss_clf 2.632, Loss_fe 2.657, Loss_kd 1.460, Train_accy 27.67, Test_accy 54.70
2024-08-19 23:01:02,849 [foster.py] => do not weight align teacher!
2024-08-19 23:01:02,850 [foster.py] => per cls weights : [1.02435533 1.02435533 1.02435533 1.02435533 1.02435533 1.02435533
 1.02435533 1.02435533 1.02435533 1.02435533 1.02435533 1.02435533
 1.02435533 1.02435533 1.02435533 1.02435533 1.02435533 1.02435533
 1.02435533 1.02435533 0.97564467 0.97564467 0.97564467 0.97564467
 0.97564467 0.97564467 0.97564467 0.97564467 0.97564467 0.97564467
 0.97564467 0.97564467 0.97564467 0.97564467 0.97564467 0.97564467
 0.97564467 0.97564467 0.97564467 0.97564467]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 3.304,  Train_accy 23.38, Test_accy 28.90:   0%|          | 0/1 [01:14<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 3.304,  Train_accy 23.38, Test_accy 28.90: 100%|██████████| 1/1 [01:14<00:00, 74.77s/it]SNet: Task 1, Epoch 1/1 => Loss 3.304,  Train_accy 23.38, Test_accy 28.90: 100%|██████████| 1/1 [01:14<00:00, 74.77s/it]
2024-08-19 23:02:19,164 [foster.py] => SNet: Task 1, Epoch 1/1 => Loss 3.304,  Train_accy 23.38, Test_accy 28.90
2024-08-19 23:02:19,164 [foster.py] => do not weight align student!
2024-08-19 23:02:25,129 [foster.py] => darknet eval: 
2024-08-19 23:02:25,129 [foster.py] => CNN top1 curve: 28.9
2024-08-19 23:02:25,129 [foster.py] => CNN top5 curve: 54.7
2024-08-19 23:02:25,131 [base.py] => Reducing exemplars...(50 per classes)
2024-08-19 23:02:31,985 [base.py] => Constructing exemplars...(50 per classes)
2024-08-19 23:03:33,197 [foster.py] => Exemplar size: 2000
2024-08-19 23:03:33,197 [trainer.py] => CNN: {'total': 54.7, '00-19': 20.25, '20-39': 89.15, 'old': 20.25, 'new': 89.15}
2024-08-19 23:03:33,197 [trainer.py] => NME: {'total': 81.82, '00-19': 75.7, '20-39': 87.95, 'old': 75.7, 'new': 87.95}
2024-08-19 23:03:33,197 [trainer.py] => CNN top1 curve: [17.8, 54.7]
2024-08-19 23:03:33,197 [trainer.py] => CNN top5 curve: [51.45, 82.6]
2024-08-19 23:03:33,197 [trainer.py] => NME top1 curve: [23.85, 81.82]
2024-08-19 23:03:33,197 [trainer.py] => NME top5 curve: [58.5, 96.45]

Average Accuracy (CNN): 36.25
Average Accuracy (NME): 52.83
2024-08-19 23:03:33,197 [trainer.py] => Average Accuracy (CNN): 36.25
2024-08-19 23:03:33,198 [trainer.py] => Average Accuracy (NME): 52.83
2024-08-19 23:03:33,198 [trainer.py] => Train Time: 185.27999999999997
2024-08-19 23:03:33,198 [trainer.py] => Test Time: 27.6 

2024-08-19 23:03:33,199 [trainer.py] => All params: 171704932
2024-08-19 23:03:33,200 [trainer.py] => Trainable params: 85890896
2024-08-19 23:03:35,006 [foster.py] => Learning on 40-60
2024-08-19 23:03:35,008 [foster.py] => All params: 171766432
2024-08-19 23:03:35,008 [foster.py] => Trainable params: 85937016
2024-08-19 23:03:35,195 [foster.py] => per cls weights : [1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457 1.04525457
 1.04525457 1.04525457 1.04525457 1.04525457 0.90949085 0.90949085
 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085
 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085
 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085 0.90949085]
  0%|          | 0/1 [00:00<?, ?it/s]Task 2, Epoch 1/1 => Loss 7.970, Loss_clf 2.157, Loss_fe 2.470, Loss_kd 2.229, Train_accy 42.90, Test_accy 50.00:   0%|          | 0/1 [01:11<?, ?it/s]Task 2, Epoch 1/1 => Loss 7.970, Loss_clf 2.157, Loss_fe 2.470, Loss_kd 2.229, Train_accy 42.90, Test_accy 50.00: 100%|██████████| 1/1 [01:11<00:00, 71.02s/it]Task 2, Epoch 1/1 => Loss 7.970, Loss_clf 2.157, Loss_fe 2.470, Loss_kd 2.229, Train_accy 42.90, Test_accy 50.00: 100%|██████████| 1/1 [01:11<00:00, 71.02s/it]
2024-08-19 23:04:46,219 [foster.py] => Task 2, Epoch 1/1 => Loss 7.970, Loss_clf 2.157, Loss_fe 2.470, Loss_kd 2.229, Train_accy 42.90, Test_accy 50.00
2024-08-19 23:04:46,220 [foster.py] => do not weight align teacher!
2024-08-19 23:04:46,221 [foster.py] => per cls weights : [1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623 1.07838623
 1.07838623 1.07838623 1.07838623 1.07838623 0.84322753 0.84322753
 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753
 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753
 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753 0.84322753]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 3.214,  Train_accy 41.57, Test_accy 37.93:   0%|          | 0/1 [01:17<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 3.214,  Train_accy 41.57, Test_accy 37.93: 100%|██████████| 1/1 [01:17<00:00, 77.76s/it]SNet: Task 2, Epoch 1/1 => Loss 3.214,  Train_accy 41.57, Test_accy 37.93: 100%|██████████| 1/1 [01:17<00:00, 77.76s/it]
2024-08-19 23:06:05,957 [foster.py] => SNet: Task 2, Epoch 1/1 => Loss 3.214,  Train_accy 41.57, Test_accy 37.93
2024-08-19 23:06:05,958 [foster.py] => do not weight align student!
2024-08-19 23:06:14,902 [foster.py] => darknet eval: 
2024-08-19 23:06:14,902 [foster.py] => CNN top1 curve: 37.93
2024-08-19 23:06:14,902 [foster.py] => CNN top5 curve: 67.22
2024-08-19 23:06:14,904 [base.py] => Reducing exemplars...(33 per classes)
2024-08-19 23:06:26,797 [base.py] => Constructing exemplars...(33 per classes)
2024-08-19 23:07:37,769 [foster.py] => Exemplar size: 1980
2024-08-19 23:07:37,769 [trainer.py] => CNN: {'total': 50.0, '00-19': 18.5, '20-39': 43.75, '40-59': 87.75, 'old': 31.12, 'new': 87.75}
2024-08-19 23:07:37,769 [trainer.py] => NME: {'total': 77.92, '00-19': 71.3, '20-39': 76.4, '40-59': 86.05, 'old': 73.85, 'new': 86.05}
2024-08-19 23:07:37,769 [trainer.py] => CNN top1 curve: [17.8, 54.7, 50.0]
2024-08-19 23:07:37,769 [trainer.py] => CNN top5 curve: [51.45, 82.6, 77.6]
2024-08-19 23:07:37,769 [trainer.py] => NME top1 curve: [23.85, 81.82, 77.92]
2024-08-19 23:07:37,769 [trainer.py] => NME top5 curve: [58.5, 96.45, 94.85]

Average Accuracy (CNN): 40.83
Average Accuracy (NME): 61.2
2024-08-19 23:07:37,769 [trainer.py] => Average Accuracy (CNN): 40.83
2024-08-19 23:07:37,769 [trainer.py] => Average Accuracy (NME): 61.2
2024-08-19 23:07:37,769 [trainer.py] => Train Time: 345.06999999999994
2024-08-19 23:07:37,769 [trainer.py] => Test Time: 59.730000000000004 

2024-08-19 23:07:37,771 [trainer.py] => All params: 171766432
2024-08-19 23:07:37,772 [trainer.py] => Trainable params: 85937016
2024-08-19 23:07:39,480 [foster.py] => Learning on 60-80
2024-08-19 23:07:39,482 [foster.py] => All params: 171827932
2024-08-19 23:07:39,483 [foster.py] => Trainable params: 85983136
2024-08-19 23:07:39,686 [foster.py] => per cls weights : [1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484 1.06951484
 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549
 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549
 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549 0.79145549
 0.79145549 0.79145549]
  0%|          | 0/1 [00:00<?, ?it/s]Task 3, Epoch 1/1 => Loss 7.087, Loss_clf 1.703, Loss_fe 1.977, Loss_kd 2.556, Train_accy 51.84, Test_accy 56.30:   0%|          | 0/1 [01:16<?, ?it/s]Task 3, Epoch 1/1 => Loss 7.087, Loss_clf 1.703, Loss_fe 1.977, Loss_kd 2.556, Train_accy 51.84, Test_accy 56.30: 100%|██████████| 1/1 [01:16<00:00, 76.18s/it]Task 3, Epoch 1/1 => Loss 7.087, Loss_clf 1.703, Loss_fe 1.977, Loss_kd 2.556, Train_accy 51.84, Test_accy 56.30: 100%|██████████| 1/1 [01:16<00:00, 76.18s/it]
2024-08-19 23:08:55,872 [foster.py] => Task 3, Epoch 1/1 => Loss 7.087, Loss_clf 1.703, Loss_fe 1.977, Loss_kd 2.556, Train_accy 51.84, Test_accy 56.30
2024-08-19 23:08:55,874 [foster.py] => do not weight align teacher!
2024-08-19 23:08:55,876 [foster.py] => per cls weights : [1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193 1.10071193
 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421
 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421
 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421 0.69786421
 0.69786421 0.69786421]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 3.406,  Train_accy 42.20, Test_accy 47.59:   0%|          | 0/1 [01:20<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 3.406,  Train_accy 42.20, Test_accy 47.59: 100%|██████████| 1/1 [01:20<00:00, 80.55s/it]SNet: Task 3, Epoch 1/1 => Loss 3.406,  Train_accy 42.20, Test_accy 47.59: 100%|██████████| 1/1 [01:20<00:00, 80.55s/it]
2024-08-19 23:10:17,969 [foster.py] => SNet: Task 3, Epoch 1/1 => Loss 3.406,  Train_accy 42.20, Test_accy 47.59
2024-08-19 23:10:17,969 [foster.py] => do not weight align student!
2024-08-19 23:10:29,739 [foster.py] => darknet eval: 
2024-08-19 23:10:29,739 [foster.py] => CNN top1 curve: 47.59
2024-08-19 23:10:29,739 [foster.py] => CNN top5 curve: 77.44
2024-08-19 23:10:29,741 [base.py] => Reducing exemplars...(25 per classes)
2024-08-19 23:10:46,161 [base.py] => Constructing exemplars...(25 per classes)
2024-08-19 23:12:06,865 [foster.py] => Exemplar size: 2000
2024-08-19 23:12:06,866 [trainer.py] => CNN: {'total': 56.3, '00-19': 28.3, '20-39': 51.55, '40-59': 63.95, '60-79': 81.4, 'old': 47.93, 'new': 81.4}
2024-08-19 23:12:06,866 [trainer.py] => NME: {'total': 73.7, '00-19': 63.85, '20-39': 74.9, '40-59': 73.3, '60-79': 82.75, 'old': 70.68, 'new': 82.75}
2024-08-19 23:12:06,866 [trainer.py] => CNN top1 curve: [17.8, 54.7, 50.0, 56.3]
2024-08-19 23:12:06,866 [trainer.py] => CNN top5 curve: [51.45, 82.6, 77.6, 83.55]
2024-08-19 23:12:06,866 [trainer.py] => NME top1 curve: [23.85, 81.82, 77.92, 73.7]
2024-08-19 23:12:06,866 [trainer.py] => NME top5 curve: [58.5, 96.45, 94.85, 93.71]

Average Accuracy (CNN): 44.7
Average Accuracy (NME): 64.32
2024-08-19 23:12:06,866 [trainer.py] => Average Accuracy (CNN): 44.7
2024-08-19 23:12:06,866 [trainer.py] => Average Accuracy (NME): 64.32
2024-08-19 23:12:06,866 [trainer.py] => Train Time: 515.2099999999999
2024-08-19 23:12:06,866 [trainer.py] => Test Time: 102.41 

2024-08-19 23:12:06,867 [trainer.py] => All params: 171827932
2024-08-19 23:12:06,868 [trainer.py] => Trainable params: 85983136
2024-08-19 23:12:08,347 [foster.py] => Learning on 80-100
2024-08-19 23:12:08,348 [foster.py] => All params: 171889432
2024-08-19 23:12:08,349 [foster.py] => Trainable params: 86029256
2024-08-19 23:12:08,543 [foster.py] => per cls weights : [1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835 1.07767835
 1.07767835 1.07767835 0.68928661 0.68928661 0.68928661 0.68928661
 0.68928661 0.68928661 0.68928661 0.68928661 0.68928661 0.68928661
 0.68928661 0.68928661 0.68928661 0.68928661 0.68928661 0.68928661
 0.68928661 0.68928661 0.68928661 0.68928661]
  0%|          | 0/1 [00:00<?, ?it/s]Task 4, Epoch 1/1 => Loss 7.379, Loss_clf 1.692, Loss_fe 2.014, Loss_kd 2.939, Train_accy 48.18, Test_accy 55.66:   0%|          | 0/1 [01:21<?, ?it/s]Task 4, Epoch 1/1 => Loss 7.379, Loss_clf 1.692, Loss_fe 2.014, Loss_kd 2.939, Train_accy 48.18, Test_accy 55.66: 100%|██████████| 1/1 [01:21<00:00, 81.48s/it]Task 4, Epoch 1/1 => Loss 7.379, Loss_clf 1.692, Loss_fe 2.014, Loss_kd 2.939, Train_accy 48.18, Test_accy 55.66: 100%|██████████| 1/1 [01:21<00:00, 81.48s/it]
2024-08-19 23:13:30,023 [foster.py] => Task 4, Epoch 1/1 => Loss 7.379, Loss_clf 1.692, Loss_fe 2.014, Loss_kd 2.939, Train_accy 48.18, Test_accy 55.66
2024-08-19 23:13:30,024 [foster.py] => do not weight align teacher!
2024-08-19 23:13:30,027 [foster.py] => per cls weights : [1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613 1.10301613
 1.10301613 1.10301613 0.5879355  0.5879355  0.5879355  0.5879355
 0.5879355  0.5879355  0.5879355  0.5879355  0.5879355  0.5879355
 0.5879355  0.5879355  0.5879355  0.5879355  0.5879355  0.5879355
 0.5879355  0.5879355  0.5879355  0.5879355 ]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 3.785,  Train_accy 26.60, Test_accy 48.85:   0%|          | 0/1 [01:23<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 3.785,  Train_accy 26.60, Test_accy 48.85: 100%|██████████| 1/1 [01:23<00:00, 83.41s/it]SNet: Task 4, Epoch 1/1 => Loss 3.785,  Train_accy 26.60, Test_accy 48.85: 100%|██████████| 1/1 [01:23<00:00, 83.41s/it]
2024-08-19 23:14:54,965 [foster.py] => SNet: Task 4, Epoch 1/1 => Loss 3.785,  Train_accy 26.60, Test_accy 48.85
2024-08-19 23:14:54,965 [foster.py] => do not weight align student!
2024-08-19 23:15:09,555 [foster.py] => darknet eval: 
2024-08-19 23:15:09,556 [foster.py] => CNN top1 curve: 48.85
2024-08-19 23:15:09,556 [foster.py] => CNN top5 curve: 79.78
2024-08-19 23:15:09,557 [base.py] => Reducing exemplars...(20 per classes)
2024-08-19 23:15:30,552 [base.py] => Constructing exemplars...(20 per classes)
2024-08-19 23:17:01,421 [foster.py] => Exemplar size: 2000
2024-08-19 23:17:01,421 [trainer.py] => CNN: {'total': 55.66, '00-19': 28.05, '20-39': 46.25, '40-59': 66.55, '60-79': 64.75, '80-99': 72.7, 'old': 51.4, 'new': 72.7}
2024-08-19 23:17:01,421 [trainer.py] => NME: {'total': 67.34, '00-19': 56.1, '20-39': 68.0, '40-59': 67.05, '60-79': 69.7, '80-99': 75.85, 'old': 65.21, 'new': 75.85}
2024-08-19 23:17:01,421 [trainer.py] => CNN top1 curve: [17.8, 54.7, 50.0, 56.3, 55.66]
2024-08-19 23:17:01,421 [trainer.py] => CNN top5 curve: [51.45, 82.6, 77.6, 83.55, 83.55]
2024-08-19 23:17:01,421 [trainer.py] => NME top1 curve: [23.85, 81.82, 77.92, 73.7, 67.34]
2024-08-19 23:17:01,421 [trainer.py] => NME top5 curve: [58.5, 96.45, 94.85, 93.71, 91.33]

Average Accuracy (CNN): 46.89
Average Accuracy (NME): 64.93
2024-08-19 23:17:01,421 [trainer.py] => Average Accuracy (CNN): 46.89
2024-08-19 23:17:01,421 [trainer.py] => Average Accuracy (NME): 64.93
2024-08-19 23:17:01,421 [trainer.py] => Train Time: 696.31
2024-08-19 23:17:01,421 [trainer.py] => Test Time: 155.92 

Accuracy Matrix (CNN):
[[17.8  20.25 18.5  28.3  28.05]
 [ 0.   89.15 43.75 51.55 46.25]
 [ 0.    0.   87.75 63.95 66.55]
 [ 0.    0.    0.   81.4  64.75]
 [ 0.    0.    0.    0.   72.7 ]]
2024-08-19 23:17:01,422 [trainer.py] => Forgetting (CNN): 20.250000000000004
Accuracy Matrix (NME):
[[23.85 75.7  71.3  63.85 56.1 ]
 [ 0.   87.95 76.4  74.9  68.  ]
 [ 0.    0.   86.05 73.3  67.05]
 [ 0.    0.    0.   82.75 69.7 ]
 [ 0.    0.    0.    0.   75.85]]
2024-08-19 23:17:01,422 [trainer.py] => Forgetting (NME): 17.9
2024-08-19 23:17:03,489 [trainer.py] => config: ./exps/foster_cifar_B0_Inc10.json
2024-08-19 23:17:03,489 [trainer.py] => prefix: cil
2024-08-19 23:17:03,489 [trainer.py] => dataset: cifar224
2024-08-19 23:17:03,489 [trainer.py] => memory_size: 2000
2024-08-19 23:17:03,489 [trainer.py] => memory_per_class: 20
2024-08-19 23:17:03,489 [trainer.py] => fixed_memory: False
2024-08-19 23:17:03,490 [trainer.py] => shuffle: True
2024-08-19 23:17:03,490 [trainer.py] => init_cls: 10
2024-08-19 23:17:03,490 [trainer.py] => increment: 10
2024-08-19 23:17:03,490 [trainer.py] => model_name: foster
2024-08-19 23:17:03,490 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-08-19 23:17:03,490 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-19 23:17:03,490 [trainer.py] => seed: 1993
2024-08-19 23:17:03,490 [trainer.py] => beta1: 0.96
2024-08-19 23:17:03,490 [trainer.py] => beta2: 0.97
2024-08-19 23:17:03,490 [trainer.py] => oofc: ft
2024-08-19 23:17:03,490 [trainer.py] => is_teacher_wa: False
2024-08-19 23:17:03,490 [trainer.py] => is_student_wa: False
2024-08-19 23:17:03,490 [trainer.py] => lambda_okd: 1
2024-08-19 23:17:03,490 [trainer.py] => wa_value: 1
2024-08-19 23:17:03,490 [trainer.py] => init_epochs: 1
2024-08-19 23:17:03,490 [trainer.py] => init_lr: 0.001
2024-08-19 23:17:03,490 [trainer.py] => init_weight_decay: 0.0005
2024-08-19 23:17:03,490 [trainer.py] => boosting_epochs: 1
2024-08-19 23:17:03,490 [trainer.py] => compression_epochs: 1
2024-08-19 23:17:03,490 [trainer.py] => lr: 0.001
2024-08-19 23:17:03,490 [trainer.py] => batch_size: 48
2024-08-19 23:17:03,490 [trainer.py] => weight_decay: 0.0005
2024-08-19 23:17:03,490 [trainer.py] => num_workers: 8
2024-08-19 23:17:03,490 [trainer.py] => T: 2
2024-08-19 23:17:04,397 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-19 23:17:05,018 [trainer.py] => All params: 0
2024-08-19 23:17:05,018 [trainer.py] => Trainable params: 0
2024-08-19 23:17:06,394 [foster.py] => Learning on 0-10
2024-08-19 23:17:06,395 [foster.py] => All params: 85814036
2024-08-19 23:17:06,395 [foster.py] => Trainable params: 85814036
  0%|          | 0/1 [00:00<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.035, Train_accy 28.46, Test_accy 81.30:   0%|          | 0/1 [00:19<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.035, Train_accy 28.46, Test_accy 81.30: 100%|██████████| 1/1 [00:19<00:00, 19.18s/it]Task 0, Epoch 1/1 => Loss 2.035, Train_accy 28.46, Test_accy 81.30: 100%|██████████| 1/1 [00:19<00:00, 19.18s/it]
2024-08-19 23:17:25,880 [foster.py] => Task 0, Epoch 1/1 => Loss 2.035, Train_accy 28.46, Test_accy 81.30
2024-08-19 23:17:25,881 [base.py] => Reducing exemplars...(200 per classes)
2024-08-19 23:17:25,881 [base.py] => Constructing exemplars...(200 per classes)
2024-08-19 23:17:45,062 [foster.py] => Exemplar size: 2000
2024-08-19 23:17:45,062 [trainer.py] => CNN: {'total': 81.3, '00-09': 81.3, 'old': 0, 'new': 81.3}
2024-08-19 23:17:45,062 [trainer.py] => NME: {'total': 85.5, '00-09': 85.5, 'old': 0, 'new': 85.5}
2024-08-19 23:17:45,062 [trainer.py] => CNN top1 curve: [81.3]
2024-08-19 23:17:45,062 [trainer.py] => CNN top5 curve: [97.6]
2024-08-19 23:17:45,062 [trainer.py] => NME top1 curve: [85.5]
2024-08-19 23:17:45,062 [trainer.py] => NME top5 curve: [98.6]

Average Accuracy (CNN): 81.3
Average Accuracy (NME): 85.5
2024-08-19 23:17:45,062 [trainer.py] => Average Accuracy (CNN): 81.3
2024-08-19 23:17:45,062 [trainer.py] => Average Accuracy (NME): 85.5
2024-08-19 23:17:45,063 [trainer.py] => Train Time: 19.48
2024-08-19 23:17:45,063 [trainer.py] => Test Time: 3.35 

2024-08-19 23:17:45,063 [trainer.py] => All params: 85814036
2024-08-19 23:17:45,064 [trainer.py] => Trainable params: 85814036
2024-08-19 23:17:46,629 [foster.py] => Learning on 10-20
2024-08-19 23:17:46,630 [foster.py] => All params: 171651122
2024-08-19 23:17:46,631 [foster.py] => Trainable params: 85844776
2024-08-19 23:17:46,760 [foster.py] => per cls weights : [1.00014232 1.00014232 1.00014232 1.00014232 1.00014232 1.00014232
 1.00014232 1.00014232 1.00014232 1.00014232 0.99985768 0.99985768
 0.99985768 0.99985768 0.99985768 0.99985768 0.99985768 0.99985768
 0.99985768 0.99985768]
  0%|          | 0/1 [00:00<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.035, Loss_clf 1.431, Loss_fe 1.665, Loss_kd 0.970, Train_accy 56.23, Test_accy 88.60:   0%|          | 0/1 [00:37<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.035, Loss_clf 1.431, Loss_fe 1.665, Loss_kd 0.970, Train_accy 56.23, Test_accy 88.60: 100%|██████████| 1/1 [00:37<00:00, 37.62s/it]Task 1, Epoch 1/1 => Loss 5.035, Loss_clf 1.431, Loss_fe 1.665, Loss_kd 0.970, Train_accy 56.23, Test_accy 88.60: 100%|██████████| 1/1 [00:37<00:00, 37.62s/it]
2024-08-19 23:18:24,383 [foster.py] => Task 1, Epoch 1/1 => Loss 5.035, Loss_clf 1.431, Loss_fe 1.665, Loss_kd 0.970, Train_accy 56.23, Test_accy 88.60
2024-08-19 23:18:24,384 [foster.py] => do not weight align teacher!
2024-08-19 23:18:24,385 [foster.py] => per cls weights : [1.0011319 1.0011319 1.0011319 1.0011319 1.0011319 1.0011319 1.0011319
 1.0011319 1.0011319 1.0011319 0.9988681 0.9988681 0.9988681 0.9988681
 0.9988681 0.9988681 0.9988681 0.9988681 0.9988681 0.9988681]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.002,  Train_accy 60.54, Test_accy 85.50:   0%|          | 0/1 [00:43<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.002,  Train_accy 60.54, Test_accy 85.50: 100%|██████████| 1/1 [00:43<00:00, 43.37s/it]SNet: Task 1, Epoch 1/1 => Loss 2.002,  Train_accy 60.54, Test_accy 85.50: 100%|██████████| 1/1 [00:43<00:00, 43.37s/it]
2024-08-19 23:19:09,317 [foster.py] => SNet: Task 1, Epoch 1/1 => Loss 2.002,  Train_accy 60.54, Test_accy 85.50
2024-08-19 23:19:09,317 [foster.py] => do not weight align student!
2024-08-19 23:19:12,510 [foster.py] => darknet eval: 
2024-08-19 23:19:12,510 [foster.py] => CNN top1 curve: 85.5
2024-08-19 23:19:12,510 [foster.py] => CNN top5 curve: 98.4
2024-08-19 23:19:12,511 [base.py] => Reducing exemplars...(100 per classes)
2024-08-19 23:19:17,571 [base.py] => Constructing exemplars...(100 per classes)
2024-08-19 23:19:51,002 [foster.py] => Exemplar size: 2000
2024-08-19 23:19:51,003 [trainer.py] => CNN: {'total': 88.6, '00-09': 85.9, '10-19': 91.3, 'old': 85.9, 'new': 91.3}
2024-08-19 23:19:51,003 [trainer.py] => NME: {'total': 91.85, '00-09': 94.1, '10-19': 89.6, 'old': 94.1, 'new': 89.6}
2024-08-19 23:19:51,003 [trainer.py] => CNN top1 curve: [81.3, 88.6]
2024-08-19 23:19:51,003 [trainer.py] => CNN top5 curve: [97.6, 98.65]
2024-08-19 23:19:51,003 [trainer.py] => NME top1 curve: [85.5, 91.85]
2024-08-19 23:19:51,003 [trainer.py] => NME top5 curve: [98.6, 99.35]

Average Accuracy (CNN): 84.95
Average Accuracy (NME): 88.68
2024-08-19 23:19:51,003 [trainer.py] => Average Accuracy (CNN): 84.95
2024-08-19 23:19:51,003 [trainer.py] => Average Accuracy (NME): 88.68
2024-08-19 23:19:51,003 [trainer.py] => Train Time: 105.32000000000001
2024-08-19 23:19:51,003 [trainer.py] => Test Time: 14.37 

2024-08-19 23:19:51,004 [trainer.py] => All params: 171651122
2024-08-19 23:19:51,005 [trainer.py] => Trainable params: 85844776
2024-08-19 23:19:52,569 [foster.py] => Learning on 20-30
2024-08-19 23:19:52,570 [foster.py] => All params: 171681872
2024-08-19 23:19:52,571 [foster.py] => Trainable params: 85867836
2024-08-19 23:19:52,708 [foster.py] => per cls weights : [1.00565524 1.00565524 1.00565524 1.00565524 1.00565524 1.00565524
 1.00565524 1.00565524 1.00565524 1.00565524 1.00565524 1.00565524
 1.00565524 1.00565524 1.00565524 1.00565524 1.00565524 1.00565524
 1.00565524 1.00565524 0.98868952 0.98868952 0.98868952 0.98868952
 0.98868952 0.98868952 0.98868952 0.98868952 0.98868952 0.98868952]
  0%|          | 0/1 [00:00<?, ?it/s]Task 2, Epoch 1/1 => Loss 4.650, Loss_clf 1.099, Loss_fe 1.443, Loss_kd 1.406, Train_accy 69.49, Test_accy 85.73:   0%|          | 0/1 [00:40<?, ?it/s]Task 2, Epoch 1/1 => Loss 4.650, Loss_clf 1.099, Loss_fe 1.443, Loss_kd 1.406, Train_accy 69.49, Test_accy 85.73: 100%|██████████| 1/1 [00:40<00:00, 40.35s/it]Task 2, Epoch 1/1 => Loss 4.650, Loss_clf 1.099, Loss_fe 1.443, Loss_kd 1.406, Train_accy 69.49, Test_accy 85.73: 100%|██████████| 1/1 [00:40<00:00, 40.35s/it]
2024-08-19 23:20:33,061 [foster.py] => Task 2, Epoch 1/1 => Loss 4.650, Loss_clf 1.099, Loss_fe 1.443, Loss_kd 1.406, Train_accy 69.49, Test_accy 85.73
2024-08-19 23:20:33,062 [foster.py] => do not weight align teacher!
2024-08-19 23:20:33,063 [foster.py] => per cls weights : [1.01610613 1.01610613 1.01610613 1.01610613 1.01610613 1.01610613
 1.01610613 1.01610613 1.01610613 1.01610613 1.01610613 1.01610613
 1.01610613 1.01610613 1.01610613 1.01610613 1.01610613 1.01610613
 1.01610613 1.01610613 0.96778774 0.96778774 0.96778774 0.96778774
 0.96778774 0.96778774 0.96778774 0.96778774 0.96778774 0.96778774]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 1.953,  Train_accy 66.26, Test_accy 84.67:   0%|          | 0/1 [00:44<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 1.953,  Train_accy 66.26, Test_accy 84.67: 100%|██████████| 1/1 [00:44<00:00, 44.86s/it]SNet: Task 2, Epoch 1/1 => Loss 1.953,  Train_accy 66.26, Test_accy 84.67: 100%|██████████| 1/1 [00:44<00:00, 44.86s/it]
2024-08-19 23:21:19,605 [foster.py] => SNet: Task 2, Epoch 1/1 => Loss 1.953,  Train_accy 66.26, Test_accy 84.67
2024-08-19 23:21:19,606 [foster.py] => do not weight align student!
2024-08-19 23:21:24,282 [foster.py] => darknet eval: 
2024-08-19 23:21:24,282 [foster.py] => CNN top1 curve: 84.67
2024-08-19 23:21:24,282 [foster.py] => CNN top5 curve: 98.13
2024-08-19 23:21:24,284 [base.py] => Reducing exemplars...(66 per classes)
2024-08-19 23:21:34,208 [base.py] => Constructing exemplars...(66 per classes)
2024-08-19 23:22:12,866 [foster.py] => Exemplar size: 1980
2024-08-19 23:22:12,866 [trainer.py] => CNN: {'total': 85.73, '00-09': 81.7, '10-19': 79.4, '20-29': 96.1, 'old': 80.55, 'new': 96.1}
2024-08-19 23:22:12,866 [trainer.py] => NME: {'total': 91.27, '00-09': 92.0, '10-19': 87.3, '20-29': 94.5, 'old': 89.65, 'new': 94.5}
2024-08-19 23:22:12,866 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73]
2024-08-19 23:22:12,866 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37]
2024-08-19 23:22:12,866 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27]
2024-08-19 23:22:12,866 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83]

Average Accuracy (CNN): 85.21
Average Accuracy (NME): 89.54
2024-08-19 23:22:12,866 [trainer.py] => Average Accuracy (CNN): 85.21
2024-08-19 23:22:12,866 [trainer.py] => Average Accuracy (NME): 89.54
2024-08-19 23:22:12,866 [trainer.py] => Train Time: 196.98000000000002
2024-08-19 23:22:12,866 [trainer.py] => Test Time: 30.630000000000003 

2024-08-19 23:22:12,868 [trainer.py] => All params: 171681872
2024-08-19 23:22:12,869 [trainer.py] => Trainable params: 85867836
2024-08-19 23:22:14,632 [foster.py] => Learning on 30-40
2024-08-19 23:22:14,634 [foster.py] => All params: 171712622
2024-08-19 23:22:14,634 [foster.py] => Trainable params: 85890896
2024-08-19 23:22:14,805 [foster.py] => per cls weights : [1.0171887  1.0171887  1.0171887  1.0171887  1.0171887  1.0171887
 1.0171887  1.0171887  1.0171887  1.0171887  1.0171887  1.0171887
 1.0171887  1.0171887  1.0171887  1.0171887  1.0171887  1.0171887
 1.0171887  1.0171887  1.0171887  1.0171887  1.0171887  1.0171887
 1.0171887  1.0171887  1.0171887  1.0171887  1.0171887  1.0171887
 0.94843391 0.94843391 0.94843391 0.94843391 0.94843391 0.94843391
 0.94843391 0.94843391 0.94843391 0.94843391]
  0%|          | 0/1 [00:00<?, ?it/s]Task 3, Epoch 1/1 => Loss 4.990, Loss_clf 1.114, Loss_fe 1.561, Loss_kd 1.736, Train_accy 68.95, Test_accy 84.00:   0%|          | 0/1 [00:42<?, ?it/s]Task 3, Epoch 1/1 => Loss 4.990, Loss_clf 1.114, Loss_fe 1.561, Loss_kd 1.736, Train_accy 68.95, Test_accy 84.00: 100%|██████████| 1/1 [00:42<00:00, 42.90s/it]Task 3, Epoch 1/1 => Loss 4.990, Loss_clf 1.114, Loss_fe 1.561, Loss_kd 1.736, Train_accy 68.95, Test_accy 84.00: 100%|██████████| 1/1 [00:42<00:00, 42.90s/it]
2024-08-19 23:22:57,708 [foster.py] => Task 3, Epoch 1/1 => Loss 4.990, Loss_clf 1.114, Loss_fe 1.561, Loss_kd 1.736, Train_accy 68.95, Test_accy 84.00
2024-08-19 23:22:57,709 [foster.py] => do not weight align teacher!
2024-08-19 23:22:57,710 [foster.py] => per cls weights : [1.03464709 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709
 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709
 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709
 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709
 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709 1.03464709
 0.89605874 0.89605874 0.89605874 0.89605874 0.89605874 0.89605874
 0.89605874 0.89605874 0.89605874 0.89605874]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.094,  Train_accy 66.16, Test_accy 82.48:   0%|          | 0/1 [00:46<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.094,  Train_accy 66.16, Test_accy 82.48: 100%|██████████| 1/1 [00:46<00:00, 46.21s/it]SNet: Task 3, Epoch 1/1 => Loss 2.094,  Train_accy 66.16, Test_accy 82.48: 100%|██████████| 1/1 [00:46<00:00, 46.21s/it]
2024-08-19 23:23:45,534 [foster.py] => SNet: Task 3, Epoch 1/1 => Loss 2.094,  Train_accy 66.16, Test_accy 82.48
2024-08-19 23:23:45,535 [foster.py] => do not weight align student!
2024-08-19 23:23:51,498 [foster.py] => darknet eval: 
2024-08-19 23:23:51,499 [foster.py] => CNN top1 curve: 82.48
2024-08-19 23:23:51,499 [foster.py] => CNN top5 curve: 98.28
2024-08-19 23:23:51,500 [base.py] => Reducing exemplars...(50 per classes)
2024-08-19 23:24:04,148 [base.py] => Constructing exemplars...(50 per classes)
2024-08-19 23:24:46,721 [foster.py] => Exemplar size: 2000
2024-08-19 23:24:46,722 [trainer.py] => CNN: {'total': 84.0, '00-09': 74.8, '10-19': 77.9, '20-29': 92.8, '30-39': 90.5, 'old': 81.83, 'new': 90.5}
2024-08-19 23:24:46,722 [trainer.py] => NME: {'total': 89.82, '00-09': 91.7, '10-19': 87.4, '20-29': 92.6, '30-39': 87.6, 'old': 90.57, 'new': 87.6}
2024-08-19 23:24:46,722 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0]
2024-08-19 23:24:46,722 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95]
2024-08-19 23:24:46,722 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82]
2024-08-19 23:24:46,722 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78]

Average Accuracy (CNN): 84.91
Average Accuracy (NME): 89.61
2024-08-19 23:24:46,722 [trainer.py] => Average Accuracy (CNN): 84.91
2024-08-19 23:24:46,722 [trainer.py] => Average Accuracy (NME): 89.61
2024-08-19 23:24:46,722 [trainer.py] => Train Time: 293.75
2024-08-19 23:24:46,722 [trainer.py] => Test Time: 52.0 

2024-08-19 23:24:46,723 [trainer.py] => All params: 171712622
2024-08-19 23:24:46,724 [trainer.py] => Trainable params: 85890896
2024-08-19 23:24:48,357 [foster.py] => Learning on 40-50
2024-08-19 23:24:48,358 [foster.py] => All params: 171743372
2024-08-19 23:24:48,359 [foster.py] => Trainable params: 85913956
2024-08-19 23:24:48,482 [foster.py] => per cls weights : [1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997 1.02666997
 1.02666997 1.02666997 1.02666997 1.02666997 0.89332013 0.89332013
 0.89332013 0.89332013 0.89332013 0.89332013 0.89332013 0.89332013
 0.89332013 0.89332013]
  0%|          | 0/1 [00:00<?, ?it/s]Task 4, Epoch 1/1 => Loss 5.598, Loss_clf 1.105, Loss_fe 2.019, Loss_kd 1.980, Train_accy 69.30, Test_accy 83.80:   0%|          | 0/1 [00:45<?, ?it/s]Task 4, Epoch 1/1 => Loss 5.598, Loss_clf 1.105, Loss_fe 2.019, Loss_kd 1.980, Train_accy 69.30, Test_accy 83.80: 100%|██████████| 1/1 [00:45<00:00, 45.55s/it]Task 4, Epoch 1/1 => Loss 5.598, Loss_clf 1.105, Loss_fe 2.019, Loss_kd 1.980, Train_accy 69.30, Test_accy 83.80: 100%|██████████| 1/1 [00:45<00:00, 45.55s/it]
2024-08-19 23:25:34,038 [foster.py] => Task 4, Epoch 1/1 => Loss 5.598, Loss_clf 1.105, Loss_fe 2.019, Loss_kd 1.980, Train_accy 69.30, Test_accy 83.80
2024-08-19 23:25:34,039 [foster.py] => do not weight align teacher!
2024-08-19 23:25:34,043 [foster.py] => per cls weights : [1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191 1.04560191
 1.04560191 1.04560191 1.04560191 1.04560191 0.81759234 0.81759234
 0.81759234 0.81759234 0.81759234 0.81759234 0.81759234 0.81759234
 0.81759234 0.81759234]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 2.317,  Train_accy 66.27, Test_accy 83.94:   0%|          | 0/1 [00:47<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 2.317,  Train_accy 66.27, Test_accy 83.94: 100%|██████████| 1/1 [00:47<00:00, 47.88s/it]SNet: Task 4, Epoch 1/1 => Loss 2.317,  Train_accy 66.27, Test_accy 83.94: 100%|██████████| 1/1 [00:47<00:00, 47.88s/it]
2024-08-19 23:26:23,437 [foster.py] => SNet: Task 4, Epoch 1/1 => Loss 2.317,  Train_accy 66.27, Test_accy 83.94
2024-08-19 23:26:23,438 [foster.py] => do not weight align student!
2024-08-19 23:26:30,783 [foster.py] => darknet eval: 
2024-08-19 23:26:30,783 [foster.py] => CNN top1 curve: 83.94
2024-08-19 23:26:30,783 [foster.py] => CNN top5 curve: 98.04
2024-08-19 23:26:30,785 [base.py] => Reducing exemplars...(40 per classes)
2024-08-19 23:26:45,288 [base.py] => Constructing exemplars...(40 per classes)
2024-08-19 23:27:32,189 [foster.py] => Exemplar size: 2000
2024-08-19 23:27:32,189 [trainer.py] => CNN: {'total': 83.8, '00-09': 80.9, '10-19': 75.7, '20-29': 89.7, '30-39': 81.5, '40-49': 91.2, 'old': 81.95, 'new': 91.2}
2024-08-19 23:27:32,189 [trainer.py] => NME: {'total': 85.74, '00-09': 90.9, '10-19': 82.9, '20-29': 89.8, '30-39': 79.4, '40-49': 85.7, 'old': 85.75, 'new': 85.7}
2024-08-19 23:27:32,189 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8]
2024-08-19 23:27:32,189 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04]
2024-08-19 23:27:32,189 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74]
2024-08-19 23:27:32,189 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2]

Average Accuracy (CNN): 84.69
Average Accuracy (NME): 88.84
2024-08-19 23:27:32,189 [trainer.py] => Average Accuracy (CNN): 84.69
2024-08-19 23:27:32,189 [trainer.py] => Average Accuracy (NME): 88.84
2024-08-19 23:27:32,190 [trainer.py] => Train Time: 396.11
2024-08-19 23:27:32,190 [trainer.py] => Test Time: 78.56 

2024-08-19 23:27:32,191 [trainer.py] => All params: 171743372
2024-08-19 23:27:32,192 [trainer.py] => Trainable params: 85913956
2024-08-19 23:27:33,788 [foster.py] => Learning on 50-60
2024-08-19 23:27:33,790 [foster.py] => All params: 171774122
2024-08-19 23:27:33,791 [foster.py] => Trainable params: 85937016
2024-08-19 23:27:33,931 [foster.py] => per cls weights : [1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 0.83171535 0.83171535 0.83171535 0.83171535
 0.83171535 0.83171535 0.83171535 0.83171535 0.83171535 0.83171535]
  0%|          | 0/1 [00:00<?, ?it/s]Task 5, Epoch 1/1 => Loss 5.798, Loss_clf 1.133, Loss_fe 1.815, Loss_kd 2.375, Train_accy 67.16, Test_accy 82.12:   0%|          | 0/1 [00:48<?, ?it/s]Task 5, Epoch 1/1 => Loss 5.798, Loss_clf 1.133, Loss_fe 1.815, Loss_kd 2.375, Train_accy 67.16, Test_accy 82.12: 100%|██████████| 1/1 [00:48<00:00, 48.06s/it]Task 5, Epoch 1/1 => Loss 5.798, Loss_clf 1.133, Loss_fe 1.815, Loss_kd 2.375, Train_accy 67.16, Test_accy 82.12: 100%|██████████| 1/1 [00:48<00:00, 48.06s/it]
2024-08-19 23:28:21,991 [foster.py] => Task 5, Epoch 1/1 => Loss 5.798, Loss_clf 1.133, Loss_fe 1.815, Loss_kd 2.375, Train_accy 67.16, Test_accy 82.12
2024-08-19 23:28:21,992 [foster.py] => do not weight align teacher!
2024-08-19 23:28:21,993 [foster.py] => per cls weights : [1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 0.74079824 0.74079824 0.74079824 0.74079824
 0.74079824 0.74079824 0.74079824 0.74079824 0.74079824 0.74079824]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 2.584,  Train_accy 62.56, Test_accy 82.13:   0%|          | 0/1 [00:49<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 2.584,  Train_accy 62.56, Test_accy 82.13: 100%|██████████| 1/1 [00:49<00:00, 49.08s/it]SNet: Task 5, Epoch 1/1 => Loss 2.584,  Train_accy 62.56, Test_accy 82.13: 100%|██████████| 1/1 [00:49<00:00, 49.08s/it]
2024-08-19 23:29:12,558 [foster.py] => SNet: Task 5, Epoch 1/1 => Loss 2.584,  Train_accy 62.56, Test_accy 82.13
2024-08-19 23:29:12,558 [foster.py] => do not weight align student!
2024-08-19 23:29:21,205 [foster.py] => darknet eval: 
2024-08-19 23:29:21,205 [foster.py] => CNN top1 curve: 82.13
2024-08-19 23:29:21,205 [foster.py] => CNN top5 curve: 97.7
2024-08-19 23:29:21,207 [base.py] => Reducing exemplars...(33 per classes)
2024-08-19 23:29:37,716 [base.py] => Constructing exemplars...(33 per classes)
2024-08-19 23:30:29,452 [foster.py] => Exemplar size: 1980
2024-08-19 23:30:29,452 [trainer.py] => CNN: {'total': 82.12, '00-09': 82.1, '10-19': 77.4, '20-29': 85.7, '30-39': 81.4, '40-49': 78.5, '50-59': 87.6, 'old': 81.02, 'new': 87.6}
2024-08-19 23:30:29,452 [trainer.py] => NME: {'total': 86.2, '00-09': 89.8, '10-19': 85.0, '20-29': 91.3, '30-39': 82.2, '40-49': 85.0, '50-59': 83.9, 'old': 86.66, 'new': 83.9}
2024-08-19 23:30:29,452 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8, 82.12]
2024-08-19 23:30:29,452 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04, 97.42]
2024-08-19 23:30:29,452 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74, 86.2]
2024-08-19 23:30:29,452 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2, 97.9]

Average Accuracy (CNN): 84.26
Average Accuracy (NME): 88.4
2024-08-19 23:30:29,452 [trainer.py] => Average Accuracy (CNN): 84.26
2024-08-19 23:30:29,452 [trainer.py] => Average Accuracy (NME): 88.4
2024-08-19 23:30:29,452 [trainer.py] => Train Time: 503.44
2024-08-19 23:30:29,452 [trainer.py] => Test Time: 110.27000000000001 

2024-08-19 23:30:29,454 [trainer.py] => All params: 171774122
2024-08-19 23:30:29,455 [trainer.py] => Trainable params: 85937016
2024-08-19 23:30:30,970 [foster.py] => Learning on 60-70
2024-08-19 23:30:30,972 [foster.py] => All params: 171804872
2024-08-19 23:30:30,973 [foster.py] => Trainable params: 85960076
2024-08-19 23:30:31,089 [foster.py] => per cls weights : [1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 0.76855853 0.76855853 0.76855853 0.76855853 0.76855853 0.76855853
 0.76855853 0.76855853 0.76855853 0.76855853]
  0%|          | 0/1 [00:00<?, ?it/s]Task 6, Epoch 1/1 => Loss 5.544, Loss_clf 1.025, Loss_fe 1.735, Loss_kd 2.386, Train_accy 68.93, Test_accy 82.54:   0%|          | 0/1 [00:50<?, ?it/s]Task 6, Epoch 1/1 => Loss 5.544, Loss_clf 1.025, Loss_fe 1.735, Loss_kd 2.386, Train_accy 68.93, Test_accy 82.54: 100%|██████████| 1/1 [00:50<00:00, 50.59s/it]Task 6, Epoch 1/1 => Loss 5.544, Loss_clf 1.025, Loss_fe 1.735, Loss_kd 2.386, Train_accy 68.93, Test_accy 82.54: 100%|██████████| 1/1 [00:50<00:00, 50.59s/it]
2024-08-19 23:31:21,686 [foster.py] => Task 6, Epoch 1/1 => Loss 5.544, Loss_clf 1.025, Loss_fe 1.735, Loss_kd 2.386, Train_accy 68.93, Test_accy 82.54
2024-08-19 23:31:21,687 [foster.py] => do not weight align teacher!
2024-08-19 23:31:21,689 [foster.py] => per cls weights : [1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 0.66898913 0.66898913 0.66898913 0.66898913 0.66898913 0.66898913
 0.66898913 0.66898913 0.66898913 0.66898913]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 2.557,  Train_accy 61.39, Test_accy 82.09:   0%|          | 0/1 [00:50<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 2.557,  Train_accy 61.39, Test_accy 82.09: 100%|██████████| 1/1 [00:50<00:00, 50.35s/it]SNet: Task 6, Epoch 1/1 => Loss 2.557,  Train_accy 61.39, Test_accy 82.09: 100%|██████████| 1/1 [00:50<00:00, 50.35s/it]
2024-08-19 23:32:13,568 [foster.py] => SNet: Task 6, Epoch 1/1 => Loss 2.557,  Train_accy 61.39, Test_accy 82.09
2024-08-19 23:32:13,568 [foster.py] => do not weight align student!
2024-08-19 23:32:24,063 [foster.py] => darknet eval: 
2024-08-19 23:32:24,063 [foster.py] => CNN top1 curve: 82.09
2024-08-19 23:32:24,063 [foster.py] => CNN top5 curve: 97.54
2024-08-19 23:32:24,065 [base.py] => Reducing exemplars...(28 per classes)
2024-08-19 23:32:42,509 [base.py] => Constructing exemplars...(28 per classes)
2024-08-19 23:33:39,298 [foster.py] => Exemplar size: 1960
2024-08-19 23:33:39,298 [trainer.py] => CNN: {'total': 82.54, '00-09': 81.8, '10-19': 78.8, '20-29': 89.0, '30-39': 81.1, '40-49': 79.1, '50-59': 81.1, '60-69': 86.9, 'old': 81.82, 'new': 86.9}
2024-08-19 23:33:39,298 [trainer.py] => NME: {'total': 84.99, '00-09': 87.9, '10-19': 81.7, '20-29': 90.2, '30-39': 80.8, '40-49': 84.8, '50-59': 80.4, '60-69': 89.1, 'old': 84.3, 'new': 89.1}
2024-08-19 23:33:39,298 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8, 82.12, 82.54]
2024-08-19 23:33:39,298 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04, 97.42, 97.33]
2024-08-19 23:33:39,298 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74, 86.2, 84.99]
2024-08-19 23:33:39,298 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2, 97.9, 97.91]

Average Accuracy (CNN): 84.01
Average Accuracy (NME): 87.91
2024-08-19 23:33:39,298 [trainer.py] => Average Accuracy (CNN): 84.01
2024-08-19 23:33:39,298 [trainer.py] => Average Accuracy (NME): 87.91
2024-08-19 23:33:39,298 [trainer.py] => Train Time: 616.47
2024-08-19 23:33:39,298 [trainer.py] => Test Time: 147.22000000000003 

2024-08-19 23:33:39,300 [trainer.py] => All params: 171804872
2024-08-19 23:33:39,301 [trainer.py] => Trainable params: 85960076
2024-08-19 23:33:40,830 [foster.py] => Learning on 70-80
2024-08-19 23:33:40,832 [foster.py] => All params: 171835622
2024-08-19 23:33:40,833 [foster.py] => Trainable params: 85983136
2024-08-19 23:33:40,953 [foster.py] => per cls weights : [1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 0.70941937 0.70941937
 0.70941937 0.70941937 0.70941937 0.70941937 0.70941937 0.70941937
 0.70941937 0.70941937]
  0%|          | 0/1 [00:00<?, ?it/s]Task 7, Epoch 1/1 => Loss 6.260, Loss_clf 1.219, Loss_fe 2.084, Loss_kd 2.587, Train_accy 57.49, Test_accy 79.05:   0%|          | 0/1 [00:53<?, ?it/s]Task 7, Epoch 1/1 => Loss 6.260, Loss_clf 1.219, Loss_fe 2.084, Loss_kd 2.587, Train_accy 57.49, Test_accy 79.05: 100%|██████████| 1/1 [00:53<00:00, 53.06s/it]Task 7, Epoch 1/1 => Loss 6.260, Loss_clf 1.219, Loss_fe 2.084, Loss_kd 2.587, Train_accy 57.49, Test_accy 79.05: 100%|██████████| 1/1 [00:53<00:00, 53.06s/it]
2024-08-19 23:34:34,014 [foster.py] => Task 7, Epoch 1/1 => Loss 6.260, Loss_clf 1.219, Loss_fe 2.084, Loss_kd 2.587, Train_accy 57.49, Test_accy 79.05
2024-08-19 23:34:34,015 [foster.py] => do not weight align teacher!
2024-08-19 23:34:34,017 [foster.py] => per cls weights : [1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 0.60609409 0.60609409
 0.60609409 0.60609409 0.60609409 0.60609409 0.60609409 0.60609409
 0.60609409 0.60609409]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.991,  Train_accy 37.69, Test_accy 77.56:   0%|          | 0/1 [00:51<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.991,  Train_accy 37.69, Test_accy 77.56: 100%|██████████| 1/1 [00:51<00:00, 51.70s/it]SNet: Task 7, Epoch 1/1 => Loss 2.991,  Train_accy 37.69, Test_accy 77.56: 100%|██████████| 1/1 [00:51<00:00, 51.70s/it]
2024-08-19 23:35:27,212 [foster.py] => SNet: Task 7, Epoch 1/1 => Loss 2.991,  Train_accy 37.69, Test_accy 77.56
2024-08-19 23:35:27,212 [foster.py] => do not weight align student!
2024-08-19 23:35:38,676 [foster.py] => darknet eval: 
2024-08-19 23:35:38,676 [foster.py] => CNN top1 curve: 77.56
2024-08-19 23:35:38,677 [foster.py] => CNN top5 curve: 96.86
2024-08-19 23:35:38,678 [base.py] => Reducing exemplars...(25 per classes)
2024-08-19 23:35:58,915 [base.py] => Constructing exemplars...(25 per classes)
2024-08-19 23:37:00,367 [foster.py] => Exemplar size: 2000
2024-08-19 23:37:00,367 [trainer.py] => CNN: {'total': 79.05, '00-09': 83.6, '10-19': 80.4, '20-29': 89.9, '30-39': 80.3, '40-49': 78.1, '50-59': 80.8, '60-69': 81.9, '70-79': 57.4, 'old': 82.14, 'new': 57.4}
2024-08-19 23:37:00,367 [trainer.py] => NME: {'total': 82.7, '00-09': 87.4, '10-19': 81.1, '20-29': 88.7, '30-39': 80.2, '40-49': 83.3, '50-59': 78.0, '60-69': 85.6, '70-79': 77.3, 'old': 83.47, 'new': 77.3}
2024-08-19 23:37:00,367 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8, 82.12, 82.54, 79.05]
2024-08-19 23:37:00,367 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04, 97.42, 97.33, 97.24]
2024-08-19 23:37:00,367 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74, 86.2, 84.99, 82.7]
2024-08-19 23:37:00,367 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2, 97.9, 97.91, 97.4]

Average Accuracy (CNN): 83.39
Average Accuracy (NME): 87.26
2024-08-19 23:37:00,367 [trainer.py] => Average Accuracy (CNN): 83.39
2024-08-19 23:37:00,367 [trainer.py] => Average Accuracy (NME): 87.26
2024-08-19 23:37:00,367 [trainer.py] => Train Time: 734.25
2024-08-19 23:37:00,368 [trainer.py] => Test Time: 189.41000000000003 

2024-08-19 23:37:00,369 [trainer.py] => All params: 171835622
2024-08-19 23:37:00,370 [trainer.py] => Trainable params: 85983136
2024-08-19 23:37:01,977 [foster.py] => Learning on 80-90
2024-08-19 23:37:01,979 [foster.py] => All params: 171866372
2024-08-19 23:37:01,980 [foster.py] => Trainable params: 86006196
2024-08-19 23:37:02,121 [foster.py] => per cls weights : [1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  0.66628401 0.66628401 0.66628401 0.66628401
 0.66628401 0.66628401 0.66628401 0.66628401 0.66628401 0.66628401]
  0%|          | 0/1 [00:00<?, ?it/s]Task 8, Epoch 1/1 => Loss 6.456, Loss_clf 1.222, Loss_fe 2.139, Loss_kd 2.751, Train_accy 54.90, Test_accy 77.56:   0%|          | 0/1 [00:55<?, ?it/s]Task 8, Epoch 1/1 => Loss 6.456, Loss_clf 1.222, Loss_fe 2.139, Loss_kd 2.751, Train_accy 54.90, Test_accy 77.56: 100%|██████████| 1/1 [00:55<00:00, 55.80s/it]Task 8, Epoch 1/1 => Loss 6.456, Loss_clf 1.222, Loss_fe 2.139, Loss_kd 2.751, Train_accy 54.90, Test_accy 77.56: 100%|██████████| 1/1 [00:55<00:00, 55.80s/it]
2024-08-19 23:37:57,921 [foster.py] => Task 8, Epoch 1/1 => Loss 6.456, Loss_clf 1.222, Loss_fe 2.139, Loss_kd 2.751, Train_accy 54.90, Test_accy 77.56
2024-08-19 23:37:57,922 [foster.py] => do not weight align teacher!
2024-08-19 23:37:57,924 [foster.py] => per cls weights : [1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 0.56219541 0.56219541 0.56219541 0.56219541
 0.56219541 0.56219541 0.56219541 0.56219541 0.56219541 0.56219541]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 3.113,  Train_accy 39.21, Test_accy 75.04:   0%|          | 0/1 [00:53<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 3.113,  Train_accy 39.21, Test_accy 75.04: 100%|██████████| 1/1 [00:53<00:00, 53.20s/it]SNet: Task 8, Epoch 1/1 => Loss 3.113,  Train_accy 39.21, Test_accy 75.04: 100%|██████████| 1/1 [00:53<00:00, 53.20s/it]
2024-08-19 23:38:52,688 [foster.py] => SNet: Task 8, Epoch 1/1 => Loss 3.113,  Train_accy 39.21, Test_accy 75.04
2024-08-19 23:38:52,688 [foster.py] => do not weight align student!
2024-08-19 23:39:05,522 [foster.py] => darknet eval: 
2024-08-19 23:39:05,522 [foster.py] => CNN top1 curve: 75.04
2024-08-19 23:39:05,522 [foster.py] => CNN top5 curve: 95.77
2024-08-19 23:39:05,524 [base.py] => Reducing exemplars...(22 per classes)
2024-08-19 23:39:27,355 [base.py] => Constructing exemplars...(22 per classes)
2024-08-19 23:40:33,708 [foster.py] => Exemplar size: 1980
2024-08-19 23:40:33,708 [trainer.py] => CNN: {'total': 77.56, '00-09': 83.4, '10-19': 78.4, '20-29': 87.7, '30-39': 78.2, '40-49': 77.6, '50-59': 79.9, '60-69': 85.9, '70-79': 60.5, '80-89': 66.4, 'old': 78.95, 'new': 66.4}
2024-08-19 23:40:33,708 [trainer.py] => NME: {'total': 81.37, '00-09': 85.5, '10-19': 80.3, '20-29': 88.3, '30-39': 79.1, '40-49': 81.7, '50-59': 77.5, '60-69': 84.5, '70-79': 74.5, '80-89': 80.9, 'old': 81.42, 'new': 80.9}
2024-08-19 23:40:33,708 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8, 82.12, 82.54, 79.05, 77.56]
2024-08-19 23:40:33,708 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04, 97.42, 97.33, 97.24, 96.66]
2024-08-19 23:40:33,708 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74, 86.2, 84.99, 82.7, 81.37]
2024-08-19 23:40:33,708 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2, 97.9, 97.91, 97.4, 96.79]

Average Accuracy (CNN): 82.74
Average Accuracy (NME): 86.6
2024-08-19 23:40:33,708 [trainer.py] => Average Accuracy (CNN): 82.74
2024-08-19 23:40:33,708 [trainer.py] => Average Accuracy (NME): 86.6
2024-08-19 23:40:33,708 [trainer.py] => Train Time: 857.71
2024-08-19 23:40:33,708 [trainer.py] => Test Time: 236.82000000000002 

2024-08-19 23:40:33,710 [trainer.py] => All params: 171866372
2024-08-19 23:40:33,711 [trainer.py] => Trainable params: 86006196
2024-08-19 23:40:35,318 [foster.py] => Learning on 90-100
2024-08-19 23:40:35,320 [foster.py] => All params: 171897122
2024-08-19 23:40:35,321 [foster.py] => Trainable params: 86029256
2024-08-19 23:40:35,451 [foster.py] => per cls weights : [1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 0.61781731 0.61781731 0.61781731 0.61781731 0.61781731 0.61781731
 0.61781731 0.61781731 0.61781731 0.61781731]
  0%|          | 0/1 [00:00<?, ?it/s]Task 9, Epoch 1/1 => Loss 6.861, Loss_clf 1.285, Loss_fe 2.242, Loss_kd 3.000, Train_accy 51.99, Test_accy 75.71:   0%|          | 0/1 [00:58<?, ?it/s]Task 9, Epoch 1/1 => Loss 6.861, Loss_clf 1.285, Loss_fe 2.242, Loss_kd 3.000, Train_accy 51.99, Test_accy 75.71: 100%|██████████| 1/1 [00:58<00:00, 58.16s/it]Task 9, Epoch 1/1 => Loss 6.861, Loss_clf 1.285, Loss_fe 2.242, Loss_kd 3.000, Train_accy 51.99, Test_accy 75.71: 100%|██████████| 1/1 [00:58<00:00, 58.16s/it]
2024-08-19 23:41:33,614 [foster.py] => Task 9, Epoch 1/1 => Loss 6.861, Loss_clf 1.285, Loss_fe 2.242, Loss_kd 3.000, Train_accy 51.99, Test_accy 75.71
2024-08-19 23:41:33,616 [foster.py] => do not weight align teacher!
2024-08-19 23:41:33,620 [foster.py] => per cls weights : [1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 0.5146777
 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777
 0.5146777 0.5146777]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 3.316,  Train_accy 32.52, Test_accy 73.48:   0%|          | 0/1 [00:54<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 3.316,  Train_accy 32.52, Test_accy 73.48: 100%|██████████| 1/1 [00:54<00:00, 54.50s/it]SNet: Task 9, Epoch 1/1 => Loss 3.316,  Train_accy 32.52, Test_accy 73.48: 100%|██████████| 1/1 [00:54<00:00, 54.50s/it]
2024-08-19 23:42:29,702 [foster.py] => SNet: Task 9, Epoch 1/1 => Loss 3.316,  Train_accy 32.52, Test_accy 73.48
2024-08-19 23:42:29,702 [foster.py] => do not weight align student!
2024-08-19 23:42:44,598 [foster.py] => darknet eval: 
2024-08-19 23:42:44,598 [foster.py] => CNN top1 curve: 73.48
2024-08-19 23:42:44,598 [foster.py] => CNN top5 curve: 95.08
2024-08-19 23:42:44,600 [base.py] => Reducing exemplars...(20 per classes)
2024-08-19 23:43:08,381 [base.py] => Constructing exemplars...(20 per classes)
2024-08-19 23:44:21,332 [foster.py] => Exemplar size: 2000
2024-08-19 23:44:21,332 [trainer.py] => CNN: {'total': 75.71, '00-09': 82.2, '10-19': 82.8, '20-29': 86.4, '30-39': 79.5, '40-49': 75.6, '50-59': 77.4, '60-69': 85.1, '70-79': 63.1, '80-89': 63.2, '90-99': 61.8, 'old': 77.26, 'new': 61.8}
2024-08-19 23:44:21,332 [trainer.py] => NME: {'total': 80.03, '00-09': 84.4, '10-19': 79.5, '20-29': 87.6, '30-39': 79.0, '40-49': 81.8, '50-59': 75.6, '60-69': 83.5, '70-79': 74.1, '80-89': 76.9, '90-99': 77.9, 'old': 80.27, 'new': 77.9}
2024-08-19 23:44:21,332 [trainer.py] => CNN top1 curve: [81.3, 88.6, 85.73, 84.0, 83.8, 82.12, 82.54, 79.05, 77.56, 75.71]
2024-08-19 23:44:21,332 [trainer.py] => CNN top5 curve: [97.6, 98.65, 98.37, 97.95, 98.04, 97.42, 97.33, 97.24, 96.66, 96.01]
2024-08-19 23:44:21,332 [trainer.py] => NME top1 curve: [85.5, 91.85, 91.27, 89.82, 85.74, 86.2, 84.99, 82.7, 81.37, 80.03]
2024-08-19 23:44:21,332 [trainer.py] => NME top5 curve: [98.6, 99.35, 98.83, 98.78, 98.2, 97.9, 97.91, 97.4, 96.79, 95.77]

Average Accuracy (CNN): 82.04
Average Accuracy (NME): 85.95
2024-08-19 23:44:21,332 [trainer.py] => Average Accuracy (CNN): 82.04
2024-08-19 23:44:21,332 [trainer.py] => Average Accuracy (NME): 85.95
2024-08-19 23:44:21,332 [trainer.py] => Train Time: 986.9100000000001
2024-08-19 23:44:21,332 [trainer.py] => Test Time: 290.64000000000004 

Accuracy Matrix (CNN):
[[81.3 85.9 81.7 74.8 80.9 82.1 81.8 83.6 83.4 82.2]
 [ 0.  91.3 79.4 77.9 75.7 77.4 78.8 80.4 78.4 82.8]
 [ 0.   0.  96.1 92.8 89.7 85.7 89.  89.9 87.7 86.4]
 [ 0.   0.   0.  90.5 81.5 81.4 81.1 80.3 78.2 79.5]
 [ 0.   0.   0.   0.  91.2 78.5 79.1 78.1 77.6 75.6]
 [ 0.   0.   0.   0.   0.  87.6 81.1 80.8 79.9 77.4]
 [ 0.   0.   0.   0.   0.   0.  86.9 81.9 85.9 85.1]
 [ 0.   0.   0.   0.   0.   0.   0.  57.4 60.5 63.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.  66.4 63.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  61.8]]
2024-08-19 23:44:21,333 [trainer.py] => Forgetting (CNN): 7.077777777777778
Accuracy Matrix (NME):
[[85.5 94.1 92.  91.7 90.9 89.8 87.9 87.4 85.5 84.4]
 [ 0.  89.6 87.3 87.4 82.9 85.  81.7 81.1 80.3 79.5]
 [ 0.   0.  94.5 92.6 89.8 91.3 90.2 88.7 88.3 87.6]
 [ 0.   0.   0.  87.6 79.4 82.2 80.8 80.2 79.1 79. ]
 [ 0.   0.   0.   0.  85.7 85.  84.8 83.3 81.7 81.8]
 [ 0.   0.   0.   0.   0.  83.9 80.4 78.  77.5 75.6]
 [ 0.   0.   0.   0.   0.   0.  89.1 85.6 84.5 83.5]
 [ 0.   0.   0.   0.   0.   0.   0.  77.3 74.5 74.1]
 [ 0.   0.   0.   0.   0.   0.   0.   0.  80.9 76.9]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  77.9]]
2024-08-19 23:44:21,334 [trainer.py] => Forgetting (NME): 6.699999999999999
2024-08-19 23:44:23,445 [trainer.py] => config: ./exps/foster_cifar_B0_Inc20.json
2024-08-19 23:44:23,445 [trainer.py] => prefix: cil
2024-08-19 23:44:23,445 [trainer.py] => dataset: cifar224
2024-08-19 23:44:23,445 [trainer.py] => memory_size: 2000
2024-08-19 23:44:23,445 [trainer.py] => memory_per_class: 20
2024-08-19 23:44:23,445 [trainer.py] => fixed_memory: False
2024-08-19 23:44:23,445 [trainer.py] => shuffle: True
2024-08-19 23:44:23,445 [trainer.py] => init_cls: 5
2024-08-19 23:44:23,445 [trainer.py] => increment: 5
2024-08-19 23:44:23,445 [trainer.py] => model_name: foster
2024-08-19 23:44:23,445 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-08-19 23:44:23,445 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-19 23:44:23,445 [trainer.py] => seed: 1993
2024-08-19 23:44:23,445 [trainer.py] => beta1: 0.96
2024-08-19 23:44:23,445 [trainer.py] => beta2: 0.97
2024-08-19 23:44:23,445 [trainer.py] => oofc: ft
2024-08-19 23:44:23,445 [trainer.py] => is_teacher_wa: False
2024-08-19 23:44:23,445 [trainer.py] => is_student_wa: False
2024-08-19 23:44:23,445 [trainer.py] => lambda_okd: 1
2024-08-19 23:44:23,445 [trainer.py] => wa_value: 1
2024-08-19 23:44:23,445 [trainer.py] => init_epochs: 1
2024-08-19 23:44:23,445 [trainer.py] => init_lr: 0.001
2024-08-19 23:44:23,445 [trainer.py] => init_weight_decay: 0.0005
2024-08-19 23:44:23,445 [trainer.py] => boosting_epochs: 1
2024-08-19 23:44:23,445 [trainer.py] => compression_epochs: 1
2024-08-19 23:44:23,445 [trainer.py] => lr: 0.001
2024-08-19 23:44:23,445 [trainer.py] => batch_size: 48
2024-08-19 23:44:23,445 [trainer.py] => weight_decay: 0.0005
2024-08-19 23:44:23,445 [trainer.py] => num_workers: 8
2024-08-19 23:44:23,445 [trainer.py] => T: 2
2024-08-19 23:44:24,375 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-19 23:44:24,987 [trainer.py] => All params: 0
2024-08-19 23:44:24,987 [trainer.py] => Trainable params: 0
2024-08-19 23:44:26,408 [foster.py] => Learning on 0-5
2024-08-19 23:44:26,408 [foster.py] => All params: 85806346
2024-08-19 23:44:26,409 [foster.py] => Trainable params: 85806346
  0%|          | 0/1 [00:00<?, ?it/s]Task 0, Epoch 1/1 => Loss 0.927, Train_accy 66.68, Test_accy 77.20:   0%|          | 0/1 [00:10<?, ?it/s]Task 0, Epoch 1/1 => Loss 0.927, Train_accy 66.68, Test_accy 77.20: 100%|██████████| 1/1 [00:10<00:00, 10.05s/it]Task 0, Epoch 1/1 => Loss 0.927, Train_accy 66.68, Test_accy 77.20: 100%|██████████| 1/1 [00:10<00:00, 10.05s/it]
2024-08-19 23:44:36,755 [foster.py] => Task 0, Epoch 1/1 => Loss 0.927, Train_accy 66.68, Test_accy 77.20
2024-08-19 23:44:36,756 [base.py] => Reducing exemplars...(400 per classes)
2024-08-19 23:44:36,756 [base.py] => Constructing exemplars...(400 per classes)
2024-08-19 23:44:48,598 [foster.py] => Exemplar size: 2000
2024-08-19 23:44:48,599 [trainer.py] => CNN: {'total': 77.2, '00-04': 77.2, 'old': 0, 'new': 77.2}
2024-08-19 23:44:48,599 [trainer.py] => NME: {'total': 94.0, '00-04': 94.0, 'old': 0, 'new': 94.0}
2024-08-19 23:44:48,599 [trainer.py] => CNN top1 curve: [77.2]
2024-08-19 23:44:48,599 [trainer.py] => CNN top5 curve: [100.0]
2024-08-19 23:44:48,599 [trainer.py] => NME top1 curve: [94.0]
2024-08-19 23:44:48,599 [trainer.py] => NME top5 curve: [100.0]

Average Accuracy (CNN): 77.2
Average Accuracy (NME): 94.0
2024-08-19 23:44:48,599 [trainer.py] => Average Accuracy (CNN): 77.2
2024-08-19 23:44:48,599 [trainer.py] => Average Accuracy (NME): 94.0
2024-08-19 23:44:48,599 [trainer.py] => Train Time: 10.34
2024-08-19 23:44:48,599 [trainer.py] => Test Time: 1.93 

2024-08-19 23:44:48,600 [trainer.py] => All params: 85806346
2024-08-19 23:44:48,600 [trainer.py] => Trainable params: 85806346
2024-08-19 23:44:50,104 [foster.py] => Learning on 5-10
2024-08-19 23:44:50,105 [foster.py] => All params: 171624217
2024-08-19 23:44:50,106 [foster.py] => Trainable params: 85821716
2024-08-19 23:44:50,218 [foster.py] => per cls weights : [1.00000004 1.00000004 1.00000004 1.00000004 1.00000004 0.99999996
 0.99999996 0.99999996 0.99999996 0.99999996]
  0%|          | 0/1 [00:00<?, ?it/s]Task 1, Epoch 1/1 => Loss 3.090, Loss_clf 0.965, Loss_fe 0.982, Loss_kd 0.571, Train_accy 68.31, Test_accy 94.50:   0%|          | 0/1 [00:23<?, ?it/s]Task 1, Epoch 1/1 => Loss 3.090, Loss_clf 0.965, Loss_fe 0.982, Loss_kd 0.571, Train_accy 68.31, Test_accy 94.50: 100%|██████████| 1/1 [00:23<00:00, 23.72s/it]Task 1, Epoch 1/1 => Loss 3.090, Loss_clf 0.965, Loss_fe 0.982, Loss_kd 0.571, Train_accy 68.31, Test_accy 94.50: 100%|██████████| 1/1 [00:23<00:00, 23.72s/it]
2024-08-19 23:45:13,937 [foster.py] => Task 1, Epoch 1/1 => Loss 3.090, Loss_clf 0.965, Loss_fe 0.982, Loss_kd 0.571, Train_accy 68.31, Test_accy 94.50
2024-08-19 23:45:13,938 [foster.py] => do not weight align teacher!
2024-08-19 23:45:13,939 [foster.py] => per cls weights : [1.00000256 1.00000256 1.00000256 1.00000256 1.00000256 0.99999744
 0.99999744 0.99999744 0.99999744 0.99999744]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 1.510,  Train_accy 65.49, Test_accy 91.80:   0%|          | 0/1 [00:27<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 1.510,  Train_accy 65.49, Test_accy 91.80: 100%|██████████| 1/1 [00:27<00:00, 27.79s/it]SNet: Task 1, Epoch 1/1 => Loss 1.510,  Train_accy 65.49, Test_accy 91.80: 100%|██████████| 1/1 [00:27<00:00, 27.79s/it]
2024-08-19 23:45:43,197 [foster.py] => SNet: Task 1, Epoch 1/1 => Loss 1.510,  Train_accy 65.49, Test_accy 91.80
2024-08-19 23:45:43,197 [foster.py] => do not weight align student!
2024-08-19 23:45:44,968 [foster.py] => darknet eval: 
2024-08-19 23:45:44,968 [foster.py] => CNN top1 curve: 91.8
2024-08-19 23:45:44,968 [foster.py] => CNN top5 curve: 99.6
2024-08-19 23:45:44,970 [base.py] => Reducing exemplars...(200 per classes)
2024-08-19 23:45:49,008 [base.py] => Constructing exemplars...(200 per classes)
2024-08-19 23:46:08,066 [foster.py] => Exemplar size: 2000
2024-08-19 23:46:08,067 [trainer.py] => CNN: {'total': 94.5, '00-04': 94.4, '05-09': 94.6, 'old': 94.4, 'new': 94.6}
2024-08-19 23:46:08,067 [trainer.py] => NME: {'total': 97.7, '00-04': 99.0, '05-09': 96.4, 'old': 99.0, 'new': 96.4}
2024-08-19 23:46:08,067 [trainer.py] => CNN top1 curve: [77.2, 94.5]
2024-08-19 23:46:08,067 [trainer.py] => CNN top5 curve: [100.0, 99.9]
2024-08-19 23:46:08,067 [trainer.py] => NME top1 curve: [94.0, 97.7]
2024-08-19 23:46:08,067 [trainer.py] => NME top5 curve: [100.0, 99.9]

Average Accuracy (CNN): 85.85
Average Accuracy (NME): 95.85
2024-08-19 23:46:08,067 [trainer.py] => Average Accuracy (CNN): 85.85
2024-08-19 23:46:08,067 [trainer.py] => Average Accuracy (NME): 95.85
2024-08-19 23:46:08,067 [trainer.py] => Train Time: 65.18
2024-08-19 23:46:08,067 [trainer.py] => Test Time: 7.71 

2024-08-19 23:46:08,068 [trainer.py] => All params: 171624217
2024-08-19 23:46:08,069 [trainer.py] => Trainable params: 85821716
2024-08-19 23:46:09,581 [foster.py] => Learning on 10-15
2024-08-19 23:46:09,583 [foster.py] => All params: 171639592
2024-08-19 23:46:09,584 [foster.py] => Trainable params: 85833246
2024-08-19 23:46:09,693 [foster.py] => per cls weights : [1.00009488 1.00009488 1.00009488 1.00009488 1.00009488 1.00009488
 1.00009488 1.00009488 1.00009488 1.00009488 0.99981024 0.99981024
 0.99981024 0.99981024 0.99981024]
  0%|          | 0/1 [00:00<?, ?it/s]Task 2, Epoch 1/1 => Loss 4.016, Loss_clf 1.030, Loss_fe 1.403, Loss_kd 1.056, Train_accy 66.93, Test_accy 91.27:   0%|          | 0/1 [00:25<?, ?it/s]Task 2, Epoch 1/1 => Loss 4.016, Loss_clf 1.030, Loss_fe 1.403, Loss_kd 1.056, Train_accy 66.93, Test_accy 91.27: 100%|██████████| 1/1 [00:25<00:00, 25.11s/it]Task 2, Epoch 1/1 => Loss 4.016, Loss_clf 1.030, Loss_fe 1.403, Loss_kd 1.056, Train_accy 66.93, Test_accy 91.27: 100%|██████████| 1/1 [00:25<00:00, 25.11s/it]
2024-08-19 23:46:34,809 [foster.py] => Task 2, Epoch 1/1 => Loss 4.016, Loss_clf 1.030, Loss_fe 1.403, Loss_kd 1.056, Train_accy 66.93, Test_accy 91.27
2024-08-19 23:46:34,810 [foster.py] => do not weight align teacher!
2024-08-19 23:46:34,813 [foster.py] => per cls weights : [1.00075432 1.00075432 1.00075432 1.00075432 1.00075432 1.00075432
 1.00075432 1.00075432 1.00075432 1.00075432 0.99849137 0.99849137
 0.99849137 0.99849137 0.99849137]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 1.653,  Train_accy 68.33, Test_accy 89.80:   0%|          | 0/1 [00:28<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 1.653,  Train_accy 68.33, Test_accy 89.80: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it]SNet: Task 2, Epoch 1/1 => Loss 1.653,  Train_accy 68.33, Test_accy 89.80: 100%|██████████| 1/1 [00:28<00:00, 28.53s/it]
2024-08-19 23:47:04,932 [foster.py] => SNet: Task 2, Epoch 1/1 => Loss 1.653,  Train_accy 68.33, Test_accy 89.80
2024-08-19 23:47:04,932 [foster.py] => do not weight align student!
2024-08-19 23:47:07,429 [foster.py] => darknet eval: 
2024-08-19 23:47:07,429 [foster.py] => CNN top1 curve: 89.8
2024-08-19 23:47:07,429 [foster.py] => CNN top5 curve: 99.4
2024-08-19 23:47:07,431 [base.py] => Reducing exemplars...(133 per classes)
2024-08-19 23:47:13,657 [base.py] => Constructing exemplars...(133 per classes)
2024-08-19 23:47:34,208 [foster.py] => Exemplar size: 1995
2024-08-19 23:47:34,208 [trainer.py] => CNN: {'total': 91.27, '00-04': 95.0, '05-09': 84.6, '10-14': 94.2, 'old': 89.8, 'new': 94.2}
2024-08-19 23:47:34,208 [trainer.py] => NME: {'total': 94.33, '00-04': 97.2, '05-09': 92.8, '10-14': 93.0, 'old': 95.0, 'new': 93.0}
2024-08-19 23:47:34,208 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27]
2024-08-19 23:47:34,208 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2]
2024-08-19 23:47:34,208 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33]
2024-08-19 23:47:34,208 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8]

Average Accuracy (CNN): 87.66
Average Accuracy (NME): 95.34
2024-08-19 23:47:34,208 [trainer.py] => Average Accuracy (CNN): 87.66
2024-08-19 23:47:34,208 [trainer.py] => Average Accuracy (NME): 95.34
2024-08-19 23:47:34,208 [trainer.py] => Train Time: 123.0
2024-08-19 23:47:34,208 [trainer.py] => Test Time: 16.2 

2024-08-19 23:47:34,210 [trainer.py] => All params: 171639592
2024-08-19 23:47:34,211 [trainer.py] => Trainable params: 85833246
2024-08-19 23:47:35,725 [foster.py] => Learning on 15-20
2024-08-19 23:47:35,726 [foster.py] => All params: 171654967
2024-08-19 23:47:35,727 [foster.py] => Trainable params: 85844776
2024-08-19 23:47:35,846 [foster.py] => per cls weights : [1.00109772 1.00109772 1.00109772 1.00109772 1.00109772 1.00109772
 1.00109772 1.00109772 1.00109772 1.00109772 1.00109772 1.00109772
 1.00109772 1.00109772 1.00109772 0.99670685 0.99670685 0.99670685
 0.99670685 0.99670685]
  0%|          | 0/1 [00:00<?, ?it/s]Task 3, Epoch 1/1 => Loss 4.458, Loss_clf 1.099, Loss_fe 1.525, Loss_kd 1.376, Train_accy 66.23, Test_accy 90.40:   0%|          | 0/1 [00:26<?, ?it/s]Task 3, Epoch 1/1 => Loss 4.458, Loss_clf 1.099, Loss_fe 1.525, Loss_kd 1.376, Train_accy 66.23, Test_accy 90.40: 100%|██████████| 1/1 [00:26<00:00, 26.39s/it]Task 3, Epoch 1/1 => Loss 4.458, Loss_clf 1.099, Loss_fe 1.525, Loss_kd 1.376, Train_accy 66.23, Test_accy 90.40: 100%|██████████| 1/1 [00:26<00:00, 26.39s/it]
2024-08-19 23:48:02,239 [foster.py] => Task 3, Epoch 1/1 => Loss 4.458, Loss_clf 1.099, Loss_fe 1.525, Loss_kd 1.376, Train_accy 66.23, Test_accy 90.40
2024-08-19 23:48:02,240 [foster.py] => do not weight align teacher!
2024-08-19 23:48:02,241 [foster.py] => per cls weights : [1.00436993 1.00436993 1.00436993 1.00436993 1.00436993 1.00436993
 1.00436993 1.00436993 1.00436993 1.00436993 1.00436993 1.00436993
 1.00436993 1.00436993 1.00436993 0.98689021 0.98689021 0.98689021
 0.98689021 0.98689021]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 1.758,  Train_accy 68.08, Test_accy 89.20:   0%|          | 0/1 [00:29<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 1.758,  Train_accy 68.08, Test_accy 89.20: 100%|██████████| 1/1 [00:29<00:00, 29.24s/it]SNet: Task 3, Epoch 1/1 => Loss 1.758,  Train_accy 68.08, Test_accy 89.20: 100%|██████████| 1/1 [00:29<00:00, 29.25s/it]
2024-08-19 23:48:33,056 [foster.py] => SNet: Task 3, Epoch 1/1 => Loss 1.758,  Train_accy 68.08, Test_accy 89.20
2024-08-19 23:48:33,057 [foster.py] => do not weight align student!
2024-08-19 23:48:36,239 [foster.py] => darknet eval: 
2024-08-19 23:48:36,240 [foster.py] => CNN top1 curve: 89.2
2024-08-19 23:48:36,240 [foster.py] => CNN top5 curve: 98.9
2024-08-19 23:48:36,241 [base.py] => Reducing exemplars...(100 per classes)
2024-08-19 23:48:44,093 [base.py] => Constructing exemplars...(100 per classes)
2024-08-19 23:49:06,619 [foster.py] => Exemplar size: 2000
2024-08-19 23:49:06,620 [trainer.py] => CNN: {'total': 90.4, '00-04': 95.8, '05-09': 84.0, '10-14': 87.8, '15-19': 94.0, 'old': 89.2, 'new': 94.0}
2024-08-19 23:49:06,620 [trainer.py] => NME: {'total': 92.4, '00-04': 97.8, '05-09': 91.2, '10-14': 91.0, '15-19': 89.6, 'old': 93.33, 'new': 89.6}
2024-08-19 23:49:06,620 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4]
2024-08-19 23:49:06,620 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7]
2024-08-19 23:49:06,620 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4]
2024-08-19 23:49:06,620 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75]

Average Accuracy (CNN): 88.34
Average Accuracy (NME): 94.61
2024-08-19 23:49:06,620 [trainer.py] => Average Accuracy (CNN): 88.34
2024-08-19 23:49:06,620 [trainer.py] => Average Accuracy (NME): 94.61
2024-08-19 23:49:06,620 [trainer.py] => Train Time: 183.48
2024-08-19 23:49:06,620 [trainer.py] => Test Time: 27.259999999999998 

2024-08-19 23:49:06,621 [trainer.py] => All params: 171654967
2024-08-19 23:49:06,622 [trainer.py] => Trainable params: 85844776
2024-08-19 23:49:08,112 [foster.py] => Learning on 20-25
2024-08-19 23:49:08,114 [foster.py] => All params: 171670342
2024-08-19 23:49:08,114 [foster.py] => Trainable params: 85856306
2024-08-19 23:49:08,231 [foster.py] => per cls weights : [1.00338549 1.00338549 1.00338549 1.00338549 1.00338549 1.00338549
 1.00338549 1.00338549 1.00338549 1.00338549 1.00338549 1.00338549
 1.00338549 1.00338549 1.00338549 1.00338549 1.00338549 1.00338549
 1.00338549 1.00338549 0.98645805 0.98645805 0.98645805 0.98645805
 0.98645805]
  0%|          | 0/1 [00:00<?, ?it/s]Task 4, Epoch 1/1 => Loss 4.536, Loss_clf 0.977, Loss_fe 1.583, Loss_kd 1.580, Train_accy 72.56, Test_accy 90.24:   0%|          | 0/1 [00:27<?, ?it/s]Task 4, Epoch 1/1 => Loss 4.536, Loss_clf 0.977, Loss_fe 1.583, Loss_kd 1.580, Train_accy 72.56, Test_accy 90.24: 100%|██████████| 1/1 [00:27<00:00, 27.71s/it]Task 4, Epoch 1/1 => Loss 4.536, Loss_clf 0.977, Loss_fe 1.583, Loss_kd 1.580, Train_accy 72.56, Test_accy 90.24: 100%|██████████| 1/1 [00:27<00:00, 27.71s/it]
2024-08-19 23:49:35,943 [foster.py] => Task 4, Epoch 1/1 => Loss 4.536, Loss_clf 0.977, Loss_fe 1.583, Loss_kd 1.580, Train_accy 72.56, Test_accy 90.24
2024-08-19 23:49:35,945 [foster.py] => do not weight align teacher!
2024-08-19 23:49:35,947 [foster.py] => per cls weights : [1.00960182 1.00960182 1.00960182 1.00960182 1.00960182 1.00960182
 1.00960182 1.00960182 1.00960182 1.00960182 1.00960182 1.00960182
 1.00960182 1.00960182 1.00960182 1.00960182 1.00960182 1.00960182
 1.00960182 1.00960182 0.96159272 0.96159272 0.96159272 0.96159272
 0.96159272]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 1.794,  Train_accy 70.11, Test_accy 89.92:   0%|          | 0/1 [00:29<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 1.794,  Train_accy 70.11, Test_accy 89.92: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it]SNet: Task 4, Epoch 1/1 => Loss 1.794,  Train_accy 70.11, Test_accy 89.92: 100%|██████████| 1/1 [00:29<00:00, 29.90s/it]
2024-08-19 23:50:07,419 [foster.py] => SNet: Task 4, Epoch 1/1 => Loss 1.794,  Train_accy 70.11, Test_accy 89.92
2024-08-19 23:50:07,419 [foster.py] => do not weight align student!
2024-08-19 23:50:11,318 [foster.py] => darknet eval: 
2024-08-19 23:50:11,319 [foster.py] => CNN top1 curve: 89.92
2024-08-19 23:50:11,319 [foster.py] => CNN top5 curve: 98.68
2024-08-19 23:50:11,320 [base.py] => Reducing exemplars...(80 per classes)
2024-08-19 23:50:20,682 [base.py] => Constructing exemplars...(80 per classes)
2024-08-19 23:50:45,416 [foster.py] => Exemplar size: 2000
2024-08-19 23:50:45,416 [trainer.py] => CNN: {'total': 90.24, '00-04': 95.4, '05-09': 88.6, '10-14': 84.6, '15-19': 87.4, '20-24': 95.2, 'old': 89.0, 'new': 95.2}
2024-08-19 23:50:45,417 [trainer.py] => NME: {'total': 90.8, '00-04': 97.6, '05-09': 90.2, '10-14': 88.4, '15-19': 88.2, '20-24': 89.6, 'old': 91.1, 'new': 89.6}
2024-08-19 23:50:45,417 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24]
2024-08-19 23:50:45,417 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96]
2024-08-19 23:50:45,417 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8]
2024-08-19 23:50:45,417 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68]

Average Accuracy (CNN): 88.72
Average Accuracy (NME): 93.85
2024-08-19 23:50:45,417 [trainer.py] => Average Accuracy (CNN): 88.72
2024-08-19 23:50:45,417 [trainer.py] => Average Accuracy (NME): 93.85
2024-08-19 23:50:45,417 [trainer.py] => Train Time: 246.64999999999998
2024-08-19 23:50:45,417 [trainer.py] => Test Time: 40.989999999999995 

2024-08-19 23:50:45,418 [trainer.py] => All params: 171670342
2024-08-19 23:50:45,419 [trainer.py] => Trainable params: 85856306
2024-08-19 23:50:46,988 [foster.py] => Learning on 25-30
2024-08-19 23:50:46,990 [foster.py] => All params: 171685717
2024-08-19 23:50:46,990 [foster.py] => Trainable params: 85867836
2024-08-19 23:50:47,110 [foster.py] => per cls weights : [1.00640205 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205
 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205
 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205
 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205 1.00640205
 1.00640205 0.96798976 0.96798976 0.96798976 0.96798976 0.96798976]
  0%|          | 0/1 [00:00<?, ?it/s]Task 5, Epoch 1/1 => Loss 4.681, Loss_clf 1.007, Loss_fe 1.601, Loss_kd 1.727, Train_accy 73.20, Test_accy 88.23:   0%|          | 0/1 [00:29<?, ?it/s]Task 5, Epoch 1/1 => Loss 4.681, Loss_clf 1.007, Loss_fe 1.601, Loss_kd 1.727, Train_accy 73.20, Test_accy 88.23: 100%|██████████| 1/1 [00:29<00:00, 29.02s/it]Task 5, Epoch 1/1 => Loss 4.681, Loss_clf 1.007, Loss_fe 1.601, Loss_kd 1.727, Train_accy 73.20, Test_accy 88.23: 100%|██████████| 1/1 [00:29<00:00, 29.02s/it]
2024-08-19 23:51:16,131 [foster.py] => Task 5, Epoch 1/1 => Loss 4.681, Loss_clf 1.007, Loss_fe 1.601, Loss_kd 1.727, Train_accy 73.20, Test_accy 88.23
2024-08-19 23:51:16,131 [foster.py] => do not weight align teacher!
2024-08-19 23:51:16,132 [foster.py] => per cls weights : [1.01478984 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984
 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984
 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984
 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984 1.01478984
 1.01478984 0.92605078 0.92605078 0.92605078 0.92605078 0.92605078]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 1.792,  Train_accy 71.62, Test_accy 87.40:   0%|          | 0/1 [00:30<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 1.792,  Train_accy 71.62, Test_accy 87.40: 100%|██████████| 1/1 [00:30<00:00, 30.72s/it]SNet: Task 5, Epoch 1/1 => Loss 1.792,  Train_accy 71.62, Test_accy 87.40: 100%|██████████| 1/1 [00:30<00:00, 30.72s/it]
2024-08-19 23:51:48,334 [foster.py] => SNet: Task 5, Epoch 1/1 => Loss 1.792,  Train_accy 71.62, Test_accy 87.40
2024-08-19 23:51:48,334 [foster.py] => do not weight align student!
2024-08-19 23:51:52,999 [foster.py] => darknet eval: 
2024-08-19 23:51:52,999 [foster.py] => CNN top1 curve: 87.4
2024-08-19 23:51:52,999 [foster.py] => CNN top5 curve: 98.4
2024-08-19 23:51:53,000 [base.py] => Reducing exemplars...(66 per classes)
2024-08-19 23:52:04,275 [base.py] => Constructing exemplars...(66 per classes)
2024-08-19 23:52:31,348 [foster.py] => Exemplar size: 1980
2024-08-19 23:52:31,349 [trainer.py] => CNN: {'total': 88.23, '00-04': 95.2, '05-09': 77.6, '10-14': 82.8, '15-19': 85.2, '20-24': 93.2, '25-29': 95.4, 'old': 86.8, 'new': 95.4}
2024-08-19 23:52:31,349 [trainer.py] => NME: {'total': 90.87, '00-04': 97.8, '05-09': 87.6, '10-14': 87.2, '15-19': 87.8, '20-24': 92.6, '25-29': 92.2, 'old': 90.6, 'new': 92.2}
2024-08-19 23:52:31,349 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23]
2024-08-19 23:52:31,349 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47]
2024-08-19 23:52:31,349 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87]
2024-08-19 23:52:31,349 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53]

Average Accuracy (CNN): 88.64
Average Accuracy (NME): 93.35
2024-08-19 23:52:31,349 [trainer.py] => Average Accuracy (CNN): 88.64
2024-08-19 23:52:31,349 [trainer.py] => Average Accuracy (NME): 93.35
2024-08-19 23:52:31,349 [trainer.py] => Train Time: 312.62
2024-08-19 23:52:31,349 [trainer.py] => Test Time: 57.309999999999995 

2024-08-19 23:52:31,350 [trainer.py] => All params: 171685717
2024-08-19 23:52:31,351 [trainer.py] => Trainable params: 85867836
2024-08-19 23:52:32,959 [foster.py] => Learning on 30-35
2024-08-19 23:52:32,960 [foster.py] => All params: 171701092
2024-08-19 23:52:32,961 [foster.py] => Trainable params: 85879366
2024-08-19 23:52:33,080 [foster.py] => per cls weights : [1.00975029 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029
 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029
 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029
 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029
 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029 1.00975029
 0.94149829 0.94149829 0.94149829 0.94149829 0.94149829]
  0%|          | 0/1 [00:00<?, ?it/s]Task 6, Epoch 1/1 => Loss 4.880, Loss_clf 1.066, Loss_fe 1.696, Loss_kd 1.815, Train_accy 68.10, Test_accy 85.94:   0%|          | 0/1 [00:30<?, ?it/s]Task 6, Epoch 1/1 => Loss 4.880, Loss_clf 1.066, Loss_fe 1.696, Loss_kd 1.815, Train_accy 68.10, Test_accy 85.94: 100%|██████████| 1/1 [00:30<00:00, 30.21s/it]Task 6, Epoch 1/1 => Loss 4.880, Loss_clf 1.066, Loss_fe 1.696, Loss_kd 1.815, Train_accy 68.10, Test_accy 85.94: 100%|██████████| 1/1 [00:30<00:00, 30.21s/it]
2024-08-19 23:53:03,296 [foster.py] => Task 6, Epoch 1/1 => Loss 4.880, Loss_clf 1.066, Loss_fe 1.696, Loss_kd 1.815, Train_accy 68.10, Test_accy 85.94
2024-08-19 23:53:03,297 [foster.py] => do not weight align teacher!
2024-08-19 23:53:03,298 [foster.py] => per cls weights : [1.01950866 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866
 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866
 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866
 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866
 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866 1.01950866
 0.88294807 0.88294807 0.88294807 0.88294807 0.88294807]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 1.856,  Train_accy 64.67, Test_accy 84.51:   0%|          | 0/1 [00:31<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 1.856,  Train_accy 64.67, Test_accy 84.51: 100%|██████████| 1/1 [00:31<00:00, 31.18s/it]SNet: Task 6, Epoch 1/1 => Loss 1.856,  Train_accy 64.67, Test_accy 84.51: 100%|██████████| 1/1 [00:31<00:00, 31.18s/it]
2024-08-19 23:53:35,985 [foster.py] => SNet: Task 6, Epoch 1/1 => Loss 1.856,  Train_accy 64.67, Test_accy 84.51
2024-08-19 23:53:35,985 [foster.py] => do not weight align student!
2024-08-19 23:53:41,473 [foster.py] => darknet eval: 
2024-08-19 23:53:41,473 [foster.py] => CNN top1 curve: 84.51
2024-08-19 23:53:41,474 [foster.py] => CNN top5 curve: 98.2
2024-08-19 23:53:41,476 [base.py] => Reducing exemplars...(57 per classes)
2024-08-19 23:53:53,640 [base.py] => Constructing exemplars...(57 per classes)
2024-08-19 23:54:23,025 [foster.py] => Exemplar size: 1995
2024-08-19 23:54:23,026 [trainer.py] => CNN: {'total': 85.94, '00-04': 94.8, '05-09': 74.4, '10-14': 81.6, '15-19': 82.4, '20-24': 89.2, '25-29': 91.2, '30-34': 88.0, 'old': 85.6, 'new': 88.0}
2024-08-19 23:54:23,026 [trainer.py] => NME: {'total': 89.46, '00-04': 98.0, '05-09': 86.4, '10-14': 86.6, '15-19': 86.2, '20-24': 93.6, '25-29': 92.2, '30-34': 83.2, 'old': 90.5, 'new': 83.2}
2024-08-19 23:54:23,026 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94]
2024-08-19 23:54:23,026 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31]
2024-08-19 23:54:23,026 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46]
2024-08-19 23:54:23,026 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86]

Average Accuracy (CNN): 88.25
Average Accuracy (NME): 92.79
2024-08-19 23:54:23,026 [trainer.py] => Average Accuracy (CNN): 88.25
2024-08-19 23:54:23,026 [trainer.py] => Average Accuracy (NME): 92.79
2024-08-19 23:54:23,026 [trainer.py] => Train Time: 381.1
2024-08-19 23:54:23,026 [trainer.py] => Test Time: 76.17999999999999 

2024-08-19 23:54:23,027 [trainer.py] => All params: 171701092
2024-08-19 23:54:23,028 [trainer.py] => Trainable params: 85879366
2024-08-19 23:54:24,566 [foster.py] => Learning on 35-40
2024-08-19 23:54:24,568 [foster.py] => All params: 171716467
2024-08-19 23:54:24,568 [foster.py] => Trainable params: 85890896
2024-08-19 23:54:24,691 [foster.py] => per cls weights : [1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098
 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098
 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098
 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098
 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098
 1.01235098 1.01235098 1.01235098 1.01235098 1.01235098 0.91354314
 0.91354314 0.91354314 0.91354314 0.91354314]
  0%|          | 0/1 [00:00<?, ?it/s]Task 7, Epoch 1/1 => Loss 5.141, Loss_clf 1.067, Loss_fe 1.827, Loss_kd 1.966, Train_accy 71.41, Test_accy 85.25:   0%|          | 0/1 [00:31<?, ?it/s]Task 7, Epoch 1/1 => Loss 5.141, Loss_clf 1.067, Loss_fe 1.827, Loss_kd 1.966, Train_accy 71.41, Test_accy 85.25: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it]Task 7, Epoch 1/1 => Loss 5.141, Loss_clf 1.067, Loss_fe 1.827, Loss_kd 1.966, Train_accy 71.41, Test_accy 85.25: 100%|██████████| 1/1 [00:31<00:00, 31.61s/it]
2024-08-19 23:54:56,304 [foster.py] => Task 7, Epoch 1/1 => Loss 5.141, Loss_clf 1.067, Loss_fe 1.827, Loss_kd 1.966, Train_accy 71.41, Test_accy 85.25
2024-08-19 23:54:56,305 [foster.py] => do not weight align teacher!
2024-08-19 23:54:56,306 [foster.py] => per cls weights : [1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012
 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012
 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012
 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012
 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012
 1.02252012 1.02252012 1.02252012 1.02252012 1.02252012 0.84235915
 0.84235915 0.84235915 0.84235915 0.84235915]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.013,  Train_accy 68.79, Test_accy 85.28:   0%|          | 0/1 [00:32<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.013,  Train_accy 68.79, Test_accy 85.28: 100%|██████████| 1/1 [00:32<00:00, 32.12s/it]SNet: Task 7, Epoch 1/1 => Loss 2.013,  Train_accy 68.79, Test_accy 85.28: 100%|██████████| 1/1 [00:32<00:00, 32.12s/it]
2024-08-19 23:55:29,994 [foster.py] => SNet: Task 7, Epoch 1/1 => Loss 2.013,  Train_accy 68.79, Test_accy 85.28
2024-08-19 23:55:29,994 [foster.py] => do not weight align student!
2024-08-19 23:55:36,065 [foster.py] => darknet eval: 
2024-08-19 23:55:36,065 [foster.py] => CNN top1 curve: 85.28
2024-08-19 23:55:36,065 [foster.py] => CNN top5 curve: 98.0
2024-08-19 23:55:36,067 [base.py] => Reducing exemplars...(50 per classes)
2024-08-19 23:55:48,804 [base.py] => Constructing exemplars...(50 per classes)
2024-08-19 23:56:20,610 [foster.py] => Exemplar size: 2000
2024-08-19 23:56:20,610 [trainer.py] => CNN: {'total': 85.25, '00-04': 91.8, '05-09': 77.2, '10-14': 79.0, '15-19': 80.4, '20-24': 87.0, '25-29': 87.2, '30-34': 86.0, '35-39': 93.4, 'old': 84.09, 'new': 93.4}
2024-08-19 23:56:20,610 [trainer.py] => NME: {'total': 87.58, '00-04': 96.2, '05-09': 82.2, '10-14': 87.4, '15-19': 85.8, '20-24': 92.0, '25-29': 90.6, '30-34': 79.0, '35-39': 87.4, 'old': 87.6, 'new': 87.4}
2024-08-19 23:56:20,610 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25]
2024-08-19 23:56:20,610 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02]
2024-08-19 23:56:20,610 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58]
2024-08-19 23:56:20,610 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35]

Average Accuracy (CNN): 87.88
Average Accuracy (NME): 92.14
2024-08-19 23:56:20,610 [trainer.py] => Average Accuracy (CNN): 87.88
2024-08-19 23:56:20,610 [trainer.py] => Average Accuracy (NME): 92.14
2024-08-19 23:56:20,610 [trainer.py] => Train Time: 452.56
2024-08-19 23:56:20,610 [trainer.py] => Test Time: 97.75 

2024-08-19 23:56:20,612 [trainer.py] => All params: 171716467
2024-08-19 23:56:20,613 [trainer.py] => Trainable params: 85890896
2024-08-19 23:56:22,083 [foster.py] => Learning on 40-45
2024-08-19 23:56:22,085 [foster.py] => All params: 171731842
2024-08-19 23:56:22,086 [foster.py] => Trainable params: 85902426
2024-08-19 23:56:22,207 [foster.py] => per cls weights : [1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308 1.01464308
 1.01464308 1.01464308 1.01464308 1.01464308 0.88285536 0.88285536
 0.88285536 0.88285536 0.88285536]
  0%|          | 0/1 [00:00<?, ?it/s]Task 8, Epoch 1/1 => Loss 5.361, Loss_clf 1.123, Loss_fe 1.848, Loss_kd 2.125, Train_accy 70.33, Test_accy 84.91:   0%|          | 0/1 [00:32<?, ?it/s]Task 8, Epoch 1/1 => Loss 5.361, Loss_clf 1.123, Loss_fe 1.848, Loss_kd 2.125, Train_accy 70.33, Test_accy 84.91: 100%|██████████| 1/1 [00:32<00:00, 32.96s/it]Task 8, Epoch 1/1 => Loss 5.361, Loss_clf 1.123, Loss_fe 1.848, Loss_kd 2.125, Train_accy 70.33, Test_accy 84.91: 100%|██████████| 1/1 [00:32<00:00, 32.96s/it]
2024-08-19 23:56:55,168 [foster.py] => Task 8, Epoch 1/1 => Loss 5.361, Loss_clf 1.123, Loss_fe 1.848, Loss_kd 2.125, Train_accy 70.33, Test_accy 84.91
2024-08-19 23:56:55,169 [foster.py] => do not weight align teacher!
2024-08-19 23:56:55,170 [foster.py] => per cls weights : [1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113 1.02483113
 1.02483113 1.02483113 1.02483113 1.02483113 0.80135095 0.80135095
 0.80135095 0.80135095 0.80135095]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 2.097,  Train_accy 69.40, Test_accy 85.09:   0%|          | 0/1 [00:32<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 2.097,  Train_accy 69.40, Test_accy 85.09: 100%|██████████| 1/1 [00:32<00:00, 32.89s/it]SNet: Task 8, Epoch 1/1 => Loss 2.097,  Train_accy 69.40, Test_accy 85.09: 100%|██████████| 1/1 [00:32<00:00, 32.89s/it]
2024-08-19 23:57:29,610 [foster.py] => SNet: Task 8, Epoch 1/1 => Loss 2.097,  Train_accy 69.40, Test_accy 85.09
2024-08-19 23:57:29,610 [foster.py] => do not weight align student!
2024-08-19 23:57:36,385 [foster.py] => darknet eval: 
2024-08-19 23:57:36,385 [foster.py] => CNN top1 curve: 85.09
2024-08-19 23:57:36,385 [foster.py] => CNN top5 curve: 98.11
2024-08-19 23:57:36,386 [base.py] => Reducing exemplars...(44 per classes)
2024-08-19 23:57:50,090 [base.py] => Constructing exemplars...(44 per classes)
2024-08-19 23:58:24,402 [foster.py] => Exemplar size: 1980
2024-08-19 23:58:24,403 [trainer.py] => CNN: {'total': 84.91, '00-04': 88.0, '05-09': 75.2, '10-14': 75.4, '15-19': 82.2, '20-24': 89.6, '25-29': 88.6, '30-34': 81.2, '35-39': 88.2, '40-44': 95.8, 'old': 83.55, 'new': 95.8}
2024-08-19 23:58:24,403 [trainer.py] => NME: {'total': 87.11, '00-04': 95.4, '05-09': 85.6, '10-14': 83.2, '15-19': 85.8, '20-24': 90.6, '25-29': 91.0, '30-34': 79.6, '35-39': 87.8, '40-44': 85.0, 'old': 87.38, 'new': 85.0}
2024-08-19 23:58:24,403 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91]
2024-08-19 23:58:24,403 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07]
2024-08-19 23:58:24,403 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11]
2024-08-19 23:58:24,403 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33]

Average Accuracy (CNN): 87.55
Average Accuracy (NME): 91.58
2024-08-19 23:58:24,403 [trainer.py] => Average Accuracy (CNN): 87.55
2024-08-19 23:58:24,403 [trainer.py] => Average Accuracy (NME): 91.58
2024-08-19 23:58:24,403 [trainer.py] => Train Time: 526.82
2024-08-19 23:58:24,403 [trainer.py] => Test Time: 122.02 

2024-08-19 23:58:24,404 [trainer.py] => All params: 171731842
2024-08-19 23:58:24,405 [trainer.py] => Trainable params: 85902426
2024-08-19 23:58:25,921 [foster.py] => Learning on 45-50
2024-08-19 23:58:25,923 [foster.py] => All params: 171747217
2024-08-19 23:58:25,924 [foster.py] => Trainable params: 85913956
2024-08-19 23:58:26,041 [foster.py] => per cls weights : [1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334 1.01687334
 1.01687334 1.01687334 1.01687334 0.84813992 0.84813992 0.84813992
 0.84813992 0.84813992]
  0%|          | 0/1 [00:00<?, ?it/s]Task 9, Epoch 1/1 => Loss 5.150, Loss_clf 1.057, Loss_fe 1.911, Loss_kd 1.964, Train_accy 71.16, Test_accy 83.74:   0%|          | 0/1 [00:34<?, ?it/s]Task 9, Epoch 1/1 => Loss 5.150, Loss_clf 1.057, Loss_fe 1.911, Loss_kd 1.964, Train_accy 71.16, Test_accy 83.74: 100%|██████████| 1/1 [00:34<00:00, 34.13s/it]Task 9, Epoch 1/1 => Loss 5.150, Loss_clf 1.057, Loss_fe 1.911, Loss_kd 1.964, Train_accy 71.16, Test_accy 83.74: 100%|██████████| 1/1 [00:34<00:00, 34.13s/it]
2024-08-19 23:59:00,177 [foster.py] => Task 9, Epoch 1/1 => Loss 5.150, Loss_clf 1.057, Loss_fe 1.911, Loss_kd 1.964, Train_accy 71.16, Test_accy 83.74
2024-08-19 23:59:00,178 [foster.py] => do not weight align teacher!
2024-08-19 23:59:00,180 [foster.py] => per cls weights : [1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297 1.02688297
 1.02688297 1.02688297 1.02688297 0.75805326 0.75805326 0.75805326
 0.75805326 0.75805326]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 2.042,  Train_accy 64.60, Test_accy 83.78:   0%|          | 0/1 [00:33<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 2.042,  Train_accy 64.60, Test_accy 83.78: 100%|██████████| 1/1 [00:33<00:00, 33.46s/it]SNet: Task 9, Epoch 1/1 => Loss 2.042,  Train_accy 64.60, Test_accy 83.78: 100%|██████████| 1/1 [00:33<00:00, 33.46s/it]
2024-08-19 23:59:35,190 [foster.py] => SNet: Task 9, Epoch 1/1 => Loss 2.042,  Train_accy 64.60, Test_accy 83.78
2024-08-19 23:59:35,190 [foster.py] => do not weight align student!
2024-08-19 23:59:42,688 [foster.py] => darknet eval: 
2024-08-19 23:59:42,688 [foster.py] => CNN top1 curve: 83.78
2024-08-19 23:59:42,688 [foster.py] => CNN top5 curve: 98.18
2024-08-19 23:59:42,690 [base.py] => Reducing exemplars...(40 per classes)
2024-08-19 23:59:57,616 [base.py] => Constructing exemplars...(40 per classes)
2024-08-20 00:00:34,421 [foster.py] => Exemplar size: 2000
2024-08-20 00:00:34,421 [trainer.py] => CNN: {'total': 83.74, '00-04': 92.8, '05-09': 74.2, '10-14': 82.0, '15-19': 82.2, '20-24': 82.0, '25-29': 85.2, '30-34': 85.2, '35-39': 83.6, '40-44': 86.0, '45-49': 84.2, 'old': 83.69, 'new': 84.2}
2024-08-20 00:00:34,421 [trainer.py] => NME: {'total': 86.58, '00-04': 96.4, '05-09': 83.2, '10-14': 82.2, '15-19': 86.0, '20-24': 91.4, '25-29': 89.2, '30-34': 81.2, '35-39': 81.6, '40-44': 83.4, '45-49': 91.2, 'old': 86.07, 'new': 91.2}
2024-08-20 00:00:34,421 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74]
2024-08-20 00:00:34,421 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14]
2024-08-20 00:00:34,421 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58]
2024-08-20 00:00:34,421 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38]

Average Accuracy (CNN): 87.17
Average Accuracy (NME): 91.08
2024-08-20 00:00:34,421 [trainer.py] => Average Accuracy (CNN): 87.17
2024-08-20 00:00:34,421 [trainer.py] => Average Accuracy (NME): 91.08
2024-08-20 00:00:34,421 [trainer.py] => Train Time: 603.5500000000001
2024-08-20 00:00:34,421 [trainer.py] => Test Time: 148.93 

2024-08-20 00:00:34,422 [trainer.py] => All params: 171747217
2024-08-20 00:00:34,423 [trainer.py] => Trainable params: 85913956
2024-08-20 00:00:35,894 [foster.py] => Learning on 50-55
2024-08-20 00:00:35,896 [foster.py] => All params: 171762592
2024-08-20 00:00:35,897 [foster.py] => Trainable params: 85925486
2024-08-20 00:00:36,015 [foster.py] => per cls weights : [1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 0.819183  0.819183  0.819183  0.819183  0.819183 ]
  0%|          | 0/1 [00:00<?, ?it/s]Task 10, Epoch 1/1 => Loss 5.485, Loss_clf 1.078, Loss_fe 1.847, Loss_kd 2.327, Train_accy 70.20, Test_accy 84.47:   0%|          | 0/1 [00:35<?, ?it/s]Task 10, Epoch 1/1 => Loss 5.485, Loss_clf 1.078, Loss_fe 1.847, Loss_kd 2.327, Train_accy 70.20, Test_accy 84.47: 100%|██████████| 1/1 [00:35<00:00, 35.54s/it]Task 10, Epoch 1/1 => Loss 5.485, Loss_clf 1.078, Loss_fe 1.847, Loss_kd 2.327, Train_accy 70.20, Test_accy 84.47: 100%|██████████| 1/1 [00:35<00:00, 35.54s/it]
2024-08-20 00:01:11,560 [foster.py] => Task 10, Epoch 1/1 => Loss 5.485, Loss_clf 1.078, Loss_fe 1.847, Loss_kd 2.327, Train_accy 70.20, Test_accy 84.47
2024-08-20 00:01:11,561 [foster.py] => do not weight align teacher!
2024-08-20 00:01:11,562 [foster.py] => per cls weights : [1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 0.72374408 0.72374408 0.72374408 0.72374408
 0.72374408]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 10, Epoch 1/1 => Loss 2.407,  Train_accy 64.47, Test_accy 84.15:   0%|          | 0/1 [00:34<?, ?it/s]SNet: Task 10, Epoch 1/1 => Loss 2.407,  Train_accy 64.47, Test_accy 84.15: 100%|██████████| 1/1 [00:34<00:00, 34.28s/it]SNet: Task 10, Epoch 1/1 => Loss 2.407,  Train_accy 64.47, Test_accy 84.15: 100%|██████████| 1/1 [00:34<00:00, 34.28s/it]
2024-08-20 00:01:47,703 [foster.py] => SNet: Task 10, Epoch 1/1 => Loss 2.407,  Train_accy 64.47, Test_accy 84.15
2024-08-20 00:01:47,704 [foster.py] => do not weight align student!
2024-08-20 00:01:55,871 [foster.py] => darknet eval: 
2024-08-20 00:01:55,872 [foster.py] => CNN top1 curve: 84.15
2024-08-20 00:01:55,872 [foster.py] => CNN top5 curve: 98.2
2024-08-20 00:01:55,874 [base.py] => Reducing exemplars...(36 per classes)
2024-08-20 00:02:13,543 [base.py] => Constructing exemplars...(36 per classes)
2024-08-20 00:02:53,152 [foster.py] => Exemplar size: 1980
2024-08-20 00:02:53,152 [trainer.py] => CNN: {'total': 84.47, '00-04': 89.0, '05-09': 81.4, '10-14': 83.0, '15-19': 87.8, '20-24': 91.2, '25-29': 84.8, '30-34': 80.2, '35-39': 85.8, '40-44': 80.2, '45-49': 82.2, '50-54': 83.6, 'old': 84.56, 'new': 83.6}
2024-08-20 00:02:53,152 [trainer.py] => NME: {'total': 85.6, '00-04': 94.4, '05-09': 80.0, '10-14': 83.4, '15-19': 85.4, '20-24': 92.0, '25-29': 88.8, '30-34': 81.0, '35-39': 82.0, '40-44': 82.6, '45-49': 88.4, '50-54': 83.6, 'old': 85.8, 'new': 83.6}
2024-08-20 00:02:53,153 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47]
2024-08-20 00:02:53,153 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25]
2024-08-20 00:02:53,153 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6]
2024-08-20 00:02:53,153 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35]

Average Accuracy (CNN): 86.92
Average Accuracy (NME): 90.58
2024-08-20 00:02:53,153 [trainer.py] => Average Accuracy (CNN): 86.92
2024-08-20 00:02:53,153 [trainer.py] => Average Accuracy (NME): 90.58
2024-08-20 00:02:53,153 [trainer.py] => Train Time: 683.49
2024-08-20 00:02:53,153 [trainer.py] => Test Time: 178.25 

2024-08-20 00:02:53,154 [trainer.py] => All params: 171762592
2024-08-20 00:02:53,155 [trainer.py] => Trainable params: 85925486
2024-08-20 00:02:54,934 [foster.py] => Learning on 55-60
2024-08-20 00:02:54,936 [foster.py] => All params: 171777967
2024-08-20 00:02:54,937 [foster.py] => Trainable params: 85937016
2024-08-20 00:02:55,091 [foster.py] => per cls weights : [1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 0.78502828 0.78502828 0.78502828 0.78502828 0.78502828]
  0%|          | 0/1 [00:00<?, ?it/s]Task 11, Epoch 1/1 => Loss 6.042, Loss_clf 1.177, Loss_fe 2.059, Loss_kd 2.571, Train_accy 66.21, Test_accy 84.90:   0%|          | 0/1 [00:36<?, ?it/s]Task 11, Epoch 1/1 => Loss 6.042, Loss_clf 1.177, Loss_fe 2.059, Loss_kd 2.571, Train_accy 66.21, Test_accy 84.90: 100%|██████████| 1/1 [00:36<00:00, 36.59s/it]Task 11, Epoch 1/1 => Loss 6.042, Loss_clf 1.177, Loss_fe 2.059, Loss_kd 2.571, Train_accy 66.21, Test_accy 84.90: 100%|██████████| 1/1 [00:36<00:00, 36.59s/it]
2024-08-20 00:03:31,679 [foster.py] => Task 11, Epoch 1/1 => Loss 6.042, Loss_clf 1.177, Loss_fe 2.059, Loss_kd 2.571, Train_accy 66.21, Test_accy 84.90
2024-08-20 00:03:31,680 [foster.py] => do not weight align teacher!
2024-08-20 00:03:31,682 [foster.py] => per cls weights : [1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 0.68504089 0.68504089 0.68504089 0.68504089 0.68504089]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 11, Epoch 1/1 => Loss 2.465,  Train_accy 63.28, Test_accy 85.02:   0%|          | 0/1 [00:34<?, ?it/s]SNet: Task 11, Epoch 1/1 => Loss 2.465,  Train_accy 63.28, Test_accy 85.02: 100%|██████████| 1/1 [00:34<00:00, 34.72s/it]SNet: Task 11, Epoch 1/1 => Loss 2.465,  Train_accy 63.28, Test_accy 85.02: 100%|██████████| 1/1 [00:34<00:00, 34.72s/it]
2024-08-20 00:04:08,070 [foster.py] => SNet: Task 11, Epoch 1/1 => Loss 2.465,  Train_accy 63.28, Test_accy 85.02
2024-08-20 00:04:08,070 [foster.py] => do not weight align student!
2024-08-20 00:04:16,742 [foster.py] => darknet eval: 
2024-08-20 00:04:16,743 [foster.py] => CNN top1 curve: 85.02
2024-08-20 00:04:16,743 [foster.py] => CNN top5 curve: 97.93
2024-08-20 00:04:16,744 [base.py] => Reducing exemplars...(33 per classes)
2024-08-20 00:04:34,954 [base.py] => Constructing exemplars...(33 per classes)
2024-08-20 00:05:16,524 [foster.py] => Exemplar size: 1980
2024-08-20 00:05:16,524 [trainer.py] => CNN: {'total': 84.9, '00-04': 91.2, '05-09': 76.4, '10-14': 81.8, '15-19': 87.4, '20-24': 93.6, '25-29': 86.6, '30-34': 77.8, '35-39': 85.4, '40-44': 85.0, '45-49': 82.8, '50-54': 79.8, '55-59': 91.0, 'old': 84.35, 'new': 91.0}
2024-08-20 00:05:16,525 [trainer.py] => NME: {'total': 86.33, '00-04': 94.2, '05-09': 82.6, '10-14': 83.0, '15-19': 86.6, '20-24': 93.8, '25-29': 89.6, '30-34': 80.8, '35-39': 83.8, '40-44': 84.2, '45-49': 89.0, '50-54': 81.8, '55-59': 86.6, 'old': 86.31, 'new': 86.6}
2024-08-20 00:05:16,525 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9]
2024-08-20 00:05:16,525 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77]
2024-08-20 00:05:16,525 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33]
2024-08-20 00:05:16,525 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78]

Average Accuracy (CNN): 86.75
Average Accuracy (NME): 90.23
2024-08-20 00:05:16,525 [trainer.py] => Average Accuracy (CNN): 86.75
2024-08-20 00:05:16,525 [trainer.py] => Average Accuracy (NME): 90.23
2024-08-20 00:05:16,525 [trainer.py] => Train Time: 765.2
2024-08-20 00:05:16,525 [trainer.py] => Test Time: 209.9 

2024-08-20 00:05:16,526 [trainer.py] => All params: 171777967
2024-08-20 00:05:16,527 [trainer.py] => Trainable params: 85937016
2024-08-20 00:05:18,048 [foster.py] => Learning on 60-65
2024-08-20 00:05:18,049 [foster.py] => All params: 171793342
2024-08-20 00:05:18,050 [foster.py] => Trainable params: 85948546
2024-08-20 00:05:18,159 [foster.py] => per cls weights : [1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 0.75511508 0.75511508 0.75511508 0.75511508 0.75511508]
  0%|          | 0/1 [00:00<?, ?it/s]Task 12, Epoch 1/1 => Loss 5.945, Loss_clf 1.084, Loss_fe 2.158, Loss_kd 2.495, Train_accy 68.62, Test_accy 84.17:   0%|          | 0/1 [00:37<?, ?it/s]Task 12, Epoch 1/1 => Loss 5.945, Loss_clf 1.084, Loss_fe 2.158, Loss_kd 2.495, Train_accy 68.62, Test_accy 84.17: 100%|██████████| 1/1 [00:37<00:00, 37.84s/it]Task 12, Epoch 1/1 => Loss 5.945, Loss_clf 1.084, Loss_fe 2.158, Loss_kd 2.495, Train_accy 68.62, Test_accy 84.17: 100%|██████████| 1/1 [00:37<00:00, 37.84s/it]
2024-08-20 00:05:56,001 [foster.py] => Task 12, Epoch 1/1 => Loss 5.945, Loss_clf 1.084, Loss_fe 2.158, Loss_kd 2.495, Train_accy 68.62, Test_accy 84.17
2024-08-20 00:05:56,002 [foster.py] => do not weight align teacher!
2024-08-20 00:05:56,004 [foster.py] => per cls weights : [1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 0.65237804 0.65237804 0.65237804 0.65237804 0.65237804]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 12, Epoch 1/1 => Loss 2.499,  Train_accy 59.82, Test_accy 83.82:   0%|          | 0/1 [00:35<?, ?it/s]SNet: Task 12, Epoch 1/1 => Loss 2.499,  Train_accy 59.82, Test_accy 83.82: 100%|██████████| 1/1 [00:35<00:00, 35.42s/it]SNet: Task 12, Epoch 1/1 => Loss 2.499,  Train_accy 59.82, Test_accy 83.82: 100%|██████████| 1/1 [00:35<00:00, 35.42s/it]
2024-08-20 00:06:32,947 [foster.py] => SNet: Task 12, Epoch 1/1 => Loss 2.499,  Train_accy 59.82, Test_accy 83.82
2024-08-20 00:06:32,948 [foster.py] => do not weight align student!
2024-08-20 00:06:42,633 [foster.py] => darknet eval: 
2024-08-20 00:06:42,634 [foster.py] => CNN top1 curve: 83.82
2024-08-20 00:06:42,634 [foster.py] => CNN top5 curve: 97.94
2024-08-20 00:06:42,635 [base.py] => Reducing exemplars...(30 per classes)
2024-08-20 00:07:01,716 [base.py] => Constructing exemplars...(30 per classes)
2024-08-20 00:07:45,586 [foster.py] => Exemplar size: 1950
2024-08-20 00:07:45,586 [trainer.py] => CNN: {'total': 84.17, '00-04': 92.4, '05-09': 79.8, '10-14': 82.6, '15-19': 83.4, '20-24': 91.4, '25-29': 88.2, '30-34': 81.8, '35-39': 88.6, '40-44': 82.6, '45-49': 83.0, '50-54': 77.8, '55-59': 80.0, '60-64': 82.6, 'old': 84.3, 'new': 82.6}
2024-08-20 00:07:45,586 [trainer.py] => NME: {'total': 85.63, '00-04': 94.0, '05-09': 83.0, '10-14': 81.8, '15-19': 85.8, '20-24': 93.6, '25-29': 89.2, '30-34': 81.2, '35-39': 83.0, '40-44': 82.4, '45-49': 88.4, '50-54': 83.6, '55-59': 82.0, '60-64': 85.2, 'old': 85.67, 'new': 85.2}
2024-08-20 00:07:45,587 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17]
2024-08-20 00:07:45,587 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0]
2024-08-20 00:07:45,587 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63]
2024-08-20 00:07:45,587 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82]

Average Accuracy (CNN): 86.56
Average Accuracy (NME): 89.88
2024-08-20 00:07:45,587 [trainer.py] => Average Accuracy (CNN): 86.56
2024-08-20 00:07:45,587 [trainer.py] => Average Accuracy (NME): 89.88
2024-08-20 00:07:45,587 [trainer.py] => Train Time: 849.73
2024-08-20 00:07:45,587 [trainer.py] => Test Time: 243.96 

2024-08-20 00:07:45,588 [trainer.py] => All params: 171793342
2024-08-20 00:07:45,589 [trainer.py] => Trainable params: 85948546
2024-08-20 00:07:47,110 [foster.py] => Learning on 65-70
2024-08-20 00:07:47,111 [foster.py] => All params: 171808717
2024-08-20 00:07:47,112 [foster.py] => Trainable params: 85960076
2024-08-20 00:07:47,206 [foster.py] => per cls weights : [1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 0.72128194
 0.72128194 0.72128194 0.72128194 0.72128194]
  0%|          | 0/1 [00:00<?, ?it/s]Task 13, Epoch 1/1 => Loss 5.817, Loss_clf 1.063, Loss_fe 2.063, Loss_kd 2.499, Train_accy 69.78, Test_accy 84.01:   0%|          | 0/1 [00:38<?, ?it/s]Task 13, Epoch 1/1 => Loss 5.817, Loss_clf 1.063, Loss_fe 2.063, Loss_kd 2.499, Train_accy 69.78, Test_accy 84.01: 100%|██████████| 1/1 [00:38<00:00, 38.92s/it]Task 13, Epoch 1/1 => Loss 5.817, Loss_clf 1.063, Loss_fe 2.063, Loss_kd 2.499, Train_accy 69.78, Test_accy 84.01: 100%|██████████| 1/1 [00:38<00:00, 38.92s/it]
2024-08-20 00:08:26,126 [foster.py] => Task 13, Epoch 1/1 => Loss 5.817, Loss_clf 1.063, Loss_fe 2.063, Loss_kd 2.499, Train_accy 69.78, Test_accy 84.01
2024-08-20 00:08:26,127 [foster.py] => do not weight align teacher!
2024-08-20 00:08:26,129 [foster.py] => per cls weights : [1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   0.61665603
 0.61665603 0.61665603 0.61665603 0.61665603]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 13, Epoch 1/1 => Loss 2.444,  Train_accy 67.42, Test_accy 83.71:   0%|          | 0/1 [00:35<?, ?it/s]SNet: Task 13, Epoch 1/1 => Loss 2.444,  Train_accy 67.42, Test_accy 83.71: 100%|██████████| 1/1 [00:35<00:00, 35.96s/it]SNet: Task 13, Epoch 1/1 => Loss 2.444,  Train_accy 67.42, Test_accy 83.71: 100%|██████████| 1/1 [00:35<00:00, 35.96s/it]
2024-08-20 00:09:03,574 [foster.py] => SNet: Task 13, Epoch 1/1 => Loss 2.444,  Train_accy 67.42, Test_accy 83.71
2024-08-20 00:09:03,574 [foster.py] => do not weight align student!
2024-08-20 00:09:13,783 [foster.py] => darknet eval: 
2024-08-20 00:09:13,784 [foster.py] => CNN top1 curve: 83.71
2024-08-20 00:09:13,784 [foster.py] => CNN top5 curve: 97.76
2024-08-20 00:09:13,785 [base.py] => Reducing exemplars...(28 per classes)
2024-08-20 00:09:34,219 [base.py] => Constructing exemplars...(28 per classes)
2024-08-20 00:10:20,926 [foster.py] => Exemplar size: 1960
2024-08-20 00:10:20,926 [trainer.py] => CNN: {'total': 84.01, '00-04': 84.0, '05-09': 82.4, '10-14': 80.4, '15-19': 85.2, '20-24': 94.0, '25-29': 87.8, '30-34': 76.4, '35-39': 87.6, '40-44': 84.2, '45-49': 84.2, '50-54': 77.2, '55-59': 87.0, '60-64': 72.8, '65-69': 93.0, 'old': 83.32, 'new': 93.0}
2024-08-20 00:10:20,926 [trainer.py] => NME: {'total': 85.7, '00-04': 91.8, '05-09': 84.4, '10-14': 82.8, '15-19': 85.8, '20-24': 92.0, '25-29': 89.0, '30-34': 79.4, '35-39': 83.0, '40-44': 82.2, '45-49': 89.2, '50-54': 82.4, '55-59': 82.6, '60-64': 82.8, '65-69': 92.4, 'old': 85.18, 'new': 92.4}
2024-08-20 00:10:20,926 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01]
2024-08-20 00:10:20,926 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73]
2024-08-20 00:10:20,926 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7]
2024-08-20 00:10:20,926 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76]

Average Accuracy (CNN): 86.37
Average Accuracy (NME): 89.58
2024-08-20 00:10:20,926 [trainer.py] => Average Accuracy (CNN): 86.37
2024-08-20 00:10:20,926 [trainer.py] => Average Accuracy (NME): 89.58
2024-08-20 00:10:20,926 [trainer.py] => Train Time: 936.36
2024-08-20 00:10:20,926 [trainer.py] => Test Time: 280.73 

2024-08-20 00:10:20,928 [trainer.py] => All params: 171808717
2024-08-20 00:10:20,929 [trainer.py] => Trainable params: 85960076
2024-08-20 00:10:22,524 [foster.py] => Learning on 70-75
2024-08-20 00:10:22,526 [foster.py] => All params: 171824092
2024-08-20 00:10:22,527 [foster.py] => Trainable params: 85971606
2024-08-20 00:10:22,613 [foster.py] => per cls weights : [1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 0.69593764 0.69593764
 0.69593764 0.69593764 0.69593764]
  0%|          | 0/1 [00:00<?, ?it/s]Task 14, Epoch 1/1 => Loss 6.274, Loss_clf 1.185, Loss_fe 2.260, Loss_kd 2.642, Train_accy 63.18, Test_accy 83.12:   0%|          | 0/1 [00:40<?, ?it/s]Task 14, Epoch 1/1 => Loss 6.274, Loss_clf 1.185, Loss_fe 2.260, Loss_kd 2.642, Train_accy 63.18, Test_accy 83.12: 100%|██████████| 1/1 [00:40<00:00, 40.39s/it]Task 14, Epoch 1/1 => Loss 6.274, Loss_clf 1.185, Loss_fe 2.260, Loss_kd 2.642, Train_accy 63.18, Test_accy 83.12: 100%|██████████| 1/1 [00:40<00:00, 40.40s/it]
2024-08-20 00:11:03,010 [foster.py] => Task 14, Epoch 1/1 => Loss 6.274, Loss_clf 1.185, Loss_fe 2.260, Loss_kd 2.642, Train_accy 63.18, Test_accy 83.12
2024-08-20 00:11:03,012 [foster.py] => do not weight align teacher!
2024-08-20 00:11:03,015 [foster.py] => per cls weights : [1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 0.5905851  0.5905851
 0.5905851  0.5905851  0.5905851 ]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 14, Epoch 1/1 => Loss 2.788,  Train_accy 56.19, Test_accy 83.75:   0%|          | 0/1 [00:36<?, ?it/s]SNet: Task 14, Epoch 1/1 => Loss 2.788,  Train_accy 56.19, Test_accy 83.75: 100%|██████████| 1/1 [00:36<00:00, 36.57s/it]SNet: Task 14, Epoch 1/1 => Loss 2.788,  Train_accy 56.19, Test_accy 83.75: 100%|██████████| 1/1 [00:36<00:00, 36.57s/it]
2024-08-20 00:11:41,107 [foster.py] => SNet: Task 14, Epoch 1/1 => Loss 2.788,  Train_accy 56.19, Test_accy 83.75
2024-08-20 00:11:41,107 [foster.py] => do not weight align student!
2024-08-20 00:11:51,850 [foster.py] => darknet eval: 
2024-08-20 00:11:51,850 [foster.py] => CNN top1 curve: 83.75
2024-08-20 00:11:51,850 [foster.py] => CNN top5 curve: 97.53
2024-08-20 00:11:51,852 [base.py] => Reducing exemplars...(26 per classes)
2024-08-20 00:12:12,516 [base.py] => Constructing exemplars...(26 per classes)
2024-08-20 00:13:01,538 [foster.py] => Exemplar size: 1950
2024-08-20 00:13:01,538 [trainer.py] => CNN: {'total': 83.12, '00-04': 89.2, '05-09': 81.6, '10-14': 79.2, '15-19': 84.0, '20-24': 89.8, '25-29': 86.8, '30-34': 78.8, '35-39': 84.0, '40-44': 84.4, '45-49': 87.2, '50-54': 79.6, '55-59': 78.8, '60-64': 69.4, '65-69': 88.8, '70-74': 85.2, 'old': 82.97, 'new': 85.2}
2024-08-20 00:13:01,538 [trainer.py] => NME: {'total': 84.84, '00-04': 91.6, '05-09': 83.6, '10-14': 81.8, '15-19': 85.6, '20-24': 93.2, '25-29': 88.6, '30-34': 80.0, '35-39': 80.8, '40-44': 82.6, '45-49': 90.2, '50-54': 82.8, '55-59': 80.8, '60-64': 80.2, '65-69': 90.0, '70-74': 80.8, 'old': 85.13, 'new': 80.8}
2024-08-20 00:13:01,538 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12]
2024-08-20 00:13:01,538 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32]
2024-08-20 00:13:01,538 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84]
2024-08-20 00:13:01,538 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61]

Average Accuracy (CNN): 86.16
Average Accuracy (NME): 89.26
2024-08-20 00:13:01,538 [trainer.py] => Average Accuracy (CNN): 86.16
2024-08-20 00:13:01,538 [trainer.py] => Average Accuracy (NME): 89.26
2024-08-20 00:13:01,538 [trainer.py] => Train Time: 1025.65
2024-08-20 00:13:01,538 [trainer.py] => Test Time: 320.12 

2024-08-20 00:13:01,540 [trainer.py] => All params: 171824092
2024-08-20 00:13:01,541 [trainer.py] => Trainable params: 85971606
2024-08-20 00:13:03,119 [foster.py] => Learning on 75-80
2024-08-20 00:13:03,121 [foster.py] => All params: 171839467
2024-08-20 00:13:03,122 [foster.py] => Trainable params: 85983136
2024-08-20 00:13:03,213 [foster.py] => per cls weights : [1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 0.6684741  0.6684741  0.6684741
 0.6684741  0.6684741 ]
  0%|          | 0/1 [00:00<?, ?it/s]Task 15, Epoch 1/1 => Loss 6.141, Loss_clf 1.054, Loss_fe 2.340, Loss_kd 2.575, Train_accy 60.34, Test_accy 82.06:   0%|          | 0/1 [00:41<?, ?it/s]Task 15, Epoch 1/1 => Loss 6.141, Loss_clf 1.054, Loss_fe 2.340, Loss_kd 2.575, Train_accy 60.34, Test_accy 82.06: 100%|██████████| 1/1 [00:41<00:00, 41.43s/it]Task 15, Epoch 1/1 => Loss 6.141, Loss_clf 1.054, Loss_fe 2.340, Loss_kd 2.575, Train_accy 60.34, Test_accy 82.06: 100%|██████████| 1/1 [00:41<00:00, 41.43s/it]
2024-08-20 00:13:44,641 [foster.py] => Task 15, Epoch 1/1 => Loss 6.141, Loss_clf 1.054, Loss_fe 2.340, Loss_kd 2.575, Train_accy 60.34, Test_accy 82.06
2024-08-20 00:13:44,642 [foster.py] => do not weight align teacher!
2024-08-20 00:13:44,644 [foster.py] => per cls weights : [1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 0.56297248 0.56297248 0.56297248
 0.56297248 0.56297248]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 15, Epoch 1/1 => Loss 2.761,  Train_accy 50.81, Test_accy 81.35:   0%|          | 0/1 [00:37<?, ?it/s]SNet: Task 15, Epoch 1/1 => Loss 2.761,  Train_accy 50.81, Test_accy 81.35: 100%|██████████| 1/1 [00:37<00:00, 37.33s/it]SNet: Task 15, Epoch 1/1 => Loss 2.761,  Train_accy 50.81, Test_accy 81.35: 100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
2024-08-20 00:14:23,441 [foster.py] => SNet: Task 15, Epoch 1/1 => Loss 2.761,  Train_accy 50.81, Test_accy 81.35
2024-08-20 00:14:23,442 [foster.py] => do not weight align student!
2024-08-20 00:14:34,881 [foster.py] => darknet eval: 
2024-08-20 00:14:34,881 [foster.py] => CNN top1 curve: 81.35
2024-08-20 00:14:34,881 [foster.py] => CNN top5 curve: 97.58
2024-08-20 00:14:34,883 [base.py] => Reducing exemplars...(25 per classes)
2024-08-20 00:14:57,551 [base.py] => Constructing exemplars...(25 per classes)
2024-08-20 00:15:49,173 [foster.py] => Exemplar size: 2000
2024-08-20 00:15:49,174 [trainer.py] => CNN: {'total': 82.06, '00-04': 90.4, '05-09': 80.8, '10-14': 83.0, '15-19': 86.0, '20-24': 91.8, '25-29': 84.8, '30-34': 77.2, '35-39': 83.8, '40-44': 82.6, '45-49': 87.2, '50-54': 77.4, '55-59': 73.8, '60-64': 80.4, '65-69': 87.2, '70-74': 76.2, '75-79': 70.4, 'old': 82.84, 'new': 70.4}
2024-08-20 00:15:49,174 [trainer.py] => NME: {'total': 83.46, '00-04': 92.4, '05-09': 84.0, '10-14': 81.2, '15-19': 85.6, '20-24': 93.0, '25-29': 87.8, '30-34': 80.2, '35-39': 81.6, '40-44': 83.6, '45-49': 87.4, '50-54': 77.6, '55-59': 78.8, '60-64': 79.2, '65-69': 89.6, '70-74': 77.8, '75-79': 75.6, 'old': 83.99, 'new': 75.6}
2024-08-20 00:15:49,174 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12, 82.06]
2024-08-20 00:15:49,174 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32, 97.59]
2024-08-20 00:15:49,174 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84, 83.46]
2024-08-20 00:15:49,174 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61, 97.55]

Average Accuracy (CNN): 85.9
Average Accuracy (NME): 88.9
2024-08-20 00:15:49,174 [trainer.py] => Average Accuracy (CNN): 85.9
2024-08-20 00:15:49,174 [trainer.py] => Average Accuracy (NME): 88.9
2024-08-20 00:15:49,174 [trainer.py] => Train Time: 1117.3700000000001
2024-08-20 00:15:49,174 [trainer.py] => Test Time: 362.16 

2024-08-20 00:15:49,175 [trainer.py] => All params: 171839467
2024-08-20 00:15:49,176 [trainer.py] => Trainable params: 85983136
2024-08-20 00:15:50,736 [foster.py] => Learning on 80-85
2024-08-20 00:15:50,738 [foster.py] => All params: 171854842
2024-08-20 00:15:50,739 [foster.py] => Trainable params: 85994666
2024-08-20 00:15:50,842 [foster.py] => per cls weights : [1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 0.65345643 0.65345643 0.65345643 0.65345643
 0.65345643]
  0%|          | 0/1 [00:00<?, ?it/s]Task 16, Epoch 1/1 => Loss 6.299, Loss_clf 1.115, Loss_fe 2.380, Loss_kd 2.639, Train_accy 61.11, Test_accy 80.25:   0%|          | 0/1 [00:43<?, ?it/s]Task 16, Epoch 1/1 => Loss 6.299, Loss_clf 1.115, Loss_fe 2.380, Loss_kd 2.639, Train_accy 61.11, Test_accy 80.25: 100%|██████████| 1/1 [00:43<00:00, 43.04s/it]Task 16, Epoch 1/1 => Loss 6.299, Loss_clf 1.115, Loss_fe 2.380, Loss_kd 2.639, Train_accy 61.11, Test_accy 80.25: 100%|██████████| 1/1 [00:43<00:00, 43.04s/it]
2024-08-20 00:16:33,881 [foster.py] => Task 16, Epoch 1/1 => Loss 6.299, Loss_clf 1.115, Loss_fe 2.380, Loss_kd 2.639, Train_accy 61.11, Test_accy 80.25
2024-08-20 00:16:33,883 [foster.py] => do not weight align teacher!
2024-08-20 00:16:33,887 [foster.py] => per cls weights : [1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 0.54808058 0.54808058 0.54808058 0.54808058
 0.54808058]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 16, Epoch 1/1 => Loss 2.800,  Train_accy 45.24, Test_accy 78.99:   0%|          | 0/1 [00:38<?, ?it/s]SNet: Task 16, Epoch 1/1 => Loss 2.800,  Train_accy 45.24, Test_accy 78.99: 100%|██████████| 1/1 [00:38<00:00, 38.37s/it]SNet: Task 16, Epoch 1/1 => Loss 2.800,  Train_accy 45.24, Test_accy 78.99: 100%|██████████| 1/1 [00:38<00:00, 38.37s/it]
2024-08-20 00:17:14,019 [foster.py] => SNet: Task 16, Epoch 1/1 => Loss 2.800,  Train_accy 45.24, Test_accy 78.99
2024-08-20 00:17:14,019 [foster.py] => do not weight align student!
2024-08-20 00:17:26,262 [foster.py] => darknet eval: 
2024-08-20 00:17:26,262 [foster.py] => CNN top1 curve: 78.99
2024-08-20 00:17:26,262 [foster.py] => CNN top5 curve: 97.16
2024-08-20 00:17:26,264 [base.py] => Reducing exemplars...(23 per classes)
2024-08-20 00:17:49,288 [base.py] => Constructing exemplars...(23 per classes)
2024-08-20 00:18:43,635 [foster.py] => Exemplar size: 1955
2024-08-20 00:18:43,635 [trainer.py] => CNN: {'total': 80.25, '00-04': 92.0, '05-09': 81.8, '10-14': 83.8, '15-19': 84.8, '20-24': 91.4, '25-29': 85.8, '30-34': 77.0, '35-39': 86.0, '40-44': 78.6, '45-49': 84.6, '50-54': 71.4, '55-59': 79.8, '60-64': 71.8, '65-69': 87.4, '70-74': 83.8, '75-79': 62.2, '80-84': 62.0, 'old': 81.39, 'new': 62.0}
2024-08-20 00:18:43,635 [trainer.py] => NME: {'total': 83.18, '00-04': 93.0, '05-09': 83.0, '10-14': 81.2, '15-19': 86.6, '20-24': 92.4, '25-29': 87.4, '30-34': 79.0, '35-39': 80.6, '40-44': 81.4, '45-49': 85.8, '50-54': 78.6, '55-59': 79.2, '60-64': 77.8, '65-69': 90.6, '70-74': 78.6, '75-79': 74.2, '80-84': 84.6, 'old': 83.09, 'new': 84.6}
2024-08-20 00:18:43,636 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12, 82.06, 80.25]
2024-08-20 00:18:43,636 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32, 97.59, 97.54]
2024-08-20 00:18:43,636 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84, 83.46, 83.18]
2024-08-20 00:18:43,636 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61, 97.55, 97.58]

Average Accuracy (CNN): 85.57
Average Accuracy (NME): 88.56
2024-08-20 00:18:43,636 [trainer.py] => Average Accuracy (CNN): 85.57
2024-08-20 00:18:43,636 [trainer.py] => Average Accuracy (NME): 88.56
2024-08-20 00:18:43,636 [trainer.py] => Train Time: 1212.8400000000001
2024-08-20 00:18:43,636 [trainer.py] => Test Time: 407.08000000000004 

2024-08-20 00:18:43,638 [trainer.py] => All params: 171854842
2024-08-20 00:18:43,639 [trainer.py] => Trainable params: 85994666
2024-08-20 00:18:45,204 [foster.py] => Learning on 85-90
2024-08-20 00:18:45,206 [foster.py] => All params: 171870217
2024-08-20 00:18:45,206 [foster.py] => Trainable params: 86006196
2024-08-20 00:18:45,308 [foster.py] => per cls weights : [1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 0.62246784 0.62246784 0.62246784 0.62246784 0.62246784]
  0%|          | 0/1 [00:00<?, ?it/s]Task 17, Epoch 1/1 => Loss 6.999, Loss_clf 1.246, Loss_fe 2.631, Loss_kd 2.949, Train_accy 56.25, Test_accy 80.10:   0%|          | 0/1 [00:44<?, ?it/s]Task 17, Epoch 1/1 => Loss 6.999, Loss_clf 1.246, Loss_fe 2.631, Loss_kd 2.949, Train_accy 56.25, Test_accy 80.10: 100%|██████████| 1/1 [00:44<00:00, 44.07s/it]Task 17, Epoch 1/1 => Loss 6.999, Loss_clf 1.246, Loss_fe 2.631, Loss_kd 2.949, Train_accy 56.25, Test_accy 80.10: 100%|██████████| 1/1 [00:44<00:00, 44.07s/it]
2024-08-20 00:19:29,380 [foster.py] => Task 17, Epoch 1/1 => Loss 6.999, Loss_clf 1.246, Loss_fe 2.631, Loss_kd 2.949, Train_accy 56.25, Test_accy 80.10
2024-08-20 00:19:29,381 [foster.py] => do not weight align teacher!
2024-08-20 00:19:29,383 [foster.py] => per cls weights : [1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 0.51797551 0.51797551 0.51797551 0.51797551 0.51797551]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 17, Epoch 1/1 => Loss 3.014,  Train_accy 46.15, Test_accy 79.26:   0%|          | 0/1 [00:38<?, ?it/s]SNet: Task 17, Epoch 1/1 => Loss 3.014,  Train_accy 46.15, Test_accy 79.26: 100%|██████████| 1/1 [00:38<00:00, 38.91s/it]SNet: Task 17, Epoch 1/1 => Loss 3.014,  Train_accy 46.15, Test_accy 79.26: 100%|██████████| 1/1 [00:38<00:00, 38.91s/it]
2024-08-20 00:20:09,765 [foster.py] => SNet: Task 17, Epoch 1/1 => Loss 3.014,  Train_accy 46.15, Test_accy 79.26
2024-08-20 00:20:09,765 [foster.py] => do not weight align student!
2024-08-20 00:20:22,584 [foster.py] => darknet eval: 
2024-08-20 00:20:22,584 [foster.py] => CNN top1 curve: 79.26
2024-08-20 00:20:22,584 [foster.py] => CNN top5 curve: 96.46
2024-08-20 00:20:22,586 [base.py] => Reducing exemplars...(22 per classes)
2024-08-20 00:20:46,585 [base.py] => Constructing exemplars...(22 per classes)
2024-08-20 00:21:43,369 [foster.py] => Exemplar size: 1980
2024-08-20 00:21:43,369 [trainer.py] => CNN: {'total': 80.1, '00-04': 90.0, '05-09': 79.0, '10-14': 81.0, '15-19': 85.2, '20-24': 92.0, '25-29': 85.4, '30-34': 78.2, '35-39': 86.6, '40-44': 81.0, '45-49': 79.4, '50-54': 76.4, '55-59': 83.2, '60-64': 69.2, '65-69': 89.4, '70-74': 80.8, '75-79': 62.6, '80-84': 71.2, '85-89': 71.2, 'old': 80.62, 'new': 71.2}
2024-08-20 00:21:43,369 [trainer.py] => NME: {'total': 82.8, '00-04': 90.8, '05-09': 81.8, '10-14': 78.2, '15-19': 85.2, '20-24': 92.2, '25-29': 88.6, '30-34': 81.4, '35-39': 81.2, '40-44': 81.6, '45-49': 85.2, '50-54': 79.0, '55-59': 80.4, '60-64': 77.8, '65-69': 91.2, '70-74': 78.0, '75-79': 73.4, '80-84': 83.0, '85-89': 81.4, 'old': 82.88, 'new': 81.4}
2024-08-20 00:21:43,370 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12, 82.06, 80.25, 80.1]
2024-08-20 00:21:43,370 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32, 97.59, 97.54, 96.99]
2024-08-20 00:21:43,370 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84, 83.46, 83.18, 82.8]
2024-08-20 00:21:43,370 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61, 97.55, 97.58, 97.22]

Average Accuracy (CNN): 85.26
Average Accuracy (NME): 88.24
2024-08-20 00:21:43,370 [trainer.py] => Average Accuracy (CNN): 85.26
2024-08-20 00:21:43,370 [trainer.py] => Average Accuracy (NME): 88.24
2024-08-20 00:21:43,370 [trainer.py] => Train Time: 1310.17
2024-08-20 00:21:43,370 [trainer.py] => Test Time: 454.30000000000007 

2024-08-20 00:21:43,371 [trainer.py] => All params: 171870217
2024-08-20 00:21:43,372 [trainer.py] => Trainable params: 86006196
2024-08-20 00:21:44,934 [foster.py] => Learning on 90-95
2024-08-20 00:21:44,936 [foster.py] => All params: 171885592
2024-08-20 00:21:44,936 [foster.py] => Trainable params: 86017726
2024-08-20 00:21:45,037 [foster.py] => per cls weights : [1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 0.60563504 0.60563504 0.60563504 0.60563504 0.60563504]
  0%|          | 0/1 [00:00<?, ?it/s]Task 18, Epoch 1/1 => Loss 6.655, Loss_clf 1.157, Loss_fe 2.476, Loss_kd 2.862, Train_accy 61.65, Test_accy 79.47:   0%|          | 0/1 [00:45<?, ?it/s]Task 18, Epoch 1/1 => Loss 6.655, Loss_clf 1.157, Loss_fe 2.476, Loss_kd 2.862, Train_accy 61.65, Test_accy 79.47: 100%|██████████| 1/1 [00:45<00:00, 45.47s/it]Task 18, Epoch 1/1 => Loss 6.655, Loss_clf 1.157, Loss_fe 2.476, Loss_kd 2.862, Train_accy 61.65, Test_accy 79.47: 100%|██████████| 1/1 [00:45<00:00, 45.47s/it]
2024-08-20 00:22:30,512 [foster.py] => Task 18, Epoch 1/1 => Loss 6.655, Loss_clf 1.157, Loss_fe 2.476, Loss_kd 2.862, Train_accy 61.65, Test_accy 79.47
2024-08-20 00:22:30,513 [foster.py] => do not weight align teacher!
2024-08-20 00:22:30,514 [foster.py] => per cls weights : [1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 0.50185859 0.50185859 0.50185859 0.50185859 0.50185859]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 18, Epoch 1/1 => Loss 2.941,  Train_accy 44.73, Test_accy 78.36:   0%|          | 0/1 [00:39<?, ?it/s]SNet: Task 18, Epoch 1/1 => Loss 2.941,  Train_accy 44.73, Test_accy 78.36: 100%|██████████| 1/1 [00:39<00:00, 39.54s/it]SNet: Task 18, Epoch 1/1 => Loss 2.941,  Train_accy 44.73, Test_accy 78.36: 100%|██████████| 1/1 [00:39<00:00, 39.54s/it]
2024-08-20 00:23:11,544 [foster.py] => SNet: Task 18, Epoch 1/1 => Loss 2.941,  Train_accy 44.73, Test_accy 78.36
2024-08-20 00:23:11,544 [foster.py] => do not weight align student!
2024-08-20 00:23:25,036 [foster.py] => darknet eval: 
2024-08-20 00:23:25,036 [foster.py] => CNN top1 curve: 78.36
2024-08-20 00:23:25,036 [foster.py] => CNN top5 curve: 96.47
2024-08-20 00:23:25,038 [base.py] => Reducing exemplars...(21 per classes)
2024-08-20 00:23:50,079 [base.py] => Constructing exemplars...(21 per classes)
2024-08-20 00:24:49,433 [foster.py] => Exemplar size: 1995
2024-08-20 00:24:49,433 [trainer.py] => CNN: {'total': 79.47, '00-04': 91.0, '05-09': 78.4, '10-14': 78.2, '15-19': 86.0, '20-24': 91.8, '25-29': 86.4, '30-34': 78.2, '35-39': 78.4, '40-44': 86.4, '45-49': 85.8, '50-54': 72.2, '55-59': 80.6, '60-64': 71.6, '65-69': 88.0, '70-74': 80.0, '75-79': 68.2, '80-84': 76.6, '85-89': 66.6, '90-94': 65.6, 'old': 80.24, 'new': 65.6}
2024-08-20 00:24:49,434 [trainer.py] => NME: {'total': 81.71, '00-04': 90.0, '05-09': 80.6, '10-14': 76.2, '15-19': 85.4, '20-24': 92.2, '25-29': 88.2, '30-34': 78.6, '35-39': 79.6, '40-44': 83.0, '45-49': 85.4, '50-54': 76.2, '55-59': 78.6, '60-64': 77.6, '65-69': 90.0, '70-74': 77.6, '75-79': 69.2, '80-84': 82.6, '85-89': 75.4, '90-94': 86.0, 'old': 81.47, 'new': 86.0}
2024-08-20 00:24:49,434 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12, 82.06, 80.25, 80.1, 79.47]
2024-08-20 00:24:49,434 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32, 97.59, 97.54, 96.99, 96.56]
2024-08-20 00:24:49,434 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84, 83.46, 83.18, 82.8, 81.71]
2024-08-20 00:24:49,434 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61, 97.55, 97.58, 97.22, 96.74]

Average Accuracy (CNN): 84.96
Average Accuracy (NME): 87.9
2024-08-20 00:24:49,434 [trainer.py] => Average Accuracy (CNN): 84.96
2024-08-20 00:24:49,434 [trainer.py] => Average Accuracy (NME): 87.9
2024-08-20 00:24:49,434 [trainer.py] => Train Time: 1410.22
2024-08-20 00:24:49,434 [trainer.py] => Test Time: 504.20000000000005 

2024-08-20 00:24:49,436 [trainer.py] => All params: 171885592
2024-08-20 00:24:49,437 [trainer.py] => Trainable params: 86017726
2024-08-20 00:24:51,123 [foster.py] => Learning on 95-100
2024-08-20 00:24:51,125 [foster.py] => All params: 171900967
2024-08-20 00:24:51,126 [foster.py] => Trainable params: 86029256
2024-08-20 00:24:51,258 [foster.py] => per cls weights : [1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   0.58815605
 0.58815605 0.58815605 0.58815605 0.58815605]
  0%|          | 0/1 [00:00<?, ?it/s]Task 19, Epoch 1/1 => Loss 7.444, Loss_clf 1.289, Loss_fe 2.982, Loss_kd 3.014, Train_accy 54.53, Test_accy 79.37:   0%|          | 0/1 [00:46<?, ?it/s]Task 19, Epoch 1/1 => Loss 7.444, Loss_clf 1.289, Loss_fe 2.982, Loss_kd 3.014, Train_accy 54.53, Test_accy 79.37: 100%|██████████| 1/1 [00:46<00:00, 46.90s/it]Task 19, Epoch 1/1 => Loss 7.444, Loss_clf 1.289, Loss_fe 2.982, Loss_kd 3.014, Train_accy 54.53, Test_accy 79.37: 100%|██████████| 1/1 [00:46<00:00, 46.90s/it]
2024-08-20 00:25:38,158 [foster.py] => Task 19, Epoch 1/1 => Loss 7.444, Loss_clf 1.289, Loss_fe 2.982, Loss_kd 3.014, Train_accy 54.53, Test_accy 79.37
2024-08-20 00:25:38,159 [foster.py] => do not weight align teacher!
2024-08-20 00:25:38,162 [foster.py] => per cls weights : [1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 0.48531931
 0.48531931 0.48531931 0.48531931 0.48531931]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 19, Epoch 1/1 => Loss 3.158,  Train_accy 43.58, Test_accy 78.48:   0%|          | 0/1 [00:40<?, ?it/s]SNet: Task 19, Epoch 1/1 => Loss 3.158,  Train_accy 43.58, Test_accy 78.48: 100%|██████████| 1/1 [00:40<00:00, 40.37s/it]SNet: Task 19, Epoch 1/1 => Loss 3.158,  Train_accy 43.58, Test_accy 78.48: 100%|██████████| 1/1 [00:40<00:00, 40.37s/it]
2024-08-20 00:26:20,064 [foster.py] => SNet: Task 19, Epoch 1/1 => Loss 3.158,  Train_accy 43.58, Test_accy 78.48
2024-08-20 00:26:20,064 [foster.py] => do not weight align student!
2024-08-20 00:26:34,257 [foster.py] => darknet eval: 
2024-08-20 00:26:34,257 [foster.py] => CNN top1 curve: 78.48
2024-08-20 00:26:34,258 [foster.py] => CNN top5 curve: 95.84
2024-08-20 00:26:34,259 [base.py] => Reducing exemplars...(20 per classes)
2024-08-20 00:26:59,916 [base.py] => Constructing exemplars...(20 per classes)
2024-08-20 00:28:02,026 [foster.py] => Exemplar size: 2000
2024-08-20 00:28:02,026 [trainer.py] => CNN: {'total': 79.37, '00-04': 87.0, '05-09': 76.0, '10-14': 73.4, '15-19': 84.0, '20-24': 91.6, '25-29': 86.8, '30-34': 82.2, '35-39': 80.2, '40-44': 83.6, '45-49': 80.0, '50-54': 71.6, '55-59': 81.6, '60-64': 71.6, '65-69': 90.8, '70-74': 80.0, '75-79': 71.2, '80-84': 77.4, '85-89': 71.8, '90-94': 76.8, '95-99': 69.8, 'old': 79.87, 'new': 69.8}
2024-08-20 00:28:02,026 [trainer.py] => NME: {'total': 81.7, '00-04': 90.0, '05-09': 80.6, '10-14': 77.4, '15-19': 86.8, '20-24': 91.8, '25-29': 87.2, '30-34': 78.6, '35-39': 79.6, '40-44': 83.6, '45-49': 86.2, '50-54': 75.6, '55-59': 80.2, '60-64': 77.4, '65-69': 89.6, '70-74': 78.4, '75-79': 72.6, '80-84': 85.2, '85-89': 75.8, '90-94': 84.2, '95-99': 73.2, 'old': 82.15, 'new': 73.2}
2024-08-20 00:28:02,026 [trainer.py] => CNN top1 curve: [77.2, 94.5, 91.27, 90.4, 90.24, 88.23, 85.94, 85.25, 84.91, 83.74, 84.47, 84.9, 84.17, 84.01, 83.12, 82.06, 80.25, 80.1, 79.47, 79.37]
2024-08-20 00:28:02,026 [trainer.py] => CNN top5 curve: [100.0, 99.9, 99.2, 98.7, 98.96, 98.47, 98.31, 98.02, 98.07, 98.14, 98.25, 97.77, 98.0, 97.73, 97.32, 97.59, 97.54, 96.99, 96.56, 96.33]
2024-08-20 00:28:02,026 [trainer.py] => NME top1 curve: [94.0, 97.7, 94.33, 92.4, 90.8, 90.87, 89.46, 87.58, 87.11, 86.58, 85.6, 86.33, 85.63, 85.7, 84.84, 83.46, 83.18, 82.8, 81.71, 81.7]
2024-08-20 00:28:02,026 [trainer.py] => NME top5 curve: [100.0, 99.9, 99.8, 98.75, 98.68, 98.53, 98.86, 98.35, 98.33, 98.38, 98.35, 97.78, 97.82, 97.76, 97.61, 97.55, 97.58, 97.22, 96.74, 96.44]

Average Accuracy (CNN): 84.68
Average Accuracy (NME): 87.59
2024-08-20 00:28:02,026 [trainer.py] => Average Accuracy (CNN): 84.68
2024-08-20 00:28:02,026 [trainer.py] => Average Accuracy (NME): 87.59
2024-08-20 00:28:02,026 [trainer.py] => Train Time: 1513.29
2024-08-20 00:28:02,026 [trainer.py] => Test Time: 556.8100000000001 

Accuracy Matrix (CNN):
[[77.2 94.4 95.  95.8 95.4 95.2 94.8 91.8 88.  92.8 89.  91.2 92.4 84.
  89.2 90.4 92.  90.  91.  87. ]
 [ 0.  94.6 84.6 84.  88.6 77.6 74.4 77.2 75.2 74.2 81.4 76.4 79.8 82.4
  81.6 80.8 81.8 79.  78.4 76. ]
 [ 0.   0.  94.2 87.8 84.6 82.8 81.6 79.  75.4 82.  83.  81.8 82.6 80.4
  79.2 83.  83.8 81.  78.2 73.4]
 [ 0.   0.   0.  94.  87.4 85.2 82.4 80.4 82.2 82.2 87.8 87.4 83.4 85.2
  84.  86.  84.8 85.2 86.  84. ]
 [ 0.   0.   0.   0.  95.2 93.2 89.2 87.  89.6 82.  91.2 93.6 91.4 94.
  89.8 91.8 91.4 92.  91.8 91.6]
 [ 0.   0.   0.   0.   0.  95.4 91.2 87.2 88.6 85.2 84.8 86.6 88.2 87.8
  86.8 84.8 85.8 85.4 86.4 86.8]
 [ 0.   0.   0.   0.   0.   0.  88.  86.  81.2 85.2 80.2 77.8 81.8 76.4
  78.8 77.2 77.  78.2 78.2 82.2]
 [ 0.   0.   0.   0.   0.   0.   0.  93.4 88.2 83.6 85.8 85.4 88.6 87.6
  84.  83.8 86.  86.6 78.4 80.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.  95.8 86.  80.2 85.  82.6 84.2
  84.4 82.6 78.6 81.  86.4 83.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  84.2 82.2 82.8 83.  84.2
  87.2 87.2 84.6 79.4 85.8 80. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  83.6 79.8 77.8 77.2
  79.6 77.4 71.4 76.4 72.2 71.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  91.  80.  87.
  78.8 73.8 79.8 83.2 80.6 81.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  82.6 72.8
  69.4 80.4 71.8 69.2 71.6 71.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  93.
  88.8 87.2 87.4 89.4 88.  90.8]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  85.2 76.2 83.8 80.8 80.  80. ]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.  70.4 62.2 62.6 68.2 71.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.  62.  71.2 76.6 77.4]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.  71.2 66.6 71.8]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.  65.6 76.8]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.  69.8]]
2024-08-20 00:28:02,028 [trainer.py] => Forgetting (CNN): 7.821052631578948
Accuracy Matrix (NME):
[[94.  99.  97.2 97.8 97.6 97.8 98.  96.2 95.4 96.4 94.4 94.2 94.  91.8
  91.6 92.4 93.  90.8 90.  90. ]
 [ 0.  96.4 92.8 91.2 90.2 87.6 86.4 82.2 85.6 83.2 80.  82.6 83.  84.4
  83.6 84.  83.  81.8 80.6 80.6]
 [ 0.   0.  93.  91.  88.4 87.2 86.6 87.4 83.2 82.2 83.4 83.  81.8 82.8
  81.8 81.2 81.2 78.2 76.2 77.4]
 [ 0.   0.   0.  89.6 88.2 87.8 86.2 85.8 85.8 86.  85.4 86.6 85.8 85.8
  85.6 85.6 86.6 85.2 85.4 86.8]
 [ 0.   0.   0.   0.  89.6 92.6 93.6 92.  90.6 91.4 92.  93.8 93.6 92.
  93.2 93.  92.4 92.2 92.2 91.8]
 [ 0.   0.   0.   0.   0.  92.2 92.2 90.6 91.  89.2 88.8 89.6 89.2 89.
  88.6 87.8 87.4 88.6 88.2 87.2]
 [ 0.   0.   0.   0.   0.   0.  83.2 79.  79.6 81.2 81.  80.8 81.2 79.4
  80.  80.2 79.  81.4 78.6 78.6]
 [ 0.   0.   0.   0.   0.   0.   0.  87.4 87.8 81.6 82.  83.8 83.  83.
  80.8 81.6 80.6 81.2 79.6 79.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.  85.  83.4 82.6 84.2 82.4 82.2
  82.6 83.6 81.4 81.6 83.  83.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.  91.2 88.4 89.  88.4 89.2
  90.2 87.4 85.8 85.2 85.4 86.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  83.6 81.8 83.6 82.4
  82.8 77.6 78.6 79.  76.2 75.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  86.6 82.  82.6
  80.8 78.8 79.2 80.4 78.6 80.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  85.2 82.8
  80.2 79.2 77.8 77.8 77.6 77.4]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  92.4
  90.  89.6 90.6 91.2 90.  89.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  80.8 77.8 78.6 78.  77.6 78.4]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.  75.6 74.2 73.4 69.2 72.6]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.  84.6 83.  82.6 85.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.  81.4 75.4 75.8]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.  86.  84.2]
 [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.   0.   0.   0.  73.2]]
2024-08-20 00:28:02,030 [trainer.py] => Forgetting (NME): 5.642105263157895
2024-08-20 00:28:04,235 [trainer.py] => config: ./exps/foster_cifar_B50_Inc5.json
2024-08-20 00:28:04,235 [trainer.py] => prefix: cil
2024-08-20 00:28:04,235 [trainer.py] => dataset: cifar224
2024-08-20 00:28:04,235 [trainer.py] => memory_size: 2000
2024-08-20 00:28:04,235 [trainer.py] => memory_per_class: 20
2024-08-20 00:28:04,235 [trainer.py] => fixed_memory: False
2024-08-20 00:28:04,235 [trainer.py] => shuffle: True
2024-08-20 00:28:04,235 [trainer.py] => init_cls: 50
2024-08-20 00:28:04,235 [trainer.py] => increment: 10
2024-08-20 00:28:04,235 [trainer.py] => model_name: foster
2024-08-20 00:28:04,235 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-08-20 00:28:04,235 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-20 00:28:04,236 [trainer.py] => seed: 1993
2024-08-20 00:28:04,236 [trainer.py] => beta1: 0.96
2024-08-20 00:28:04,236 [trainer.py] => beta2: 0.97
2024-08-20 00:28:04,236 [trainer.py] => oofc: ft
2024-08-20 00:28:04,236 [trainer.py] => is_teacher_wa: False
2024-08-20 00:28:04,236 [trainer.py] => is_student_wa: False
2024-08-20 00:28:04,236 [trainer.py] => lambda_okd: 1
2024-08-20 00:28:04,236 [trainer.py] => wa_value: 1
2024-08-20 00:28:04,236 [trainer.py] => init_epochs: 1
2024-08-20 00:28:04,236 [trainer.py] => init_lr: 0.001
2024-08-20 00:28:04,236 [trainer.py] => init_weight_decay: 0.0005
2024-08-20 00:28:04,236 [trainer.py] => boosting_epochs: 1
2024-08-20 00:28:04,236 [trainer.py] => compression_epochs: 1
2024-08-20 00:28:04,236 [trainer.py] => lr: 0.001
2024-08-20 00:28:04,236 [trainer.py] => batch_size: 48
2024-08-20 00:28:04,236 [trainer.py] => weight_decay: 0.0005
2024-08-20 00:28:04,236 [trainer.py] => num_workers: 8
2024-08-20 00:28:04,236 [trainer.py] => T: 2
2024-08-20 00:28:05,171 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-20 00:28:05,792 [trainer.py] => All params: 0
2024-08-20 00:28:05,793 [trainer.py] => Trainable params: 0
2024-08-20 00:28:07,218 [foster.py] => Learning on 0-50
2024-08-20 00:28:07,219 [foster.py] => All params: 85875556
2024-08-20 00:28:07,219 [foster.py] => Trainable params: 85875556
  0%|          | 0/1 [00:00<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20:   0%|          | 0/1 [01:33<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20: 100%|██████████| 1/1 [01:33<00:00, 93.52s/it]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20: 100%|██████████| 1/1 [01:33<00:00, 93.53s/it]
2024-08-20 00:29:41,103 [foster.py] => Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20
2024-08-20 00:29:41,104 [base.py] => Reducing exemplars...(40 per classes)
2024-08-20 00:29:41,104 [base.py] => Constructing exemplars...(40 per classes)
2024-08-20 00:30:56,547 [foster.py] => Exemplar size: 2000
2024-08-20 00:30:56,547 [trainer.py] => CNN: {'total': 89.2, '00-49': 89.2, 'old': 0, 'new': 89.2}
2024-08-20 00:30:56,547 [trainer.py] => NME: {'total': 90.68, '00-49': 90.68, 'old': 0, 'new': 90.68}
2024-08-20 00:30:56,547 [trainer.py] => CNN top1 curve: [89.2]
2024-08-20 00:30:56,547 [trainer.py] => CNN top5 curve: [98.62]
2024-08-20 00:30:56,547 [trainer.py] => NME top1 curve: [90.68]
2024-08-20 00:30:56,547 [trainer.py] => NME top5 curve: [98.66]

Average Accuracy (CNN): 89.2
Average Accuracy (NME): 90.68
2024-08-20 00:30:56,547 [trainer.py] => Average Accuracy (CNN): 89.2
2024-08-20 00:30:56,547 [trainer.py] => Average Accuracy (NME): 90.68
2024-08-20 00:30:56,547 [trainer.py] => Train Time: 93.81
2024-08-20 00:30:56,547 [trainer.py] => Test Time: 14.78 

2024-08-20 00:30:56,548 [trainer.py] => All params: 85875556
2024-08-20 00:30:56,549 [trainer.py] => Trainable params: 85875556
2024-08-20 00:30:58,147 [foster.py] => Learning on 50-60
2024-08-20 00:30:58,148 [foster.py] => All params: 171774122
2024-08-20 00:30:58,149 [foster.py] => Trainable params: 85937016
2024-08-20 00:30:58,275 [foster.py] => per cls weights : [1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693 1.03365693
 1.03365693 1.03365693 0.83171535 0.83171535 0.83171535 0.83171535
 0.83171535 0.83171535 0.83171535 0.83171535 0.83171535 0.83171535]
  0%|          | 0/1 [00:00<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.632, Loss_clf 1.028, Loss_fe 1.565, Loss_kd 2.533, Train_accy 71.53, Test_accy 87.68:   0%|          | 0/1 [00:47<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.632, Loss_clf 1.028, Loss_fe 1.565, Loss_kd 2.533, Train_accy 71.53, Test_accy 87.68: 100%|██████████| 1/1 [00:47<00:00, 47.95s/it]Task 1, Epoch 1/1 => Loss 5.632, Loss_clf 1.028, Loss_fe 1.565, Loss_kd 2.533, Train_accy 71.53, Test_accy 87.68: 100%|██████████| 1/1 [00:47<00:00, 47.95s/it]
2024-08-20 00:31:46,231 [foster.py] => Task 1, Epoch 1/1 => Loss 5.632, Loss_clf 1.028, Loss_fe 1.565, Loss_kd 2.533, Train_accy 71.53, Test_accy 87.68
2024-08-20 00:31:46,232 [foster.py] => do not weight align teacher!
2024-08-20 00:31:46,233 [foster.py] => per cls weights : [1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035 1.05184035
 1.05184035 1.05184035 0.74079824 0.74079824 0.74079824 0.74079824
 0.74079824 0.74079824 0.74079824 0.74079824 0.74079824 0.74079824]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.687,  Train_accy 64.06, Test_accy 88.28:   0%|          | 0/1 [00:49<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.687,  Train_accy 64.06, Test_accy 88.28: 100%|██████████| 1/1 [00:49<00:00, 49.08s/it]SNet: Task 1, Epoch 1/1 => Loss 2.687,  Train_accy 64.06, Test_accy 88.28: 100%|██████████| 1/1 [00:49<00:00, 49.08s/it]
2024-08-20 00:32:36,818 [foster.py] => SNet: Task 1, Epoch 1/1 => Loss 2.687,  Train_accy 64.06, Test_accy 88.28
2024-08-20 00:32:36,818 [foster.py] => do not weight align student!
2024-08-20 00:32:45,522 [foster.py] => darknet eval: 
2024-08-20 00:32:45,522 [foster.py] => CNN top1 curve: 88.28
2024-08-20 00:32:45,522 [foster.py] => CNN top5 curve: 98.53
2024-08-20 00:32:45,523 [base.py] => Reducing exemplars...(33 per classes)
2024-08-20 00:32:59,863 [base.py] => Constructing exemplars...(33 per classes)
2024-08-20 00:33:50,536 [foster.py] => Exemplar size: 1980
2024-08-20 00:33:50,536 [trainer.py] => CNN: {'total': 87.68, '00-49': 87.8, '50-59': 87.1, 'old': 87.8, 'new': 87.1}
2024-08-20 00:33:50,536 [trainer.py] => NME: {'total': 89.9, '00-49': 90.64, '50-59': 86.2, 'old': 90.64, 'new': 86.2}
2024-08-20 00:33:50,536 [trainer.py] => CNN top1 curve: [89.2, 87.68]
2024-08-20 00:33:50,536 [trainer.py] => CNN top5 curve: [98.62, 98.25]
2024-08-20 00:33:50,536 [trainer.py] => NME top1 curve: [90.68, 89.9]
2024-08-20 00:33:50,536 [trainer.py] => NME top5 curve: [98.66, 98.68]

Average Accuracy (CNN): 88.44
Average Accuracy (NME): 90.29
2024-08-20 00:33:50,536 [trainer.py] => Average Accuracy (CNN): 88.44
2024-08-20 00:33:50,536 [trainer.py] => Average Accuracy (NME): 90.29
2024-08-20 00:33:50,536 [trainer.py] => Train Time: 201.11
2024-08-20 00:33:50,536 [trainer.py] => Test Time: 46.46 

2024-08-20 00:33:50,538 [trainer.py] => All params: 171774122
2024-08-20 00:33:50,539 [trainer.py] => Trainable params: 85937016
2024-08-20 00:33:52,140 [foster.py] => Learning on 60-70
2024-08-20 00:33:52,142 [foster.py] => All params: 171804872
2024-08-20 00:33:52,143 [foster.py] => Trainable params: 85960076
2024-08-20 00:33:52,345 [foster.py] => per cls weights : [1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358 1.03857358
 0.76855853 0.76855853 0.76855853 0.76855853 0.76855853 0.76855853
 0.76855853 0.76855853 0.76855853 0.76855853]
  0%|          | 0/1 [00:00<?, ?it/s]Task 2, Epoch 1/1 => Loss 5.471, Loss_clf 0.890, Loss_fe 1.560, Loss_kd 2.589, Train_accy 72.75, Test_accy 87.47:   0%|          | 0/1 [00:50<?, ?it/s]Task 2, Epoch 1/1 => Loss 5.471, Loss_clf 0.890, Loss_fe 1.560, Loss_kd 2.589, Train_accy 72.75, Test_accy 87.47: 100%|██████████| 1/1 [00:50<00:00, 50.50s/it]Task 2, Epoch 1/1 => Loss 5.471, Loss_clf 0.890, Loss_fe 1.560, Loss_kd 2.589, Train_accy 72.75, Test_accy 87.47: 100%|██████████| 1/1 [00:50<00:00, 50.50s/it]
2024-08-20 00:34:42,853 [foster.py] => Task 2, Epoch 1/1 => Loss 5.471, Loss_clf 0.890, Loss_fe 1.560, Loss_kd 2.589, Train_accy 72.75, Test_accy 87.47
2024-08-20 00:34:42,854 [foster.py] => do not weight align teacher!
2024-08-20 00:34:42,856 [foster.py] => per cls weights : [1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848 1.05516848
 0.66898913 0.66898913 0.66898913 0.66898913 0.66898913 0.66898913
 0.66898913 0.66898913 0.66898913 0.66898913]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 2.699,  Train_accy 61.89, Test_accy 87.27:   0%|          | 0/1 [00:50<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 2.699,  Train_accy 61.89, Test_accy 87.27: 100%|██████████| 1/1 [00:50<00:00, 50.32s/it]SNet: Task 2, Epoch 1/1 => Loss 2.699,  Train_accy 61.89, Test_accy 87.27: 100%|██████████| 1/1 [00:50<00:00, 50.32s/it]
2024-08-20 00:35:34,692 [foster.py] => SNet: Task 2, Epoch 1/1 => Loss 2.699,  Train_accy 61.89, Test_accy 87.27
2024-08-20 00:35:34,692 [foster.py] => do not weight align student!
2024-08-20 00:35:44,736 [foster.py] => darknet eval: 
2024-08-20 00:35:44,736 [foster.py] => CNN top1 curve: 87.27
2024-08-20 00:35:44,736 [foster.py] => CNN top5 curve: 98.37
2024-08-20 00:35:44,738 [base.py] => Reducing exemplars...(28 per classes)
2024-08-20 00:36:01,341 [base.py] => Constructing exemplars...(28 per classes)
2024-08-20 00:36:58,123 [foster.py] => Exemplar size: 1960
2024-08-20 00:36:58,123 [trainer.py] => CNN: {'total': 87.47, '00-49': 88.8, '50-59': 79.1, '60-69': 89.2, 'old': 87.18, 'new': 89.2}
2024-08-20 00:36:58,123 [trainer.py] => NME: {'total': 88.99, '00-49': 89.9, '50-59': 83.8, '60-69': 89.6, 'old': 88.88, 'new': 89.6}
2024-08-20 00:36:58,123 [trainer.py] => CNN top1 curve: [89.2, 87.68, 87.47]
2024-08-20 00:36:58,123 [trainer.py] => CNN top5 curve: [98.62, 98.25, 98.24]
2024-08-20 00:36:58,123 [trainer.py] => NME top1 curve: [90.68, 89.9, 88.99]
2024-08-20 00:36:58,123 [trainer.py] => NME top5 curve: [98.66, 98.68, 98.61]

Average Accuracy (CNN): 88.12
Average Accuracy (NME): 89.86
2024-08-20 00:36:58,123 [trainer.py] => Average Accuracy (CNN): 88.12
2024-08-20 00:36:58,123 [trainer.py] => Average Accuracy (NME): 89.86
2024-08-20 00:36:58,123 [trainer.py] => Train Time: 313.6
2024-08-20 00:36:58,123 [trainer.py] => Test Time: 83.99000000000001 

2024-08-20 00:36:58,125 [trainer.py] => All params: 171804872
2024-08-20 00:36:58,126 [trainer.py] => Trainable params: 85960076
2024-08-20 00:36:59,617 [foster.py] => Learning on 70-80
2024-08-20 00:36:59,619 [foster.py] => All params: 171835622
2024-08-20 00:36:59,619 [foster.py] => Trainable params: 85983136
2024-08-20 00:36:59,775 [foster.py] => per cls weights : [1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152 1.04151152
 1.04151152 1.04151152 1.04151152 1.04151152 0.70941937 0.70941937
 0.70941937 0.70941937 0.70941937 0.70941937 0.70941937 0.70941937
 0.70941937 0.70941937]
  0%|          | 0/1 [00:00<?, ?it/s]Task 3, Epoch 1/1 => Loss 5.978, Loss_clf 1.082, Loss_fe 1.857, Loss_kd 2.658, Train_accy 62.20, Test_accy 83.98:   0%|          | 0/1 [00:53<?, ?it/s]Task 3, Epoch 1/1 => Loss 5.978, Loss_clf 1.082, Loss_fe 1.857, Loss_kd 2.658, Train_accy 62.20, Test_accy 83.98: 100%|██████████| 1/1 [00:53<00:00, 53.50s/it]Task 3, Epoch 1/1 => Loss 5.978, Loss_clf 1.082, Loss_fe 1.857, Loss_kd 2.658, Train_accy 62.20, Test_accy 83.98: 100%|██████████| 1/1 [00:53<00:00, 53.50s/it]
2024-08-20 00:37:53,277 [foster.py] => Task 3, Epoch 1/1 => Loss 5.978, Loss_clf 1.082, Loss_fe 1.857, Loss_kd 2.658, Train_accy 62.20, Test_accy 83.98
2024-08-20 00:37:53,277 [foster.py] => do not weight align teacher!
2024-08-20 00:37:53,279 [foster.py] => per cls weights : [1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227 1.05627227
 1.05627227 1.05627227 1.05627227 1.05627227 0.60609409 0.60609409
 0.60609409 0.60609409 0.60609409 0.60609409 0.60609409 0.60609409
 0.60609409 0.60609409]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.989,  Train_accy 47.40, Test_accy 83.21:   0%|          | 0/1 [00:52<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.989,  Train_accy 47.40, Test_accy 83.21: 100%|██████████| 1/1 [00:52<00:00, 52.09s/it]SNet: Task 3, Epoch 1/1 => Loss 2.989,  Train_accy 47.40, Test_accy 83.21: 100%|██████████| 1/1 [00:52<00:00, 52.09s/it]
2024-08-20 00:38:47,063 [foster.py] => SNet: Task 3, Epoch 1/1 => Loss 2.989,  Train_accy 47.40, Test_accy 83.21
2024-08-20 00:38:47,063 [foster.py] => do not weight align student!
2024-08-20 00:38:58,913 [foster.py] => darknet eval: 
2024-08-20 00:38:58,914 [foster.py] => CNN top1 curve: 83.21
2024-08-20 00:38:58,914 [foster.py] => CNN top5 curve: 97.85
2024-08-20 00:38:58,915 [base.py] => Reducing exemplars...(25 per classes)
2024-08-20 00:39:18,719 [base.py] => Constructing exemplars...(25 per classes)
2024-08-20 00:40:20,691 [foster.py] => Exemplar size: 2000
2024-08-20 00:40:20,692 [trainer.py] => CNN: {'total': 83.98, '00-49': 87.66, '50-59': 78.2, '60-69': 82.2, '70-79': 73.1, 'old': 85.53, 'new': 73.1}
2024-08-20 00:40:20,692 [trainer.py] => NME: {'total': 86.56, '00-49': 89.38, '50-59': 80.6, '60-69': 86.1, '70-79': 78.9, 'old': 87.66, 'new': 78.9}
2024-08-20 00:40:20,692 [trainer.py] => CNN top1 curve: [89.2, 87.68, 87.47, 83.98]
2024-08-20 00:40:20,692 [trainer.py] => CNN top5 curve: [98.62, 98.25, 98.24, 97.96]
2024-08-20 00:40:20,692 [trainer.py] => NME top1 curve: [90.68, 89.9, 88.99, 86.56]
2024-08-20 00:40:20,692 [trainer.py] => NME top5 curve: [98.66, 98.68, 98.61, 98.21]

Average Accuracy (CNN): 87.08
Average Accuracy (NME): 89.03
2024-08-20 00:40:20,692 [trainer.py] => Average Accuracy (CNN): 87.08
2024-08-20 00:40:20,692 [trainer.py] => Average Accuracy (NME): 89.03
2024-08-20 00:40:20,692 [trainer.py] => Train Time: 432.83000000000004
2024-08-20 00:40:20,692 [trainer.py] => Test Time: 126.75 

2024-08-20 00:40:20,693 [trainer.py] => All params: 171835622
2024-08-20 00:40:20,694 [trainer.py] => Trainable params: 85983136
2024-08-20 00:40:22,187 [foster.py] => Learning on 80-90
2024-08-20 00:40:22,189 [foster.py] => All params: 171866372
2024-08-20 00:40:22,190 [foster.py] => Trainable params: 86006196
2024-08-20 00:40:22,344 [foster.py] => per cls weights : [1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  1.0417145  1.0417145  1.0417145  1.0417145
 1.0417145  1.0417145  0.66628401 0.66628401 0.66628401 0.66628401
 0.66628401 0.66628401 0.66628401 0.66628401 0.66628401 0.66628401]
  0%|          | 0/1 [00:00<?, ?it/s]Task 4, Epoch 1/1 => Loss 6.328, Loss_clf 1.083, Loss_fe 2.007, Loss_kd 2.878, Train_accy 61.14, Test_accy 82.63:   0%|          | 0/1 [00:56<?, ?it/s]Task 4, Epoch 1/1 => Loss 6.328, Loss_clf 1.083, Loss_fe 2.007, Loss_kd 2.878, Train_accy 61.14, Test_accy 82.63: 100%|██████████| 1/1 [00:56<00:00, 56.30s/it]Task 4, Epoch 1/1 => Loss 6.328, Loss_clf 1.083, Loss_fe 2.007, Loss_kd 2.878, Train_accy 61.14, Test_accy 82.63: 100%|██████████| 1/1 [00:56<00:00, 56.30s/it]
2024-08-20 00:41:18,645 [foster.py] => Task 4, Epoch 1/1 => Loss 6.328, Loss_clf 1.083, Loss_fe 2.007, Loss_kd 2.878, Train_accy 61.14, Test_accy 82.63
2024-08-20 00:41:18,646 [foster.py] => do not weight align teacher!
2024-08-20 00:41:18,647 [foster.py] => per cls weights : [1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557 1.05472557
 1.05472557 1.05472557 0.56219541 0.56219541 0.56219541 0.56219541
 0.56219541 0.56219541 0.56219541 0.56219541 0.56219541 0.56219541]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 3.158,  Train_accy 49.44, Test_accy 81.92:   0%|          | 0/1 [00:53<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 3.158,  Train_accy 49.44, Test_accy 81.92: 100%|██████████| 1/1 [00:53<00:00, 53.67s/it]SNet: Task 4, Epoch 1/1 => Loss 3.158,  Train_accy 49.44, Test_accy 81.92: 100%|██████████| 1/1 [00:53<00:00, 53.67s/it]
2024-08-20 00:42:13,815 [foster.py] => SNet: Task 4, Epoch 1/1 => Loss 3.158,  Train_accy 49.44, Test_accy 81.92
2024-08-20 00:42:13,815 [foster.py] => do not weight align student!
2024-08-20 00:42:26,906 [foster.py] => darknet eval: 
2024-08-20 00:42:26,906 [foster.py] => CNN top1 curve: 81.92
2024-08-20 00:42:26,906 [foster.py] => CNN top5 curve: 97.53
2024-08-20 00:42:26,908 [base.py] => Reducing exemplars...(22 per classes)
2024-08-20 00:42:48,920 [base.py] => Constructing exemplars...(22 per classes)
2024-08-20 00:43:56,198 [foster.py] => Exemplar size: 1980
2024-08-20 00:43:56,199 [trainer.py] => CNN: {'total': 82.63, '00-49': 87.64, '50-59': 74.0, '60-69': 86.2, '70-79': 66.6, '80-89': 78.7, 'old': 83.12, 'new': 78.7}
2024-08-20 00:43:56,199 [trainer.py] => NME: {'total': 85.44, '00-49': 88.1, '50-59': 79.9, '60-69': 86.2, '70-79': 76.3, '80-89': 86.1, 'old': 85.36, 'new': 86.1}
2024-08-20 00:43:56,199 [trainer.py] => CNN top1 curve: [89.2, 87.68, 87.47, 83.98, 82.63]
2024-08-20 00:43:56,199 [trainer.py] => CNN top5 curve: [98.62, 98.25, 98.24, 97.96, 97.54]
2024-08-20 00:43:56,199 [trainer.py] => NME top1 curve: [90.68, 89.9, 88.99, 86.56, 85.44]
2024-08-20 00:43:56,199 [trainer.py] => NME top5 curve: [98.66, 98.68, 98.61, 98.21, 97.77]

Average Accuracy (CNN): 86.19
Average Accuracy (NME): 88.31
2024-08-20 00:43:56,199 [trainer.py] => Average Accuracy (CNN): 86.19
2024-08-20 00:43:56,199 [trainer.py] => Average Accuracy (NME): 88.31
2024-08-20 00:43:56,199 [trainer.py] => Train Time: 557.48
2024-08-20 00:43:56,199 [trainer.py] => Test Time: 174.87 

2024-08-20 00:43:56,200 [trainer.py] => All params: 171866372
2024-08-20 00:43:56,201 [trainer.py] => Trainable params: 86006196
2024-08-20 00:43:57,660 [foster.py] => Learning on 90-100
2024-08-20 00:43:57,662 [foster.py] => All params: 171897122
2024-08-20 00:43:57,663 [foster.py] => Trainable params: 86029256
2024-08-20 00:43:57,823 [foster.py] => per cls weights : [1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474 1.04246474
 0.61781731 0.61781731 0.61781731 0.61781731 0.61781731 0.61781731
 0.61781731 0.61781731 0.61781731 0.61781731]
  0%|          | 0/1 [00:00<?, ?it/s]Task 5, Epoch 1/1 => Loss 6.588, Loss_clf 1.146, Loss_fe 2.074, Loss_kd 3.031, Train_accy 58.98, Test_accy 80.81:   0%|          | 0/1 [00:58<?, ?it/s]Task 5, Epoch 1/1 => Loss 6.588, Loss_clf 1.146, Loss_fe 2.074, Loss_kd 3.031, Train_accy 58.98, Test_accy 80.81: 100%|██████████| 1/1 [00:58<00:00, 58.68s/it]Task 5, Epoch 1/1 => Loss 6.588, Loss_clf 1.146, Loss_fe 2.074, Loss_kd 3.031, Train_accy 58.98, Test_accy 80.81: 100%|██████████| 1/1 [00:58<00:00, 58.68s/it]
2024-08-20 00:44:56,505 [foster.py] => Task 5, Epoch 1/1 => Loss 6.588, Loss_clf 1.146, Loss_fe 2.074, Loss_kd 3.031, Train_accy 58.98, Test_accy 80.81
2024-08-20 00:44:56,506 [foster.py] => do not weight align teacher!
2024-08-20 00:44:56,508 [foster.py] => per cls weights : [1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247
 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 1.0539247 0.5146777
 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777 0.5146777
 0.5146777 0.5146777]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 3.358,  Train_accy 36.15, Test_accy 79.06:   0%|          | 0/1 [00:55<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 3.358,  Train_accy 36.15, Test_accy 79.06: 100%|██████████| 1/1 [00:55<00:00, 55.03s/it]SNet: Task 5, Epoch 1/1 => Loss 3.358,  Train_accy 36.15, Test_accy 79.06: 100%|██████████| 1/1 [00:55<00:00, 55.03s/it]
2024-08-20 00:45:53,031 [foster.py] => SNet: Task 5, Epoch 1/1 => Loss 3.358,  Train_accy 36.15, Test_accy 79.06
2024-08-20 00:45:53,032 [foster.py] => do not weight align student!
2024-08-20 00:46:07,770 [foster.py] => darknet eval: 
2024-08-20 00:46:07,770 [foster.py] => CNN top1 curve: 79.06
2024-08-20 00:46:07,770 [foster.py] => CNN top5 curve: 96.59
2024-08-20 00:46:07,771 [base.py] => Reducing exemplars...(20 per classes)
2024-08-20 00:46:31,789 [base.py] => Constructing exemplars...(20 per classes)
2024-08-20 00:47:44,482 [foster.py] => Exemplar size: 2000
2024-08-20 00:47:44,482 [trainer.py] => CNN: {'total': 80.81, '00-49': 87.58, '50-59': 75.4, '60-69': 86.8, '70-79': 66.3, '80-89': 75.6, '90-99': 66.1, 'old': 82.44, 'new': 66.1}
2024-08-20 00:47:44,482 [trainer.py] => NME: {'total': 84.43, '00-49': 88.14, '50-59': 77.8, '60-69': 85.8, '70-79': 77.0, '80-89': 81.1, '90-99': 81.9, 'old': 84.71, 'new': 81.9}
2024-08-20 00:47:44,482 [trainer.py] => CNN top1 curve: [89.2, 87.68, 87.47, 83.98, 82.63, 80.81]
2024-08-20 00:47:44,482 [trainer.py] => CNN top5 curve: [98.62, 98.25, 98.24, 97.96, 97.54, 97.27]
2024-08-20 00:47:44,482 [trainer.py] => NME top1 curve: [90.68, 89.9, 88.99, 86.56, 85.44, 84.43]
2024-08-20 00:47:44,482 [trainer.py] => NME top5 curve: [98.66, 98.68, 98.61, 98.21, 97.77, 97.53]

Average Accuracy (CNN): 85.3
Average Accuracy (NME): 87.67
2024-08-20 00:47:44,482 [trainer.py] => Average Accuracy (CNN): 85.3
2024-08-20 00:47:44,483 [trainer.py] => Average Accuracy (NME): 87.67
2024-08-20 00:47:44,483 [trainer.py] => Train Time: 687.52
2024-08-20 00:47:44,483 [trainer.py] => Test Time: 228.4 

Accuracy Matrix (CNN):
[[89.2  87.8  88.8  87.66 87.64 87.58]
 [ 0.   87.1  79.1  78.2  74.   75.4 ]
 [ 0.    0.   89.2  82.2  86.2  86.8 ]
 [ 0.    0.    0.   73.1  66.6  66.3 ]
 [ 0.    0.    0.    0.   78.7  75.6 ]
 [ 0.    0.    0.    0.    0.   66.1 ]]
2024-08-20 00:47:44,483 [trainer.py] => Forgetting (CNN): 5.1240000000000006
Accuracy Matrix (NME):
[[90.68 90.64 89.9  89.38 88.1  88.14]
 [ 0.   86.2  83.8  80.6  79.9  77.8 ]
 [ 0.    0.   89.6  86.1  86.2  85.8 ]
 [ 0.    0.    0.   78.9  76.3  77.  ]
 [ 0.    0.    0.    0.   86.1  81.1 ]
 [ 0.    0.    0.    0.    0.   81.9 ]]
2024-08-20 00:47:44,484 [trainer.py] => Forgetting (NME): 4.328000000000003
2024-08-20 00:47:46,592 [trainer.py] => config: ./exps/foster_cifar_B50_Inc10.json
2024-08-20 00:47:46,593 [trainer.py] => prefix: cil
2024-08-20 00:47:46,593 [trainer.py] => dataset: cifar224
2024-08-20 00:47:46,593 [trainer.py] => memory_size: 2000
2024-08-20 00:47:46,593 [trainer.py] => memory_per_class: 20
2024-08-20 00:47:46,593 [trainer.py] => fixed_memory: False
2024-08-20 00:47:46,593 [trainer.py] => shuffle: True
2024-08-20 00:47:46,593 [trainer.py] => init_cls: 50
2024-08-20 00:47:46,593 [trainer.py] => increment: 5
2024-08-20 00:47:46,593 [trainer.py] => model_name: foster
2024-08-20 00:47:46,593 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-08-20 00:47:46,593 [trainer.py] => device: [device(type='cuda', index=0)]
2024-08-20 00:47:46,593 [trainer.py] => seed: 1993
2024-08-20 00:47:46,593 [trainer.py] => beta1: 0.96
2024-08-20 00:47:46,593 [trainer.py] => beta2: 0.97
2024-08-20 00:47:46,593 [trainer.py] => oofc: ft
2024-08-20 00:47:46,593 [trainer.py] => is_teacher_wa: False
2024-08-20 00:47:46,593 [trainer.py] => is_student_wa: False
2024-08-20 00:47:46,593 [trainer.py] => lambda_okd: 1
2024-08-20 00:47:46,593 [trainer.py] => wa_value: 1
2024-08-20 00:47:46,593 [trainer.py] => init_epochs: 1
2024-08-20 00:47:46,593 [trainer.py] => init_lr: 0.001
2024-08-20 00:47:46,593 [trainer.py] => init_weight_decay: 0.0005
2024-08-20 00:47:46,593 [trainer.py] => boosting_epochs: 1
2024-08-20 00:47:46,593 [trainer.py] => compression_epochs: 1
2024-08-20 00:47:46,593 [trainer.py] => lr: 0.001
2024-08-20 00:47:46,593 [trainer.py] => batch_size: 48
2024-08-20 00:47:46,593 [trainer.py] => weight_decay: 0.0005
2024-08-20 00:47:46,593 [trainer.py] => num_workers: 8
2024-08-20 00:47:46,593 [trainer.py] => T: 2
2024-08-20 00:47:47,523 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-08-20 00:47:48,134 [trainer.py] => All params: 0
2024-08-20 00:47:48,135 [trainer.py] => Trainable params: 0
2024-08-20 00:47:49,531 [foster.py] => Learning on 0-50
2024-08-20 00:47:49,532 [foster.py] => All params: 85875556
2024-08-20 00:47:49,532 [foster.py] => Trainable params: 85875556
  0%|          | 0/1 [00:00<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20:   0%|          | 0/1 [01:32<?, ?it/s]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20: 100%|██████████| 1/1 [01:32<00:00, 92.74s/it]Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20: 100%|██████████| 1/1 [01:32<00:00, 92.75s/it]
2024-08-20 00:49:22,639 [foster.py] => Task 0, Epoch 1/1 => Loss 2.525, Train_accy 35.02, Test_accy 89.20
2024-08-20 00:49:22,640 [base.py] => Reducing exemplars...(40 per classes)
2024-08-20 00:49:22,640 [base.py] => Constructing exemplars...(40 per classes)
2024-08-20 00:50:37,056 [foster.py] => Exemplar size: 2000
2024-08-20 00:50:37,056 [trainer.py] => CNN: {'total': 89.2, '00-49': 89.2, 'old': 0, 'new': 89.2}
2024-08-20 00:50:37,056 [trainer.py] => NME: {'total': 90.68, '00-49': 90.68, 'old': 0, 'new': 90.68}
2024-08-20 00:50:37,056 [trainer.py] => CNN top1 curve: [89.2]
2024-08-20 00:50:37,056 [trainer.py] => CNN top5 curve: [98.62]
2024-08-20 00:50:37,056 [trainer.py] => NME top1 curve: [90.68]
2024-08-20 00:50:37,056 [trainer.py] => NME top5 curve: [98.66]

Average Accuracy (CNN): 89.2
Average Accuracy (NME): 90.68
2024-08-20 00:50:37,057 [trainer.py] => Average Accuracy (CNN): 89.2
2024-08-20 00:50:37,057 [trainer.py] => Average Accuracy (NME): 90.68
2024-08-20 00:50:37,057 [trainer.py] => Train Time: 93.04
2024-08-20 00:50:37,057 [trainer.py] => Test Time: 15.11 

2024-08-20 00:50:37,057 [trainer.py] => All params: 85875556
2024-08-20 00:50:37,058 [trainer.py] => Trainable params: 85875556
2024-08-20 00:50:38,572 [foster.py] => Learning on 50-55
2024-08-20 00:50:38,574 [foster.py] => All params: 171762592
2024-08-20 00:50:38,574 [foster.py] => Trainable params: 85925486
2024-08-20 00:50:38,696 [foster.py] => per cls weights : [1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817 1.0180817
 1.0180817 0.819183  0.819183  0.819183  0.819183  0.819183 ]
  0%|          | 0/1 [00:00<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.467, Loss_clf 0.930, Loss_fe 1.718, Loss_kd 2.563, Train_accy 73.80, Test_accy 87.96:   0%|          | 0/1 [00:35<?, ?it/s]Task 1, Epoch 1/1 => Loss 5.467, Loss_clf 0.930, Loss_fe 1.718, Loss_kd 2.563, Train_accy 73.80, Test_accy 87.96: 100%|██████████| 1/1 [00:35<00:00, 35.30s/it]Task 1, Epoch 1/1 => Loss 5.467, Loss_clf 0.930, Loss_fe 1.718, Loss_kd 2.563, Train_accy 73.80, Test_accy 87.96: 100%|██████████| 1/1 [00:35<00:00, 35.30s/it]
2024-08-20 00:51:13,994 [foster.py] => Task 1, Epoch 1/1 => Loss 5.467, Loss_clf 0.930, Loss_fe 1.718, Loss_kd 2.563, Train_accy 73.80, Test_accy 87.96
2024-08-20 00:51:13,996 [foster.py] => do not weight align teacher!
2024-08-20 00:51:13,998 [foster.py] => per cls weights : [1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559 1.02762559
 1.02762559 1.02762559 0.72374408 0.72374408 0.72374408 0.72374408
 0.72374408]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.524,  Train_accy 68.93, Test_accy 87.78:   0%|          | 0/1 [00:34<?, ?it/s]SNet: Task 1, Epoch 1/1 => Loss 2.524,  Train_accy 68.93, Test_accy 87.78: 100%|██████████| 1/1 [00:34<00:00, 34.09s/it]SNet: Task 1, Epoch 1/1 => Loss 2.524,  Train_accy 68.93, Test_accy 87.78: 100%|██████████| 1/1 [00:34<00:00, 34.09s/it]
2024-08-20 00:51:49,694 [foster.py] => SNet: Task 1, Epoch 1/1 => Loss 2.524,  Train_accy 68.93, Test_accy 87.78
2024-08-20 00:51:49,694 [foster.py] => do not weight align student!
2024-08-20 00:51:57,857 [foster.py] => darknet eval: 
2024-08-20 00:51:57,858 [foster.py] => CNN top1 curve: 87.78
2024-08-20 00:51:57,858 [foster.py] => CNN top5 curve: 98.51
2024-08-20 00:51:57,860 [base.py] => Reducing exemplars...(36 per classes)
2024-08-20 00:52:11,842 [base.py] => Constructing exemplars...(36 per classes)
2024-08-20 00:52:50,580 [foster.py] => Exemplar size: 1980
2024-08-20 00:52:50,580 [trainer.py] => CNN: {'total': 87.96, '00-49': 87.82, '50-54': 89.4, 'old': 87.82, 'new': 89.4}
2024-08-20 00:52:50,580 [trainer.py] => NME: {'total': 89.6, '00-49': 90.1, '50-54': 84.6, 'old': 90.1, 'new': 84.6}
2024-08-20 00:52:50,580 [trainer.py] => CNN top1 curve: [89.2, 87.96]
2024-08-20 00:52:50,580 [trainer.py] => CNN top5 curve: [98.62, 98.45]
2024-08-20 00:52:50,580 [trainer.py] => NME top1 curve: [90.68, 89.6]
2024-08-20 00:52:50,580 [trainer.py] => NME top5 curve: [98.66, 98.69]

Average Accuracy (CNN): 88.58
Average Accuracy (NME): 90.14
2024-08-20 00:52:50,580 [trainer.py] => Average Accuracy (CNN): 88.58
2024-08-20 00:52:50,580 [trainer.py] => Average Accuracy (NME): 90.14
2024-08-20 00:52:50,580 [trainer.py] => Train Time: 172.29000000000002
2024-08-20 00:52:50,580 [trainer.py] => Test Time: 44.46 

2024-08-20 00:52:50,582 [trainer.py] => All params: 171762592
2024-08-20 00:52:50,582 [trainer.py] => Trainable params: 85925486
2024-08-20 00:52:52,119 [foster.py] => Learning on 55-60
2024-08-20 00:52:52,120 [foster.py] => All params: 171777967
2024-08-20 00:52:52,121 [foster.py] => Trainable params: 85937016
2024-08-20 00:52:52,252 [foster.py] => per cls weights : [1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288 1.01954288
 1.01954288 0.78502828 0.78502828 0.78502828 0.78502828 0.78502828]
  0%|          | 0/1 [00:00<?, ?it/s]Task 2, Epoch 1/1 => Loss 5.934, Loss_clf 1.033, Loss_fe 1.935, Loss_kd 2.718, Train_accy 69.53, Test_accy 87.97:   0%|          | 0/1 [00:36<?, ?it/s]Task 2, Epoch 1/1 => Loss 5.934, Loss_clf 1.033, Loss_fe 1.935, Loss_kd 2.718, Train_accy 69.53, Test_accy 87.97: 100%|██████████| 1/1 [00:36<00:00, 36.54s/it]Task 2, Epoch 1/1 => Loss 5.934, Loss_clf 1.033, Loss_fe 1.935, Loss_kd 2.718, Train_accy 69.53, Test_accy 87.97: 100%|██████████| 1/1 [00:36<00:00, 36.54s/it]
2024-08-20 00:53:28,795 [foster.py] => Task 2, Epoch 1/1 => Loss 5.934, Loss_clf 1.033, Loss_fe 1.935, Loss_kd 2.718, Train_accy 69.53, Test_accy 87.97
2024-08-20 00:53:28,796 [foster.py] => do not weight align teacher!
2024-08-20 00:53:28,797 [foster.py] => per cls weights : [1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265 1.02863265
 1.02863265 0.68504089 0.68504089 0.68504089 0.68504089 0.68504089]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 2.574,  Train_accy 64.71, Test_accy 88.13:   0%|          | 0/1 [00:34<?, ?it/s]SNet: Task 2, Epoch 1/1 => Loss 2.574,  Train_accy 64.71, Test_accy 88.13: 100%|██████████| 1/1 [00:34<00:00, 34.78s/it]SNet: Task 2, Epoch 1/1 => Loss 2.574,  Train_accy 64.71, Test_accy 88.13: 100%|██████████| 1/1 [00:34<00:00, 34.78s/it]
2024-08-20 00:54:05,114 [foster.py] => SNet: Task 2, Epoch 1/1 => Loss 2.574,  Train_accy 64.71, Test_accy 88.13
2024-08-20 00:54:05,114 [foster.py] => do not weight align student!
2024-08-20 00:54:13,998 [foster.py] => darknet eval: 
2024-08-20 00:54:13,998 [foster.py] => CNN top1 curve: 88.13
2024-08-20 00:54:13,998 [foster.py] => CNN top5 curve: 98.4
2024-08-20 00:54:13,999 [base.py] => Reducing exemplars...(33 per classes)
2024-08-20 00:54:28,664 [base.py] => Constructing exemplars...(33 per classes)
2024-08-20 00:55:10,101 [foster.py] => Exemplar size: 1980
2024-08-20 00:55:10,101 [trainer.py] => CNN: {'total': 87.97, '00-49': 88.84, '50-54': 80.6, '55-59': 86.6, 'old': 88.09, 'new': 86.6}
2024-08-20 00:55:10,101 [trainer.py] => NME: {'total': 89.0, '00-49': 89.84, '50-54': 83.0, '55-59': 86.6, 'old': 89.22, 'new': 86.6}
2024-08-20 00:55:10,101 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97]
2024-08-20 00:55:10,101 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07]
2024-08-20 00:55:10,101 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0]
2024-08-20 00:55:10,101 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42]

Average Accuracy (CNN): 88.38
Average Accuracy (NME): 89.76
2024-08-20 00:55:10,101 [trainer.py] => Average Accuracy (CNN): 88.38
2024-08-20 00:55:10,101 [trainer.py] => Average Accuracy (NME): 89.76
2024-08-20 00:55:10,101 [trainer.py] => Train Time: 254.13000000000002
2024-08-20 00:55:10,101 [trainer.py] => Test Time: 76.52000000000001 

2024-08-20 00:55:10,102 [trainer.py] => All params: 171777967
2024-08-20 00:55:10,103 [trainer.py] => Trainable params: 85937016
2024-08-20 00:55:11,613 [foster.py] => Learning on 60-65
2024-08-20 00:55:11,614 [foster.py] => All params: 171793342
2024-08-20 00:55:11,615 [foster.py] => Trainable params: 85948546
2024-08-20 00:55:11,743 [foster.py] => per cls weights : [1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708 1.02040708
 0.75511508 0.75511508 0.75511508 0.75511508 0.75511508]
  0%|          | 0/1 [00:00<?, ?it/s]Task 3, Epoch 1/1 => Loss 5.582, Loss_clf 0.916, Loss_fe 1.810, Loss_kd 2.637, Train_accy 72.32, Test_accy 87.38:   0%|          | 0/1 [00:38<?, ?it/s]Task 3, Epoch 1/1 => Loss 5.582, Loss_clf 0.916, Loss_fe 1.810, Loss_kd 2.637, Train_accy 72.32, Test_accy 87.38: 100%|██████████| 1/1 [00:38<00:00, 38.12s/it]Task 3, Epoch 1/1 => Loss 5.582, Loss_clf 0.916, Loss_fe 1.810, Loss_kd 2.637, Train_accy 72.32, Test_accy 87.38: 100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
2024-08-20 00:55:49,863 [foster.py] => Task 3, Epoch 1/1 => Loss 5.582, Loss_clf 0.916, Loss_fe 1.810, Loss_kd 2.637, Train_accy 72.32, Test_accy 87.38
2024-08-20 00:55:49,863 [foster.py] => do not weight align teacher!
2024-08-20 00:55:49,865 [foster.py] => per cls weights : [1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 1.0289685  1.0289685  1.0289685  1.0289685  1.0289685  1.0289685
 0.65237804 0.65237804 0.65237804 0.65237804 0.65237804]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.473,  Train_accy 65.78, Test_accy 87.69:   0%|          | 0/1 [00:35<?, ?it/s]SNet: Task 3, Epoch 1/1 => Loss 2.473,  Train_accy 65.78, Test_accy 87.69: 100%|██████████| 1/1 [00:35<00:00, 35.64s/it]SNet: Task 3, Epoch 1/1 => Loss 2.473,  Train_accy 65.78, Test_accy 87.69: 100%|██████████| 1/1 [00:35<00:00, 35.64s/it]
2024-08-20 00:56:27,014 [foster.py] => SNet: Task 3, Epoch 1/1 => Loss 2.473,  Train_accy 65.78, Test_accy 87.69
2024-08-20 00:56:27,014 [foster.py] => do not weight align student!
2024-08-20 00:56:36,724 [foster.py] => darknet eval: 
2024-08-20 00:56:36,724 [foster.py] => CNN top1 curve: 87.69
2024-08-20 00:56:36,724 [foster.py] => CNN top5 curve: 98.23
2024-08-20 00:56:36,726 [base.py] => Reducing exemplars...(30 per classes)
2024-08-20 00:56:53,120 [base.py] => Constructing exemplars...(30 per classes)
2024-08-20 00:57:37,599 [foster.py] => Exemplar size: 1950
2024-08-20 00:57:37,600 [trainer.py] => CNN: {'total': 87.38, '00-49': 88.48, '50-54': 83.8, '55-59': 78.8, '60-64': 88.6, 'old': 87.28, 'new': 88.6}
2024-08-20 00:57:37,600 [trainer.py] => NME: {'total': 88.12, '00-49': 89.36, '50-54': 84.2, '55-59': 82.4, '60-64': 85.4, 'old': 88.35, 'new': 85.4}
2024-08-20 00:57:37,600 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38]
2024-08-20 00:57:37,600 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38]
2024-08-20 00:57:37,600 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12]
2024-08-20 00:57:37,600 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38]

Average Accuracy (CNN): 88.13
Average Accuracy (NME): 89.35
2024-08-20 00:57:37,600 [trainer.py] => Average Accuracy (CNN): 88.13
2024-08-20 00:57:37,600 [trainer.py] => Average Accuracy (NME): 89.35
2024-08-20 00:57:37,600 [trainer.py] => Train Time: 339.20000000000005
2024-08-20 00:57:37,600 [trainer.py] => Test Time: 111.4 

2024-08-20 00:57:37,601 [trainer.py] => All params: 171793342
2024-08-20 00:57:37,602 [trainer.py] => Trainable params: 85948546
2024-08-20 00:57:39,150 [foster.py] => Learning on 65-70
2024-08-20 00:57:39,152 [foster.py] => All params: 171808717
2024-08-20 00:57:39,153 [foster.py] => Trainable params: 85960076
2024-08-20 00:57:39,282 [foster.py] => per cls weights : [1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985
 1.02143985 1.02143985 1.02143985 1.02143985 1.02143985 0.72128194
 0.72128194 0.72128194 0.72128194 0.72128194]
  0%|          | 0/1 [00:00<?, ?it/s]Task 4, Epoch 1/1 => Loss 5.879, Loss_clf 0.891, Loss_fe 2.054, Loss_kd 2.725, Train_accy 73.78, Test_accy 86.47:   0%|          | 0/1 [00:39<?, ?it/s]Task 4, Epoch 1/1 => Loss 5.879, Loss_clf 0.891, Loss_fe 2.054, Loss_kd 2.725, Train_accy 73.78, Test_accy 86.47: 100%|██████████| 1/1 [00:39<00:00, 39.25s/it]Task 4, Epoch 1/1 => Loss 5.879, Loss_clf 0.891, Loss_fe 2.054, Loss_kd 2.725, Train_accy 73.78, Test_accy 86.47: 100%|██████████| 1/1 [00:39<00:00, 39.25s/it]
2024-08-20 00:58:18,536 [foster.py] => Task 4, Epoch 1/1 => Loss 5.879, Loss_clf 0.891, Loss_fe 2.054, Loss_kd 2.725, Train_accy 73.78, Test_accy 86.47
2024-08-20 00:58:18,537 [foster.py] => do not weight align teacher!
2024-08-20 00:58:18,539 [foster.py] => per cls weights : [1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   1.029488
 1.029488   1.029488   1.029488   1.029488   1.029488   0.61665603
 0.61665603 0.61665603 0.61665603 0.61665603]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 2.689,  Train_accy 63.42, Test_accy 86.59:   0%|          | 0/1 [00:36<?, ?it/s]SNet: Task 4, Epoch 1/1 => Loss 2.689,  Train_accy 63.42, Test_accy 86.59: 100%|██████████| 1/1 [00:36<00:00, 36.16s/it]SNet: Task 4, Epoch 1/1 => Loss 2.689,  Train_accy 63.42, Test_accy 86.59: 100%|██████████| 1/1 [00:36<00:00, 36.16s/it]
2024-08-20 00:58:56,258 [foster.py] => SNet: Task 4, Epoch 1/1 => Loss 2.689,  Train_accy 63.42, Test_accy 86.59
2024-08-20 00:58:56,258 [foster.py] => do not weight align student!
2024-08-20 00:59:06,688 [foster.py] => darknet eval: 
2024-08-20 00:59:06,688 [foster.py] => CNN top1 curve: 86.59
2024-08-20 00:59:06,688 [foster.py] => CNN top5 curve: 98.31
2024-08-20 00:59:06,689 [base.py] => Reducing exemplars...(28 per classes)
2024-08-20 00:59:24,455 [base.py] => Constructing exemplars...(28 per classes)
2024-08-20 01:00:11,593 [foster.py] => Exemplar size: 1960
2024-08-20 01:00:11,594 [trainer.py] => CNN: {'total': 86.47, '00-49': 88.36, '50-54': 75.4, '55-59': 85.0, '60-64': 79.2, '65-69': 87.4, 'old': 86.4, 'new': 87.4}
2024-08-20 01:00:11,594 [trainer.py] => NME: {'total': 87.89, '00-49': 88.98, '50-54': 84.0, '55-59': 83.0, '60-64': 82.2, '65-69': 91.4, 'old': 87.62, 'new': 91.4}
2024-08-20 01:00:11,594 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47]
2024-08-20 01:00:11,594 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09]
2024-08-20 01:00:11,594 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89]
2024-08-20 01:00:11,594 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19]

Average Accuracy (CNN): 87.8
Average Accuracy (NME): 89.06
2024-08-20 01:00:11,594 [trainer.py] => Average Accuracy (CNN): 87.8
2024-08-20 01:00:11,594 [trainer.py] => Average Accuracy (NME): 89.06
2024-08-20 01:00:11,594 [trainer.py] => Train Time: 426.69000000000005
2024-08-20 01:00:11,594 [trainer.py] => Test Time: 148.93 

2024-08-20 01:00:11,596 [trainer.py] => All params: 171808717
2024-08-20 01:00:11,597 [trainer.py] => Trainable params: 85960076
2024-08-20 01:00:13,185 [foster.py] => Learning on 70-75
2024-08-20 01:00:13,186 [foster.py] => All params: 171824092
2024-08-20 01:00:13,187 [foster.py] => Trainable params: 85971606
2024-08-20 01:00:13,315 [foster.py] => per cls weights : [1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874 1.02171874
 1.02171874 1.02171874 1.02171874 1.02171874 0.69593764 0.69593764
 0.69593764 0.69593764 0.69593764]
  0%|          | 0/1 [00:00<?, ?it/s]Task 5, Epoch 1/1 => Loss 6.078, Loss_clf 1.037, Loss_fe 2.140, Loss_kd 2.707, Train_accy 68.30, Test_accy 85.68:   0%|          | 0/1 [00:40<?, ?it/s]Task 5, Epoch 1/1 => Loss 6.078, Loss_clf 1.037, Loss_fe 2.140, Loss_kd 2.707, Train_accy 68.30, Test_accy 85.68: 100%|██████████| 1/1 [00:40<00:00, 40.61s/it]Task 5, Epoch 1/1 => Loss 6.078, Loss_clf 1.037, Loss_fe 2.140, Loss_kd 2.707, Train_accy 68.30, Test_accy 85.68: 100%|██████████| 1/1 [00:40<00:00, 40.61s/it]
2024-08-20 01:00:53,928 [foster.py] => Task 5, Epoch 1/1 => Loss 6.078, Loss_clf 1.037, Loss_fe 2.140, Loss_kd 2.707, Train_accy 68.30, Test_accy 85.68
2024-08-20 01:00:53,929 [foster.py] => do not weight align teacher!
2024-08-20 01:00:53,930 [foster.py] => per cls weights : [1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392 1.02924392
 1.02924392 1.02924392 1.02924392 1.02924392 0.5905851  0.5905851
 0.5905851  0.5905851  0.5905851 ]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 2.822,  Train_accy 54.53, Test_accy 85.41:   0%|          | 0/1 [00:37<?, ?it/s]SNet: Task 5, Epoch 1/1 => Loss 2.822,  Train_accy 54.53, Test_accy 85.41: 100%|██████████| 1/1 [00:37<00:00, 37.05s/it]SNet: Task 5, Epoch 1/1 => Loss 2.822,  Train_accy 54.53, Test_accy 85.41: 100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
2024-08-20 01:01:32,479 [foster.py] => SNet: Task 5, Epoch 1/1 => Loss 2.822,  Train_accy 54.53, Test_accy 85.41
2024-08-20 01:01:32,479 [foster.py] => do not weight align student!
2024-08-20 01:01:43,614 [foster.py] => darknet eval: 
2024-08-20 01:01:43,615 [foster.py] => CNN top1 curve: 85.41
2024-08-20 01:01:43,615 [foster.py] => CNN top5 curve: 98.09
2024-08-20 01:01:43,616 [base.py] => Reducing exemplars...(26 per classes)
2024-08-20 01:02:01,525 [base.py] => Constructing exemplars...(26 per classes)
2024-08-20 01:02:51,196 [foster.py] => Exemplar size: 1950
2024-08-20 01:02:51,196 [trainer.py] => CNN: {'total': 85.68, '00-49': 87.76, '50-54': 84.6, '55-59': 81.2, '60-64': 78.4, '65-69': 88.2, '70-74': 75.2, 'old': 86.43, 'new': 75.2}
2024-08-20 01:02:51,196 [trainer.py] => NME: {'total': 87.49, '00-49': 89.06, '50-54': 82.6, '55-59': 84.2, '60-64': 79.0, '65-69': 92.0, '70-74': 84.0, 'old': 87.74, 'new': 84.0}
2024-08-20 01:02:51,196 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68]
2024-08-20 01:02:51,196 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03]
2024-08-20 01:02:51,197 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49]
2024-08-20 01:02:51,197 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21]

Average Accuracy (CNN): 87.44
Average Accuracy (NME): 88.8
2024-08-20 01:02:51,197 [trainer.py] => Average Accuracy (CNN): 87.44
2024-08-20 01:02:51,197 [trainer.py] => Average Accuracy (NME): 88.8
2024-08-20 01:02:51,197 [trainer.py] => Train Time: 517.08
2024-08-20 01:02:51,197 [trainer.py] => Test Time: 189.10000000000002 

2024-08-20 01:02:51,198 [trainer.py] => All params: 171824092
2024-08-20 01:02:51,199 [trainer.py] => Trainable params: 85971606
2024-08-20 01:02:52,704 [foster.py] => Learning on 75-80
2024-08-20 01:02:52,705 [foster.py] => All params: 171839467
2024-08-20 01:02:52,706 [foster.py] => Trainable params: 85983136
2024-08-20 01:02:52,833 [foster.py] => per cls weights : [1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173 1.02210173
 1.02210173 1.02210173 1.02210173 0.6684741  0.6684741  0.6684741
 0.6684741  0.6684741 ]
  0%|          | 0/1 [00:00<?, ?it/s]Task 6, Epoch 1/1 => Loss 5.919, Loss_clf 1.005, Loss_fe 2.209, Loss_kd 2.537, Train_accy 59.91, Test_accy 82.88:   0%|          | 0/1 [00:41<?, ?it/s]Task 6, Epoch 1/1 => Loss 5.919, Loss_clf 1.005, Loss_fe 2.209, Loss_kd 2.537, Train_accy 59.91, Test_accy 82.88: 100%|██████████| 1/1 [00:41<00:00, 41.95s/it]Task 6, Epoch 1/1 => Loss 5.919, Loss_clf 1.005, Loss_fe 2.209, Loss_kd 2.537, Train_accy 59.91, Test_accy 82.88: 100%|██████████| 1/1 [00:41<00:00, 41.95s/it]
2024-08-20 01:03:34,784 [foster.py] => Task 6, Epoch 1/1 => Loss 5.919, Loss_clf 1.005, Loss_fe 2.209, Loss_kd 2.537, Train_accy 59.91, Test_accy 82.88
2024-08-20 01:03:34,785 [foster.py] => do not weight align teacher!
2024-08-20 01:03:34,786 [foster.py] => per cls weights : [1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517 1.02913517
 1.02913517 1.02913517 1.02913517 0.56297248 0.56297248 0.56297248
 0.56297248 0.56297248]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 2.662,  Train_accy 52.43, Test_accy 82.55:   0%|          | 0/1 [00:37<?, ?it/s]SNet: Task 6, Epoch 1/1 => Loss 2.662,  Train_accy 52.43, Test_accy 82.55: 100%|██████████| 1/1 [00:37<00:00, 37.60s/it]SNet: Task 6, Epoch 1/1 => Loss 2.662,  Train_accy 52.43, Test_accy 82.55: 100%|██████████| 1/1 [00:37<00:00, 37.60s/it]
2024-08-20 01:04:13,950 [foster.py] => SNet: Task 6, Epoch 1/1 => Loss 2.662,  Train_accy 52.43, Test_accy 82.55
2024-08-20 01:04:13,951 [foster.py] => do not weight align student!
2024-08-20 01:04:25,974 [foster.py] => darknet eval: 
2024-08-20 01:04:25,974 [foster.py] => CNN top1 curve: 82.55
2024-08-20 01:04:25,974 [foster.py] => CNN top5 curve: 97.95
2024-08-20 01:04:25,975 [base.py] => Reducing exemplars...(25 per classes)
2024-08-20 01:04:45,802 [base.py] => Constructing exemplars...(25 per classes)
2024-08-20 01:05:38,106 [foster.py] => Exemplar size: 2000
2024-08-20 01:05:38,106 [trainer.py] => CNN: {'total': 82.88, '00-49': 87.42, '50-54': 74.2, '55-59': 71.0, '60-64': 86.2, '65-69': 90.0, '70-74': 61.4, '75-79': 69.0, 'old': 83.8, 'new': 69.0}
2024-08-20 01:05:38,106 [trainer.py] => NME: {'total': 86.01, '00-49': 88.56, '50-54': 78.4, '55-59': 80.6, '60-64': 79.8, '65-69': 92.8, '70-74': 82.0, '75-79': 77.0, 'old': 86.61, 'new': 77.0}
2024-08-20 01:05:38,106 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68, 82.88]
2024-08-20 01:05:38,106 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03, 97.91]
2024-08-20 01:05:38,106 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49, 86.01]
2024-08-20 01:05:38,106 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21, 97.9]

Average Accuracy (CNN): 86.79
Average Accuracy (NME): 88.4
2024-08-20 01:05:38,106 [trainer.py] => Average Accuracy (CNN): 86.79
2024-08-20 01:05:38,106 [trainer.py] => Average Accuracy (NME): 88.4
2024-08-20 01:05:38,106 [trainer.py] => Train Time: 610.3100000000001
2024-08-20 01:05:38,106 [trainer.py] => Test Time: 231.95000000000002 

2024-08-20 01:05:38,108 [trainer.py] => All params: 171839467
2024-08-20 01:05:38,109 [trainer.py] => Trainable params: 85983136
2024-08-20 01:05:39,651 [foster.py] => Learning on 80-85
2024-08-20 01:05:39,653 [foster.py] => All params: 171854842
2024-08-20 01:05:39,653 [foster.py] => Trainable params: 85994666
2024-08-20 01:05:39,783 [foster.py] => per cls weights : [1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897 1.02165897
 1.02165897 1.02165897 0.65345643 0.65345643 0.65345643 0.65345643
 0.65345643]
  0%|          | 0/1 [00:00<?, ?it/s]Task 7, Epoch 1/1 => Loss 6.125, Loss_clf 0.985, Loss_fe 2.257, Loss_kd 2.712, Train_accy 64.60, Test_accy 83.29:   0%|          | 0/1 [00:43<?, ?it/s]Task 7, Epoch 1/1 => Loss 6.125, Loss_clf 0.985, Loss_fe 2.257, Loss_kd 2.712, Train_accy 64.60, Test_accy 83.29: 100%|██████████| 1/1 [00:43<00:00, 43.36s/it]Task 7, Epoch 1/1 => Loss 6.125, Loss_clf 0.985, Loss_fe 2.257, Loss_kd 2.712, Train_accy 64.60, Test_accy 83.29: 100%|██████████| 1/1 [00:43<00:00, 43.36s/it]
2024-08-20 01:06:23,145 [foster.py] => Task 7, Epoch 1/1 => Loss 6.125, Loss_clf 0.985, Loss_fe 2.257, Loss_kd 2.712, Train_accy 64.60, Test_accy 83.29
2024-08-20 01:06:23,146 [foster.py] => do not weight align teacher!
2024-08-20 01:06:23,149 [foster.py] => per cls weights : [1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496 1.02824496
 1.02824496 1.02824496 0.54808058 0.54808058 0.54808058 0.54808058
 0.54808058]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.842,  Train_accy 50.82, Test_accy 82.60:   0%|          | 0/1 [00:38<?, ?it/s]SNet: Task 7, Epoch 1/1 => Loss 2.842,  Train_accy 50.82, Test_accy 82.60: 100%|██████████| 1/1 [00:38<00:00, 38.67s/it]SNet: Task 7, Epoch 1/1 => Loss 2.842,  Train_accy 50.82, Test_accy 82.60: 100%|██████████| 1/1 [00:38<00:00, 38.67s/it]
2024-08-20 01:07:03,384 [foster.py] => SNet: Task 7, Epoch 1/1 => Loss 2.842,  Train_accy 50.82, Test_accy 82.60
2024-08-20 01:07:03,385 [foster.py] => do not weight align student!
2024-08-20 01:07:15,941 [foster.py] => darknet eval: 
2024-08-20 01:07:15,941 [foster.py] => CNN top1 curve: 82.6
2024-08-20 01:07:15,941 [foster.py] => CNN top5 curve: 97.94
2024-08-20 01:07:15,945 [base.py] => Reducing exemplars...(23 per classes)
2024-08-20 01:07:35,751 [base.py] => Constructing exemplars...(23 per classes)
2024-08-20 01:08:30,605 [foster.py] => Exemplar size: 1955
2024-08-20 01:08:30,605 [trainer.py] => CNN: {'total': 83.29, '00-49': 87.96, '50-54': 72.4, '55-59': 84.0, '60-64': 81.6, '65-69': 89.6, '70-74': 74.8, '75-79': 64.8, '80-84': 69.2, 'old': 84.18, 'new': 69.2}
2024-08-20 01:08:30,605 [trainer.py] => NME: {'total': 85.07, '00-49': 87.28, '50-54': 77.6, '55-59': 80.6, '60-64': 78.2, '65-69': 92.8, '70-74': 81.4, '75-79': 74.6, '80-84': 88.2, 'old': 84.88, 'new': 88.2}
2024-08-20 01:08:30,606 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68, 82.88, 83.29]
2024-08-20 01:08:30,606 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03, 97.91, 98.01]
2024-08-20 01:08:30,606 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49, 86.01, 85.07]
2024-08-20 01:08:30,606 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21, 97.9, 97.94]

Average Accuracy (CNN): 86.35
Average Accuracy (NME): 87.98
2024-08-20 01:08:30,606 [trainer.py] => Average Accuracy (CNN): 86.35
2024-08-20 01:08:30,606 [trainer.py] => Average Accuracy (NME): 87.98
2024-08-20 01:08:30,606 [trainer.py] => Train Time: 706.5500000000001
2024-08-20 01:08:30,606 [trainer.py] => Test Time: 277.47 

2024-08-20 01:08:30,607 [trainer.py] => All params: 171854842
2024-08-20 01:08:30,608 [trainer.py] => Trainable params: 85994666
2024-08-20 01:08:32,167 [foster.py] => Learning on 85-90
2024-08-20 01:08:32,169 [foster.py] => All params: 171870217
2024-08-20 01:08:32,170 [foster.py] => Trainable params: 86006196
2024-08-20 01:08:32,297 [foster.py] => per cls weights : [1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777 1.02220777
 1.02220777 0.62246784 0.62246784 0.62246784 0.62246784 0.62246784]
  0%|          | 0/1 [00:00<?, ?it/s]Task 8, Epoch 1/1 => Loss 6.677, Loss_clf 1.184, Loss_fe 2.410, Loss_kd 2.912, Train_accy 58.63, Test_accy 83.07:   0%|          | 0/1 [00:44<?, ?it/s]Task 8, Epoch 1/1 => Loss 6.677, Loss_clf 1.184, Loss_fe 2.410, Loss_kd 2.912, Train_accy 58.63, Test_accy 83.07: 100%|██████████| 1/1 [00:44<00:00, 44.48s/it]Task 8, Epoch 1/1 => Loss 6.677, Loss_clf 1.184, Loss_fe 2.410, Loss_kd 2.912, Train_accy 58.63, Test_accy 83.07: 100%|██████████| 1/1 [00:44<00:00, 44.48s/it]
2024-08-20 01:09:16,774 [foster.py] => Task 8, Epoch 1/1 => Loss 6.677, Loss_clf 1.184, Loss_fe 2.410, Loss_kd 2.912, Train_accy 58.63, Test_accy 83.07
2024-08-20 01:09:16,775 [foster.py] => do not weight align teacher!
2024-08-20 01:09:16,777 [foster.py] => per cls weights : [1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438 1.02835438
 1.02835438 0.51797551 0.51797551 0.51797551 0.51797551 0.51797551]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 3.001,  Train_accy 45.23, Test_accy 81.78:   0%|          | 0/1 [00:39<?, ?it/s]SNet: Task 8, Epoch 1/1 => Loss 3.001,  Train_accy 45.23, Test_accy 81.78: 100%|██████████| 1/1 [00:39<00:00, 39.09s/it]SNet: Task 8, Epoch 1/1 => Loss 3.001,  Train_accy 45.23, Test_accy 81.78: 100%|██████████| 1/1 [00:39<00:00, 39.09s/it]
2024-08-20 01:09:57,746 [foster.py] => SNet: Task 8, Epoch 1/1 => Loss 3.001,  Train_accy 45.23, Test_accy 81.78
2024-08-20 01:09:57,746 [foster.py] => do not weight align student!
2024-08-20 01:10:11,098 [foster.py] => darknet eval: 
2024-08-20 01:10:11,098 [foster.py] => CNN top1 curve: 81.78
2024-08-20 01:10:11,098 [foster.py] => CNN top5 curve: 97.34
2024-08-20 01:10:11,100 [base.py] => Reducing exemplars...(22 per classes)
2024-08-20 01:10:32,656 [base.py] => Constructing exemplars...(22 per classes)
2024-08-20 01:11:30,135 [foster.py] => Exemplar size: 1980
2024-08-20 01:11:30,135 [trainer.py] => CNN: {'total': 83.07, '00-49': 87.22, '50-54': 68.2, '55-59': 79.8, '60-64': 76.4, '65-69': 92.4, '70-74': 77.2, '75-79': 80.0, '80-84': 80.0, '85-89': 69.0, 'old': 83.89, 'new': 69.0}
2024-08-20 01:11:30,135 [trainer.py] => NME: {'total': 84.76, '00-49': 87.44, '50-54': 77.6, '55-59': 81.6, '60-64': 78.8, '65-69': 92.6, '70-74': 80.4, '75-79': 73.8, '80-84': 85.0, '85-89': 81.4, 'old': 84.95, 'new': 81.4}
2024-08-20 01:11:30,135 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68, 82.88, 83.29, 83.07]
2024-08-20 01:11:30,135 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03, 97.91, 98.01, 97.61]
2024-08-20 01:11:30,135 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49, 86.01, 85.07, 84.76]
2024-08-20 01:11:30,135 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21, 97.9, 97.94, 97.74]

Average Accuracy (CNN): 85.99
Average Accuracy (NME): 87.62
2024-08-20 01:11:30,135 [trainer.py] => Average Accuracy (CNN): 85.99
2024-08-20 01:11:30,135 [trainer.py] => Average Accuracy (NME): 87.62
2024-08-20 01:11:30,135 [trainer.py] => Train Time: 805.44
2024-08-20 01:11:30,135 [trainer.py] => Test Time: 325.54 

2024-08-20 01:11:30,137 [trainer.py] => All params: 171870217
2024-08-20 01:11:30,138 [trainer.py] => Trainable params: 86006196
2024-08-20 01:11:31,666 [foster.py] => Learning on 90-95
2024-08-20 01:11:31,668 [foster.py] => All params: 171885592
2024-08-20 01:11:31,669 [foster.py] => Trainable params: 86017726
2024-08-20 01:11:31,804 [foster.py] => per cls weights : [1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916 1.02190916
 0.60563504 0.60563504 0.60563504 0.60563504 0.60563504]
  0%|          | 0/1 [00:00<?, ?it/s]Task 9, Epoch 1/1 => Loss 6.600, Loss_clf 1.108, Loss_fe 2.464, Loss_kd 2.869, Train_accy 62.10, Test_accy 82.23:   0%|          | 0/1 [00:45<?, ?it/s]Task 9, Epoch 1/1 => Loss 6.600, Loss_clf 1.108, Loss_fe 2.464, Loss_kd 2.869, Train_accy 62.10, Test_accy 82.23: 100%|██████████| 1/1 [00:45<00:00, 46.00s/it]Task 9, Epoch 1/1 => Loss 6.600, Loss_clf 1.108, Loss_fe 2.464, Loss_kd 2.869, Train_accy 62.10, Test_accy 82.23: 100%|██████████| 1/1 [00:45<00:00, 46.00s/it]
2024-08-20 01:12:17,805 [foster.py] => Task 9, Epoch 1/1 => Loss 6.600, Loss_clf 1.108, Loss_fe 2.464, Loss_kd 2.869, Train_accy 62.10, Test_accy 82.23
2024-08-20 01:12:17,806 [foster.py] => do not weight align teacher!
2024-08-20 01:12:17,807 [foster.py] => per cls weights : [1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452 1.02767452
 0.50185859 0.50185859 0.50185859 0.50185859 0.50185859]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 2.852,  Train_accy 53.19, Test_accy 81.84:   0%|          | 0/1 [00:39<?, ?it/s]SNet: Task 9, Epoch 1/1 => Loss 2.852,  Train_accy 53.19, Test_accy 81.84: 100%|██████████| 1/1 [00:39<00:00, 39.99s/it]SNet: Task 9, Epoch 1/1 => Loss 2.852,  Train_accy 53.19, Test_accy 81.84: 100%|██████████| 1/1 [00:39<00:00, 39.99s/it]
2024-08-20 01:12:59,394 [foster.py] => SNet: Task 9, Epoch 1/1 => Loss 2.852,  Train_accy 53.19, Test_accy 81.84
2024-08-20 01:12:59,394 [foster.py] => do not weight align student!
2024-08-20 01:13:13,372 [foster.py] => darknet eval: 
2024-08-20 01:13:13,373 [foster.py] => CNN top1 curve: 81.84
2024-08-20 01:13:13,373 [foster.py] => CNN top5 curve: 97.41
2024-08-20 01:13:13,374 [base.py] => Reducing exemplars...(21 per classes)
2024-08-20 01:13:35,606 [base.py] => Constructing exemplars...(21 per classes)
2024-08-20 01:14:35,892 [foster.py] => Exemplar size: 1995
2024-08-20 01:14:35,893 [trainer.py] => CNN: {'total': 82.23, '00-49': 86.88, '50-54': 72.2, '55-59': 80.8, '60-64': 80.4, '65-69': 92.0, '70-74': 72.6, '75-79': 74.4, '80-84': 86.2, '85-89': 60.8, '90-94': 74.2, 'old': 82.68, 'new': 74.2}
2024-08-20 01:14:35,893 [trainer.py] => NME: {'total': 84.34, '00-49': 87.2, '50-54': 78.2, '55-59': 79.2, '60-64': 75.6, '65-69': 91.6, '70-74': 81.0, '75-79': 75.2, '80-84': 85.8, '85-89': 73.6, '90-94': 90.2, 'old': 84.01, 'new': 90.2}
2024-08-20 01:14:35,893 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68, 82.88, 83.29, 83.07, 82.23]
2024-08-20 01:14:35,893 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03, 97.91, 98.01, 97.61, 97.37]
2024-08-20 01:14:35,893 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49, 86.01, 85.07, 84.76, 84.34]
2024-08-20 01:14:35,893 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21, 97.9, 97.94, 97.74, 97.52]

Average Accuracy (CNN): 85.61
Average Accuracy (NME): 87.3
2024-08-20 01:14:35,893 [trainer.py] => Average Accuracy (CNN): 85.61
2024-08-20 01:14:35,893 [trainer.py] => Average Accuracy (NME): 87.3
2024-08-20 01:14:35,893 [trainer.py] => Train Time: 907.1
2024-08-20 01:14:35,893 [trainer.py] => Test Time: 376.57000000000005 

2024-08-20 01:14:35,895 [trainer.py] => All params: 171885592
2024-08-20 01:14:35,896 [trainer.py] => Trainable params: 86017726
2024-08-20 01:14:37,424 [foster.py] => Learning on 95-100
2024-08-20 01:14:37,426 [foster.py] => All params: 171900967
2024-08-20 01:14:37,427 [foster.py] => Trainable params: 86029256
2024-08-20 01:14:37,557 [foster.py] => per cls weights : [1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   1.021676
 1.021676   1.021676   1.021676   1.021676   1.021676   0.58815605
 0.58815605 0.58815605 0.58815605 0.58815605]
  0%|          | 0/1 [00:00<?, ?it/s]Task 10, Epoch 1/1 => Loss 6.731, Loss_clf 1.088, Loss_fe 2.466, Loss_kd 3.019, Train_accy 59.62, Test_accy 81.98:   0%|          | 0/1 [00:47<?, ?it/s]Task 10, Epoch 1/1 => Loss 6.731, Loss_clf 1.088, Loss_fe 2.466, Loss_kd 3.019, Train_accy 59.62, Test_accy 81.98: 100%|██████████| 1/1 [00:47<00:00, 47.32s/it]Task 10, Epoch 1/1 => Loss 6.731, Loss_clf 1.088, Loss_fe 2.466, Loss_kd 3.019, Train_accy 59.62, Test_accy 81.98: 100%|██████████| 1/1 [00:47<00:00, 47.32s/it]
2024-08-20 01:15:24,882 [foster.py] => Task 10, Epoch 1/1 => Loss 6.731, Loss_clf 1.088, Loss_fe 2.466, Loss_kd 3.019, Train_accy 59.62, Test_accy 81.98
2024-08-20 01:15:24,883 [foster.py] => do not weight align teacher!
2024-08-20 01:15:24,885 [foster.py] => per cls weights : [1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846
 1.02708846 1.02708846 1.02708846 1.02708846 1.02708846 0.48531931
 0.48531931 0.48531931 0.48531931 0.48531931]
  0%|          | 0/1 [00:00<?, ?it/s]SNet: Task 10, Epoch 1/1 => Loss 3.147,  Train_accy 46.59, Test_accy 81.26:   0%|          | 0/1 [00:40<?, ?it/s]SNet: Task 10, Epoch 1/1 => Loss 3.147,  Train_accy 46.59, Test_accy 81.26: 100%|██████████| 1/1 [00:40<00:00, 40.71s/it]SNet: Task 10, Epoch 1/1 => Loss 3.147,  Train_accy 46.59, Test_accy 81.26: 100%|██████████| 1/1 [00:40<00:00, 40.71s/it]
2024-08-20 01:16:07,152 [foster.py] => SNet: Task 10, Epoch 1/1 => Loss 3.147,  Train_accy 46.59, Test_accy 81.26
2024-08-20 01:16:07,152 [foster.py] => do not weight align student!
2024-08-20 01:16:21,874 [foster.py] => darknet eval: 
2024-08-20 01:16:21,874 [foster.py] => CNN top1 curve: 81.26
2024-08-20 01:16:21,874 [foster.py] => CNN top5 curve: 96.89
2024-08-20 01:16:21,876 [base.py] => Reducing exemplars...(20 per classes)
2024-08-20 01:16:44,878 [base.py] => Constructing exemplars...(20 per classes)
2024-08-20 01:17:47,746 [foster.py] => Exemplar size: 2000
2024-08-20 01:17:47,746 [trainer.py] => CNN: {'total': 81.98, '00-49': 86.82, '50-54': 71.0, '55-59': 80.0, '60-64': 75.8, '65-69': 91.0, '70-74': 77.6, '75-79': 67.8, '80-84': 86.2, '85-89': 67.2, '90-94': 81.0, '95-99': 73.8, 'old': 82.41, 'new': 73.8}
2024-08-20 01:17:47,746 [trainer.py] => NME: {'total': 83.95, '00-49': 87.02, '50-54': 76.2, '55-59': 80.6, '60-64': 77.8, '65-69': 92.4, '70-74': 81.2, '75-79': 74.6, '80-84': 85.4, '85-89': 74.8, '90-94': 88.2, '95-99': 77.6, 'old': 84.28, 'new': 77.6}
2024-08-20 01:17:47,746 [trainer.py] => CNN top1 curve: [89.2, 87.96, 87.97, 87.38, 86.47, 85.68, 82.88, 83.29, 83.07, 82.23, 81.98]
2024-08-20 01:17:47,746 [trainer.py] => CNN top5 curve: [98.62, 98.45, 98.07, 98.38, 98.09, 98.03, 97.91, 98.01, 97.61, 97.37, 97.32]
2024-08-20 01:17:47,746 [trainer.py] => NME top1 curve: [90.68, 89.6, 89.0, 88.12, 87.89, 87.49, 86.01, 85.07, 84.76, 84.34, 83.95]
2024-08-20 01:17:47,746 [trainer.py] => NME top5 curve: [98.66, 98.69, 98.42, 98.38, 98.19, 98.21, 97.9, 97.94, 97.74, 97.52, 97.19]

Average Accuracy (CNN): 85.28
Average Accuracy (NME): 86.99
2024-08-20 01:17:47,746 [trainer.py] => Average Accuracy (CNN): 85.28
2024-08-20 01:17:47,746 [trainer.py] => Average Accuracy (NME): 86.99
2024-08-20 01:17:47,746 [trainer.py] => Train Time: 1011.51
2024-08-20 01:17:47,746 [trainer.py] => Test Time: 430.14000000000004 

Accuracy Matrix (CNN):
[[89.2  87.82 88.84 88.48 88.36 87.76 87.42 87.96 87.22 86.88 86.82]
 [ 0.   89.4  80.6  83.8  75.4  84.6  74.2  72.4  68.2  72.2  71.  ]
 [ 0.    0.   86.6  78.8  85.   81.2  71.   84.   79.8  80.8  80.  ]
 [ 0.    0.    0.   88.6  79.2  78.4  86.2  81.6  76.4  80.4  75.8 ]
 [ 0.    0.    0.    0.   87.4  88.2  90.   89.6  92.4  92.   91.  ]
 [ 0.    0.    0.    0.    0.   75.2  61.4  74.8  77.2  72.6  77.6 ]
 [ 0.    0.    0.    0.    0.    0.   69.   64.8  80.   74.4  67.8 ]
 [ 0.    0.    0.    0.    0.    0.    0.   69.2  80.   86.2  86.2 ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.   69.   60.8  67.2 ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.   74.2  81.  ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   73.8 ]]
2024-08-20 01:17:47,747 [trainer.py] => Forgetting (CNN): 5.558000000000002
Accuracy Matrix (NME):
[[90.68 90.1  89.84 89.36 88.98 89.06 88.56 87.28 87.44 87.2  87.02]
 [ 0.   84.6  83.   84.2  84.   82.6  78.4  77.6  77.6  78.2  76.2 ]
 [ 0.    0.   86.6  82.4  83.   84.2  80.6  80.6  81.6  79.2  80.6 ]
 [ 0.    0.    0.   85.4  82.2  79.   79.8  78.2  78.8  75.6  77.8 ]
 [ 0.    0.    0.    0.   91.4  92.   92.8  92.8  92.6  91.6  92.4 ]
 [ 0.    0.    0.    0.    0.   84.   82.   81.4  80.4  81.   81.2 ]
 [ 0.    0.    0.    0.    0.    0.   77.   74.6  73.8  75.2  74.6 ]
 [ 0.    0.    0.    0.    0.    0.    0.   88.2  85.   85.8  85.4 ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.   81.4  73.6  74.8 ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.   90.2  88.2 ]
 [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   77.6 ]]
2024-08-20 01:17:47,748 [trainer.py] => Forgetting (NME): 4.266000000000001
