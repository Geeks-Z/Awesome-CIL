nohup: 忽略输入
2024-04-30 08:20:13,325 [trainer.py] => config: ./exps/finetune_omn_B150_Inc5.json
2024-04-30 08:20:13,325 [trainer.py] => prefix: reproduce
2024-04-30 08:20:13,325 [trainer.py] => dataset: omnibenchmark
2024-04-30 08:20:13,325 [trainer.py] => memory_size: 0
2024-04-30 08:20:13,325 [trainer.py] => memory_per_class: 0
2024-04-30 08:20:13,325 [trainer.py] => fixed_memory: False
2024-04-30 08:20:13,325 [trainer.py] => shuffle: True
2024-04-30 08:20:13,325 [trainer.py] => init_cls: 150
2024-04-30 08:20:13,325 [trainer.py] => increment: 30
2024-04-30 08:20:13,325 [trainer.py] => model_name: finetune
2024-04-30 08:20:13,325 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-04-30 08:20:13,326 [trainer.py] => device: [device(type='cuda', index=6)]
2024-04-30 08:20:13,326 [trainer.py] => seed: 1993
2024-04-30 08:20:13,326 [trainer.py] => init_epoch: 20
2024-04-30 08:20:13,326 [trainer.py] => init_lr: 0.001
2024-04-30 08:20:13,326 [trainer.py] => init_milestones: [60, 120, 170]
2024-04-30 08:20:13,326 [trainer.py] => init_lr_decay: 0.1
2024-04-30 08:20:13,326 [trainer.py] => init_weight_decay: 0.0005
2024-04-30 08:20:13,326 [trainer.py] => epochs: 20
2024-04-30 08:20:13,326 [trainer.py] => lrate: 0.001
2024-04-30 08:20:13,326 [trainer.py] => milestones: [40, 70]
2024-04-30 08:20:13,326 [trainer.py] => lrate_decay: 0.1
2024-04-30 08:20:13,326 [trainer.py] => batch_size: 48
2024-04-30 08:20:13,326 [trainer.py] => weight_decay: 0.0002
2024-04-30 08:20:13,634 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
This is for the BaseNet initialization.
After BaseNet initialization.
2024-04-30 08:20:17,864 [trainer.py] => All params: 85798656
2024-04-30 08:20:17,865 [trainer.py] => Trainable params: 85798656
2024-04-30 08:20:17,867 [finetune.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.162, Train_accy 49.62, Test_accy 76.55:   0%|          | 0/20 [05:08<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.162, Train_accy 49.62, Test_accy 76.55:   5%|▌         | 1/20 [05:08<1:37:33, 308.08s/it]Task 0, Epoch 2/20 => Loss 0.909, Train_accy 73.49:   5%|▌         | 1/20 [10:09<1:37:33, 308.08s/it]                 Task 0, Epoch 2/20 => Loss 0.909, Train_accy 73.49:  10%|█         | 2/20 [10:09<1:31:10, 303.91s/it]Task 0, Epoch 3/20 => Loss 0.774, Train_accy 77.27:  10%|█         | 2/20 [15:09<1:31:10, 303.91s/it]Task 0, Epoch 3/20 => Loss 0.774, Train_accy 77.27:  15%|█▌        | 3/20 [15:09<1:25:38, 302.28s/it]Task 0, Epoch 4/20 => Loss 0.682, Train_accy 79.92:  15%|█▌        | 3/20 [20:08<1:25:38, 302.28s/it]Task 0, Epoch 4/20 => Loss 0.682, Train_accy 79.92:  20%|██        | 4/20 [20:08<1:20:16, 301.06s/it]Task 0, Epoch 5/20 => Loss 0.625, Train_accy 81.51:  20%|██        | 4/20 [25:07<1:20:16, 301.06s/it]Task 0, Epoch 5/20 => Loss 0.625, Train_accy 81.51:  25%|██▌       | 5/20 [25:07<1:15:04, 300.27s/it]Task 0, Epoch 6/20 => Loss 0.575, Train_accy 82.85, Test_accy 85.20:  25%|██▌       | 5/20 [30:16<1:15:04, 300.27s/it]Task 0, Epoch 6/20 => Loss 0.575, Train_accy 82.85, Test_accy 85.20:  30%|███       | 6/20 [30:16<1:10:45, 303.24s/it]Task 0, Epoch 7/20 => Loss 0.547, Train_accy 83.74:  30%|███       | 6/20 [35:18<1:10:45, 303.24s/it]                 Task 0, Epoch 7/20 => Loss 0.547, Train_accy 83.74:  35%|███▌      | 7/20 [35:18<1:05:38, 302.93s/it]Task 0, Epoch 8/20 => Loss 0.516, Train_accy 84.57:  35%|███▌      | 7/20 [40:18<1:05:38, 302.93s/it]Task 0, Epoch 8/20 => Loss 0.516, Train_accy 84.57:  40%|████      | 8/20 [40:18<1:00:21, 301.77s/it]Task 0, Epoch 9/20 => Loss 0.490, Train_accy 85.43:  40%|████      | 8/20 [45:18<1:00:21, 301.77s/it]Task 0, Epoch 9/20 => Loss 0.490, Train_accy 85.43:  45%|████▌     | 9/20 [45:18<55:13, 301.25s/it]  Task 0, Epoch 10/20 => Loss 0.473, Train_accy 85.96:  45%|████▌     | 9/20 [50:18<55:13, 301.25s/it]Task 0, Epoch 10/20 => Loss 0.473, Train_accy 85.96:  50%|█████     | 10/20 [50:18<50:10, 301.01s/it]Task 0, Epoch 11/20 => Loss 0.459, Train_accy 86.25, Test_accy 85.57:  50%|█████     | 10/20 [55:27<50:10, 301.01s/it]Task 0, Epoch 11/20 => Loss 0.459, Train_accy 86.25, Test_accy 85.57:  55%|█████▌    | 11/20 [55:27<45:30, 303.37s/it]Task 0, Epoch 12/20 => Loss 0.439, Train_accy 86.88:  55%|█████▌    | 11/20 [1:00:25<45:30, 303.37s/it]               Task 0, Epoch 12/20 => Loss 0.439, Train_accy 86.88:  60%|██████    | 12/20 [1:00:25<40:15, 301.88s/it]Task 0, Epoch 13/20 => Loss 0.423, Train_accy 87.27:  60%|██████    | 12/20 [1:05:25<40:15, 301.88s/it]Task 0, Epoch 13/20 => Loss 0.423, Train_accy 87.27:  65%|██████▌   | 13/20 [1:05:25<35:08, 301.18s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.88:  65%|██████▌   | 13/20 [1:10:24<35:08, 301.18s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.88:  70%|███████   | 14/20 [1:10:24<30:03, 300.52s/it]Task 0, Epoch 15/20 => Loss 0.398, Train_accy 88.00:  70%|███████   | 14/20 [1:15:23<30:03, 300.52s/it]Task 0, Epoch 15/20 => Loss 0.398, Train_accy 88.00:  75%|███████▌  | 15/20 [1:15:23<25:00, 300.12s/it]Task 0, Epoch 16/20 => Loss 0.385, Train_accy 88.57, Test_accy 85.24:  75%|███████▌  | 15/20 [1:20:31<25:00, 300.12s/it]Task 0, Epoch 16/20 => Loss 0.385, Train_accy 88.57, Test_accy 85.24:  80%|████████  | 16/20 [1:20:31<20:09, 302.34s/it]Task 0, Epoch 17/20 => Loss 0.381, Train_accy 88.61:  80%|████████  | 16/20 [1:25:30<20:09, 302.34s/it]                 Task 0, Epoch 17/20 => Loss 0.381, Train_accy 88.61:  85%|████████▌ | 17/20 [1:25:30<15:04, 301.38s/it]Task 0, Epoch 18/20 => Loss 0.365, Train_accy 89.21:  85%|████████▌ | 17/20 [1:30:29<15:04, 301.38s/it]Task 0, Epoch 18/20 => Loss 0.365, Train_accy 89.21:  90%|█████████ | 18/20 [1:30:29<10:01, 300.76s/it]Task 0, Epoch 19/20 => Loss 0.356, Train_accy 89.43:  90%|█████████ | 18/20 [1:35:28<10:01, 300.76s/it]Task 0, Epoch 19/20 => Loss 0.356, Train_accy 89.43:  95%|█████████▌| 19/20 [1:35:28<05:00, 300.30s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56:  95%|█████████▌| 19/20 [1:40:27<05:00, 300.30s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56: 100%|██████████| 20/20 [1:40:27<00:00, 299.80s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56: 100%|██████████| 20/20 [1:40:27<00:00, 301.37s/it]
2024-04-30 10:00:45,809 [finetune.py] => Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56
2024-04-30 10:00:54,119 [trainer.py] => No NME accuracy.
2024-04-30 10:00:54,120 [trainer.py] => CNN: {'total': 84.7, '00-149': 84.7, 'old': 0, 'new': 84.7}
2024-04-30 10:00:54,120 [trainer.py] => CNN top1 curve: [84.7]
2024-04-30 10:00:54,120 [trainer.py] => CNN top5 curve: [97.16]

Average Accuracy (CNN): 84.7
2024-04-30 10:00:54,120 [trainer.py] => Average Accuracy (CNN): 84.7 

2024-04-30 10:00:54,120 [trainer.py] => Train Time: 12055.32
2024-04-30 10:00:54,120 [trainer.py] => Test Time: 8.3 

2024-04-30 10:00:54,121 [trainer.py] => All params: 85914006
2024-04-30 10:00:54,122 [trainer.py] => Trainable params: 85914006
2024-04-30 10:00:54,125 [finetune.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.708, Train_accy 30.01, Test_accy 77.26:   0%|          | 0/20 [01:09<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.708, Train_accy 30.01, Test_accy 77.26:   5%|▌         | 1/20 [01:09<22:00, 69.53s/it]Task 1, Epoch 2/20 => Loss 0.311, Train_accy 47.06:   5%|▌         | 1/20 [02:09<22:00, 69.53s/it]                 Task 1, Epoch 2/20 => Loss 0.311, Train_accy 47.06:  10%|█         | 2/20 [02:09<19:06, 63.67s/it]Task 1, Epoch 3/20 => Loss 0.245, Train_accy 54.98:  10%|█         | 2/20 [03:08<19:06, 63.67s/it]Task 1, Epoch 3/20 => Loss 0.245, Train_accy 54.98:  15%|█▌        | 3/20 [03:08<17:30, 61.78s/it]Task 1, Epoch 4/20 => Loss 0.217, Train_accy 62.04:  15%|█▌        | 3/20 [04:08<17:30, 61.78s/it]Task 1, Epoch 4/20 => Loss 0.217, Train_accy 62.04:  20%|██        | 4/20 [04:08<16:14, 60.90s/it]Task 1, Epoch 5/20 => Loss 0.199, Train_accy 63.72:  20%|██        | 4/20 [05:07<16:14, 60.90s/it]Task 1, Epoch 5/20 => Loss 0.199, Train_accy 63.72:  25%|██▌       | 5/20 [05:07<15:07, 60.49s/it]Task 1, Epoch 6/20 => Loss 0.192, Train_accy 68.52, Test_accy 79.57:  25%|██▌       | 5/20 [06:17<15:07, 60.49s/it]Task 1, Epoch 6/20 => Loss 0.192, Train_accy 68.52, Test_accy 79.57:  30%|███       | 6/20 [06:17<14:50, 63.59s/it]Task 1, Epoch 7/20 => Loss 0.173, Train_accy 72.62:  30%|███       | 6/20 [07:17<14:50, 63.59s/it]                 Task 1, Epoch 7/20 => Loss 0.173, Train_accy 72.62:  35%|███▌      | 7/20 [07:17<13:29, 62.25s/it]Task 1, Epoch 8/20 => Loss 0.157, Train_accy 75.66:  35%|███▌      | 7/20 [08:16<13:29, 62.25s/it]Task 1, Epoch 8/20 => Loss 0.157, Train_accy 75.66:  40%|████      | 8/20 [08:16<12:16, 61.34s/it]Task 1, Epoch 9/20 => Loss 0.159, Train_accy 76.94:  40%|████      | 8/20 [09:16<12:16, 61.34s/it]Task 1, Epoch 9/20 => Loss 0.159, Train_accy 76.94:  45%|████▌     | 9/20 [09:16<11:09, 60.83s/it]Task 1, Epoch 10/20 => Loss 0.147, Train_accy 79.23:  45%|████▌     | 9/20 [10:15<11:09, 60.83s/it]Task 1, Epoch 10/20 => Loss 0.147, Train_accy 79.23:  50%|█████     | 10/20 [10:15<10:04, 60.41s/it]Task 1, Epoch 11/20 => Loss 0.144, Train_accy 81.32, Test_accy 78.54:  50%|█████     | 10/20 [11:24<10:04, 60.41s/it]Task 1, Epoch 11/20 => Loss 0.144, Train_accy 81.32, Test_accy 78.54:  55%|█████▌    | 11/20 [11:24<09:27, 63.07s/it]Task 1, Epoch 12/20 => Loss 0.123, Train_accy 83.51:  55%|█████▌    | 11/20 [12:24<09:27, 63.07s/it]                 Task 1, Epoch 12/20 => Loss 0.123, Train_accy 83.51:  60%|██████    | 12/20 [12:24<08:15, 61.97s/it]Task 1, Epoch 13/20 => Loss 0.126, Train_accy 82.73:  60%|██████    | 12/20 [13:23<08:15, 61.97s/it]Task 1, Epoch 13/20 => Loss 0.126, Train_accy 82.73:  65%|██████▌   | 13/20 [13:23<07:08, 61.15s/it]Task 1, Epoch 14/20 => Loss 0.134, Train_accy 83.04:  65%|██████▌   | 13/20 [14:22<07:08, 61.15s/it]Task 1, Epoch 14/20 => Loss 0.134, Train_accy 83.04:  70%|███████   | 14/20 [14:22<06:03, 60.65s/it]Task 1, Epoch 15/20 => Loss 0.125, Train_accy 83.18:  70%|███████   | 14/20 [15:22<06:03, 60.65s/it]Task 1, Epoch 15/20 => Loss 0.125, Train_accy 83.18:  75%|███████▌  | 15/20 [15:22<05:01, 60.38s/it]Task 1, Epoch 16/20 => Loss 0.129, Train_accy 84.81, Test_accy 77.39:  75%|███████▌  | 15/20 [16:32<05:01, 60.38s/it]Task 1, Epoch 16/20 => Loss 0.129, Train_accy 84.81, Test_accy 77.39:  80%|████████  | 16/20 [16:32<04:12, 63.16s/it]Task 1, Epoch 17/20 => Loss 0.134, Train_accy 85.41:  80%|████████  | 16/20 [17:31<04:12, 63.16s/it]                 Task 1, Epoch 17/20 => Loss 0.134, Train_accy 85.41:  85%|████████▌ | 17/20 [17:31<03:06, 62.04s/it]Task 1, Epoch 18/20 => Loss 0.121, Train_accy 86.88:  85%|████████▌ | 17/20 [18:31<03:06, 62.04s/it]Task 1, Epoch 18/20 => Loss 0.121, Train_accy 86.88:  90%|█████████ | 18/20 [18:31<02:02, 61.29s/it]Task 1, Epoch 19/20 => Loss 0.107, Train_accy 88.12:  90%|█████████ | 18/20 [19:31<02:02, 61.29s/it]Task 1, Epoch 19/20 => Loss 0.107, Train_accy 88.12:  95%|█████████▌| 19/20 [19:31<01:00, 60.84s/it]Task 1, Epoch 20/20 => Loss 0.106, Train_accy 88.91:  95%|█████████▌| 19/20 [20:30<01:00, 60.84s/it]Task 1, Epoch 20/20 => Loss 0.106, Train_accy 88.91: 100%|██████████| 20/20 [20:30<00:00, 60.47s/it]Task 1, Epoch 20/20 => Loss 0.106, Train_accy 88.91: 100%|██████████| 20/20 [20:30<00:00, 61.53s/it]
2024-04-30 10:21:24,814 [finetune.py] => Task 1, Epoch 20/20 => Loss 0.106, Train_accy 88.91
2024-04-30 10:21:34,710 [trainer.py] => No NME accuracy.
2024-04-30 10:21:34,710 [trainer.py] => CNN: {'total': 76.53, '00-149': 74.72, '150-179': 85.62, 'old': 74.72, 'new': 85.62}
2024-04-30 10:21:34,711 [trainer.py] => CNN top1 curve: [84.7, 76.53]
2024-04-30 10:21:34,711 [trainer.py] => CNN top5 curve: [97.16, 94.96]

Average Accuracy (CNN): 80.62
2024-04-30 10:21:34,711 [trainer.py] => Average Accuracy (CNN): 80.62 

2024-04-30 10:21:34,711 [trainer.py] => Train Time: 13285.99
2024-04-30 10:21:34,711 [trainer.py] => Test Time: 18.19 

2024-04-30 10:21:34,712 [trainer.py] => All params: 85937076
2024-04-30 10:21:34,713 [trainer.py] => Trainable params: 85937076
2024-04-30 10:21:34,717 [finetune.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.651, Train_accy 39.19, Test_accy 72.45:   0%|          | 0/20 [01:11<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.651, Train_accy 39.19, Test_accy 72.45:   5%|▌         | 1/20 [01:11<22:31, 71.14s/it]Task 2, Epoch 2/20 => Loss 0.354, Train_accy 60.89:   5%|▌         | 1/20 [02:10<22:31, 71.14s/it]                 Task 2, Epoch 2/20 => Loss 0.354, Train_accy 60.89:  10%|█         | 2/20 [02:10<19:19, 64.40s/it]Task 2, Epoch 3/20 => Loss 0.275, Train_accy 68.74:  10%|█         | 2/20 [03:10<19:19, 64.40s/it]Task 2, Epoch 3/20 => Loss 0.275, Train_accy 68.74:  15%|█▌        | 3/20 [03:10<17:38, 62.28s/it]Task 2, Epoch 4/20 => Loss 0.233, Train_accy 72.57:  15%|█▌        | 3/20 [04:10<17:38, 62.28s/it]Task 2, Epoch 4/20 => Loss 0.233, Train_accy 72.57:  20%|██        | 4/20 [04:10<16:19, 61.22s/it]Task 2, Epoch 5/20 => Loss 0.212, Train_accy 76.12:  20%|██        | 4/20 [05:09<16:19, 61.22s/it]Task 2, Epoch 5/20 => Loss 0.212, Train_accy 76.12:  25%|██▌       | 5/20 [05:09<15:08, 60.57s/it]Task 2, Epoch 6/20 => Loss 0.191, Train_accy 78.65, Test_accy 72.71:  25%|██▌       | 5/20 [06:20<15:08, 60.57s/it]Task 2, Epoch 6/20 => Loss 0.191, Train_accy 78.65, Test_accy 72.71:  30%|███       | 6/20 [06:20<14:58, 64.15s/it]Task 2, Epoch 7/20 => Loss 0.192, Train_accy 80.31:  30%|███       | 6/20 [07:19<14:58, 64.15s/it]                 Task 2, Epoch 7/20 => Loss 0.192, Train_accy 80.31:  35%|███▌      | 7/20 [07:20<13:33, 62.57s/it]Task 2, Epoch 8/20 => Loss 0.187, Train_accy 80.27:  35%|███▌      | 7/20 [08:19<13:33, 62.57s/it]Task 2, Epoch 8/20 => Loss 0.187, Train_accy 80.27:  40%|████      | 8/20 [08:19<12:18, 61.54s/it]Task 2, Epoch 9/20 => Loss 0.157, Train_accy 82.68:  40%|████      | 8/20 [09:18<12:18, 61.54s/it]Task 2, Epoch 9/20 => Loss 0.157, Train_accy 82.68:  45%|████▌     | 9/20 [09:18<11:10, 60.95s/it]Task 2, Epoch 10/20 => Loss 0.148, Train_accy 84.07:  45%|████▌     | 9/20 [10:18<11:10, 60.95s/it]Task 2, Epoch 10/20 => Loss 0.148, Train_accy 84.07:  50%|█████     | 10/20 [10:18<10:05, 60.51s/it]Task 2, Epoch 11/20 => Loss 0.146, Train_accy 84.64, Test_accy 73.26:  50%|█████     | 10/20 [11:29<10:05, 60.51s/it]Task 2, Epoch 11/20 => Loss 0.146, Train_accy 84.64, Test_accy 73.26:  55%|█████▌    | 11/20 [11:29<09:33, 63.73s/it]Task 2, Epoch 12/20 => Loss 0.145, Train_accy 85.99:  55%|█████▌    | 11/20 [12:29<09:33, 63.73s/it]                 Task 2, Epoch 12/20 => Loss 0.145, Train_accy 85.99:  60%|██████    | 12/20 [12:29<08:19, 62.45s/it]Task 2, Epoch 13/20 => Loss 0.130, Train_accy 86.92:  60%|██████    | 12/20 [13:28<08:19, 62.45s/it]Task 2, Epoch 13/20 => Loss 0.130, Train_accy 86.92:  65%|██████▌   | 13/20 [13:28<07:10, 61.56s/it]Task 2, Epoch 14/20 => Loss 0.146, Train_accy 87.96:  65%|██████▌   | 13/20 [14:28<07:10, 61.56s/it]Task 2, Epoch 14/20 => Loss 0.146, Train_accy 87.96:  70%|███████   | 14/20 [14:28<06:05, 60.98s/it]Task 2, Epoch 15/20 => Loss 0.124, Train_accy 88.68:  70%|███████   | 14/20 [15:27<06:05, 60.98s/it]Task 2, Epoch 15/20 => Loss 0.124, Train_accy 88.68:  75%|███████▌  | 15/20 [15:27<05:02, 60.49s/it]Task 2, Epoch 16/20 => Loss 0.121, Train_accy 90.21, Test_accy 71.97:  75%|███████▌  | 15/20 [16:38<05:02, 60.49s/it]Task 2, Epoch 16/20 => Loss 0.121, Train_accy 90.21, Test_accy 71.97:  80%|████████  | 16/20 [16:38<04:14, 63.56s/it]Task 2, Epoch 17/20 => Loss 0.132, Train_accy 90.75:  80%|████████  | 16/20 [17:37<04:14, 63.56s/it]                 Task 2, Epoch 17/20 => Loss 0.132, Train_accy 90.75:  85%|████████▌ | 17/20 [17:37<03:06, 62.33s/it]Task 2, Epoch 18/20 => Loss 0.150, Train_accy 89.52:  85%|████████▌ | 17/20 [18:37<03:06, 62.33s/it]Task 2, Epoch 18/20 => Loss 0.150, Train_accy 89.52:  90%|█████████ | 18/20 [18:37<02:02, 61.47s/it]Task 2, Epoch 19/20 => Loss 0.123, Train_accy 90.38:  90%|█████████ | 18/20 [19:36<02:02, 61.47s/it]Task 2, Epoch 19/20 => Loss 0.123, Train_accy 90.38:  95%|█████████▌| 19/20 [19:36<01:00, 60.76s/it]Task 2, Epoch 20/20 => Loss 0.117, Train_accy 90.82:  95%|█████████▌| 19/20 [20:35<01:00, 60.76s/it]Task 2, Epoch 20/20 => Loss 0.117, Train_accy 90.82: 100%|██████████| 20/20 [20:35<00:00, 60.25s/it]Task 2, Epoch 20/20 => Loss 0.117, Train_accy 90.82: 100%|██████████| 20/20 [20:35<00:00, 61.77s/it]
2024-04-30 10:42:10,106 [finetune.py] => Task 2, Epoch 20/20 => Loss 0.117, Train_accy 90.82
2024-04-30 10:42:21,799 [trainer.py] => No NME accuracy.
2024-04-30 10:42:21,799 [trainer.py] => CNN: {'total': 70.37, '00-149': 66.77, '150-179': 68.23, '180-209': 90.62, 'old': 67.01, 'new': 90.62}
2024-04-30 10:42:21,799 [trainer.py] => CNN top1 curve: [84.7, 76.53, 70.37]
2024-04-30 10:42:21,799 [trainer.py] => CNN top5 curve: [97.16, 94.96, 93.17]

Average Accuracy (CNN): 77.2
2024-04-30 10:42:21,799 [trainer.py] => Average Accuracy (CNN): 77.2 

2024-04-30 10:42:21,799 [trainer.py] => Train Time: 14521.36
2024-04-30 10:42:21,799 [trainer.py] => Test Time: 29.880000000000003 

2024-04-30 10:42:21,800 [trainer.py] => All params: 85960146
2024-04-30 10:42:21,801 [trainer.py] => Trainable params: 85960146
2024-04-30 10:42:21,804 [finetune.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.677, Train_accy 35.90, Test_accy 65.23:   0%|          | 0/20 [01:15<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.677, Train_accy 35.90, Test_accy 65.23:   5%|▌         | 1/20 [01:15<24:02, 75.95s/it]Task 3, Epoch 2/20 => Loss 0.331, Train_accy 54.27:   5%|▌         | 1/20 [02:18<24:02, 75.95s/it]                 Task 3, Epoch 2/20 => Loss 0.331, Train_accy 54.27:  10%|█         | 2/20 [02:18<20:27, 68.19s/it]Task 3, Epoch 3/20 => Loss 0.275, Train_accy 61.44:  10%|█         | 2/20 [03:21<20:27, 68.19s/it]Task 3, Epoch 3/20 => Loss 0.275, Train_accy 61.44:  15%|█▌        | 3/20 [03:21<18:35, 65.63s/it]Task 3, Epoch 4/20 => Loss 0.257, Train_accy 64.71:  15%|█▌        | 3/20 [04:23<18:35, 65.63s/it]Task 3, Epoch 4/20 => Loss 0.257, Train_accy 64.71:  20%|██        | 4/20 [04:23<17:10, 64.40s/it]Task 3, Epoch 5/20 => Loss 0.227, Train_accy 70.13:  20%|██        | 4/20 [05:26<17:10, 64.40s/it]Task 3, Epoch 5/20 => Loss 0.227, Train_accy 70.13:  25%|██▌       | 5/20 [05:26<15:55, 63.68s/it]Task 3, Epoch 6/20 => Loss 0.210, Train_accy 73.73, Test_accy 66.62:  25%|██▌       | 5/20 [06:41<15:55, 63.68s/it]Task 3, Epoch 6/20 => Loss 0.210, Train_accy 73.73, Test_accy 66.62:  30%|███       | 6/20 [06:41<15:46, 67.60s/it]Task 3, Epoch 7/20 => Loss 0.195, Train_accy 75.86:  30%|███       | 6/20 [07:43<15:46, 67.60s/it]                 Task 3, Epoch 7/20 => Loss 0.195, Train_accy 75.86:  35%|███▌      | 7/20 [07:43<14:17, 65.92s/it]Task 3, Epoch 8/20 => Loss 0.190, Train_accy 77.22:  35%|███▌      | 7/20 [08:46<14:17, 65.92s/it]Task 3, Epoch 8/20 => Loss 0.190, Train_accy 77.22:  40%|████      | 8/20 [08:46<12:58, 64.87s/it]Task 3, Epoch 9/20 => Loss 0.185, Train_accy 77.70:  40%|████      | 8/20 [09:48<12:58, 64.87s/it]Task 3, Epoch 9/20 => Loss 0.185, Train_accy 77.70:  45%|████▌     | 9/20 [09:48<11:44, 64.04s/it]Task 3, Epoch 10/20 => Loss 0.173, Train_accy 79.08:  45%|████▌     | 9/20 [10:51<11:44, 64.04s/it]Task 3, Epoch 10/20 => Loss 0.173, Train_accy 79.08:  50%|█████     | 10/20 [10:51<10:35, 63.52s/it]Task 3, Epoch 11/20 => Loss 0.167, Train_accy 81.06, Test_accy 66.92:  50%|█████     | 10/20 [12:06<10:35, 63.52s/it]Task 3, Epoch 11/20 => Loss 0.167, Train_accy 81.06, Test_accy 66.92:  55%|█████▌    | 11/20 [12:06<10:03, 67.11s/it]Task 3, Epoch 12/20 => Loss 0.153, Train_accy 82.37:  55%|█████▌    | 11/20 [13:08<10:03, 67.11s/it]                 Task 3, Epoch 12/20 => Loss 0.153, Train_accy 82.37:  60%|██████    | 12/20 [13:08<08:45, 65.63s/it]Task 3, Epoch 13/20 => Loss 0.150, Train_accy 84.10:  60%|██████    | 12/20 [14:10<08:45, 65.63s/it]Task 3, Epoch 13/20 => Loss 0.150, Train_accy 84.10:  65%|██████▌   | 13/20 [14:10<07:32, 64.61s/it]Task 3, Epoch 14/20 => Loss 0.147, Train_accy 85.04:  65%|██████▌   | 13/20 [15:13<07:32, 64.61s/it]Task 3, Epoch 14/20 => Loss 0.147, Train_accy 85.04:  70%|███████   | 14/20 [15:13<06:23, 63.92s/it]Task 3, Epoch 15/20 => Loss 0.137, Train_accy 85.48:  70%|███████   | 14/20 [16:15<06:23, 63.92s/it]Task 3, Epoch 15/20 => Loss 0.137, Train_accy 85.48:  75%|███████▌  | 15/20 [16:15<05:17, 63.49s/it]Task 3, Epoch 16/20 => Loss 0.148, Train_accy 86.47, Test_accy 64.70:  75%|███████▌  | 15/20 [17:31<05:17, 63.49s/it]Task 3, Epoch 16/20 => Loss 0.148, Train_accy 86.47, Test_accy 64.70:  80%|████████  | 16/20 [17:31<04:28, 67.11s/it]Task 3, Epoch 17/20 => Loss 0.124, Train_accy 87.82:  80%|████████  | 16/20 [18:33<04:28, 67.11s/it]                 Task 3, Epoch 17/20 => Loss 0.124, Train_accy 87.82:  85%|████████▌ | 17/20 [18:33<03:17, 65.70s/it]Task 3, Epoch 18/20 => Loss 0.126, Train_accy 88.32:  85%|████████▌ | 17/20 [19:36<03:17, 65.70s/it]Task 3, Epoch 18/20 => Loss 0.126, Train_accy 88.32:  90%|█████████ | 18/20 [19:36<02:09, 64.84s/it]Task 3, Epoch 19/20 => Loss 0.123, Train_accy 88.63:  90%|█████████ | 18/20 [20:39<02:09, 64.84s/it]Task 3, Epoch 19/20 => Loss 0.123, Train_accy 88.63:  95%|█████████▌| 19/20 [20:39<01:04, 64.38s/it]Task 3, Epoch 20/20 => Loss 0.118, Train_accy 88.79:  95%|█████████▌| 19/20 [21:42<01:04, 64.38s/it]Task 3, Epoch 20/20 => Loss 0.118, Train_accy 88.79: 100%|██████████| 20/20 [21:42<00:00, 64.04s/it]Task 3, Epoch 20/20 => Loss 0.118, Train_accy 88.79: 100%|██████████| 20/20 [21:42<00:00, 65.15s/it]
2024-04-30 11:04:04,807 [finetune.py] => Task 3, Epoch 20/20 => Loss 0.118, Train_accy 88.79
2024-04-30 11:04:18,180 [trainer.py] => No NME accuracy.
2024-04-30 11:04:18,180 [trainer.py] => CNN: {'total': 63.68, '00-149': 57.52, '150-179': 59.03, '180-209': 76.05, '210-239': 86.81, 'old': 60.37, 'new': 86.81}
2024-04-30 11:04:18,180 [trainer.py] => CNN top1 curve: [84.7, 76.53, 70.37, 63.68]
2024-04-30 11:04:18,180 [trainer.py] => CNN top5 curve: [97.16, 94.96, 93.17, 91.62]

Average Accuracy (CNN): 73.82
2024-04-30 11:04:18,180 [trainer.py] => Average Accuracy (CNN): 73.82 

2024-04-30 11:04:18,181 [trainer.py] => Train Time: 15824.35
2024-04-30 11:04:18,181 [trainer.py] => Test Time: 43.25 

2024-04-30 11:04:18,182 [trainer.py] => All params: 85983216
2024-04-30 11:04:18,183 [trainer.py] => Trainable params: 85983216
2024-04-30 11:04:18,187 [finetune.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.608, Train_accy 35.47, Test_accy 60.24:   0%|          | 0/20 [01:17<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.608, Train_accy 35.47, Test_accy 60.24:   5%|▌         | 1/20 [01:17<24:26, 77.16s/it]Task 4, Epoch 2/20 => Loss 0.266, Train_accy 54.92:   5%|▌         | 1/20 [02:19<24:26, 77.16s/it]                 Task 4, Epoch 2/20 => Loss 0.266, Train_accy 54.92:  10%|█         | 2/20 [02:19<20:33, 68.52s/it]Task 4, Epoch 3/20 => Loss 0.219, Train_accy 61.90:  10%|█         | 2/20 [03:21<20:33, 68.52s/it]Task 4, Epoch 3/20 => Loss 0.219, Train_accy 61.90:  15%|█▌        | 3/20 [03:21<18:36, 65.67s/it]Task 4, Epoch 4/20 => Loss 0.188, Train_accy 67.82:  15%|█▌        | 3/20 [04:24<18:36, 65.67s/it]Task 4, Epoch 4/20 => Loss 0.188, Train_accy 67.82:  20%|██        | 4/20 [04:24<17:10, 64.39s/it]Task 4, Epoch 5/20 => Loss 0.168, Train_accy 71.31:  20%|██        | 4/20 [05:26<17:10, 64.39s/it]Task 4, Epoch 5/20 => Loss 0.168, Train_accy 71.31:  25%|██▌       | 5/20 [05:26<15:55, 63.70s/it]Task 4, Epoch 6/20 => Loss 0.155, Train_accy 73.92, Test_accy 63.24:  25%|██▌       | 5/20 [06:43<15:55, 63.70s/it]Task 4, Epoch 6/20 => Loss 0.155, Train_accy 73.92, Test_accy 63.24:  30%|███       | 6/20 [06:43<15:55, 68.22s/it]Task 4, Epoch 7/20 => Loss 0.161, Train_accy 75.96:  30%|███       | 6/20 [07:46<15:55, 68.22s/it]                 Task 4, Epoch 7/20 => Loss 0.161, Train_accy 75.96:  35%|███▌      | 7/20 [07:46<14:21, 66.25s/it]Task 4, Epoch 8/20 => Loss 0.149, Train_accy 78.35:  35%|███▌      | 7/20 [08:48<14:21, 66.25s/it]Task 4, Epoch 8/20 => Loss 0.149, Train_accy 78.35:  40%|████      | 8/20 [08:48<12:59, 64.98s/it]Task 4, Epoch 9/20 => Loss 0.142, Train_accy 79.97:  40%|████      | 8/20 [09:50<12:59, 64.98s/it]Task 4, Epoch 9/20 => Loss 0.142, Train_accy 79.97:  45%|████▌     | 9/20 [09:50<11:45, 64.15s/it]Task 4, Epoch 10/20 => Loss 0.139, Train_accy 82.09:  45%|████▌     | 9/20 [10:52<11:45, 64.15s/it]Task 4, Epoch 10/20 => Loss 0.139, Train_accy 82.09:  50%|█████     | 10/20 [10:52<10:36, 63.61s/it]Task 4, Epoch 11/20 => Loss 0.136, Train_accy 82.86, Test_accy 60.89:  50%|█████     | 10/20 [12:10<10:36, 63.61s/it]Task 4, Epoch 11/20 => Loss 0.136, Train_accy 82.86, Test_accy 60.89:  55%|█████▌    | 11/20 [12:10<10:09, 67.74s/it]Task 4, Epoch 12/20 => Loss 0.134, Train_accy 83.93:  55%|█████▌    | 11/20 [13:12<10:09, 67.74s/it]                 Task 4, Epoch 12/20 => Loss 0.134, Train_accy 83.93:  60%|██████    | 12/20 [13:12<08:48, 66.04s/it]Task 4, Epoch 13/20 => Loss 0.127, Train_accy 85.30:  60%|██████    | 12/20 [14:14<08:48, 66.04s/it]Task 4, Epoch 13/20 => Loss 0.127, Train_accy 85.30:  65%|██████▌   | 13/20 [14:14<07:34, 64.92s/it]Task 4, Epoch 14/20 => Loss 0.116, Train_accy 86.54:  65%|██████▌   | 13/20 [15:16<07:34, 64.92s/it]Task 4, Epoch 14/20 => Loss 0.116, Train_accy 86.54:  70%|███████   | 14/20 [15:16<06:24, 64.06s/it]Task 4, Epoch 15/20 => Loss 0.116, Train_accy 86.55:  70%|███████   | 14/20 [16:19<06:24, 64.06s/it]Task 4, Epoch 15/20 => Loss 0.116, Train_accy 86.55:  75%|███████▌  | 15/20 [16:19<05:18, 63.62s/it]Task 4, Epoch 16/20 => Loss 0.119, Train_accy 86.51, Test_accy 59.96:  75%|███████▌  | 15/20 [17:36<05:18, 63.62s/it]Task 4, Epoch 16/20 => Loss 0.119, Train_accy 86.51, Test_accy 59.96:  80%|████████  | 16/20 [17:36<04:30, 67.66s/it]Task 4, Epoch 17/20 => Loss 0.112, Train_accy 86.67:  80%|████████  | 16/20 [18:38<04:30, 67.66s/it]                 Task 4, Epoch 17/20 => Loss 0.112, Train_accy 86.67:  85%|████████▌ | 17/20 [18:38<03:18, 66.15s/it]Task 4, Epoch 18/20 => Loss 0.104, Train_accy 86.77:  85%|████████▌ | 17/20 [19:41<03:18, 66.15s/it]Task 4, Epoch 18/20 => Loss 0.104, Train_accy 86.77:  90%|█████████ | 18/20 [19:41<02:09, 64.96s/it]Task 4, Epoch 19/20 => Loss 0.103, Train_accy 88.01:  90%|█████████ | 18/20 [20:43<02:09, 64.96s/it]Task 4, Epoch 19/20 => Loss 0.103, Train_accy 88.01:  95%|█████████▌| 19/20 [20:43<01:04, 64.15s/it]Task 4, Epoch 20/20 => Loss 0.100, Train_accy 88.24:  95%|█████████▌| 19/20 [21:45<01:04, 64.15s/it]Task 4, Epoch 20/20 => Loss 0.100, Train_accy 88.24: 100%|██████████| 20/20 [21:45<00:00, 63.54s/it]Task 4, Epoch 20/20 => Loss 0.100, Train_accy 88.24: 100%|██████████| 20/20 [21:45<00:00, 65.28s/it]
2024-04-30 11:26:03,723 [finetune.py] => Task 4, Epoch 20/20 => Loss 0.100, Train_accy 88.24
2024-04-30 11:26:18,754 [trainer.py] => No NME accuracy.
2024-04-30 11:26:18,754 [trainer.py] => CNN: {'total': 59.2, '00-149': 52.44, '150-179': 46.66, '180-209': 60.8, '210-239': 77.3, '240-269': 85.81, 'old': 55.87, 'new': 85.81}
2024-04-30 11:26:18,754 [trainer.py] => CNN top1 curve: [84.7, 76.53, 70.37, 63.68, 59.2]
2024-04-30 11:26:18,754 [trainer.py] => CNN top5 curve: [97.16, 94.96, 93.17, 91.62, 91.03]

Average Accuracy (CNN): 70.9
2024-04-30 11:26:18,754 [trainer.py] => Average Accuracy (CNN): 70.9 

2024-04-30 11:26:18,754 [trainer.py] => Train Time: 17129.87
2024-04-30 11:26:18,754 [trainer.py] => Test Time: 58.28 

2024-04-30 11:26:18,755 [trainer.py] => All params: 86006286
2024-04-30 11:26:18,756 [trainer.py] => Trainable params: 86006286
2024-04-30 11:26:18,760 [finetune.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.635, Train_accy 35.28, Test_accy 56.19:   0%|          | 0/20 [01:14<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.635, Train_accy 35.28, Test_accy 56.19:   5%|▌         | 1/20 [01:14<23:40, 74.74s/it]Task 5, Epoch 2/20 => Loss 0.270, Train_accy 55.69:   5%|▌         | 1/20 [02:13<23:40, 74.74s/it]                 Task 5, Epoch 2/20 => Loss 0.270, Train_accy 55.69:  10%|█         | 2/20 [02:13<19:36, 65.38s/it]Task 5, Epoch 3/20 => Loss 0.239, Train_accy 64.16:  10%|█         | 2/20 [03:12<19:36, 65.38s/it]Task 5, Epoch 3/20 => Loss 0.239, Train_accy 64.16:  15%|█▌        | 3/20 [03:12<17:37, 62.21s/it]Task 5, Epoch 4/20 => Loss 0.196, Train_accy 67.69:  15%|█▌        | 3/20 [04:10<17:37, 62.21s/it]Task 5, Epoch 4/20 => Loss 0.196, Train_accy 67.69:  20%|██        | 4/20 [04:10<16:13, 60.83s/it]Task 5, Epoch 5/20 => Loss 0.184, Train_accy 70.40:  20%|██        | 4/20 [05:09<16:13, 60.83s/it]Task 5, Epoch 5/20 => Loss 0.184, Train_accy 70.40:  25%|██▌       | 5/20 [05:09<14:59, 59.99s/it]Task 5, Epoch 6/20 => Loss 0.167, Train_accy 73.24, Test_accy 56.07:  25%|██▌       | 5/20 [06:24<14:59, 59.99s/it]Task 5, Epoch 6/20 => Loss 0.167, Train_accy 73.24, Test_accy 56.07:  30%|███       | 6/20 [06:24<15:11, 65.08s/it]Task 5, Epoch 7/20 => Loss 0.161, Train_accy 74.72:  30%|███       | 6/20 [07:22<15:11, 65.08s/it]                 Task 5, Epoch 7/20 => Loss 0.161, Train_accy 74.72:  35%|███▌      | 7/20 [07:22<13:38, 62.96s/it]Task 5, Epoch 8/20 => Loss 0.139, Train_accy 75.61:  35%|███▌      | 7/20 [08:21<13:38, 62.96s/it]Task 5, Epoch 8/20 => Loss 0.139, Train_accy 75.61:  40%|████      | 8/20 [08:21<12:20, 61.68s/it]Task 5, Epoch 9/20 => Loss 0.145, Train_accy 77.61:  40%|████      | 8/20 [09:20<12:20, 61.68s/it]Task 5, Epoch 9/20 => Loss 0.145, Train_accy 77.61:  45%|████▌     | 9/20 [09:20<11:08, 60.76s/it]Task 5, Epoch 10/20 => Loss 0.131, Train_accy 78.10:  45%|████▌     | 9/20 [10:18<11:08, 60.76s/it]Task 5, Epoch 10/20 => Loss 0.131, Train_accy 78.10:  50%|█████     | 10/20 [10:18<10:00, 60.01s/it]Task 5, Epoch 11/20 => Loss 0.123, Train_accy 80.00, Test_accy 56.39:  50%|█████     | 10/20 [11:33<10:00, 60.01s/it]Task 5, Epoch 11/20 => Loss 0.123, Train_accy 80.00, Test_accy 56.39:  55%|█████▌    | 11/20 [11:33<09:40, 64.51s/it]Task 5, Epoch 12/20 => Loss 0.121, Train_accy 80.09:  55%|█████▌    | 11/20 [12:32<09:40, 64.51s/it]                 Task 5, Epoch 12/20 => Loss 0.121, Train_accy 80.09:  60%|██████    | 12/20 [12:32<08:22, 62.78s/it]Task 5, Epoch 13/20 => Loss 0.118, Train_accy 80.31:  60%|██████    | 12/20 [13:43<08:22, 62.78s/it]Task 5, Epoch 13/20 => Loss 0.118, Train_accy 80.31:  65%|██████▌   | 13/20 [13:43<07:38, 65.46s/it]Task 5, Epoch 14/20 => Loss 0.115, Train_accy 80.81:  65%|██████▌   | 13/20 [14:55<07:38, 65.46s/it]Task 5, Epoch 14/20 => Loss 0.115, Train_accy 80.81:  70%|███████   | 14/20 [14:55<06:43, 67.17s/it]Task 5, Epoch 15/20 => Loss 0.115, Train_accy 81.58:  70%|███████   | 14/20 [15:53<06:43, 67.17s/it]Task 5, Epoch 15/20 => Loss 0.115, Train_accy 81.58:  75%|███████▌  | 15/20 [15:53<05:23, 64.65s/it]Task 5, Epoch 16/20 => Loss 0.108, Train_accy 84.19, Test_accy 56.27:  75%|███████▌  | 15/20 [17:08<05:23, 64.65s/it]Task 5, Epoch 16/20 => Loss 0.108, Train_accy 84.19, Test_accy 56.27:  80%|████████  | 16/20 [17:08<04:31, 67.78s/it]Task 5, Epoch 17/20 => Loss 0.099, Train_accy 84.89:  80%|████████  | 16/20 [18:07<04:31, 67.78s/it]                 Task 5, Epoch 17/20 => Loss 0.099, Train_accy 84.89:  85%|████████▌ | 17/20 [18:07<03:15, 65.10s/it]Task 5, Epoch 18/20 => Loss 0.109, Train_accy 84.29:  85%|████████▌ | 17/20 [19:06<03:15, 65.10s/it]Task 5, Epoch 18/20 => Loss 0.109, Train_accy 84.29:  90%|█████████ | 18/20 [19:06<02:06, 63.16s/it]Task 5, Epoch 19/20 => Loss 0.101, Train_accy 85.46:  90%|█████████ | 18/20 [20:05<02:06, 63.16s/it]Task 5, Epoch 19/20 => Loss 0.101, Train_accy 85.46:  95%|█████████▌| 19/20 [20:05<01:01, 61.91s/it]Task 5, Epoch 20/20 => Loss 0.097, Train_accy 85.38:  95%|█████████▌| 19/20 [21:03<01:01, 61.91s/it]Task 5, Epoch 20/20 => Loss 0.097, Train_accy 85.38: 100%|██████████| 20/20 [21:03<00:00, 60.90s/it]Task 5, Epoch 20/20 => Loss 0.097, Train_accy 85.38: 100%|██████████| 20/20 [21:03<00:00, 63.20s/it]
2024-04-30 11:47:22,772 [finetune.py] => Task 5, Epoch 20/20 => Loss 0.097, Train_accy 85.38
2024-04-30 11:47:39,049 [trainer.py] => No NME accuracy.
2024-04-30 11:47:39,049 [trainer.py] => CNN: {'total': 54.47, '00-149': 47.16, '150-179': 41.47, '180-209': 48.91, '210-239': 58.93, '240-269': 74.62, '270-299': 84.95, 'old': 51.09, 'new': 84.95}
2024-04-30 11:47:39,050 [trainer.py] => CNN top1 curve: [84.7, 76.53, 70.37, 63.68, 59.2, 54.47]
2024-04-30 11:47:39,050 [trainer.py] => CNN top5 curve: [97.16, 94.96, 93.17, 91.62, 91.03, 87.35]

Average Accuracy (CNN): 68.16
2024-04-30 11:47:39,050 [trainer.py] => Average Accuracy (CNN): 68.16 

2024-04-30 11:47:39,050 [trainer.py] => Train Time: 18393.86
2024-04-30 11:47:39,050 [trainer.py] => Test Time: 74.56 

Accuracy Matrix (CNN):
[[84.7  74.72 66.77 57.52 52.44 47.16]
 [ 0.   85.62 68.23 59.03 46.66 41.47]
 [ 0.    0.   90.62 76.05 60.8  48.91]
 [ 0.    0.    0.   86.81 77.3  58.93]
 [ 0.    0.    0.    0.   85.81 74.62]
 [ 0.    0.    0.    0.    0.   84.95]]
2024-04-30 11:47:39,051 [trainer.py] => Forgetting (CNN): 32.49400000000001
2024-04-30 11:47:42,306 [trainer.py] => config: ./exps/icarl_omn_B150_Inc5.json
2024-04-30 11:47:42,306 [trainer.py] => prefix: reproduce
2024-04-30 11:47:42,307 [trainer.py] => dataset: omnibenchmark
2024-04-30 11:47:42,307 [trainer.py] => memory_size: 6000
2024-04-30 11:47:42,307 [trainer.py] => memory_per_class: 20
2024-04-30 11:47:42,307 [trainer.py] => fixed_memory: True
2024-04-30 11:47:42,307 [trainer.py] => shuffle: True
2024-04-30 11:47:42,307 [trainer.py] => init_cls: 150
2024-04-30 11:47:42,307 [trainer.py] => increment: 30
2024-04-30 11:47:42,307 [trainer.py] => model_name: icarl
2024-04-30 11:47:42,307 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-04-30 11:47:42,307 [trainer.py] => device: [device(type='cuda', index=6)]
2024-04-30 11:47:42,307 [trainer.py] => seed: 1993
2024-04-30 11:47:42,307 [trainer.py] => init_epoch: 20
2024-04-30 11:47:42,307 [trainer.py] => init_lr: 0.001
2024-04-30 11:47:42,307 [trainer.py] => init_milestones: [60, 120, 170]
2024-04-30 11:47:42,307 [trainer.py] => init_lr_decay: 0.1
2024-04-30 11:47:42,307 [trainer.py] => init_weight_decay: 0.0005
2024-04-30 11:47:42,307 [trainer.py] => epochs: 20
2024-04-30 11:47:42,307 [trainer.py] => lrate: 0.001
2024-04-30 11:47:42,307 [trainer.py] => milestones: [80, 120]
2024-04-30 11:47:42,307 [trainer.py] => lrate_decay: 0.1
2024-04-30 11:47:42,307 [trainer.py] => batch_size: 48
2024-04-30 11:47:42,307 [trainer.py] => weight_decay: 0.0002
2024-04-30 11:47:42,307 [trainer.py] => T: 2
2024-04-30 11:47:42,677 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
This is for the BaseNet initialization.
After BaseNet initialization.
2024-04-30 11:47:46,241 [trainer.py] => All params: 85798656
2024-04-30 11:47:46,242 [trainer.py] => Trainable params: 85798656
2024-04-30 11:47:46,243 [icarl.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.162, Train_accy 49.62, Test_accy 76.55:   0%|          | 0/20 [05:11<?, ?it/s]Task 0, Epoch 1/20 => Loss 2.162, Train_accy 49.62, Test_accy 76.55:   5%|▌         | 1/20 [05:11<1:38:44, 311.81s/it]Task 0, Epoch 2/20 => Loss 0.909, Train_accy 73.49:   5%|▌         | 1/20 [10:12<1:38:44, 311.81s/it]                 Task 0, Epoch 2/20 => Loss 0.909, Train_accy 73.49:  10%|█         | 2/20 [10:12<1:31:36, 305.39s/it]Task 0, Epoch 3/20 => Loss 0.774, Train_accy 77.27:  10%|█         | 2/20 [15:13<1:31:36, 305.39s/it]Task 0, Epoch 3/20 => Loss 0.774, Train_accy 77.27:  15%|█▌        | 3/20 [15:13<1:25:54, 303.22s/it]Task 0, Epoch 4/20 => Loss 0.682, Train_accy 79.92:  15%|█▌        | 3/20 [20:14<1:25:54, 303.22s/it]Task 0, Epoch 4/20 => Loss 0.682, Train_accy 79.92:  20%|██        | 4/20 [20:14<1:20:36, 302.30s/it]Task 0, Epoch 5/20 => Loss 0.625, Train_accy 81.51:  20%|██        | 4/20 [25:15<1:20:36, 302.30s/it]Task 0, Epoch 5/20 => Loss 0.625, Train_accy 81.51:  25%|██▌       | 5/20 [25:15<1:15:28, 301.89s/it]Task 0, Epoch 6/20 => Loss 0.575, Train_accy 82.85, Test_accy 85.20:  25%|██▌       | 5/20 [30:24<1:15:28, 301.89s/it]Task 0, Epoch 6/20 => Loss 0.575, Train_accy 82.85, Test_accy 85.20:  30%|███       | 6/20 [30:24<1:11:03, 304.51s/it]Task 0, Epoch 7/20 => Loss 0.547, Train_accy 83.74:  30%|███       | 6/20 [35:27<1:11:03, 304.51s/it]                 Task 0, Epoch 7/20 => Loss 0.547, Train_accy 83.74:  35%|███▌      | 7/20 [35:27<1:05:48, 303.71s/it]Task 0, Epoch 8/20 => Loss 0.516, Train_accy 84.57:  35%|███▌      | 7/20 [40:29<1:05:48, 303.71s/it]Task 0, Epoch 8/20 => Loss 0.516, Train_accy 84.57:  40%|████      | 8/20 [40:29<1:00:37, 303.15s/it]Task 0, Epoch 9/20 => Loss 0.490, Train_accy 85.43:  40%|████      | 8/20 [45:30<1:00:37, 303.15s/it]Task 0, Epoch 9/20 => Loss 0.490, Train_accy 85.43:  45%|████▌     | 9/20 [45:30<55:29, 302.68s/it]  Task 0, Epoch 10/20 => Loss 0.473, Train_accy 85.96:  45%|████▌     | 9/20 [50:30<55:29, 302.68s/it]Task 0, Epoch 10/20 => Loss 0.473, Train_accy 85.96:  50%|█████     | 10/20 [50:30<50:16, 301.69s/it]Task 0, Epoch 11/20 => Loss 0.459, Train_accy 86.25, Test_accy 85.57:  50%|█████     | 10/20 [55:38<50:16, 301.69s/it]Task 0, Epoch 11/20 => Loss 0.459, Train_accy 86.25, Test_accy 85.57:  55%|█████▌    | 11/20 [55:38<45:33, 303.76s/it]Task 0, Epoch 12/20 => Loss 0.439, Train_accy 86.88:  55%|█████▌    | 11/20 [1:00:38<45:33, 303.76s/it]               Task 0, Epoch 12/20 => Loss 0.439, Train_accy 86.88:  60%|██████    | 12/20 [1:00:38<40:20, 302.53s/it]Task 0, Epoch 13/20 => Loss 0.423, Train_accy 87.27:  60%|██████    | 12/20 [1:05:39<40:20, 302.53s/it]Task 0, Epoch 13/20 => Loss 0.423, Train_accy 87.27:  65%|██████▌   | 13/20 [1:05:39<35:15, 302.18s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.88:  65%|██████▌   | 13/20 [1:10:39<35:15, 302.18s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.88:  70%|███████   | 14/20 [1:10:39<30:08, 301.48s/it]Task 0, Epoch 15/20 => Loss 0.398, Train_accy 88.00:  70%|███████   | 14/20 [1:15:39<30:08, 301.48s/it]Task 0, Epoch 15/20 => Loss 0.398, Train_accy 88.00:  75%|███████▌  | 15/20 [1:15:39<25:04, 300.90s/it]Task 0, Epoch 16/20 => Loss 0.385, Train_accy 88.57, Test_accy 85.24:  75%|███████▌  | 15/20 [1:20:46<25:04, 300.90s/it]Task 0, Epoch 16/20 => Loss 0.385, Train_accy 88.57, Test_accy 85.24:  80%|████████  | 16/20 [1:20:46<20:11, 302.87s/it]Task 0, Epoch 17/20 => Loss 0.381, Train_accy 88.61:  80%|████████  | 16/20 [1:25:46<20:11, 302.87s/it]                 Task 0, Epoch 17/20 => Loss 0.381, Train_accy 88.61:  85%|████████▌ | 17/20 [1:25:46<15:05, 301.95s/it]Task 0, Epoch 18/20 => Loss 0.365, Train_accy 89.21:  85%|████████▌ | 17/20 [1:30:46<15:05, 301.95s/it]Task 0, Epoch 18/20 => Loss 0.365, Train_accy 89.21:  90%|█████████ | 18/20 [1:30:46<10:02, 301.36s/it]Task 0, Epoch 19/20 => Loss 0.356, Train_accy 89.43:  90%|█████████ | 18/20 [1:35:46<10:02, 301.36s/it]Task 0, Epoch 19/20 => Loss 0.356, Train_accy 89.43:  95%|█████████▌| 19/20 [1:35:46<05:01, 301.08s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56:  95%|█████████▌| 19/20 [1:40:47<05:01, 301.08s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56: 100%|██████████| 20/20 [1:40:47<00:00, 300.89s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56: 100%|██████████| 20/20 [1:40:47<00:00, 302.36s/it]
2024-04-30 13:28:34,021 [icarl.py] => Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.56
2024-04-30 13:28:34,022 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 13:34:10,109 [icarl.py] => Exemplar size: 3000
2024-04-30 13:34:10,109 [trainer.py] => CNN: {'total': 84.7, '00-149': 84.7, 'old': 0, 'new': 84.7}
2024-04-30 13:34:10,109 [trainer.py] => NME: {'total': 85.04, '00-149': 85.04, 'old': 0, 'new': 85.04}
2024-04-30 13:34:10,110 [trainer.py] => CNN top1 curve: [84.7]
2024-04-30 13:34:10,110 [trainer.py] => CNN top5 curve: [97.16]
2024-04-30 13:34:10,110 [trainer.py] => NME top1 curve: [85.04]
2024-04-30 13:34:10,110 [trainer.py] => NME top5 curve: [97.43]

Average Accuracy (CNN): 84.7
Average Accuracy (NME): 85.04
2024-04-30 13:34:10,110 [trainer.py] => Average Accuracy (CNN): 84.7
2024-04-30 13:34:10,110 [trainer.py] => Average Accuracy (NME): 85.04
2024-04-30 13:34:10,110 [trainer.py] => Train Time: 0
2024-04-30 13:34:10,110 [trainer.py] => Test Time: 16.95 

2024-04-30 13:34:10,110 [trainer.py] => All params: 85914006
2024-04-30 13:34:10,111 [trainer.py] => Trainable params: 85914006
2024-04-30 13:34:10,113 [icarl.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 3.488, Train_accy 75.28, Test_accy 76.36:   0%|          | 0/20 [01:57<?, ?it/s]Task 1, Epoch 1/20 => Loss 3.488, Train_accy 75.28, Test_accy 76.36:   5%|▌         | 1/20 [01:57<37:10, 117.40s/it]Task 1, Epoch 2/20 => Loss 2.865, Train_accy 86.23:   5%|▌         | 1/20 [03:44<37:10, 117.40s/it]                 Task 1, Epoch 2/20 => Loss 2.865, Train_accy 86.23:  10%|█         | 2/20 [03:44<33:21, 111.21s/it]Task 1, Epoch 3/20 => Loss 2.755, Train_accy 89.24:  10%|█         | 2/20 [05:31<33:21, 111.21s/it]Task 1, Epoch 3/20 => Loss 2.755, Train_accy 89.24:  15%|█▌        | 3/20 [05:31<30:56, 109.23s/it]Task 1, Epoch 4/20 => Loss 2.707, Train_accy 90.68:  15%|█▌        | 3/20 [07:18<30:56, 109.23s/it]Task 1, Epoch 4/20 => Loss 2.707, Train_accy 90.68:  20%|██        | 4/20 [07:18<28:52, 108.31s/it]Task 1, Epoch 5/20 => Loss 2.687, Train_accy 91.20:  20%|██        | 4/20 [09:05<28:52, 108.31s/it]Task 1, Epoch 5/20 => Loss 2.687, Train_accy 91.20:  25%|██▌       | 5/20 [09:05<26:57, 107.86s/it]Task 1, Epoch 6/20 => Loss 2.653, Train_accy 92.13, Test_accy 78.45:  25%|██▌       | 5/20 [11:02<26:57, 107.86s/it]Task 1, Epoch 6/20 => Loss 2.653, Train_accy 92.13, Test_accy 78.45:  30%|███       | 6/20 [11:02<25:53, 110.94s/it]Task 1, Epoch 7/20 => Loss 2.628, Train_accy 92.43:  30%|███       | 6/20 [12:49<25:53, 110.94s/it]                 Task 1, Epoch 7/20 => Loss 2.628, Train_accy 92.43:  35%|███▌      | 7/20 [12:49<23:45, 109.68s/it]Task 1, Epoch 8/20 => Loss 2.612, Train_accy 93.24:  35%|███▌      | 7/20 [14:36<23:45, 109.68s/it]Task 1, Epoch 8/20 => Loss 2.612, Train_accy 93.24:  40%|████      | 8/20 [14:36<21:46, 108.84s/it]Task 1, Epoch 9/20 => Loss 2.614, Train_accy 93.22:  40%|████      | 8/20 [16:23<21:46, 108.84s/it]Task 1, Epoch 9/20 => Loss 2.614, Train_accy 93.22:  45%|████▌     | 9/20 [16:23<19:52, 108.40s/it]Task 1, Epoch 10/20 => Loss 2.570, Train_accy 93.81:  45%|████▌     | 9/20 [18:10<19:52, 108.40s/it]Task 1, Epoch 10/20 => Loss 2.570, Train_accy 93.81:  50%|█████     | 10/20 [18:10<17:59, 107.99s/it]Task 1, Epoch 11/20 => Loss 2.609, Train_accy 93.94, Test_accy 79.84:  50%|█████     | 10/20 [20:07<17:59, 107.99s/it]Task 1, Epoch 11/20 => Loss 2.609, Train_accy 93.94, Test_accy 79.84:  55%|█████▌    | 11/20 [20:07<16:37, 110.81s/it]Task 1, Epoch 12/20 => Loss 2.595, Train_accy 93.83:  55%|█████▌    | 11/20 [21:55<16:37, 110.81s/it]                 Task 1, Epoch 12/20 => Loss 2.595, Train_accy 93.83:  60%|██████    | 12/20 [21:55<14:37, 109.74s/it]Task 1, Epoch 13/20 => Loss 2.553, Train_accy 94.63:  60%|██████    | 12/20 [23:42<14:37, 109.74s/it]Task 1, Epoch 13/20 => Loss 2.553, Train_accy 94.63:  65%|██████▌   | 13/20 [23:42<12:42, 108.95s/it]Task 1, Epoch 14/20 => Loss 2.563, Train_accy 94.43:  65%|██████▌   | 13/20 [25:29<12:42, 108.95s/it]Task 1, Epoch 14/20 => Loss 2.563, Train_accy 94.43:  70%|███████   | 14/20 [25:29<10:50, 108.43s/it]Task 1, Epoch 15/20 => Loss 2.537, Train_accy 94.71:  70%|███████   | 14/20 [27:16<10:50, 108.43s/it]Task 1, Epoch 15/20 => Loss 2.537, Train_accy 94.71:  75%|███████▌  | 15/20 [27:16<08:59, 107.98s/it]Task 1, Epoch 16/20 => Loss 2.543, Train_accy 94.81, Test_accy 79.45:  75%|███████▌  | 15/20 [29:13<08:59, 107.98s/it]Task 1, Epoch 16/20 => Loss 2.543, Train_accy 94.81, Test_accy 79.45:  80%|████████  | 16/20 [29:13<07:22, 110.67s/it]Task 1, Epoch 17/20 => Loss 2.526, Train_accy 95.16:  80%|████████  | 16/20 [31:00<07:22, 110.67s/it]                 Task 1, Epoch 17/20 => Loss 2.526, Train_accy 95.16:  85%|████████▌ | 17/20 [31:00<05:28, 109.56s/it]Task 1, Epoch 18/20 => Loss 2.544, Train_accy 95.10:  85%|████████▌ | 17/20 [32:47<05:28, 109.56s/it]Task 1, Epoch 18/20 => Loss 2.544, Train_accy 95.10:  90%|█████████ | 18/20 [32:47<03:37, 108.79s/it]Task 1, Epoch 19/20 => Loss 2.547, Train_accy 94.92:  90%|█████████ | 18/20 [34:34<03:37, 108.79s/it]Task 1, Epoch 19/20 => Loss 2.547, Train_accy 94.92:  95%|█████████▌| 19/20 [34:34<01:48, 108.27s/it]Task 1, Epoch 20/20 => Loss 2.527, Train_accy 95.52:  95%|█████████▌| 19/20 [36:21<01:48, 108.27s/it]Task 1, Epoch 20/20 => Loss 2.527, Train_accy 95.52: 100%|██████████| 20/20 [36:21<00:00, 108.02s/it]Task 1, Epoch 20/20 => Loss 2.527, Train_accy 95.52: 100%|██████████| 20/20 [36:21<00:00, 109.09s/it]
2024-04-30 14:10:31,962 [icarl.py] => Task 1, Epoch 20/20 => Loss 2.527, Train_accy 95.52
2024-04-30 14:10:31,963 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 14:13:00,320 [icarl.py] => Exemplar size: 3600
2024-04-30 14:13:00,320 [trainer.py] => CNN: {'total': 79.15, '00-149': 76.52, '150-179': 92.31, 'old': 76.52, 'new': 92.31}
2024-04-30 14:13:00,320 [trainer.py] => NME: {'total': 83.13, '00-149': 82.87, '150-179': 84.45, 'old': 82.87, 'new': 84.45}
2024-04-30 14:13:00,320 [trainer.py] => CNN top1 curve: [84.7, 79.15]
2024-04-30 14:13:00,320 [trainer.py] => CNN top5 curve: [97.16, 95.71]
2024-04-30 14:13:00,321 [trainer.py] => NME top1 curve: [85.04, 83.13]
2024-04-30 14:13:00,321 [trainer.py] => NME top5 curve: [97.43, 96.66]

Average Accuracy (CNN): 81.93
Average Accuracy (NME): 84.08
2024-04-30 14:13:00,321 [trainer.py] => Average Accuracy (CNN): 81.93
2024-04-30 14:13:00,321 [trainer.py] => Average Accuracy (NME): 84.08
2024-04-30 14:13:00,321 [trainer.py] => Train Time: 0
2024-04-30 14:13:00,321 [trainer.py] => Test Time: 36.879999999999995 

2024-04-30 14:13:00,321 [trainer.py] => All params: 85937076
2024-04-30 14:13:00,322 [trainer.py] => Trainable params: 85937076
2024-04-30 14:13:00,323 [icarl.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 3.444, Train_accy 76.57, Test_accy 75.98:   0%|          | 0/20 [02:03<?, ?it/s]Task 2, Epoch 1/20 => Loss 3.444, Train_accy 76.57, Test_accy 75.98:   5%|▌         | 1/20 [02:03<39:06, 123.49s/it]Task 2, Epoch 2/20 => Loss 2.839, Train_accy 87.55:   5%|▌         | 1/20 [03:55<39:06, 123.49s/it]                 Task 2, Epoch 2/20 => Loss 2.839, Train_accy 87.55:  10%|█         | 2/20 [03:55<35:04, 116.89s/it]Task 2, Epoch 3/20 => Loss 2.749, Train_accy 89.50:  10%|█         | 2/20 [05:47<35:04, 116.89s/it]Task 2, Epoch 3/20 => Loss 2.749, Train_accy 89.50:  15%|█▌        | 3/20 [05:47<32:29, 114.66s/it]Task 2, Epoch 4/20 => Loss 2.710, Train_accy 90.71:  15%|█▌        | 3/20 [07:39<32:29, 114.66s/it]Task 2, Epoch 4/20 => Loss 2.710, Train_accy 90.71:  20%|██        | 4/20 [07:39<30:18, 113.63s/it]Task 2, Epoch 5/20 => Loss 2.679, Train_accy 91.55:  20%|██        | 4/20 [09:31<30:18, 113.63s/it]Task 2, Epoch 5/20 => Loss 2.679, Train_accy 91.55:  25%|██▌       | 5/20 [09:31<28:15, 113.00s/it]Task 2, Epoch 6/20 => Loss 2.697, Train_accy 92.11, Test_accy 77.18:  25%|██▌       | 5/20 [11:35<28:15, 113.00s/it]Task 2, Epoch 6/20 => Loss 2.697, Train_accy 92.11, Test_accy 77.18:  30%|███       | 6/20 [11:35<27:12, 116.64s/it]Task 2, Epoch 7/20 => Loss 2.639, Train_accy 92.89:  30%|███       | 6/20 [13:27<27:12, 116.64s/it]                 Task 2, Epoch 7/20 => Loss 2.639, Train_accy 92.89:  35%|███▌      | 7/20 [13:27<24:58, 115.24s/it]Task 2, Epoch 8/20 => Loss 2.627, Train_accy 93.53:  35%|███▌      | 7/20 [15:19<24:58, 115.24s/it]Task 2, Epoch 8/20 => Loss 2.627, Train_accy 93.53:  40%|████      | 8/20 [15:19<22:50, 114.21s/it]Task 2, Epoch 9/20 => Loss 2.612, Train_accy 93.80:  40%|████      | 8/20 [17:11<22:50, 114.21s/it]Task 2, Epoch 9/20 => Loss 2.612, Train_accy 93.80:  45%|████▌     | 9/20 [17:11<20:49, 113.57s/it]Task 2, Epoch 10/20 => Loss 2.604, Train_accy 94.21:  45%|████▌     | 9/20 [19:05<20:49, 113.57s/it]Task 2, Epoch 10/20 => Loss 2.604, Train_accy 94.21:  50%|█████     | 10/20 [19:05<18:55, 113.57s/it]Task 2, Epoch 11/20 => Loss 2.634, Train_accy 93.97, Test_accy 76.08:  50%|█████     | 10/20 [21:10<18:55, 113.57s/it]Task 2, Epoch 11/20 => Loss 2.634, Train_accy 93.97, Test_accy 76.08:  55%|█████▌    | 11/20 [21:10<17:33, 117.01s/it]Task 2, Epoch 12/20 => Loss 2.603, Train_accy 94.39:  55%|█████▌    | 11/20 [23:03<17:33, 117.01s/it]                 Task 2, Epoch 12/20 => Loss 2.603, Train_accy 94.39:  60%|██████    | 12/20 [23:03<15:26, 115.82s/it]Task 2, Epoch 13/20 => Loss 2.610, Train_accy 94.60:  60%|██████    | 12/20 [24:57<15:26, 115.82s/it]Task 2, Epoch 13/20 => Loss 2.610, Train_accy 94.60:  65%|██████▌   | 13/20 [24:57<13:26, 115.15s/it]Task 2, Epoch 14/20 => Loss 2.554, Train_accy 95.29:  65%|██████▌   | 13/20 [26:50<13:26, 115.15s/it]Task 2, Epoch 14/20 => Loss 2.554, Train_accy 95.29:  70%|███████   | 14/20 [26:50<11:27, 114.63s/it]Task 2, Epoch 15/20 => Loss 2.572, Train_accy 94.86:  70%|███████   | 14/20 [28:43<11:27, 114.63s/it]Task 2, Epoch 15/20 => Loss 2.572, Train_accy 94.86:  75%|███████▌  | 15/20 [28:43<09:31, 114.26s/it]Task 2, Epoch 16/20 => Loss 2.575, Train_accy 94.95, Test_accy 75.41:  75%|███████▌  | 15/20 [30:48<09:31, 114.26s/it]Task 2, Epoch 16/20 => Loss 2.575, Train_accy 94.95, Test_accy 75.41:  80%|████████  | 16/20 [30:48<07:49, 117.38s/it]Task 2, Epoch 17/20 => Loss 2.558, Train_accy 95.34:  80%|████████  | 16/20 [32:41<07:49, 117.38s/it]                 Task 2, Epoch 17/20 => Loss 2.558, Train_accy 95.34:  85%|████████▌ | 17/20 [32:41<05:48, 116.07s/it]Task 2, Epoch 18/20 => Loss 2.562, Train_accy 95.42:  85%|████████▌ | 17/20 [34:34<05:48, 116.07s/it]Task 2, Epoch 18/20 => Loss 2.562, Train_accy 95.42:  90%|█████████ | 18/20 [34:34<03:50, 115.22s/it]Task 2, Epoch 19/20 => Loss 2.545, Train_accy 95.78:  90%|█████████ | 18/20 [36:28<03:50, 115.22s/it]Task 2, Epoch 19/20 => Loss 2.545, Train_accy 95.78:  95%|█████████▌| 19/20 [36:28<01:54, 114.65s/it]Task 2, Epoch 20/20 => Loss 2.575, Train_accy 95.36:  95%|█████████▌| 19/20 [38:21<01:54, 114.65s/it]Task 2, Epoch 20/20 => Loss 2.575, Train_accy 95.36: 100%|██████████| 20/20 [38:21<00:00, 114.19s/it]Task 2, Epoch 20/20 => Loss 2.575, Train_accy 95.36: 100%|██████████| 20/20 [38:21<00:00, 115.06s/it]
2024-04-30 14:51:21,534 [icarl.py] => Task 2, Epoch 20/20 => Loss 2.575, Train_accy 95.36
2024-04-30 14:51:21,535 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 14:54:05,650 [icarl.py] => Exemplar size: 4200
2024-04-30 14:54:05,651 [trainer.py] => CNN: {'total': 76.8, '00-149': 73.11, '150-179': 80.1, '180-209': 91.96, 'old': 74.28, 'new': 91.96}
2024-04-30 14:54:05,651 [trainer.py] => NME: {'total': 81.14, '00-149': 80.59, '150-179': 78.93, '180-209': 86.1, 'old': 80.32, 'new': 86.1}
2024-04-30 14:54:05,651 [trainer.py] => CNN top1 curve: [84.7, 79.15, 76.8]
2024-04-30 14:54:05,651 [trainer.py] => CNN top5 curve: [97.16, 95.71, 93.86]
2024-04-30 14:54:05,651 [trainer.py] => NME top1 curve: [85.04, 83.13, 81.14]
2024-04-30 14:54:05,651 [trainer.py] => NME top5 curve: [97.43, 96.66, 95.66]

Average Accuracy (CNN): 80.22
Average Accuracy (NME): 83.1
2024-04-30 14:54:05,651 [trainer.py] => Average Accuracy (CNN): 80.22
2024-04-30 14:54:05,651 [trainer.py] => Average Accuracy (NME): 83.1
2024-04-30 14:54:05,651 [trainer.py] => Train Time: 0
2024-04-30 14:54:05,651 [trainer.py] => Test Time: 60.25 

2024-04-30 14:54:05,651 [trainer.py] => All params: 85960146
2024-04-30 14:54:05,652 [trainer.py] => Trainable params: 85960146
2024-04-30 14:54:05,654 [icarl.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 3.342, Train_accy 76.89, Test_accy 71.01:   0%|          | 0/20 [02:16<?, ?it/s]Task 3, Epoch 1/20 => Loss 3.342, Train_accy 76.89, Test_accy 71.01:   5%|▌         | 1/20 [02:16<43:13, 136.48s/it]Task 3, Epoch 2/20 => Loss 2.667, Train_accy 87.14:   5%|▌         | 1/20 [04:19<43:13, 136.48s/it]                 Task 3, Epoch 2/20 => Loss 2.667, Train_accy 87.14:  10%|█         | 2/20 [04:19<38:32, 128.49s/it]Task 3, Epoch 3/20 => Loss 2.559, Train_accy 89.70:  10%|█         | 2/20 [06:22<38:32, 128.49s/it]Task 3, Epoch 3/20 => Loss 2.559, Train_accy 89.70:  15%|█▌        | 3/20 [06:22<35:42, 126.04s/it]Task 3, Epoch 4/20 => Loss 2.521, Train_accy 90.77:  15%|█▌        | 3/20 [08:25<35:42, 126.04s/it]Task 3, Epoch 4/20 => Loss 2.521, Train_accy 90.77:  20%|██        | 4/20 [08:25<33:20, 125.01s/it]Task 3, Epoch 5/20 => Loss 2.490, Train_accy 91.63:  20%|██        | 4/20 [10:29<33:20, 125.01s/it]Task 3, Epoch 5/20 => Loss 2.490, Train_accy 91.63:  25%|██▌       | 5/20 [10:29<31:06, 124.44s/it]Task 3, Epoch 6/20 => Loss 2.481, Train_accy 92.24, Test_accy 70.28:  25%|██▌       | 5/20 [12:46<31:06, 124.44s/it]Task 3, Epoch 6/20 => Loss 2.481, Train_accy 92.24, Test_accy 70.28:  30%|███       | 6/20 [12:46<30:01, 128.66s/it]Task 3, Epoch 7/20 => Loss 2.447, Train_accy 92.82:  30%|███       | 6/20 [14:49<30:01, 128.66s/it]                 Task 3, Epoch 7/20 => Loss 2.447, Train_accy 92.82:  35%|███▌      | 7/20 [14:49<27:28, 126.82s/it]Task 3, Epoch 8/20 => Loss 2.449, Train_accy 93.44:  35%|███▌      | 7/20 [16:51<27:28, 126.82s/it]Task 3, Epoch 8/20 => Loss 2.449, Train_accy 93.44:  40%|████      | 8/20 [16:51<25:06, 125.52s/it]Task 3, Epoch 9/20 => Loss 2.436, Train_accy 93.63:  40%|████      | 8/20 [18:54<25:06, 125.52s/it]Task 3, Epoch 9/20 => Loss 2.436, Train_accy 93.63:  45%|████▌     | 9/20 [18:54<22:51, 124.71s/it]Task 3, Epoch 10/20 => Loss 2.420, Train_accy 94.11:  45%|████▌     | 9/20 [20:58<22:51, 124.71s/it]Task 3, Epoch 10/20 => Loss 2.420, Train_accy 94.11:  50%|█████     | 10/20 [20:58<20:42, 124.23s/it]Task 3, Epoch 11/20 => Loss 2.419, Train_accy 93.94, Test_accy 72.08:  50%|█████     | 10/20 [23:14<20:42, 124.23s/it]Task 3, Epoch 11/20 => Loss 2.419, Train_accy 93.94, Test_accy 72.08:  55%|█████▌    | 11/20 [23:14<19:11, 127.98s/it]Task 3, Epoch 12/20 => Loss 2.426, Train_accy 94.08:  55%|█████▌    | 11/20 [25:17<19:11, 127.98s/it]                 Task 3, Epoch 12/20 => Loss 2.426, Train_accy 94.08:  60%|██████    | 12/20 [25:17<16:51, 126.45s/it]Task 3, Epoch 13/20 => Loss 2.386, Train_accy 94.60:  60%|██████    | 12/20 [27:20<16:51, 126.45s/it]Task 3, Epoch 13/20 => Loss 2.386, Train_accy 94.60:  65%|██████▌   | 13/20 [27:20<14:38, 125.44s/it]Task 3, Epoch 14/20 => Loss 2.386, Train_accy 94.88:  65%|██████▌   | 13/20 [29:24<14:38, 125.44s/it]Task 3, Epoch 14/20 => Loss 2.386, Train_accy 94.88:  70%|███████   | 14/20 [29:24<12:28, 124.83s/it]Task 3, Epoch 15/20 => Loss 2.375, Train_accy 94.97:  70%|███████   | 14/20 [31:27<12:28, 124.83s/it]Task 3, Epoch 15/20 => Loss 2.375, Train_accy 94.97:  75%|███████▌  | 15/20 [31:27<10:22, 124.43s/it]Task 3, Epoch 16/20 => Loss 2.397, Train_accy 94.66, Test_accy 71.70:  75%|███████▌  | 15/20 [33:43<10:22, 124.43s/it]Task 3, Epoch 16/20 => Loss 2.397, Train_accy 94.66, Test_accy 71.70:  80%|████████  | 16/20 [33:43<08:32, 128.03s/it]Task 3, Epoch 17/20 => Loss 2.362, Train_accy 95.25:  80%|████████  | 16/20 [35:46<08:32, 128.03s/it]                 Task 3, Epoch 17/20 => Loss 2.362, Train_accy 95.25:  85%|████████▌ | 17/20 [35:46<06:19, 126.46s/it]Task 3, Epoch 18/20 => Loss 2.400, Train_accy 94.82:  85%|████████▌ | 17/20 [37:49<06:19, 126.46s/it]Task 3, Epoch 18/20 => Loss 2.400, Train_accy 94.82:  90%|█████████ | 18/20 [37:49<04:10, 125.39s/it]Task 3, Epoch 19/20 => Loss 2.379, Train_accy 95.38:  90%|█████████ | 18/20 [39:52<04:10, 125.39s/it]Task 3, Epoch 19/20 => Loss 2.379, Train_accy 95.38:  95%|█████████▌| 19/20 [39:52<02:04, 124.71s/it]Task 3, Epoch 20/20 => Loss 2.363, Train_accy 95.46:  95%|█████████▌| 19/20 [41:55<02:04, 124.71s/it]Task 3, Epoch 20/20 => Loss 2.363, Train_accy 95.46: 100%|██████████| 20/20 [41:55<00:00, 124.25s/it]Task 3, Epoch 20/20 => Loss 2.363, Train_accy 95.46: 100%|██████████| 20/20 [41:55<00:00, 125.80s/it]
2024-04-30 15:36:01,611 [icarl.py] => Task 3, Epoch 20/20 => Loss 2.363, Train_accy 95.46
2024-04-30 15:36:01,612 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 15:39:01,944 [icarl.py] => Exemplar size: 4800
2024-04-30 15:39:01,944 [trainer.py] => CNN: {'total': 71.47, '00-149': 65.73, '150-179': 67.73, '180-209': 82.24, '210-239': 93.16, 'old': 68.37, 'new': 93.16}
2024-04-30 15:39:01,944 [trainer.py] => NME: {'total': 78.07, '00-149': 76.85, '150-179': 74.58, '180-209': 81.24, '210-239': 84.47, 'old': 77.15, 'new': 84.47}
2024-04-30 15:39:01,944 [trainer.py] => CNN top1 curve: [84.7, 79.15, 76.8, 71.47]
2024-04-30 15:39:01,944 [trainer.py] => CNN top5 curve: [97.16, 95.71, 93.86, 91.12]
2024-04-30 15:39:01,944 [trainer.py] => NME top1 curve: [85.04, 83.13, 81.14, 78.07]
2024-04-30 15:39:01,944 [trainer.py] => NME top5 curve: [97.43, 96.66, 95.66, 94.47]

Average Accuracy (CNN): 78.03
Average Accuracy (NME): 81.84
2024-04-30 15:39:01,944 [trainer.py] => Average Accuracy (CNN): 78.03
2024-04-30 15:39:01,945 [trainer.py] => Average Accuracy (NME): 81.84
2024-04-30 15:39:01,945 [trainer.py] => Train Time: 0
2024-04-30 15:39:01,945 [trainer.py] => Test Time: 87.43 

2024-04-30 15:39:01,945 [trainer.py] => All params: 85983216
2024-04-30 15:39:01,946 [trainer.py] => Trainable params: 85983216
2024-04-30 15:39:01,949 [icarl.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 3.252, Train_accy 80.67, Test_accy 68.07:   0%|          | 0/20 [02:22<?, ?it/s]Task 4, Epoch 1/20 => Loss 3.252, Train_accy 80.67, Test_accy 68.07:   5%|▌         | 1/20 [02:22<45:08, 142.56s/it]Task 4, Epoch 2/20 => Loss 2.663, Train_accy 89.64:   5%|▌         | 1/20 [04:30<45:08, 142.56s/it]                 Task 4, Epoch 2/20 => Loss 2.663, Train_accy 89.64:  10%|█         | 2/20 [04:30<40:07, 133.73s/it]Task 4, Epoch 3/20 => Loss 2.596, Train_accy 91.46:  10%|█         | 2/20 [06:37<40:07, 133.73s/it]Task 4, Epoch 3/20 => Loss 2.596, Train_accy 91.46:  15%|█▌        | 3/20 [06:37<37:04, 130.84s/it]Task 4, Epoch 4/20 => Loss 2.555, Train_accy 92.55:  15%|█▌        | 3/20 [08:44<37:04, 130.84s/it]Task 4, Epoch 4/20 => Loss 2.555, Train_accy 92.55:  20%|██        | 4/20 [08:44<34:27, 129.25s/it]Task 4, Epoch 5/20 => Loss 2.514, Train_accy 93.10:  20%|██        | 4/20 [10:51<34:27, 129.25s/it]Task 4, Epoch 5/20 => Loss 2.514, Train_accy 93.10:  25%|██▌       | 5/20 [10:51<32:06, 128.45s/it]Task 4, Epoch 6/20 => Loss 2.505, Train_accy 93.57, Test_accy 69.24:  25%|██▌       | 5/20 [13:12<32:06, 128.45s/it]Task 4, Epoch 6/20 => Loss 2.505, Train_accy 93.57, Test_accy 69.24:  30%|███       | 6/20 [13:12<31:00, 132.88s/it]Task 4, Epoch 7/20 => Loss 2.484, Train_accy 94.19:  30%|███       | 6/20 [15:20<31:00, 132.88s/it]                 Task 4, Epoch 7/20 => Loss 2.484, Train_accy 94.19:  35%|███▌      | 7/20 [15:20<28:24, 131.13s/it]Task 4, Epoch 8/20 => Loss 2.470, Train_accy 94.65:  35%|███▌      | 7/20 [17:27<28:24, 131.13s/it]Task 4, Epoch 8/20 => Loss 2.470, Train_accy 94.65:  40%|████      | 8/20 [17:27<25:58, 129.89s/it]Task 4, Epoch 9/20 => Loss 2.455, Train_accy 94.70:  40%|████      | 8/20 [19:34<25:58, 129.89s/it]Task 4, Epoch 9/20 => Loss 2.455, Train_accy 94.70:  45%|████▌     | 9/20 [19:34<23:38, 128.95s/it]Task 4, Epoch 10/20 => Loss 2.448, Train_accy 95.06:  45%|████▌     | 9/20 [21:41<23:38, 128.95s/it]Task 4, Epoch 10/20 => Loss 2.448, Train_accy 95.06:  50%|█████     | 10/20 [21:41<21:22, 128.27s/it]Task 4, Epoch 11/20 => Loss 2.450, Train_accy 94.78, Test_accy 68.33:  50%|█████     | 10/20 [24:02<21:22, 128.27s/it]Task 4, Epoch 11/20 => Loss 2.450, Train_accy 94.78, Test_accy 68.33:  55%|█████▌    | 11/20 [24:02<19:51, 132.34s/it]Task 4, Epoch 12/20 => Loss 2.444, Train_accy 95.06:  55%|█████▌    | 11/20 [26:09<19:51, 132.34s/it]                 Task 4, Epoch 12/20 => Loss 2.444, Train_accy 95.06:  60%|██████    | 12/20 [26:09<17:25, 130.70s/it]Task 4, Epoch 13/20 => Loss 2.443, Train_accy 95.13:  60%|██████    | 12/20 [28:17<17:25, 130.70s/it]Task 4, Epoch 13/20 => Loss 2.443, Train_accy 95.13:  65%|██████▌   | 13/20 [28:17<15:08, 129.74s/it]Task 4, Epoch 14/20 => Loss 2.456, Train_accy 95.07:  65%|██████▌   | 13/20 [30:24<15:08, 129.74s/it]Task 4, Epoch 14/20 => Loss 2.456, Train_accy 95.07:  70%|███████   | 14/20 [30:24<12:54, 129.00s/it]Task 4, Epoch 15/20 => Loss 2.460, Train_accy 95.18:  70%|███████   | 14/20 [32:31<12:54, 129.00s/it]Task 4, Epoch 15/20 => Loss 2.460, Train_accy 95.18:  75%|███████▌  | 15/20 [32:31<10:42, 128.50s/it]Task 4, Epoch 16/20 => Loss 2.437, Train_accy 95.60, Test_accy 69.04:  75%|███████▌  | 15/20 [34:52<10:42, 128.50s/it]Task 4, Epoch 16/20 => Loss 2.437, Train_accy 95.60, Test_accy 69.04:  80%|████████  | 16/20 [34:52<08:49, 132.28s/it]Task 4, Epoch 17/20 => Loss 2.424, Train_accy 95.51:  80%|████████  | 16/20 [36:59<08:49, 132.28s/it]                 Task 4, Epoch 17/20 => Loss 2.424, Train_accy 95.51:  85%|████████▌ | 17/20 [36:59<06:31, 130.45s/it]Task 4, Epoch 18/20 => Loss 2.423, Train_accy 95.82:  85%|████████▌ | 17/20 [39:05<06:31, 130.45s/it]Task 4, Epoch 18/20 => Loss 2.423, Train_accy 95.82:  90%|█████████ | 18/20 [39:05<04:18, 129.09s/it]Task 4, Epoch 19/20 => Loss 2.412, Train_accy 95.95:  90%|█████████ | 18/20 [41:10<04:18, 129.09s/it]Task 4, Epoch 19/20 => Loss 2.412, Train_accy 95.95:  95%|█████████▌| 19/20 [41:10<02:08, 128.04s/it]Task 4, Epoch 20/20 => Loss 2.405, Train_accy 96.06:  95%|█████████▌| 19/20 [43:16<02:08, 128.04s/it]Task 4, Epoch 20/20 => Loss 2.405, Train_accy 96.06: 100%|██████████| 20/20 [43:16<00:00, 127.35s/it]Task 4, Epoch 20/20 => Loss 2.405, Train_accy 96.06: 100%|██████████| 20/20 [43:16<00:00, 129.82s/it]
2024-04-30 16:22:18,399 [icarl.py] => Task 4, Epoch 20/20 => Loss 2.405, Train_accy 96.06
2024-04-30 16:22:18,400 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 16:25:41,185 [icarl.py] => Exemplar size: 5400
2024-04-30 16:25:41,185 [trainer.py] => CNN: {'total': 68.67, '00-149': 60.29, '150-179': 62.71, '180-209': 72.86, '210-239': 86.48, '240-269': 94.49, 'old': 65.43, 'new': 94.49}
2024-04-30 16:25:41,185 [trainer.py] => NME: {'total': 76.07, '00-149': 73.71, '150-179': 72.58, '180-209': 76.72, '210-239': 81.3, '240-269': 85.48, 'old': 74.9, 'new': 85.48}
2024-04-30 16:25:41,185 [trainer.py] => CNN top1 curve: [84.7, 79.15, 76.8, 71.47, 68.67]
2024-04-30 16:25:41,185 [trainer.py] => CNN top5 curve: [97.16, 95.71, 93.86, 91.12, 89.59]
2024-04-30 16:25:41,185 [trainer.py] => NME top1 curve: [85.04, 83.13, 81.14, 78.07, 76.07]
2024-04-30 16:25:41,185 [trainer.py] => NME top5 curve: [97.43, 96.66, 95.66, 94.47, 94.32]

Average Accuracy (CNN): 76.16
Average Accuracy (NME): 80.69
2024-04-30 16:25:41,185 [trainer.py] => Average Accuracy (CNN): 76.16
2024-04-30 16:25:41,185 [trainer.py] => Average Accuracy (NME): 80.69
2024-04-30 16:25:41,185 [trainer.py] => Train Time: 0
2024-04-30 16:25:41,185 [trainer.py] => Test Time: 117.36000000000001 

2024-04-30 16:25:41,186 [trainer.py] => All params: 86006286
2024-04-30 16:25:41,186 [trainer.py] => Trainable params: 86006286
2024-04-30 16:25:41,188 [icarl.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 3.257, Train_accy 80.35, Test_accy 67.02:   0%|          | 0/20 [02:22<?, ?it/s]Task 5, Epoch 1/20 => Loss 3.257, Train_accy 80.35, Test_accy 67.02:   5%|▌         | 1/20 [02:22<45:14, 142.88s/it]Task 5, Epoch 2/20 => Loss 2.754, Train_accy 88.19:   5%|▌         | 1/20 [04:29<45:14, 142.88s/it]                 Task 5, Epoch 2/20 => Loss 2.754, Train_accy 88.19:  10%|█         | 2/20 [04:29<40:02, 133.47s/it]Task 5, Epoch 3/20 => Loss 2.618, Train_accy 91.20:  10%|█         | 2/20 [06:36<40:02, 133.47s/it]Task 5, Epoch 3/20 => Loss 2.618, Train_accy 91.20:  15%|█▌        | 3/20 [06:36<36:57, 130.43s/it]Task 5, Epoch 4/20 => Loss 2.596, Train_accy 91.81:  15%|█▌        | 3/20 [08:43<36:57, 130.43s/it]Task 5, Epoch 4/20 => Loss 2.596, Train_accy 91.81:  20%|██        | 4/20 [08:43<34:25, 129.10s/it]Task 5, Epoch 5/20 => Loss 2.566, Train_accy 93.16:  20%|██        | 4/20 [10:49<34:25, 129.10s/it]Task 5, Epoch 5/20 => Loss 2.566, Train_accy 93.16:  25%|██▌       | 5/20 [10:49<32:00, 128.06s/it]Task 5, Epoch 6/20 => Loss 2.538, Train_accy 93.37, Test_accy 67.69:  25%|██▌       | 5/20 [13:12<32:00, 128.06s/it]Task 5, Epoch 6/20 => Loss 2.538, Train_accy 93.37, Test_accy 67.69:  30%|███       | 6/20 [13:12<31:02, 133.07s/it]Task 5, Epoch 7/20 => Loss 2.499, Train_accy 94.39:  30%|███       | 6/20 [15:23<31:02, 133.07s/it]                 Task 5, Epoch 7/20 => Loss 2.499, Train_accy 94.39:  35%|███▌      | 7/20 [15:23<28:42, 132.49s/it]Task 5, Epoch 8/20 => Loss 2.513, Train_accy 94.09:  35%|███▌      | 7/20 [18:11<28:42, 132.49s/it]Task 5, Epoch 8/20 => Loss 2.513, Train_accy 94.09:  40%|████      | 8/20 [18:11<28:42, 143.54s/it]Task 5, Epoch 9/20 => Loss 2.476, Train_accy 94.83:  40%|████      | 8/20 [20:58<28:42, 143.54s/it]Task 5, Epoch 9/20 => Loss 2.476, Train_accy 94.83:  45%|████▌     | 9/20 [20:58<27:40, 150.96s/it]Task 5, Epoch 10/20 => Loss 2.498, Train_accy 94.69:  45%|████▌     | 9/20 [23:45<27:40, 150.96s/it]Task 5, Epoch 10/20 => Loss 2.498, Train_accy 94.69:  50%|█████     | 10/20 [23:45<25:58, 155.90s/it]Task 5, Epoch 11/20 => Loss 2.493, Train_accy 94.86, Test_accy 66.22:  50%|█████     | 10/20 [26:53<25:58, 155.90s/it]Task 5, Epoch 11/20 => Loss 2.493, Train_accy 94.86, Test_accy 66.22:  55%|█████▌    | 11/20 [26:53<24:50, 165.65s/it]Task 5, Epoch 12/20 => Loss 2.469, Train_accy 95.42:  55%|█████▌    | 11/20 [29:39<24:50, 165.65s/it]                 Task 5, Epoch 12/20 => Loss 2.469, Train_accy 95.42:  60%|██████    | 12/20 [29:39<22:06, 165.86s/it]Task 5, Epoch 13/20 => Loss 2.490, Train_accy 95.11:  60%|██████    | 12/20 [32:26<22:06, 165.86s/it]Task 5, Epoch 13/20 => Loss 2.490, Train_accy 95.11:  65%|██████▌   | 13/20 [32:26<19:22, 166.13s/it]Task 5, Epoch 14/20 => Loss 2.447, Train_accy 95.82:  65%|██████▌   | 13/20 [35:13<19:22, 166.13s/it]Task 5, Epoch 14/20 => Loss 2.447, Train_accy 95.82:  70%|███████   | 14/20 [35:13<16:38, 166.35s/it]Task 5, Epoch 15/20 => Loss 2.450, Train_accy 95.91:  70%|███████   | 14/20 [37:59<16:38, 166.35s/it]Task 5, Epoch 15/20 => Loss 2.450, Train_accy 95.91:  75%|███████▌  | 15/20 [37:59<13:51, 166.30s/it]Task 5, Epoch 16/20 => Loss 2.462, Train_accy 95.72, Test_accy 65.85:  75%|███████▌  | 15/20 [41:06<13:51, 166.30s/it]Task 5, Epoch 16/20 => Loss 2.462, Train_accy 95.72, Test_accy 65.85:  80%|████████  | 16/20 [41:06<11:30, 172.53s/it]Task 5, Epoch 17/20 => Loss 2.447, Train_accy 95.76:  80%|████████  | 16/20 [43:52<11:30, 172.53s/it]                 Task 5, Epoch 17/20 => Loss 2.447, Train_accy 95.76:  85%|████████▌ | 17/20 [43:52<08:32, 170.76s/it]Task 5, Epoch 18/20 => Loss 2.484, Train_accy 95.28:  85%|████████▌ | 17/20 [46:38<08:32, 170.76s/it]Task 5, Epoch 18/20 => Loss 2.484, Train_accy 95.28:  90%|█████████ | 18/20 [46:38<05:38, 169.33s/it]Task 5, Epoch 19/20 => Loss 2.451, Train_accy 96.03:  90%|█████████ | 18/20 [49:25<05:38, 169.33s/it]Task 5, Epoch 19/20 => Loss 2.451, Train_accy 96.03:  95%|█████████▌| 19/20 [49:25<02:48, 168.58s/it]Task 5, Epoch 20/20 => Loss 2.459, Train_accy 95.90:  95%|█████████▌| 19/20 [52:12<02:48, 168.58s/it]Task 5, Epoch 20/20 => Loss 2.459, Train_accy 95.90: 100%|██████████| 20/20 [52:12<00:00, 168.11s/it]Task 5, Epoch 20/20 => Loss 2.459, Train_accy 95.90: 100%|██████████| 20/20 [52:12<00:00, 156.64s/it]
2024-04-30 17:17:53,966 [icarl.py] => Task 5, Epoch 20/20 => Loss 2.459, Train_accy 95.90
2024-04-30 17:17:53,968 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 17:21:53,419 [icarl.py] => Exemplar size: 6000
2024-04-30 17:21:53,420 [trainer.py] => CNN: {'total': 66.35, '00-149': 57.78, '150-179': 60.54, '180-209': 64.49, '210-239': 74.29, '240-269': 81.64, '270-299': 93.65, 'old': 63.32, 'new': 93.65}
2024-04-30 17:21:53,420 [trainer.py] => NME: {'total': 74.24, '00-149': 71.48, '150-179': 70.57, '180-209': 73.87, '210-239': 77.13, '240-269': 78.46, '270-299': 84.95, 'old': 73.05, 'new': 84.95}
2024-04-30 17:21:53,420 [trainer.py] => CNN top1 curve: [84.7, 79.15, 76.8, 71.47, 68.67, 66.35]
2024-04-30 17:21:53,420 [trainer.py] => CNN top5 curve: [97.16, 95.71, 93.86, 91.12, 89.59, 88.1]
2024-04-30 17:21:53,420 [trainer.py] => NME top1 curve: [85.04, 83.13, 81.14, 78.07, 76.07, 74.24]
2024-04-30 17:21:53,420 [trainer.py] => NME top5 curve: [97.43, 96.66, 95.66, 94.47, 94.32, 93.05]

Average Accuracy (CNN): 74.52
Average Accuracy (NME): 79.61
2024-04-30 17:21:53,420 [trainer.py] => Average Accuracy (CNN): 74.52
2024-04-30 17:21:53,420 [trainer.py] => Average Accuracy (NME): 79.61
2024-04-30 17:21:53,420 [trainer.py] => Train Time: 0
2024-04-30 17:21:53,420 [trainer.py] => Test Time: 160.19 

Accuracy Matrix (CNN):
[[84.7  76.52 73.11 65.73 60.29 57.78]
 [ 0.   92.31 80.1  67.73 62.71 60.54]
 [ 0.    0.   91.96 82.24 72.86 64.49]
 [ 0.    0.    0.   93.16 86.48 74.29]
 [ 0.    0.    0.    0.   94.49 81.64]
 [ 0.    0.    0.    0.    0.   93.65]]
2024-04-30 17:21:53,421 [trainer.py] => Forgetting (CNN): 23.575999999999997
Accuracy Matrix (NME):
[[85.04 82.87 80.59 76.85 73.71 71.48]
 [ 0.   84.45 78.93 74.58 72.58 70.57]
 [ 0.    0.   86.1  81.24 76.72 73.87]
 [ 0.    0.    0.   84.47 81.3  77.13]
 [ 0.    0.    0.    0.   85.48 78.46]
 [ 0.    0.    0.    0.    0.   84.95]]
2024-04-30 17:21:53,421 [trainer.py] => Forgetting (NME): 10.806000000000003
2024-04-30 17:21:56,731 [trainer.py] => config: ./exps/der_omn_B150_Inc5.json
2024-04-30 17:21:56,731 [trainer.py] => prefix: reproduce
2024-04-30 17:21:56,731 [trainer.py] => dataset: omnibenchmark
2024-04-30 17:21:56,731 [trainer.py] => memory_size: 6000
2024-04-30 17:21:56,732 [trainer.py] => memory_per_class: 20
2024-04-30 17:21:56,732 [trainer.py] => fixed_memory: True
2024-04-30 17:21:56,732 [trainer.py] => shuffle: True
2024-04-30 17:21:56,732 [trainer.py] => init_cls: 150
2024-04-30 17:21:56,732 [trainer.py] => increment: 30
2024-04-30 17:21:56,732 [trainer.py] => model_name: der
2024-04-30 17:21:56,732 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-04-30 17:21:56,732 [trainer.py] => device: [device(type='cuda', index=6)]
2024-04-30 17:21:56,732 [trainer.py] => seed: 1993
2024-04-30 17:21:56,732 [trainer.py] => init_epoch: 20
2024-04-30 17:21:56,732 [trainer.py] => init_lr: 0.001
2024-04-30 17:21:56,732 [trainer.py] => init_milestones: [60, 120, 170]
2024-04-30 17:21:56,732 [trainer.py] => init_lr_decay: 0.1
2024-04-30 17:21:56,732 [trainer.py] => init_weight_decay: 0.0005
2024-04-30 17:21:56,732 [trainer.py] => epochs: 20
2024-04-30 17:21:56,732 [trainer.py] => lrate: 0.001
2024-04-30 17:21:56,732 [trainer.py] => milestones: [80, 120, 150]
2024-04-30 17:21:56,732 [trainer.py] => lrate_decay: 0.1
2024-04-30 17:21:56,732 [trainer.py] => batch_size: 48
2024-04-30 17:21:56,732 [trainer.py] => weight_decay: 0.0002
2024-04-30 17:21:56,732 [trainer.py] => T: 2
2024-04-30 17:21:58,315 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2024-04-30 17:21:59,175 [trainer.py] => All params: 0
2024-04-30 17:21:59,175 [trainer.py] => Trainable params: 0
2024-04-30 17:22:01,971 [der.py] => Learning on 0-150
2024-04-30 17:22:01,972 [der.py] => All params: 86030125
2024-04-30 17:22:01,972 [der.py] => Trainable params: 86030125
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.570, Train_accy 59.55, Test_accy 76.15:   0%|          | 0/20 [06:47<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.570, Train_accy 59.55, Test_accy 76.15:   5%|▌         | 1/20 [06:47<2:09:10, 407.93s/it]Task 0, Epoch 2/20 => Loss 0.892, Train_accy 74.29:   5%|▌         | 1/20 [13:22<2:09:10, 407.93s/it]                 Task 0, Epoch 2/20 => Loss 0.892, Train_accy 74.29:  10%|█         | 2/20 [13:22<2:00:01, 400.08s/it]Task 0, Epoch 3/20 => Loss 0.758, Train_accy 77.66:  10%|█         | 2/20 [19:57<2:00:01, 400.08s/it]Task 0, Epoch 3/20 => Loss 0.758, Train_accy 77.66:  15%|█▌        | 3/20 [19:57<1:52:43, 397.85s/it]Task 0, Epoch 4/20 => Loss 0.679, Train_accy 79.97:  15%|█▌        | 3/20 [26:31<1:52:43, 397.85s/it]Task 0, Epoch 4/20 => Loss 0.679, Train_accy 79.97:  20%|██        | 4/20 [26:31<1:45:42, 396.39s/it]Task 0, Epoch 5/20 => Loss 0.636, Train_accy 81.15:  20%|██        | 4/20 [33:05<1:45:42, 396.39s/it]Task 0, Epoch 5/20 => Loss 0.636, Train_accy 81.15:  25%|██▌       | 5/20 [33:05<1:38:52, 395.48s/it]Task 0, Epoch 6/20 => Loss 0.583, Train_accy 82.50, Test_accy 84.47:  25%|██▌       | 5/20 [39:49<1:38:52, 395.48s/it]Task 0, Epoch 6/20 => Loss 0.583, Train_accy 82.50, Test_accy 84.47:  30%|███       | 6/20 [39:49<1:32:55, 398.25s/it]Task 0, Epoch 7/20 => Loss 0.551, Train_accy 83.73:  30%|███       | 6/20 [46:28<1:32:55, 398.25s/it]                 Task 0, Epoch 7/20 => Loss 0.551, Train_accy 83.73:  35%|███▌      | 7/20 [46:28<1:26:20, 398.51s/it]Task 0, Epoch 8/20 => Loss 0.518, Train_accy 84.63:  35%|███▌      | 7/20 [53:05<1:26:20, 398.51s/it]Task 0, Epoch 8/20 => Loss 0.518, Train_accy 84.63:  40%|████      | 8/20 [53:05<1:19:37, 398.15s/it]Task 0, Epoch 9/20 => Loss 0.486, Train_accy 85.49:  40%|████      | 8/20 [59:43<1:19:37, 398.15s/it]Task 0, Epoch 9/20 => Loss 0.486, Train_accy 85.49:  45%|████▌     | 9/20 [59:43<1:12:57, 397.99s/it]Task 0, Epoch 10/20 => Loss 0.472, Train_accy 85.93:  45%|████▌     | 9/20 [1:06:22<1:12:57, 397.99s/it]Task 0, Epoch 10/20 => Loss 0.472, Train_accy 85.93:  50%|█████     | 10/20 [1:06:22<1:06:23, 398.32s/it]Task 0, Epoch 11/20 => Loss 0.458, Train_accy 86.26, Test_accy 85.00:  50%|█████     | 10/20 [1:13:12<1:06:23, 398.32s/it]Task 0, Epoch 11/20 => Loss 0.458, Train_accy 86.26, Test_accy 85.00:  55%|█████▌    | 11/20 [1:13:12<1:00:16, 401.84s/it]Task 0, Epoch 12/20 => Loss 0.442, Train_accy 86.94:  55%|█████▌    | 11/20 [1:19:49<1:00:16, 401.84s/it]                 Task 0, Epoch 12/20 => Loss 0.442, Train_accy 86.94:  60%|██████    | 12/20 [1:19:49<53:23, 400.44s/it]  Task 0, Epoch 13/20 => Loss 0.411, Train_accy 87.73:  60%|██████    | 12/20 [1:26:27<53:23, 400.44s/it]Task 0, Epoch 13/20 => Loss 0.411, Train_accy 87.73:  65%|██████▌   | 13/20 [1:26:27<46:37, 399.63s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.84:  65%|██████▌   | 13/20 [1:32:58<46:37, 399.63s/it]Task 0, Epoch 14/20 => Loss 0.407, Train_accy 87.84:  70%|███████   | 14/20 [1:32:58<39:42, 397.10s/it]Task 0, Epoch 15/20 => Loss 0.395, Train_accy 88.15:  70%|███████   | 14/20 [1:38:01<39:42, 397.10s/it]Task 0, Epoch 15/20 => Loss 0.395, Train_accy 88.15:  75%|███████▌  | 15/20 [1:38:01<30:43, 368.78s/it]Task 0, Epoch 16/20 => Loss 0.391, Train_accy 88.48, Test_accy 84.50:  75%|███████▌  | 15/20 [1:43:14<30:43, 368.78s/it]Task 0, Epoch 16/20 => Loss 0.391, Train_accy 88.48, Test_accy 84.50:  80%|████████  | 16/20 [1:43:14<23:27, 351.79s/it]Task 0, Epoch 17/20 => Loss 0.375, Train_accy 88.83:  80%|████████  | 16/20 [1:48:16<23:27, 351.79s/it]                 Task 0, Epoch 17/20 => Loss 0.375, Train_accy 88.83:  85%|████████▌ | 17/20 [1:48:16<16:51, 337.02s/it]Task 0, Epoch 18/20 => Loss 0.374, Train_accy 88.99:  85%|████████▌ | 17/20 [1:53:19<16:51, 337.02s/it]Task 0, Epoch 18/20 => Loss 0.374, Train_accy 88.99:  90%|█████████ | 18/20 [1:53:19<10:53, 326.72s/it]Task 0, Epoch 19/20 => Loss 0.358, Train_accy 89.51:  90%|█████████ | 18/20 [1:58:21<10:53, 326.72s/it]Task 0, Epoch 19/20 => Loss 0.358, Train_accy 89.51:  95%|█████████▌| 19/20 [1:58:21<05:19, 319.32s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.59:  95%|█████████▌| 19/20 [2:03:23<05:19, 319.32s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.59: 100%|██████████| 20/20 [2:03:23<00:00, 313.99s/it]Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.59: 100%|██████████| 20/20 [2:03:23<00:00, 370.16s/it]
2024-04-30 19:25:25,694 [der.py] => Task 0, Epoch 20/20 => Loss 0.353, Train_accy 89.59
2024-04-30 19:25:25,696 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 19:30:54,935 [der.py] => Exemplar size: 3000
2024-04-30 19:30:54,936 [trainer.py] => CNN: {'total': 85.27, '00-149': 85.27, 'old': 0, 'new': 85.27}
2024-04-30 19:30:54,936 [trainer.py] => NME: {'total': 85.27, '00-149': 85.27, 'old': 0, 'new': 85.27}
2024-04-30 19:30:54,936 [trainer.py] => CNN top1 curve: [85.27]
2024-04-30 19:30:54,936 [trainer.py] => CNN top5 curve: [97.39]
2024-04-30 19:30:54,936 [trainer.py] => NME top1 curve: [85.27]
2024-04-30 19:30:54,936 [trainer.py] => NME top5 curve: [97.53]

Average Accuracy (CNN): 85.27
Average Accuracy (NME): 85.27
2024-04-30 19:30:54,936 [trainer.py] => Average Accuracy (CNN): 85.27
2024-04-30 19:30:54,936 [trainer.py] => Average Accuracy (NME): 85.27
2024-04-30 19:30:54,936 [trainer.py] => Train Time: 7403.69
2024-04-30 19:30:54,936 [trainer.py] => Test Time: 16.62 

2024-04-30 19:30:54,938 [trainer.py] => All params: 86030125
2024-04-30 19:30:54,938 [trainer.py] => Trainable params: 86030125
2024-04-30 19:30:57,638 [der.py] => Learning on 150-180
2024-04-30 19:30:57,640 [der.py] => All params: 171897811
2024-04-30 19:30:57,641 [der.py] => Trainable params: 86099155
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 2.004, Loss_clf 1.150, Loss_aux 0.854, Train_accy 76.21, Test_accy 76.73:   0%|          | 0/20 [02:04<?, ?it/s]Task 1, Epoch 1/20 => Loss 2.004, Loss_clf 1.150, Loss_aux 0.854, Train_accy 76.21, Test_accy 76.73:   5%|▌         | 1/20 [02:04<39:34, 124.96s/it]Task 1, Epoch 2/20 => Loss 0.964, Loss_clf 0.495, Loss_aux 0.469, Train_accy 85.55:   5%|▌         | 1/20 [03:53<39:34, 124.96s/it]                 Task 1, Epoch 2/20 => Loss 0.964, Loss_clf 0.495, Loss_aux 0.469, Train_accy 85.55:  10%|█         | 2/20 [03:53<34:34, 115.23s/it]Task 1, Epoch 3/20 => Loss 0.810, Loss_clf 0.415, Loss_aux 0.395, Train_accy 87.81:  10%|█         | 2/20 [05:41<34:34, 115.23s/it]Task 1, Epoch 3/20 => Loss 0.810, Loss_clf 0.415, Loss_aux 0.395, Train_accy 87.81:  15%|█▌        | 3/20 [05:41<31:41, 111.87s/it]Task 1, Epoch 4/20 => Loss 0.745, Loss_clf 0.381, Loss_aux 0.364, Train_accy 88.76:  15%|█▌        | 3/20 [07:29<31:41, 111.87s/it]Task 1, Epoch 4/20 => Loss 0.745, Loss_clf 0.381, Loss_aux 0.364, Train_accy 88.76:  20%|██        | 4/20 [07:29<29:24, 110.28s/it]Task 1, Epoch 5/20 => Loss 0.661, Loss_clf 0.338, Loss_aux 0.324, Train_accy 90.08:  20%|██        | 4/20 [09:16<29:24, 110.28s/it]Task 1, Epoch 5/20 => Loss 0.661, Loss_clf 0.338, Loss_aux 0.324, Train_accy 90.08:  25%|██▌       | 5/20 [09:16<27:17, 109.14s/it]Task 1, Epoch 6/20 => Loss 0.654, Loss_clf 0.338, Loss_aux 0.316, Train_accy 90.44, Test_accy 77.87:  25%|██▌       | 5/20 [11:23<27:17, 109.14s/it]Task 1, Epoch 6/20 => Loss 0.654, Loss_clf 0.338, Loss_aux 0.316, Train_accy 90.44, Test_accy 77.87:  30%|███       | 6/20 [11:23<26:52, 115.17s/it]Task 1, Epoch 7/20 => Loss 0.607, Loss_clf 0.315, Loss_aux 0.292, Train_accy 90.94:  30%|███       | 6/20 [13:11<26:52, 115.17s/it]                 Task 1, Epoch 7/20 => Loss 0.607, Loss_clf 0.315, Loss_aux 0.292, Train_accy 90.94:  35%|███▌      | 7/20 [13:11<24:28, 112.99s/it]Task 1, Epoch 8/20 => Loss 0.546, Loss_clf 0.282, Loss_aux 0.264, Train_accy 91.83:  35%|███▌      | 7/20 [14:59<24:28, 112.99s/it]Task 1, Epoch 8/20 => Loss 0.546, Loss_clf 0.282, Loss_aux 0.264, Train_accy 91.83:  40%|████      | 8/20 [14:59<22:18, 111.51s/it]Task 1, Epoch 9/20 => Loss 0.553, Loss_clf 0.290, Loss_aux 0.263, Train_accy 91.62:  40%|████      | 8/20 [16:48<22:18, 111.51s/it]Task 1, Epoch 9/20 => Loss 0.553, Loss_clf 0.290, Loss_aux 0.263, Train_accy 91.62:  45%|████▌     | 9/20 [16:48<20:16, 110.57s/it]Task 1, Epoch 10/20 => Loss 0.514, Loss_clf 0.269, Loss_aux 0.245, Train_accy 92.17:  45%|████▌     | 9/20 [18:36<20:16, 110.57s/it]Task 1, Epoch 10/20 => Loss 0.514, Loss_clf 0.269, Loss_aux 0.245, Train_accy 92.17:  50%|█████     | 10/20 [18:36<18:18, 109.88s/it]Task 1, Epoch 11/20 => Loss 0.447, Loss_clf 0.232, Loss_aux 0.216, Train_accy 93.40, Test_accy 80.12:  50%|█████     | 10/20 [20:42<18:18, 109.88s/it]Task 1, Epoch 11/20 => Loss 0.447, Loss_clf 0.232, Loss_aux 0.216, Train_accy 93.40, Test_accy 80.12:  55%|█████▌    | 11/20 [20:42<17:12, 114.69s/it]Task 1, Epoch 12/20 => Loss 0.466, Loss_clf 0.250, Loss_aux 0.217, Train_accy 92.59:  55%|█████▌    | 11/20 [22:29<17:12, 114.69s/it]                 Task 1, Epoch 12/20 => Loss 0.466, Loss_clf 0.250, Loss_aux 0.217, Train_accy 92.59:  60%|██████    | 12/20 [22:29<14:58, 112.33s/it]Task 1, Epoch 13/20 => Loss 0.456, Loss_clf 0.239, Loss_aux 0.217, Train_accy 93.16:  60%|██████    | 12/20 [24:16<14:58, 112.33s/it]Task 1, Epoch 13/20 => Loss 0.456, Loss_clf 0.239, Loss_aux 0.217, Train_accy 93.16:  65%|██████▌   | 13/20 [24:16<12:54, 110.65s/it]Task 1, Epoch 14/20 => Loss 0.476, Loss_clf 0.249, Loss_aux 0.227, Train_accy 92.69:  65%|██████▌   | 13/20 [26:03<12:54, 110.65s/it]Task 1, Epoch 14/20 => Loss 0.476, Loss_clf 0.249, Loss_aux 0.227, Train_accy 92.69:  70%|███████   | 14/20 [26:03<10:57, 109.55s/it]Task 1, Epoch 15/20 => Loss 0.433, Loss_clf 0.228, Loss_aux 0.205, Train_accy 93.54:  70%|███████   | 14/20 [27:50<10:57, 109.55s/it]Task 1, Epoch 15/20 => Loss 0.433, Loss_clf 0.228, Loss_aux 0.205, Train_accy 93.54:  75%|███████▌  | 15/20 [27:50<09:04, 108.88s/it]Task 1, Epoch 16/20 => Loss 0.453, Loss_clf 0.239, Loss_aux 0.213, Train_accy 93.19, Test_accy 80.43:  75%|███████▌  | 15/20 [29:56<09:04, 108.88s/it]Task 1, Epoch 16/20 => Loss 0.453, Loss_clf 0.239, Loss_aux 0.213, Train_accy 93.19, Test_accy 80.43:  80%|████████  | 16/20 [29:56<07:35, 113.97s/it]Task 1, Epoch 17/20 => Loss 0.383, Loss_clf 0.201, Loss_aux 0.182, Train_accy 94.13:  80%|████████  | 16/20 [31:43<07:35, 113.97s/it]                 Task 1, Epoch 17/20 => Loss 0.383, Loss_clf 0.201, Loss_aux 0.182, Train_accy 94.13:  85%|████████▌ | 17/20 [31:43<05:35, 111.90s/it]Task 1, Epoch 18/20 => Loss 0.408, Loss_clf 0.213, Loss_aux 0.196, Train_accy 94.04:  85%|████████▌ | 17/20 [33:30<05:35, 111.90s/it]Task 1, Epoch 18/20 => Loss 0.408, Loss_clf 0.213, Loss_aux 0.196, Train_accy 94.04:  90%|█████████ | 18/20 [33:30<03:40, 110.49s/it]Task 1, Epoch 19/20 => Loss 0.380, Loss_clf 0.203, Loss_aux 0.176, Train_accy 94.19:  90%|█████████ | 18/20 [35:17<03:40, 110.49s/it]Task 1, Epoch 19/20 => Loss 0.380, Loss_clf 0.203, Loss_aux 0.176, Train_accy 94.19:  95%|█████████▌| 19/20 [35:17<01:49, 109.53s/it]Task 1, Epoch 20/20 => Loss 0.388, Loss_clf 0.205, Loss_aux 0.183, Train_accy 94.15:  95%|█████████▌| 19/20 [37:05<01:49, 109.53s/it]Task 1, Epoch 20/20 => Loss 0.388, Loss_clf 0.205, Loss_aux 0.183, Train_accy 94.15: 100%|██████████| 20/20 [37:05<00:00, 108.84s/it]Task 1, Epoch 20/20 => Loss 0.388, Loss_clf 0.205, Loss_aux 0.183, Train_accy 94.15: 100%|██████████| 20/20 [37:05<00:00, 111.25s/it]
2024-04-30 20:08:02,732 [der.py] => Task 1, Epoch 20/20 => Loss 0.388, Loss_clf 0.205, Loss_aux 0.183, Train_accy 94.15
2024-04-30 20:08:02,733 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 20:11:22,949 [der.py] => Exemplar size: 3600
2024-04-30 20:11:22,949 [trainer.py] => CNN: {'total': 80.15, '00-149': 77.69, '150-179': 92.47, 'old': 77.69, 'new': 92.47}
2024-04-30 20:11:22,949 [trainer.py] => NME: {'total': 82.04, '00-149': 81.2, '150-179': 86.29, 'old': 81.2, 'new': 86.29}
2024-04-30 20:11:22,949 [trainer.py] => CNN top1 curve: [85.27, 80.15]
2024-04-30 20:11:22,949 [trainer.py] => CNN top5 curve: [97.39, 95.49]
2024-04-30 20:11:22,950 [trainer.py] => NME top1 curve: [85.27, 82.04]
2024-04-30 20:11:22,950 [trainer.py] => NME top5 curve: [97.53, 96.07]

Average Accuracy (CNN): 82.71
Average Accuracy (NME): 83.66
2024-04-30 20:11:22,950 [trainer.py] => Average Accuracy (CNN): 82.71
2024-04-30 20:11:22,950 [trainer.py] => Average Accuracy (NME): 83.66
2024-04-30 20:11:22,950 [trainer.py] => Train Time: 9628.76
2024-04-30 20:11:22,950 [trainer.py] => Test Time: 53.75 

2024-04-30 20:11:22,951 [trainer.py] => All params: 171897811
2024-04-30 20:11:22,953 [trainer.py] => Trainable params: 86099155
2024-04-30 20:11:26,050 [der.py] => Learning on 180-210
2024-04-30 20:11:26,053 [der.py] => All params: 257903857
2024-04-30 20:11:26,055 [der.py] => Trainable params: 86306545
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 1.939, Loss_clf 1.131, Loss_aux 0.809, Train_accy 77.02, Test_accy 75.98:   0%|          | 0/20 [02:52<?, ?it/s]Task 2, Epoch 1/20 => Loss 1.939, Loss_clf 1.131, Loss_aux 0.809, Train_accy 77.02, Test_accy 75.98:   5%|▌         | 1/20 [02:52<54:42, 172.76s/it]Task 2, Epoch 2/20 => Loss 0.912, Loss_clf 0.460, Loss_aux 0.452, Train_accy 86.06:   5%|▌         | 1/20 [05:14<54:42, 172.76s/it]                 Task 2, Epoch 2/20 => Loss 0.912, Loss_clf 0.460, Loss_aux 0.452, Train_accy 86.06:  10%|█         | 2/20 [05:14<46:16, 154.25s/it]Task 2, Epoch 3/20 => Loss 0.810, Loss_clf 0.415, Loss_aux 0.395, Train_accy 87.22:  10%|█         | 2/20 [07:34<46:16, 154.25s/it]Task 2, Epoch 3/20 => Loss 0.810, Loss_clf 0.415, Loss_aux 0.395, Train_accy 87.22:  15%|█▌        | 3/20 [07:34<41:58, 148.17s/it]Task 2, Epoch 4/20 => Loss 0.716, Loss_clf 0.364, Loss_aux 0.352, Train_accy 88.86:  15%|█▌        | 3/20 [09:55<41:58, 148.17s/it]Task 2, Epoch 4/20 => Loss 0.716, Loss_clf 0.364, Loss_aux 0.352, Train_accy 88.86:  20%|██        | 4/20 [09:55<38:45, 145.33s/it]Task 2, Epoch 5/20 => Loss 0.651, Loss_clf 0.338, Loss_aux 0.313, Train_accy 89.99:  20%|██        | 4/20 [12:16<38:45, 145.33s/it]Task 2, Epoch 5/20 => Loss 0.651, Loss_clf 0.338, Loss_aux 0.313, Train_accy 89.99:  25%|██▌       | 5/20 [12:16<35:56, 143.74s/it]Task 2, Epoch 6/20 => Loss 0.600, Loss_clf 0.313, Loss_aux 0.287, Train_accy 90.78, Test_accy 76.99:  25%|██▌       | 5/20 [15:09<35:56, 143.74s/it]Task 2, Epoch 6/20 => Loss 0.600, Loss_clf 0.313, Loss_aux 0.287, Train_accy 90.78, Test_accy 76.99:  30%|███       | 6/20 [15:09<35:47, 153.39s/it]Task 2, Epoch 7/20 => Loss 0.578, Loss_clf 0.303, Loss_aux 0.274, Train_accy 91.04:  30%|███       | 6/20 [17:29<35:47, 153.39s/it]                 Task 2, Epoch 7/20 => Loss 0.578, Loss_clf 0.303, Loss_aux 0.274, Train_accy 91.04:  35%|███▌      | 7/20 [17:29<32:21, 149.33s/it]Task 2, Epoch 8/20 => Loss 0.590, Loss_clf 0.304, Loss_aux 0.285, Train_accy 91.07:  35%|███▌      | 7/20 [19:51<32:21, 149.33s/it]Task 2, Epoch 8/20 => Loss 0.590, Loss_clf 0.304, Loss_aux 0.285, Train_accy 91.07:  40%|████      | 8/20 [19:51<29:21, 146.77s/it]Task 2, Epoch 9/20 => Loss 0.535, Loss_clf 0.281, Loss_aux 0.253, Train_accy 91.80:  40%|████      | 8/20 [22:12<29:21, 146.77s/it]Task 2, Epoch 9/20 => Loss 0.535, Loss_clf 0.281, Loss_aux 0.253, Train_accy 91.80:  45%|████▌     | 9/20 [22:12<26:35, 145.06s/it]Task 2, Epoch 10/20 => Loss 0.526, Loss_clf 0.276, Loss_aux 0.249, Train_accy 91.91:  45%|████▌     | 9/20 [24:33<26:35, 145.06s/it]Task 2, Epoch 10/20 => Loss 0.526, Loss_clf 0.276, Loss_aux 0.249, Train_accy 91.91:  50%|█████     | 10/20 [24:33<23:58, 143.83s/it]Task 2, Epoch 11/20 => Loss 0.506, Loss_clf 0.264, Loss_aux 0.243, Train_accy 92.41, Test_accy 77.49:  50%|█████     | 10/20 [27:25<23:58, 143.83s/it]Task 2, Epoch 11/20 => Loss 0.506, Loss_clf 0.264, Loss_aux 0.243, Train_accy 92.41, Test_accy 77.49:  55%|█████▌    | 11/20 [27:25<22:52, 152.48s/it]Task 2, Epoch 12/20 => Loss 0.479, Loss_clf 0.250, Loss_aux 0.229, Train_accy 92.76:  55%|█████▌    | 11/20 [29:47<22:52, 152.48s/it]                 Task 2, Epoch 12/20 => Loss 0.479, Loss_clf 0.250, Loss_aux 0.229, Train_accy 92.76:  60%|██████    | 12/20 [29:47<19:53, 149.13s/it]Task 2, Epoch 13/20 => Loss 0.483, Loss_clf 0.256, Loss_aux 0.227, Train_accy 92.98:  60%|██████    | 12/20 [32:08<19:53, 149.13s/it]Task 2, Epoch 13/20 => Loss 0.483, Loss_clf 0.256, Loss_aux 0.227, Train_accy 92.98:  65%|██████▌   | 13/20 [32:08<17:06, 146.69s/it]Task 2, Epoch 14/20 => Loss 0.453, Loss_clf 0.240, Loss_aux 0.212, Train_accy 93.16:  65%|██████▌   | 13/20 [34:29<17:06, 146.69s/it]Task 2, Epoch 14/20 => Loss 0.453, Loss_clf 0.240, Loss_aux 0.212, Train_accy 93.16:  70%|███████   | 14/20 [34:29<14:29, 144.90s/it]Task 2, Epoch 15/20 => Loss 0.449, Loss_clf 0.242, Loss_aux 0.207, Train_accy 93.32:  70%|███████   | 14/20 [36:50<14:29, 144.90s/it]Task 2, Epoch 15/20 => Loss 0.449, Loss_clf 0.242, Loss_aux 0.207, Train_accy 93.32:  75%|███████▌  | 15/20 [36:50<11:58, 143.73s/it]Task 2, Epoch 16/20 => Loss 0.418, Loss_clf 0.223, Loss_aux 0.194, Train_accy 93.60, Test_accy 78.13:  75%|███████▌  | 15/20 [39:41<11:58, 143.73s/it]Task 2, Epoch 16/20 => Loss 0.418, Loss_clf 0.223, Loss_aux 0.194, Train_accy 93.60, Test_accy 78.13:  80%|████████  | 16/20 [39:41<10:08, 152.22s/it]Task 2, Epoch 17/20 => Loss 0.397, Loss_clf 0.210, Loss_aux 0.187, Train_accy 93.79:  80%|████████  | 16/20 [42:02<10:08, 152.22s/it]                 Task 2, Epoch 17/20 => Loss 0.397, Loss_clf 0.210, Loss_aux 0.187, Train_accy 93.79:  85%|████████▌ | 17/20 [42:02<07:26, 148.84s/it]Task 2, Epoch 18/20 => Loss 0.390, Loss_clf 0.209, Loss_aux 0.181, Train_accy 94.11:  85%|████████▌ | 17/20 [44:24<07:26, 148.84s/it]Task 2, Epoch 18/20 => Loss 0.390, Loss_clf 0.209, Loss_aux 0.181, Train_accy 94.11:  90%|█████████ | 18/20 [44:24<04:53, 146.52s/it]Task 2, Epoch 19/20 => Loss 0.438, Loss_clf 0.232, Loss_aux 0.207, Train_accy 93.20:  90%|█████████ | 18/20 [46:45<04:53, 146.52s/it]Task 2, Epoch 19/20 => Loss 0.438, Loss_clf 0.232, Loss_aux 0.207, Train_accy 93.20:  95%|█████████▌| 19/20 [46:45<02:24, 144.87s/it]Task 2, Epoch 20/20 => Loss 0.412, Loss_clf 0.211, Loss_aux 0.201, Train_accy 93.83:  95%|█████████▌| 19/20 [49:06<02:24, 144.87s/it]Task 2, Epoch 20/20 => Loss 0.412, Loss_clf 0.211, Loss_aux 0.201, Train_accy 93.83: 100%|██████████| 20/20 [49:06<00:00, 143.85s/it]Task 2, Epoch 20/20 => Loss 0.412, Loss_clf 0.211, Loss_aux 0.201, Train_accy 93.83: 100%|██████████| 20/20 [49:06<00:00, 147.33s/it]
2024-04-30 21:00:32,706 [der.py] => Task 2, Epoch 20/20 => Loss 0.412, Loss_clf 0.211, Loss_aux 0.201, Train_accy 93.83
2024-04-30 21:00:32,708 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 21:05:44,436 [der.py] => Exemplar size: 4200
2024-04-30 21:05:44,437 [trainer.py] => CNN: {'total': 77.39, '00-149': 74.98, '150-179': 75.08, '180-209': 91.79, 'old': 75.0, 'new': 91.79}
2024-04-30 21:05:44,437 [trainer.py] => NME: {'total': 79.42, '00-149': 78.16, '150-179': 80.94, '180-209': 84.25, 'old': 78.62, 'new': 84.25}
2024-04-30 21:05:44,437 [trainer.py] => CNN top1 curve: [85.27, 80.15, 77.39]
2024-04-30 21:05:44,437 [trainer.py] => CNN top5 curve: [97.39, 95.49, 94.29]
2024-04-30 21:05:44,437 [trainer.py] => NME top1 curve: [85.27, 82.04, 79.42]
2024-04-30 21:05:44,437 [trainer.py] => NME top5 curve: [97.53, 96.07, 95.25]

Average Accuracy (CNN): 80.94
Average Accuracy (NME): 82.24
2024-04-30 21:05:44,437 [trainer.py] => Average Accuracy (CNN): 80.94
2024-04-30 21:05:44,437 [trainer.py] => Average Accuracy (NME): 82.24
2024-04-30 21:05:44,437 [trainer.py] => Train Time: 12575.39
2024-04-30 21:05:44,437 [trainer.py] => Test Time: 136.94 

2024-04-30 21:05:44,439 [trainer.py] => All params: 257903857
2024-04-30 21:05:44,440 [trainer.py] => Trainable params: 86306545
2024-04-30 21:05:47,070 [der.py] => Learning on 210-240
2024-04-30 21:05:47,074 [der.py] => All params: 343955983
2024-04-30 21:05:47,076 [der.py] => Trainable params: 86560015
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 1.987, Loss_clf 1.149, Loss_aux 0.838, Train_accy 77.08, Test_accy 72.47:   0%|          | 0/20 [05:03<?, ?it/s]Task 3, Epoch 1/20 => Loss 1.987, Loss_clf 1.149, Loss_aux 0.838, Train_accy 77.08, Test_accy 72.47:   5%|▌         | 1/20 [05:03<1:36:15, 303.97s/it]Task 3, Epoch 2/20 => Loss 0.974, Loss_clf 0.486, Loss_aux 0.488, Train_accy 85.41:   5%|▌         | 1/20 [09:06<1:36:15, 303.97s/it]                 Task 3, Epoch 2/20 => Loss 0.974, Loss_clf 0.486, Loss_aux 0.488, Train_accy 85.41:  10%|█         | 2/20 [09:06<1:20:16, 267.58s/it]Task 3, Epoch 3/20 => Loss 0.866, Loss_clf 0.440, Loss_aux 0.426, Train_accy 86.87:  10%|█         | 2/20 [13:08<1:20:16, 267.58s/it]Task 3, Epoch 3/20 => Loss 0.866, Loss_clf 0.440, Loss_aux 0.426, Train_accy 86.87:  15%|█▌        | 3/20 [13:08<1:12:30, 255.93s/it]Task 3, Epoch 4/20 => Loss 0.757, Loss_clf 0.391, Loss_aux 0.366, Train_accy 88.23:  15%|█▌        | 3/20 [17:09<1:12:30, 255.93s/it]Task 3, Epoch 4/20 => Loss 0.757, Loss_clf 0.391, Loss_aux 0.366, Train_accy 88.23:  20%|██        | 4/20 [17:09<1:06:41, 250.10s/it]Task 3, Epoch 5/20 => Loss 0.742, Loss_clf 0.383, Loss_aux 0.358, Train_accy 88.83:  20%|██        | 4/20 [21:11<1:06:41, 250.10s/it]Task 3, Epoch 5/20 => Loss 0.742, Loss_clf 0.383, Loss_aux 0.358, Train_accy 88.83:  25%|██▌       | 5/20 [21:11<1:01:50, 247.39s/it]Task 3, Epoch 6/20 => Loss 0.666, Loss_clf 0.343, Loss_aux 0.324, Train_accy 90.03, Test_accy 72.47:  25%|██▌       | 5/20 [26:15<1:01:50, 247.39s/it]Task 3, Epoch 6/20 => Loss 0.666, Loss_clf 0.343, Loss_aux 0.324, Train_accy 90.03, Test_accy 72.47:  30%|███       | 6/20 [26:15<1:02:12, 266.60s/it]Task 3, Epoch 7/20 => Loss 0.607, Loss_clf 0.312, Loss_aux 0.294, Train_accy 90.81:  30%|███       | 6/20 [30:18<1:02:12, 266.60s/it]                 Task 3, Epoch 7/20 => Loss 0.607, Loss_clf 0.312, Loss_aux 0.294, Train_accy 90.81:  35%|███▌      | 7/20 [30:18<56:03, 258.77s/it]  Task 3, Epoch 8/20 => Loss 0.606, Loss_clf 0.316, Loss_aux 0.291, Train_accy 90.68:  35%|███▌      | 7/20 [34:21<56:03, 258.77s/it]Task 3, Epoch 8/20 => Loss 0.606, Loss_clf 0.316, Loss_aux 0.291, Train_accy 90.68:  40%|████      | 8/20 [34:21<50:44, 253.70s/it]Task 3, Epoch 9/20 => Loss 0.573, Loss_clf 0.299, Loss_aux 0.274, Train_accy 91.17:  40%|████      | 8/20 [38:24<50:44, 253.70s/it]Task 3, Epoch 9/20 => Loss 0.573, Loss_clf 0.299, Loss_aux 0.274, Train_accy 91.17:  45%|████▌     | 9/20 [38:24<45:54, 250.43s/it]Task 3, Epoch 10/20 => Loss 0.553, Loss_clf 0.287, Loss_aux 0.266, Train_accy 91.74:  45%|████▌     | 9/20 [42:27<45:54, 250.43s/it]Task 3, Epoch 10/20 => Loss 0.553, Loss_clf 0.287, Loss_aux 0.266, Train_accy 91.74:  50%|█████     | 10/20 [42:27<41:22, 248.20s/it]Task 3, Epoch 11/20 => Loss 0.512, Loss_clf 0.269, Loss_aux 0.243, Train_accy 92.20, Test_accy 73.45:  50%|█████     | 10/20 [47:32<41:22, 248.20s/it]Task 3, Epoch 11/20 => Loss 0.512, Loss_clf 0.269, Loss_aux 0.243, Train_accy 92.20, Test_accy 73.45:  55%|█████▌    | 11/20 [47:32<39:49, 265.46s/it]Task 3, Epoch 12/20 => Loss 0.520, Loss_clf 0.271, Loss_aux 0.249, Train_accy 92.20:  55%|█████▌    | 11/20 [51:34<39:49, 265.46s/it]                 Task 3, Epoch 12/20 => Loss 0.520, Loss_clf 0.271, Loss_aux 0.249, Train_accy 92.20:  60%|██████    | 12/20 [51:34<34:27, 258.40s/it]Task 3, Epoch 13/20 => Loss 0.506, Loss_clf 0.267, Loss_aux 0.239, Train_accy 92.37:  60%|██████    | 12/20 [55:38<34:27, 258.40s/it]Task 3, Epoch 13/20 => Loss 0.506, Loss_clf 0.267, Loss_aux 0.239, Train_accy 92.37:  65%|██████▌   | 13/20 [55:38<29:39, 254.16s/it]Task 3, Epoch 14/20 => Loss 0.496, Loss_clf 0.266, Loss_aux 0.229, Train_accy 92.46:  65%|██████▌   | 13/20 [59:44<29:39, 254.16s/it]Task 3, Epoch 14/20 => Loss 0.496, Loss_clf 0.266, Loss_aux 0.229, Train_accy 92.46:  70%|███████   | 14/20 [59:44<25:08, 251.46s/it]Task 3, Epoch 15/20 => Loss 0.452, Loss_clf 0.237, Loss_aux 0.215, Train_accy 93.23:  70%|███████   | 14/20 [1:03:49<25:08, 251.46s/it]Task 3, Epoch 15/20 => Loss 0.452, Loss_clf 0.237, Loss_aux 0.215, Train_accy 93.23:  75%|███████▌  | 15/20 [1:03:49<20:47, 249.50s/it]Task 3, Epoch 16/20 => Loss 0.447, Loss_clf 0.239, Loss_aux 0.208, Train_accy 93.21, Test_accy 73.96:  75%|███████▌  | 15/20 [1:08:55<20:47, 249.50s/it]Task 3, Epoch 16/20 => Loss 0.447, Loss_clf 0.239, Loss_aux 0.208, Train_accy 93.21, Test_accy 73.96:  80%|████████  | 16/20 [1:08:55<17:46, 266.74s/it]Task 3, Epoch 17/20 => Loss 0.442, Loss_clf 0.232, Loss_aux 0.210, Train_accy 93.38:  80%|████████  | 16/20 [1:13:00<17:46, 266.74s/it]                 Task 3, Epoch 17/20 => Loss 0.442, Loss_clf 0.232, Loss_aux 0.210, Train_accy 93.38:  85%|████████▌ | 17/20 [1:13:00<13:00, 260.18s/it]Task 3, Epoch 18/20 => Loss 0.457, Loss_clf 0.239, Loss_aux 0.218, Train_accy 93.35:  85%|████████▌ | 17/20 [1:17:05<13:00, 260.18s/it]Task 3, Epoch 18/20 => Loss 0.457, Loss_clf 0.239, Loss_aux 0.218, Train_accy 93.35:  90%|█████████ | 18/20 [1:17:05<08:31, 255.53s/it]Task 3, Epoch 19/20 => Loss 0.449, Loss_clf 0.239, Loss_aux 0.210, Train_accy 93.25:  90%|█████████ | 18/20 [1:21:11<08:31, 255.53s/it]Task 3, Epoch 19/20 => Loss 0.449, Loss_clf 0.239, Loss_aux 0.210, Train_accy 93.25:  95%|█████████▌| 19/20 [1:21:11<04:12, 252.56s/it]Task 3, Epoch 20/20 => Loss 0.415, Loss_clf 0.222, Loss_aux 0.192, Train_accy 93.79:  95%|█████████▌| 19/20 [1:25:15<04:12, 252.56s/it]Task 3, Epoch 20/20 => Loss 0.415, Loss_clf 0.222, Loss_aux 0.192, Train_accy 93.79: 100%|██████████| 20/20 [1:25:15<00:00, 250.13s/it]Task 3, Epoch 20/20 => Loss 0.415, Loss_clf 0.222, Loss_aux 0.192, Train_accy 93.79: 100%|██████████| 20/20 [1:25:15<00:00, 255.78s/it]
2024-04-30 22:31:02,906 [der.py] => Task 3, Epoch 20/20 => Loss 0.415, Loss_clf 0.222, Loss_aux 0.192, Train_accy 93.79
2024-04-30 22:31:02,907 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-04-30 22:38:38,858 [der.py] => Exemplar size: 4800
2024-04-30 22:38:38,859 [trainer.py] => CNN: {'total': 74.23, '00-149': 70.77, '150-179': 69.23, '180-209': 78.06, '210-239': 92.65, 'old': 71.59, 'new': 92.65}
2024-04-30 22:38:38,859 [trainer.py] => NME: {'total': 77.86, '00-149': 75.72, '150-179': 77.76, '180-209': 82.75, '210-239': 83.81, 'old': 77.01, 'new': 83.81}
2024-04-30 22:38:38,859 [trainer.py] => CNN top1 curve: [85.27, 80.15, 77.39, 74.23]
2024-04-30 22:38:38,859 [trainer.py] => CNN top5 curve: [97.39, 95.49, 94.29, 92.96]
2024-04-30 22:38:38,859 [trainer.py] => NME top1 curve: [85.27, 82.04, 79.42, 77.86]
2024-04-30 22:38:38,859 [trainer.py] => NME top5 curve: [97.53, 96.07, 95.25, 94.74]

Average Accuracy (CNN): 79.26
Average Accuracy (NME): 81.15
2024-04-30 22:38:38,859 [trainer.py] => Average Accuracy (CNN): 79.26
2024-04-30 22:38:38,859 [trainer.py] => Average Accuracy (NME): 81.15
2024-04-30 22:38:38,859 [trainer.py] => Train Time: 17691.21
2024-04-30 22:38:38,859 [trainer.py] => Test Time: 263.36 

2024-04-30 22:38:38,861 [trainer.py] => All params: 343955983
2024-04-30 22:38:38,863 [trainer.py] => Trainable params: 86560015
2024-04-30 22:38:42,751 [der.py] => Learning on 240-270
2024-04-30 22:38:42,759 [der.py] => All params: 430054189
2024-04-30 22:38:42,762 [der.py] => Trainable params: 86859565
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 1.829, Loss_clf 1.048, Loss_aux 0.781, Train_accy 80.80, Test_accy 71.43:   0%|          | 0/20 [06:22<?, ?it/s]Task 4, Epoch 1/20 => Loss 1.829, Loss_clf 1.048, Loss_aux 0.781, Train_accy 80.80, Test_accy 71.43:   5%|▌         | 1/20 [06:22<2:00:58, 382.00s/it]Task 4, Epoch 2/20 => Loss 0.824, Loss_clf 0.425, Loss_aux 0.398, Train_accy 87.95:   5%|▌         | 1/20 [11:19<2:00:58, 382.00s/it]                 Task 4, Epoch 2/20 => Loss 0.824, Loss_clf 0.425, Loss_aux 0.398, Train_accy 87.95:  10%|█         | 2/20 [11:19<1:39:39, 332.22s/it]Task 4, Epoch 3/20 => Loss 0.710, Loss_clf 0.372, Loss_aux 0.338, Train_accy 89.62:  10%|█         | 2/20 [16:15<1:39:39, 332.22s/it]Task 4, Epoch 3/20 => Loss 0.710, Loss_clf 0.372, Loss_aux 0.338, Train_accy 89.62:  15%|█▌        | 3/20 [16:15<1:29:29, 315.87s/it]Task 4, Epoch 4/20 => Loss 0.657, Loss_clf 0.343, Loss_aux 0.314, Train_accy 90.23:  15%|█▌        | 3/20 [21:12<1:29:29, 315.87s/it]Task 4, Epoch 4/20 => Loss 0.657, Loss_clf 0.343, Loss_aux 0.314, Train_accy 90.23:  20%|██        | 4/20 [21:12<1:22:12, 308.26s/it]Task 4, Epoch 5/20 => Loss 0.604, Loss_clf 0.318, Loss_aux 0.286, Train_accy 90.81:  20%|██        | 4/20 [26:08<1:22:12, 308.26s/it]Task 4, Epoch 5/20 => Loss 0.604, Loss_clf 0.318, Loss_aux 0.286, Train_accy 90.81:  25%|██▌       | 5/20 [26:08<1:15:59, 303.95s/it]Task 4, Epoch 6/20 => Loss 0.563, Loss_clf 0.302, Loss_aux 0.261, Train_accy 91.52, Test_accy 72.75:  25%|██▌       | 5/20 [32:29<1:15:59, 303.95s/it]Task 4, Epoch 6/20 => Loss 0.563, Loss_clf 0.302, Loss_aux 0.261, Train_accy 91.52, Test_accy 72.75:  30%|███       | 6/20 [32:29<1:16:58, 329.92s/it]Task 4, Epoch 7/20 => Loss 0.543, Loss_clf 0.289, Loss_aux 0.254, Train_accy 91.75:  30%|███       | 6/20 [37:24<1:16:58, 329.92s/it]                 Task 4, Epoch 7/20 => Loss 0.543, Loss_clf 0.289, Loss_aux 0.254, Train_accy 91.75:  35%|███▌      | 7/20 [37:24<1:09:03, 318.70s/it]Task 4, Epoch 8/20 => Loss 0.503, Loss_clf 0.276, Loss_aux 0.226, Train_accy 92.25:  35%|███▌      | 7/20 [42:19<1:09:03, 318.70s/it]Task 4, Epoch 8/20 => Loss 0.503, Loss_clf 0.276, Loss_aux 0.226, Train_accy 92.25:  40%|████      | 8/20 [42:19<1:02:12, 311.05s/it]Task 4, Epoch 9/20 => Loss 0.485, Loss_clf 0.261, Loss_aux 0.224, Train_accy 92.73:  40%|████      | 8/20 [47:16<1:02:12, 311.05s/it]Task 4, Epoch 9/20 => Loss 0.485, Loss_clf 0.261, Loss_aux 0.224, Train_accy 92.73:  45%|████▌     | 9/20 [47:16<56:12, 306.62s/it]  Task 4, Epoch 10/20 => Loss 0.469, Loss_clf 0.250, Loss_aux 0.219, Train_accy 93.29:  45%|████▌     | 9/20 [52:11<56:12, 306.62s/it]Task 4, Epoch 10/20 => Loss 0.469, Loss_clf 0.250, Loss_aux 0.219, Train_accy 93.29:  50%|█████     | 10/20 [52:11<50:30, 303.01s/it]Task 4, Epoch 11/20 => Loss 0.434, Loss_clf 0.228, Loss_aux 0.207, Train_accy 93.72, Test_accy 72.51:  50%|█████     | 10/20 [58:32<50:30, 303.01s/it]Task 4, Epoch 11/20 => Loss 0.434, Loss_clf 0.228, Loss_aux 0.207, Train_accy 93.72, Test_accy 72.51:  55%|█████▌    | 11/20 [58:32<49:03, 327.02s/it]Task 4, Epoch 12/20 => Loss 0.419, Loss_clf 0.225, Loss_aux 0.193, Train_accy 93.49:  55%|█████▌    | 11/20 [1:03:27<49:03, 327.02s/it]               Task 4, Epoch 12/20 => Loss 0.419, Loss_clf 0.225, Loss_aux 0.193, Train_accy 93.49:  60%|██████    | 12/20 [1:03:27<42:17, 317.14s/it]Task 4, Epoch 13/20 => Loss 0.416, Loss_clf 0.229, Loss_aux 0.187, Train_accy 93.54:  60%|██████    | 12/20 [1:08:22<42:17, 317.14s/it]Task 4, Epoch 13/20 => Loss 0.416, Loss_clf 0.229, Loss_aux 0.187, Train_accy 93.54:  65%|██████▌   | 13/20 [1:08:22<36:14, 310.70s/it]Task 4, Epoch 14/20 => Loss 0.439, Loss_clf 0.238, Loss_aux 0.201, Train_accy 93.55:  65%|██████▌   | 13/20 [1:12:37<36:14, 310.70s/it]Task 4, Epoch 14/20 => Loss 0.439, Loss_clf 0.238, Loss_aux 0.201, Train_accy 93.55:  70%|███████   | 14/20 [1:12:37<29:22, 293.75s/it]Task 4, Epoch 15/20 => Loss 0.406, Loss_clf 0.225, Loss_aux 0.182, Train_accy 93.79:  70%|███████   | 14/20 [1:16:22<29:22, 293.75s/it]Task 4, Epoch 15/20 => Loss 0.406, Loss_clf 0.225, Loss_aux 0.182, Train_accy 93.79:  75%|███████▌  | 15/20 [1:16:22<22:45, 273.11s/it]Task 4, Epoch 16/20 => Loss 0.378, Loss_clf 0.210, Loss_aux 0.168, Train_accy 94.14, Test_accy 72.84:  75%|███████▌  | 15/20 [1:21:12<22:45, 273.11s/it]Task 4, Epoch 16/20 => Loss 0.378, Loss_clf 0.210, Loss_aux 0.168, Train_accy 94.14, Test_accy 72.84:  80%|████████  | 16/20 [1:21:12<18:32, 278.14s/it]Task 4, Epoch 17/20 => Loss 0.396, Loss_clf 0.215, Loss_aux 0.181, Train_accy 93.91:  80%|████████  | 16/20 [1:24:57<18:32, 278.14s/it]                 Task 4, Epoch 17/20 => Loss 0.396, Loss_clf 0.215, Loss_aux 0.181, Train_accy 93.91:  85%|████████▌ | 17/20 [1:24:57<13:06, 262.08s/it]Task 4, Epoch 18/20 => Loss 0.385, Loss_clf 0.216, Loss_aux 0.169, Train_accy 94.06:  85%|████████▌ | 17/20 [1:28:43<13:06, 262.08s/it]Task 4, Epoch 18/20 => Loss 0.385, Loss_clf 0.216, Loss_aux 0.169, Train_accy 94.06:  90%|█████████ | 18/20 [1:28:43<08:22, 251.14s/it]Task 4, Epoch 19/20 => Loss 0.364, Loss_clf 0.204, Loss_aux 0.160, Train_accy 94.55:  90%|█████████ | 18/20 [1:32:27<08:22, 251.14s/it]Task 4, Epoch 19/20 => Loss 0.364, Loss_clf 0.204, Loss_aux 0.160, Train_accy 94.55:  95%|█████████▌| 19/20 [1:32:27<04:03, 243.01s/it]Task 4, Epoch 20/20 => Loss 0.384, Loss_clf 0.215, Loss_aux 0.169, Train_accy 94.09:  95%|█████████▌| 19/20 [1:36:11<04:03, 243.01s/it]Task 4, Epoch 20/20 => Loss 0.384, Loss_clf 0.215, Loss_aux 0.169, Train_accy 94.09: 100%|██████████| 20/20 [1:36:11<00:00, 237.55s/it]Task 4, Epoch 20/20 => Loss 0.384, Loss_clf 0.215, Loss_aux 0.169, Train_accy 94.09: 100%|██████████| 20/20 [1:36:11<00:00, 288.60s/it]
2024-05-01 00:14:54,813 [der.py] => Task 4, Epoch 20/20 => Loss 0.384, Loss_clf 0.215, Loss_aux 0.169, Train_accy 94.09
2024-05-01 00:14:54,814 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 00:22:59,264 [der.py] => Exemplar size: 5400
2024-05-01 00:22:59,265 [trainer.py] => CNN: {'total': 72.32, '00-149': 66.97, '150-179': 68.39, '180-209': 70.35, '210-239': 83.81, '240-269': 93.49, 'old': 69.67, 'new': 93.49}
2024-05-01 00:22:59,265 [trainer.py] => NME: {'total': 76.02, '00-149': 72.68, '150-179': 74.41, '180-209': 77.72, '210-239': 83.81, '240-269': 84.81, 'old': 74.92, 'new': 84.81}
2024-05-01 00:22:59,265 [trainer.py] => CNN top1 curve: [85.27, 80.15, 77.39, 74.23, 72.32]
2024-05-01 00:22:59,265 [trainer.py] => CNN top5 curve: [97.39, 95.49, 94.29, 92.96, 92.52]
2024-05-01 00:22:59,265 [trainer.py] => NME top1 curve: [85.27, 82.04, 79.42, 77.86, 76.02]
2024-05-01 00:22:59,265 [trainer.py] => NME top5 curve: [97.53, 96.07, 95.25, 94.74, 94.21]

Average Accuracy (CNN): 77.87
Average Accuracy (NME): 80.12
2024-05-01 00:22:59,265 [trainer.py] => Average Accuracy (CNN): 77.87
2024-05-01 00:22:59,265 [trainer.py] => Average Accuracy (NME): 80.12
2024-05-01 00:22:59,265 [trainer.py] => Train Time: 23463.239999999998
2024-05-01 00:22:59,265 [trainer.py] => Test Time: 397.5 

2024-05-01 00:22:59,268 [trainer.py] => All params: 430054189
2024-05-01 00:22:59,270 [trainer.py] => Trainable params: 86859565
2024-05-01 00:23:03,649 [der.py] => Learning on 270-300
2024-05-01 00:23:03,656 [der.py] => All params: 516198475
2024-05-01 00:23:03,659 [der.py] => Trainable params: 87205195
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 1.821, Loss_clf 1.046, Loss_aux 0.775, Train_accy 80.05, Test_accy 69.21:   0%|          | 0/20 [05:45<?, ?it/s]Task 5, Epoch 1/20 => Loss 1.821, Loss_clf 1.046, Loss_aux 0.775, Train_accy 80.05, Test_accy 69.21:   5%|▌         | 1/20 [05:45<1:49:29, 345.76s/it]Task 5, Epoch 2/20 => Loss 0.893, Loss_clf 0.452, Loss_aux 0.441, Train_accy 87.27:   5%|▌         | 1/20 [10:03<1:49:29, 345.76s/it]                 Task 5, Epoch 2/20 => Loss 0.893, Loss_clf 0.452, Loss_aux 0.441, Train_accy 87.27:  10%|█         | 2/20 [10:03<1:28:16, 294.25s/it]Task 5, Epoch 3/20 => Loss 0.754, Loss_clf 0.408, Loss_aux 0.346, Train_accy 88.74:  10%|█         | 2/20 [14:23<1:28:16, 294.25s/it]Task 5, Epoch 3/20 => Loss 0.754, Loss_clf 0.408, Loss_aux 0.346, Train_accy 88.74:  15%|█▌        | 3/20 [14:23<1:18:56, 278.63s/it]Task 5, Epoch 4/20 => Loss 1.195, Loss_clf 0.769, Loss_aux 0.426, Train_accy 88.67:  15%|█▌        | 3/20 [18:43<1:18:56, 278.63s/it]Task 5, Epoch 4/20 => Loss 1.195, Loss_clf 0.769, Loss_aux 0.426, Train_accy 88.67:  20%|██        | 4/20 [18:43<1:12:17, 271.10s/it]Task 5, Epoch 5/20 => Loss 0.655, Loss_clf 0.352, Loss_aux 0.303, Train_accy 90.59:  20%|██        | 4/20 [23:03<1:12:17, 271.10s/it]Task 5, Epoch 5/20 => Loss 0.655, Loss_clf 0.352, Loss_aux 0.303, Train_accy 90.59:  25%|██▌       | 5/20 [23:03<1:06:43, 266.91s/it]Task 5, Epoch 6/20 => Loss 0.835, Loss_clf 0.485, Loss_aux 0.350, Train_accy 89.84, Test_accy 69.59:  25%|██▌       | 5/20 [28:49<1:06:43, 266.91s/it]Task 5, Epoch 6/20 => Loss 0.835, Loss_clf 0.485, Loss_aux 0.350, Train_accy 89.84, Test_accy 69.59:  30%|███       | 6/20 [28:49<1:08:33, 293.84s/it]Task 5, Epoch 7/20 => Loss 0.702, Loss_clf 0.368, Loss_aux 0.334, Train_accy 90.84:  30%|███       | 6/20 [33:08<1:08:33, 293.84s/it]                 Task 5, Epoch 7/20 => Loss 0.702, Loss_clf 0.368, Loss_aux 0.334, Train_accy 90.84:  35%|███▌      | 7/20 [33:08<1:01:13, 282.60s/it]Task 5, Epoch 8/20 => Loss 0.648, Loss_clf 0.318, Loss_aux 0.331, Train_accy 91.59:  35%|███▌      | 7/20 [37:28<1:01:13, 282.60s/it]Task 5, Epoch 8/20 => Loss 0.648, Loss_clf 0.318, Loss_aux 0.331, Train_accy 91.59:  40%|████      | 8/20 [37:28<55:04, 275.34s/it]  Task 5, Epoch 9/20 => Loss 0.539, Loss_clf 0.300, Loss_aux 0.239, Train_accy 92.11:  40%|████      | 8/20 [41:47<55:04, 275.34s/it]Task 5, Epoch 9/20 => Loss 0.539, Loss_clf 0.300, Loss_aux 0.239, Train_accy 92.11:  45%|████▌     | 9/20 [41:47<49:34, 270.40s/it]Task 5, Epoch 10/20 => Loss 0.591, Loss_clf 0.297, Loss_aux 0.294, Train_accy 91.95:  45%|████▌     | 9/20 [46:07<49:34, 270.40s/it]Task 5, Epoch 10/20 => Loss 0.591, Loss_clf 0.297, Loss_aux 0.294, Train_accy 91.95:  50%|█████     | 10/20 [46:07<44:30, 267.07s/it]Task 5, Epoch 11/20 => Loss 0.475, Loss_clf 0.257, Loss_aux 0.218, Train_accy 92.69, Test_accy 70.03:  50%|█████     | 10/20 [51:54<44:30, 267.07s/it]Task 5, Epoch 11/20 => Loss 0.475, Loss_clf 0.257, Loss_aux 0.218, Train_accy 92.69, Test_accy 70.03:  55%|█████▌    | 11/20 [51:54<43:42, 291.37s/it]Task 5, Epoch 12/20 => Loss 0.484, Loss_clf 0.264, Loss_aux 0.220, Train_accy 92.49:  55%|█████▌    | 11/20 [56:13<43:42, 291.37s/it]                 Task 5, Epoch 12/20 => Loss 0.484, Loss_clf 0.264, Loss_aux 0.220, Train_accy 92.49:  60%|██████    | 12/20 [56:13<37:32, 281.59s/it]Task 5, Epoch 13/20 => Loss 0.420, Loss_clf 0.228, Loss_aux 0.192, Train_accy 93.87:  60%|██████    | 12/20 [1:00:32<37:32, 281.59s/it]Task 5, Epoch 13/20 => Loss 0.420, Loss_clf 0.228, Loss_aux 0.192, Train_accy 93.87:  65%|██████▌   | 13/20 [1:00:32<32:03, 274.85s/it]Task 5, Epoch 14/20 => Loss 0.424, Loss_clf 0.239, Loss_aux 0.184, Train_accy 93.19:  65%|██████▌   | 13/20 [1:04:52<32:03, 274.85s/it]Task 5, Epoch 14/20 => Loss 0.424, Loss_clf 0.239, Loss_aux 0.184, Train_accy 93.19:  70%|███████   | 14/20 [1:04:52<27:02, 270.41s/it]Task 5, Epoch 15/20 => Loss 0.413, Loss_clf 0.231, Loss_aux 0.182, Train_accy 93.62:  70%|███████   | 14/20 [1:09:11<27:02, 270.41s/it]Task 5, Epoch 15/20 => Loss 0.413, Loss_clf 0.231, Loss_aux 0.182, Train_accy 93.62:  75%|███████▌  | 15/20 [1:09:11<22:15, 267.04s/it]Task 5, Epoch 16/20 => Loss 0.414, Loss_clf 0.229, Loss_aux 0.185, Train_accy 93.61, Test_accy 69.77:  75%|███████▌  | 15/20 [1:14:57<22:15, 267.04s/it]Task 5, Epoch 16/20 => Loss 0.414, Loss_clf 0.229, Loss_aux 0.185, Train_accy 93.61, Test_accy 69.77:  80%|████████  | 16/20 [1:14:57<19:23, 290.80s/it]Task 5, Epoch 17/20 => Loss 0.430, Loss_clf 0.232, Loss_aux 0.199, Train_accy 93.70:  80%|████████  | 16/20 [1:19:17<19:23, 290.80s/it]                 Task 5, Epoch 17/20 => Loss 0.430, Loss_clf 0.232, Loss_aux 0.199, Train_accy 93.70:  85%|████████▌ | 17/20 [1:19:17<14:04, 281.48s/it]Task 5, Epoch 18/20 => Loss 0.395, Loss_clf 0.220, Loss_aux 0.175, Train_accy 93.94:  85%|████████▌ | 17/20 [1:23:37<14:04, 281.48s/it]Task 5, Epoch 18/20 => Loss 0.395, Loss_clf 0.220, Loss_aux 0.175, Train_accy 93.94:  90%|█████████ | 18/20 [1:23:37<09:09, 274.94s/it]Task 5, Epoch 19/20 => Loss 0.351, Loss_clf 0.194, Loss_aux 0.157, Train_accy 94.67:  90%|█████████ | 18/20 [1:27:57<09:09, 274.94s/it]Task 5, Epoch 19/20 => Loss 0.351, Loss_clf 0.194, Loss_aux 0.157, Train_accy 94.67:  95%|█████████▌| 19/20 [1:27:57<04:30, 270.43s/it]Task 5, Epoch 20/20 => Loss 0.366, Loss_clf 0.204, Loss_aux 0.161, Train_accy 94.24:  95%|█████████▌| 19/20 [1:32:16<04:30, 270.43s/it]Task 5, Epoch 20/20 => Loss 0.366, Loss_clf 0.204, Loss_aux 0.161, Train_accy 94.24: 100%|██████████| 20/20 [1:32:16<00:00, 267.17s/it]Task 5, Epoch 20/20 => Loss 0.366, Loss_clf 0.204, Loss_aux 0.161, Train_accy 94.24: 100%|██████████| 20/20 [1:32:16<00:00, 276.85s/it]
2024-05-01 01:55:20,691 [der.py] => Task 5, Epoch 20/20 => Loss 0.366, Loss_clf 0.204, Loss_aux 0.161, Train_accy 94.24
2024-05-01 01:55:20,693 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 02:05:05,347 [der.py] => Exemplar size: 6000
2024-05-01 02:05:05,347 [trainer.py] => CNN: {'total': 70.89, '00-149': 65.3, '150-179': 68.9, '180-209': 69.18, '210-239': 72.95, '240-269': 78.63, '270-299': 92.81, 'old': 68.46, 'new': 92.81}
2024-05-01 02:05:05,347 [trainer.py] => NME: {'total': 74.82, '00-149': 71.04, '150-179': 71.24, '180-209': 75.71, '210-239': 81.8, '240-269': 81.3, '270-299': 82.94, 'old': 73.92, 'new': 82.94}
2024-05-01 02:05:05,347 [trainer.py] => CNN top1 curve: [85.27, 80.15, 77.39, 74.23, 72.32, 70.89]
2024-05-01 02:05:05,347 [trainer.py] => CNN top5 curve: [97.39, 95.49, 94.29, 92.96, 92.52, 91.7]
2024-05-01 02:05:05,347 [trainer.py] => NME top1 curve: [85.27, 82.04, 79.42, 77.86, 76.02, 74.82]
2024-05-01 02:05:05,347 [trainer.py] => NME top5 curve: [97.53, 96.07, 95.25, 94.74, 94.21, 93.53]

Average Accuracy (CNN): 76.71
Average Accuracy (NME): 79.24
2024-05-01 02:05:05,347 [trainer.py] => Average Accuracy (CNN): 76.71
2024-05-01 02:05:05,347 [trainer.py] => Average Accuracy (NME): 79.24
2024-05-01 02:05:05,347 [trainer.py] => Train Time: 29000.25
2024-05-01 02:05:05,347 [trainer.py] => Test Time: 576.17 

Accuracy Matrix (CNN):
[[85.27 77.69 74.98 70.77 66.97 65.3 ]
 [ 0.   92.47 75.08 69.23 68.39 68.9 ]
 [ 0.    0.   91.79 78.06 70.35 69.18]
 [ 0.    0.    0.   92.65 83.81 72.95]
 [ 0.    0.    0.    0.   93.49 78.63]
 [ 0.    0.    0.    0.    0.   92.81]]
2024-05-01 02:05:05,348 [trainer.py] => Forgetting (CNN): 20.142
Accuracy Matrix (NME):
[[85.27 81.2  78.16 75.72 72.68 71.04]
 [ 0.   86.29 80.94 77.76 74.41 71.24]
 [ 0.    0.   84.25 82.75 77.72 75.71]
 [ 0.    0.    0.   83.81 83.81 81.8 ]
 [ 0.    0.    0.    0.   84.81 81.3 ]
 [ 0.    0.    0.    0.    0.   82.94]]
2024-05-01 02:05:05,349 [trainer.py] => Forgetting (NME): 8.668000000000003
2024-05-01 02:05:09,757 [trainer.py] => config: ./exps/foster_omn_B150_Inc5.json
2024-05-01 02:05:09,769 [trainer.py] => prefix: cil
2024-05-01 02:05:09,769 [trainer.py] => dataset: omnibenchmark
2024-05-01 02:05:09,769 [trainer.py] => memory_size: 6000
2024-05-01 02:05:09,769 [trainer.py] => memory_per_class: 20
2024-05-01 02:05:09,769 [trainer.py] => fixed_memory: True
2024-05-01 02:05:09,769 [trainer.py] => shuffle: True
2024-05-01 02:05:09,769 [trainer.py] => init_cls: 150
2024-05-01 02:05:09,769 [trainer.py] => increment: 30
2024-05-01 02:05:09,769 [trainer.py] => model_name: foster
2024-05-01 02:05:09,769 [trainer.py] => backbone_type: vit_base_patch16_224_in21k
2024-05-01 02:05:09,769 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-01 02:05:09,769 [trainer.py] => seed: 1993
2024-05-01 02:05:09,769 [trainer.py] => beta1: 0.96
2024-05-01 02:05:09,769 [trainer.py] => beta2: 0.97
2024-05-01 02:05:09,769 [trainer.py] => oofc: ft
2024-05-01 02:05:09,769 [trainer.py] => is_teacher_wa: False
2024-05-01 02:05:09,769 [trainer.py] => is_student_wa: False
2024-05-01 02:05:09,769 [trainer.py] => lambda_okd: 1
2024-05-01 02:05:09,769 [trainer.py] => wa_value: 1
2024-05-01 02:05:09,769 [trainer.py] => init_epochs: 20
2024-05-01 02:05:09,769 [trainer.py] => init_lr: 0.001
2024-05-01 02:05:09,770 [trainer.py] => init_weight_decay: 0.0005
2024-05-01 02:05:09,770 [trainer.py] => boosting_epochs: 20
2024-05-01 02:05:09,770 [trainer.py] => compression_epochs: 20
2024-05-01 02:05:09,770 [trainer.py] => lr: 0.001
2024-05-01 02:05:09,770 [trainer.py] => batch_size: 48
2024-05-01 02:05:09,770 [trainer.py] => weight_decay: 0.0005
2024-05-01 02:05:09,770 [trainer.py] => num_workers: 8
2024-05-01 02:05:09,770 [trainer.py] => T: 2
2024-05-01 02:05:11,235 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2024-05-01 02:05:12,140 [trainer.py] => All params: 0
2024-05-01 02:05:12,141 [trainer.py] => Trainable params: 0
2024-05-01 02:05:16,696 [foster.py] => Learning on 0-150
2024-05-01 02:05:16,698 [foster.py] => All params: 86029356
2024-05-01 02:05:16,699 [foster.py] => Trainable params: 86029356
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.546, Train_accy 60.30, Test_accy 78.16:   0%|          | 0/20 [05:01<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.546, Train_accy 60.30, Test_accy 78.16:   5%|▌         | 1/20 [05:01<1:35:24, 301.30s/it]Task 0, Epoch 2/20 => Loss 0.887, Train_accy 74.26:   5%|▌         | 1/20 [09:53<1:35:24, 301.30s/it]                 Task 0, Epoch 2/20 => Loss 0.887, Train_accy 74.26:  10%|█         | 2/20 [09:53<1:28:49, 296.08s/it]Task 0, Epoch 3/20 => Loss 0.753, Train_accy 77.84:  10%|█         | 2/20 [14:46<1:28:49, 296.08s/it]Task 0, Epoch 3/20 => Loss 0.753, Train_accy 77.84:  15%|█▌        | 3/20 [14:46<1:23:24, 294.39s/it]Task 0, Epoch 4/20 => Loss 0.675, Train_accy 79.96:  15%|█▌        | 3/20 [19:38<1:23:24, 294.39s/it]Task 0, Epoch 4/20 => Loss 0.675, Train_accy 79.96:  20%|██        | 4/20 [19:38<1:18:17, 293.61s/it]Task 0, Epoch 5/20 => Loss 0.611, Train_accy 81.72:  20%|██        | 4/20 [24:30<1:18:17, 293.61s/it]Task 0, Epoch 5/20 => Loss 0.611, Train_accy 81.72:  25%|██▌       | 5/20 [24:30<1:13:17, 293.15s/it]Task 0, Epoch 6/20 => Loss 0.546, Train_accy 83.64, Test_accy 83.87:  25%|██▌       | 5/20 [29:31<1:13:17, 293.15s/it]Task 0, Epoch 6/20 => Loss 0.546, Train_accy 83.64, Test_accy 83.87:  30%|███       | 6/20 [29:31<1:08:59, 295.69s/it]Task 0, Epoch 7/20 => Loss 0.514, Train_accy 84.57:  30%|███       | 6/20 [34:23<1:08:59, 295.69s/it]                 Task 0, Epoch 7/20 => Loss 0.514, Train_accy 84.57:  35%|███▌      | 7/20 [34:23<1:03:50, 294.63s/it]Task 0, Epoch 8/20 => Loss 0.468, Train_accy 86.06:  35%|███▌      | 7/20 [39:16<1:03:50, 294.63s/it]Task 0, Epoch 8/20 => Loss 0.468, Train_accy 86.06:  40%|████      | 8/20 [39:16<58:46, 293.90s/it]  Task 0, Epoch 9/20 => Loss 0.432, Train_accy 87.09:  40%|████      | 8/20 [44:08<58:46, 293.90s/it]Task 0, Epoch 9/20 => Loss 0.432, Train_accy 87.09:  45%|████▌     | 9/20 [44:08<53:47, 293.40s/it]Task 0, Epoch 10/20 => Loss 0.410, Train_accy 87.74:  45%|████▌     | 9/20 [49:00<53:47, 293.40s/it]Task 0, Epoch 10/20 => Loss 0.410, Train_accy 87.74:  50%|█████     | 10/20 [49:00<48:50, 293.09s/it]Task 0, Epoch 11/20 => Loss 0.367, Train_accy 89.01, Test_accy 86.27:  50%|█████     | 10/20 [54:01<48:50, 293.09s/it]Task 0, Epoch 11/20 => Loss 0.367, Train_accy 89.01, Test_accy 86.27:  55%|█████▌    | 11/20 [54:01<44:19, 295.45s/it]Task 0, Epoch 12/20 => Loss 0.349, Train_accy 89.73:  55%|█████▌    | 11/20 [58:53<44:19, 295.45s/it]                 Task 0, Epoch 12/20 => Loss 0.349, Train_accy 89.73:  60%|██████    | 12/20 [58:53<39:15, 294.42s/it]Task 0, Epoch 13/20 => Loss 0.320, Train_accy 90.38:  60%|██████    | 12/20 [1:03:46<39:15, 294.42s/it]Task 0, Epoch 13/20 => Loss 0.320, Train_accy 90.38:  65%|██████▌   | 13/20 [1:03:46<34:16, 293.77s/it]Task 0, Epoch 14/20 => Loss 0.303, Train_accy 90.97:  65%|██████▌   | 13/20 [1:08:38<34:16, 293.77s/it]Task 0, Epoch 14/20 => Loss 0.303, Train_accy 90.97:  70%|███████   | 14/20 [1:08:38<29:19, 293.30s/it]Task 0, Epoch 15/20 => Loss 0.285, Train_accy 91.60:  70%|███████   | 14/20 [1:13:30<29:19, 293.30s/it]Task 0, Epoch 15/20 => Loss 0.285, Train_accy 91.60:  75%|███████▌  | 15/20 [1:13:30<24:24, 292.95s/it]Task 0, Epoch 16/20 => Loss 0.264, Train_accy 92.13, Test_accy 87.54:  75%|███████▌  | 15/20 [1:18:30<24:24, 292.95s/it]Task 0, Epoch 16/20 => Loss 0.264, Train_accy 92.13, Test_accy 87.54:  80%|████████  | 16/20 [1:18:30<19:40, 295.13s/it]Task 0, Epoch 17/20 => Loss 0.252, Train_accy 92.58:  80%|████████  | 16/20 [1:23:22<19:40, 295.13s/it]                 Task 0, Epoch 17/20 => Loss 0.252, Train_accy 92.58:  85%|████████▌ | 17/20 [1:23:22<14:42, 294.21s/it]Task 0, Epoch 18/20 => Loss 0.248, Train_accy 92.77:  85%|████████▌ | 17/20 [1:28:14<14:42, 294.21s/it]Task 0, Epoch 18/20 => Loss 0.248, Train_accy 92.77:  90%|█████████ | 18/20 [1:28:14<09:47, 293.53s/it]Task 0, Epoch 19/20 => Loss 0.243, Train_accy 92.90:  90%|█████████ | 18/20 [1:33:06<09:47, 293.53s/it]Task 0, Epoch 19/20 => Loss 0.243, Train_accy 92.90:  95%|█████████▌| 19/20 [1:33:06<04:53, 293.02s/it]Task 0, Epoch 20/20 => Loss 0.248, Train_accy 92.76:  95%|█████████▌| 19/20 [1:37:58<04:53, 293.02s/it]Task 0, Epoch 20/20 => Loss 0.248, Train_accy 92.76: 100%|██████████| 20/20 [1:37:58<00:00, 292.73s/it]Task 0, Epoch 20/20 => Loss 0.248, Train_accy 92.76: 100%|██████████| 20/20 [1:37:58<00:00, 293.93s/it]
2024-05-01 03:43:15,850 [foster.py] => Task 0, Epoch 20/20 => Loss 0.248, Train_accy 92.76
2024-05-01 03:43:15,852 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 03:48:23,654 [foster.py] => Exemplar size: 3000
2024-05-01 03:48:23,654 [trainer.py] => CNN: {'total': 87.61, '00-149': 87.61, 'old': 0, 'new': 87.61}
2024-05-01 03:48:23,654 [trainer.py] => NME: {'total': 86.81, '00-149': 86.81, 'old': 0, 'new': 86.81}
2024-05-01 03:48:23,654 [trainer.py] => CNN top1 curve: [87.61]
2024-05-01 03:48:23,655 [trainer.py] => CNN top5 curve: [97.83]
2024-05-01 03:48:23,655 [trainer.py] => NME top1 curve: [86.81]
2024-05-01 03:48:23,655 [trainer.py] => NME top5 curve: [97.7]

Average Accuracy (CNN): 87.61
Average Accuracy (NME): 86.81
2024-05-01 03:48:23,655 [trainer.py] => Average Accuracy (CNN): 87.61
2024-05-01 03:48:23,655 [trainer.py] => Average Accuracy (NME): 86.81
2024-05-01 03:48:23,655 [trainer.py] => Train Time: 5879.09
2024-05-01 03:48:23,655 [trainer.py] => Test Time: 16.63 

2024-05-01 03:48:23,655 [trainer.py] => All params: 86029356
2024-05-01 03:48:23,656 [trainer.py] => Trainable params: 86029356
2024-05-01 03:48:25,796 [foster.py] => Learning on 150-180
2024-05-01 03:48:25,798 [foster.py] => All params: 172127742
2024-05-01 03:48:25,799 [foster.py] => Trainable params: 86213736
2024-05-01 03:48:25,868 [foster.py] => per cls weights : [1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548 1.07952548
 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259
 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259
 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259
 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259
 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259 0.60237259]
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 4.406, Loss_clf 1.046, Loss_fe 1.629, Loss_kd 1.443, Train_accy 49.02, Test_accy 79.98:   0%|          | 0/20 [02:04<?, ?it/s]Task 1, Epoch 1/20 => Loss 4.406, Loss_clf 1.046, Loss_fe 1.629, Loss_kd 1.443, Train_accy 49.02, Test_accy 79.98:   5%|▌         | 1/20 [02:04<39:28, 124.64s/it]Task 1, Epoch 2/20 => Loss 2.936, Loss_clf 0.523, Loss_fe 0.709, Loss_kd 1.420, Train_accy 50.93:   5%|▌         | 1/20 [03:50<39:28, 124.64s/it]                 Task 1, Epoch 2/20 => Loss 2.936, Loss_clf 0.523, Loss_fe 0.709, Loss_kd 1.420, Train_accy 50.93:  10%|█         | 2/20 [03:50<34:01, 113.39s/it]Task 1, Epoch 3/20 => Loss 2.716, Loss_clf 0.430, Loss_fe 0.582, Loss_kd 1.421, Train_accy 52.33:  10%|█         | 2/20 [05:35<34:01, 113.39s/it]Task 1, Epoch 3/20 => Loss 2.716, Loss_clf 0.430, Loss_fe 0.582, Loss_kd 1.421, Train_accy 52.33:  15%|█▌        | 3/20 [05:35<31:04, 109.70s/it]Task 1, Epoch 4/20 => Loss 2.610, Loss_clf 0.391, Loss_fe 0.516, Loss_kd 1.419, Train_accy 53.40:  15%|█▌        | 3/20 [07:20<31:04, 109.70s/it]Task 1, Epoch 4/20 => Loss 2.610, Loss_clf 0.391, Loss_fe 0.516, Loss_kd 1.419, Train_accy 53.40:  20%|██        | 4/20 [07:20<28:47, 107.98s/it]Task 1, Epoch 5/20 => Loss 2.498, Loss_clf 0.351, Loss_fe 0.449, Loss_kd 1.415, Train_accy 53.98:  20%|██        | 4/20 [09:06<28:47, 107.98s/it]Task 1, Epoch 5/20 => Loss 2.498, Loss_clf 0.351, Loss_fe 0.449, Loss_kd 1.415, Train_accy 53.98:  25%|██▌       | 5/20 [09:06<26:45, 107.01s/it]Task 1, Epoch 6/20 => Loss 2.408, Loss_clf 0.310, Loss_fe 0.400, Loss_kd 1.415, Train_accy 55.48, Test_accy 80.62:  25%|██▌       | 5/20 [11:09<26:45, 107.01s/it]Task 1, Epoch 6/20 => Loss 2.408, Loss_clf 0.310, Loss_fe 0.400, Loss_kd 1.415, Train_accy 55.48, Test_accy 80.62:  30%|███       | 6/20 [11:09<26:17, 112.68s/it]Task 1, Epoch 7/20 => Loss 2.378, Loss_clf 0.300, Loss_fe 0.375, Loss_kd 1.419, Train_accy 54.96:  30%|███       | 6/20 [12:55<26:17, 112.68s/it]                 Task 1, Epoch 7/20 => Loss 2.378, Loss_clf 0.300, Loss_fe 0.375, Loss_kd 1.419, Train_accy 54.96:  35%|███▌      | 7/20 [12:55<23:53, 110.25s/it]Task 1, Epoch 8/20 => Loss 2.312, Loss_clf 0.280, Loss_fe 0.334, Loss_kd 1.415, Train_accy 56.19:  35%|███▌      | 7/20 [14:40<23:53, 110.25s/it]Task 1, Epoch 8/20 => Loss 2.312, Loss_clf 0.280, Loss_fe 0.334, Loss_kd 1.415, Train_accy 56.19:  40%|████      | 8/20 [14:40<21:44, 108.68s/it]Task 1, Epoch 9/20 => Loss 2.293, Loss_clf 0.265, Loss_fe 0.318, Loss_kd 1.426, Train_accy 56.15:  40%|████      | 8/20 [16:25<21:44, 108.68s/it]Task 1, Epoch 9/20 => Loss 2.293, Loss_clf 0.265, Loss_fe 0.318, Loss_kd 1.426, Train_accy 56.15:  45%|████▌     | 9/20 [16:25<19:43, 107.61s/it]Task 1, Epoch 10/20 => Loss 2.206, Loss_clf 0.236, Loss_fe 0.277, Loss_kd 1.411, Train_accy 56.18:  45%|████▌     | 9/20 [18:10<19:43, 107.61s/it]Task 1, Epoch 10/20 => Loss 2.206, Loss_clf 0.236, Loss_fe 0.277, Loss_kd 1.411, Train_accy 56.18:  50%|█████     | 10/20 [18:10<17:49, 106.91s/it]Task 1, Epoch 11/20 => Loss 2.186, Loss_clf 0.231, Loss_fe 0.269, Loss_kd 1.406, Train_accy 56.58, Test_accy 80.60:  50%|█████     | 10/20 [20:14<17:49, 106.91s/it]Task 1, Epoch 11/20 => Loss 2.186, Loss_clf 0.231, Loss_fe 0.269, Loss_kd 1.406, Train_accy 56.58, Test_accy 80.60:  55%|█████▌    | 11/20 [20:14<16:48, 112.00s/it]Task 1, Epoch 12/20 => Loss 2.184, Loss_clf 0.226, Loss_fe 0.252, Loss_kd 1.421, Train_accy 57.30:  55%|█████▌    | 11/20 [21:59<16:48, 112.00s/it]                 Task 1, Epoch 12/20 => Loss 2.184, Loss_clf 0.226, Loss_fe 0.252, Loss_kd 1.421, Train_accy 57.30:  60%|██████    | 12/20 [21:59<14:39, 109.97s/it]Task 1, Epoch 13/20 => Loss 2.110, Loss_clf 0.195, Loss_fe 0.222, Loss_kd 1.410, Train_accy 58.73:  60%|██████    | 12/20 [23:45<14:39, 109.97s/it]Task 1, Epoch 13/20 => Loss 2.110, Loss_clf 0.195, Loss_fe 0.222, Loss_kd 1.410, Train_accy 58.73:  65%|██████▌   | 13/20 [23:45<12:39, 108.57s/it]Task 1, Epoch 14/20 => Loss 2.106, Loss_clf 0.196, Loss_fe 0.211, Loss_kd 1.415, Train_accy 58.51:  65%|██████▌   | 13/20 [25:30<12:39, 108.57s/it]Task 1, Epoch 14/20 => Loss 2.106, Loss_clf 0.196, Loss_fe 0.211, Loss_kd 1.415, Train_accy 58.51:  70%|███████   | 14/20 [25:30<10:45, 107.56s/it]Task 1, Epoch 15/20 => Loss 2.085, Loss_clf 0.179, Loss_fe 0.201, Loss_kd 1.420, Train_accy 58.96:  70%|███████   | 14/20 [27:15<10:45, 107.56s/it]Task 1, Epoch 15/20 => Loss 2.085, Loss_clf 0.179, Loss_fe 0.201, Loss_kd 1.420, Train_accy 58.96:  75%|███████▌  | 15/20 [27:15<08:54, 106.87s/it]Task 1, Epoch 16/20 => Loss 2.071, Loss_clf 0.182, Loss_fe 0.189, Loss_kd 1.416, Train_accy 59.25, Test_accy 80.93:  75%|███████▌  | 15/20 [29:19<08:54, 106.87s/it]Task 1, Epoch 16/20 => Loss 2.071, Loss_clf 0.182, Loss_fe 0.189, Loss_kd 1.416, Train_accy 59.25, Test_accy 80.93:  80%|████████  | 16/20 [29:19<07:27, 111.95s/it]Task 1, Epoch 17/20 => Loss 2.049, Loss_clf 0.169, Loss_fe 0.182, Loss_kd 1.415, Train_accy 59.24:  80%|████████  | 16/20 [31:04<07:27, 111.95s/it]                 Task 1, Epoch 17/20 => Loss 2.049, Loss_clf 0.169, Loss_fe 0.182, Loss_kd 1.415, Train_accy 59.24:  85%|████████▌ | 17/20 [31:04<05:29, 110.00s/it]Task 1, Epoch 18/20 => Loss 2.059, Loss_clf 0.174, Loss_fe 0.180, Loss_kd 1.420, Train_accy 60.50:  85%|████████▌ | 17/20 [32:50<05:29, 110.00s/it]Task 1, Epoch 18/20 => Loss 2.059, Loss_clf 0.174, Loss_fe 0.180, Loss_kd 1.420, Train_accy 60.50:  90%|█████████ | 18/20 [32:50<03:37, 108.60s/it]Task 1, Epoch 19/20 => Loss 2.033, Loss_clf 0.166, Loss_fe 0.169, Loss_kd 1.414, Train_accy 60.60:  90%|█████████ | 18/20 [34:35<03:37, 108.60s/it]Task 1, Epoch 19/20 => Loss 2.033, Loss_clf 0.166, Loss_fe 0.169, Loss_kd 1.414, Train_accy 60.60:  95%|█████████▌| 19/20 [34:35<01:47, 107.64s/it]Task 1, Epoch 20/20 => Loss 2.022, Loss_clf 0.160, Loss_fe 0.166, Loss_kd 1.413, Train_accy 60.51:  95%|█████████▌| 19/20 [36:21<01:47, 107.64s/it]Task 1, Epoch 20/20 => Loss 2.022, Loss_clf 0.160, Loss_fe 0.166, Loss_kd 1.413, Train_accy 60.51: 100%|██████████| 20/20 [36:21<00:00, 106.98s/it]Task 1, Epoch 20/20 => Loss 2.022, Loss_clf 0.160, Loss_fe 0.166, Loss_kd 1.413, Train_accy 60.51: 100%|██████████| 20/20 [36:21<00:00, 109.05s/it]
2024-05-01 04:24:46,925 [foster.py] => Task 1, Epoch 20/20 => Loss 2.022, Loss_clf 0.160, Loss_fe 0.166, Loss_kd 1.413, Train_accy 60.51
2024-05-01 04:24:46,925 [foster.py] => do not weight align teacher!
2024-05-01 04:24:46,930 [foster.py] => per cls weights : [1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529 1.09966529
 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353
 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353
 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353
 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353
 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353 0.50167353]
  0%|          | 0/20 [00:00<?, ?it/s]SNet: Task 1, Epoch 1/20 => Loss 1.640,  Train_accy 45.54, Test_accy 79.06:   0%|          | 0/20 [02:23<?, ?it/s]SNet: Task 1, Epoch 1/20 => Loss 1.640,  Train_accy 45.54, Test_accy 79.06:   5%|▌         | 1/20 [02:23<45:18, 143.10s/it]SNet: Task 1, Epoch 2/20 => Loss 1.519,  Train_accy 48.93:   5%|▌         | 1/20 [04:36<45:18, 143.10s/it]                 SNet: Task 1, Epoch 2/20 => Loss 1.519,  Train_accy 48.93:  10%|█         | 2/20 [04:36<41:12, 137.34s/it]SNet: Task 1, Epoch 3/20 => Loss 1.496,  Train_accy 49.70:  10%|█         | 2/20 [06:49<41:12, 137.34s/it]SNet: Task 1, Epoch 3/20 => Loss 1.496,  Train_accy 49.70:  15%|█▌        | 3/20 [06:49<38:23, 135.50s/it]SNet: Task 1, Epoch 4/20 => Loss 1.482,  Train_accy 50.00:  15%|█▌        | 3/20 [09:03<38:23, 135.50s/it]SNet: Task 1, Epoch 4/20 => Loss 1.482,  Train_accy 50.00:  20%|██        | 4/20 [09:03<35:54, 134.64s/it]SNet: Task 1, Epoch 5/20 => Loss 1.477,  Train_accy 49.61:  20%|██        | 4/20 [11:16<35:54, 134.64s/it]SNet: Task 1, Epoch 5/20 => Loss 1.477,  Train_accy 49.61:  25%|██▌       | 5/20 [11:16<33:32, 134.14s/it]SNet: Task 1, Epoch 6/20 => Loss 1.479,  Train_accy 49.95, Test_accy 79.37:  25%|██▌       | 5/20 [13:39<33:32, 134.14s/it]SNet: Task 1, Epoch 6/20 => Loss 1.479,  Train_accy 49.95, Test_accy 79.37:  30%|███       | 6/20 [13:39<32:00, 137.18s/it]SNet: Task 1, Epoch 7/20 => Loss 1.474,  Train_accy 50.23:  30%|███       | 6/20 [15:52<32:00, 137.18s/it]                 SNet: Task 1, Epoch 7/20 => Loss 1.474,  Train_accy 50.23:  35%|███▌      | 7/20 [15:52<29:26, 135.91s/it]SNet: Task 1, Epoch 8/20 => Loss 1.469,  Train_accy 50.38:  35%|███▌      | 7/20 [18:06<29:26, 135.91s/it]SNet: Task 1, Epoch 8/20 => Loss 1.469,  Train_accy 50.38:  40%|████      | 8/20 [18:06<27:01, 135.10s/it]SNet: Task 1, Epoch 9/20 => Loss 1.461,  Train_accy 51.03:  40%|████      | 8/20 [20:19<27:01, 135.10s/it]SNet: Task 1, Epoch 9/20 => Loss 1.461,  Train_accy 51.03:  45%|████▌     | 9/20 [20:19<24:39, 134.53s/it]SNet: Task 1, Epoch 10/20 => Loss 1.452,  Train_accy 51.04:  45%|████▌     | 9/20 [22:32<24:39, 134.53s/it]SNet: Task 1, Epoch 10/20 => Loss 1.452,  Train_accy 51.04:  50%|█████     | 10/20 [22:32<22:21, 134.14s/it]SNet: Task 1, Epoch 11/20 => Loss 1.453,  Train_accy 50.66, Test_accy 79.45:  50%|█████     | 10/20 [24:55<22:21, 134.14s/it]SNet: Task 1, Epoch 11/20 => Loss 1.453,  Train_accy 50.66, Test_accy 79.45:  55%|█████▌    | 11/20 [24:55<20:32, 136.97s/it]SNet: Task 1, Epoch 12/20 => Loss 1.467,  Train_accy 50.20:  55%|█████▌    | 11/20 [27:09<20:32, 136.97s/it]                 SNet: Task 1, Epoch 12/20 => Loss 1.467,  Train_accy 50.20:  60%|██████    | 12/20 [27:09<18:06, 135.87s/it]SNet: Task 1, Epoch 13/20 => Loss 1.454,  Train_accy 50.92:  60%|██████    | 12/20 [29:22<18:06, 135.87s/it]SNet: Task 1, Epoch 13/20 => Loss 1.454,  Train_accy 50.92:  65%|██████▌   | 13/20 [29:22<15:45, 135.09s/it]SNet: Task 1, Epoch 14/20 => Loss 1.458,  Train_accy 50.66:  65%|██████▌   | 13/20 [31:35<15:45, 135.09s/it]SNet: Task 1, Epoch 14/20 => Loss 1.458,  Train_accy 50.66:  70%|███████   | 14/20 [31:35<13:27, 134.56s/it]SNet: Task 1, Epoch 15/20 => Loss 1.467,  Train_accy 50.56:  70%|███████   | 14/20 [33:49<13:27, 134.56s/it]SNet: Task 1, Epoch 15/20 => Loss 1.467,  Train_accy 50.56:  75%|███████▌  | 15/20 [33:49<11:10, 134.17s/it]SNet: Task 1, Epoch 16/20 => Loss 1.458,  Train_accy 50.75, Test_accy 79.32:  75%|███████▌  | 15/20 [36:12<11:10, 134.17s/it]SNet: Task 1, Epoch 16/20 => Loss 1.458,  Train_accy 50.75, Test_accy 79.32:  80%|████████  | 16/20 [36:12<09:07, 136.92s/it]SNet: Task 1, Epoch 17/20 => Loss 1.464,  Train_accy 49.99:  80%|████████  | 16/20 [38:25<09:07, 136.92s/it]                 SNet: Task 1, Epoch 17/20 => Loss 1.464,  Train_accy 49.99:  85%|████████▌ | 17/20 [38:25<06:47, 135.85s/it]SNet: Task 1, Epoch 18/20 => Loss 1.446,  Train_accy 50.61:  85%|████████▌ | 17/20 [40:39<06:47, 135.85s/it]SNet: Task 1, Epoch 18/20 => Loss 1.446,  Train_accy 50.61:  90%|█████████ | 18/20 [40:39<04:30, 135.11s/it]SNet: Task 1, Epoch 19/20 => Loss 1.453,  Train_accy 50.80:  90%|█████████ | 18/20 [42:52<04:30, 135.11s/it]SNet: Task 1, Epoch 19/20 => Loss 1.453,  Train_accy 50.80:  95%|█████████▌| 19/20 [42:52<02:14, 134.53s/it]SNet: Task 1, Epoch 20/20 => Loss 1.448,  Train_accy 50.73:  95%|█████████▌| 19/20 [45:05<02:14, 134.53s/it]SNet: Task 1, Epoch 20/20 => Loss 1.448,  Train_accy 50.73: 100%|██████████| 20/20 [45:05<00:00, 134.14s/it]SNet: Task 1, Epoch 20/20 => Loss 1.448,  Train_accy 50.73: 100%|██████████| 20/20 [45:05<00:00, 135.28s/it]
2024-05-01 05:09:55,041 [foster.py] => SNet: Task 1, Epoch 20/20 => Loss 1.448,  Train_accy 50.73
2024-05-01 05:09:55,041 [foster.py] => do not weight align student!
2024-05-01 05:10:04,990 [foster.py] => darknet eval: 
2024-05-01 05:10:04,990 [foster.py] => CNN top1 curve: 79.2
2024-05-01 05:10:04,990 [foster.py] => CNN top5 curve: 96.41
2024-05-01 05:10:04,993 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 05:13:20,244 [foster.py] => Exemplar size: 3600
2024-05-01 05:13:20,244 [trainer.py] => CNN: {'total': 80.93, '00-149': 87.27, '150-179': 49.16, 'old': 87.27, 'new': 49.16}
2024-05-01 05:13:20,244 [trainer.py] => NME: {'total': 84.02, '00-149': 83.9, '150-179': 84.62, 'old': 83.9, 'new': 84.62}
2024-05-01 05:13:20,244 [trainer.py] => CNN top1 curve: [87.61, 80.93]
2024-05-01 05:13:20,244 [trainer.py] => CNN top5 curve: [97.83, 97.02]
2024-05-01 05:13:20,244 [trainer.py] => NME top1 curve: [86.81, 84.02]
2024-05-01 05:13:20,244 [trainer.py] => NME top5 curve: [97.7, 96.91]

Average Accuracy (CNN): 84.27
Average Accuracy (NME): 85.42
2024-05-01 05:13:20,244 [trainer.py] => Average Accuracy (CNN): 84.27
2024-05-01 05:13:20,244 [trainer.py] => Average Accuracy (NME): 85.42
2024-05-01 05:13:20,244 [trainer.py] => Train Time: 10778.27
2024-05-01 05:13:20,244 [trainer.py] => Test Time: 54.269999999999996 

2024-05-01 05:13:20,246 [trainer.py] => All params: 172127742
2024-05-01 05:13:20,247 [trainer.py] => Trainable params: 86213736
2024-05-01 05:13:22,559 [foster.py] => Learning on 180-210
2024-05-01 05:13:22,560 [foster.py] => All params: 172219992
2024-05-01 05:13:22,561 [foster.py] => Trainable params: 86282916
2024-05-01 05:13:22,620 [foster.py] => per cls weights : [1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899 1.06739899
 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604
 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604
 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604
 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604
 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604 0.59560604]
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 4.805, Loss_clf 1.090, Loss_fe 1.804, Loss_kd 1.637, Train_accy 51.42, Test_accy 76.96:   0%|          | 0/20 [02:12<?, ?it/s]Task 2, Epoch 1/20 => Loss 4.805, Loss_clf 1.090, Loss_fe 1.804, Loss_kd 1.637, Train_accy 51.42, Test_accy 76.96:   5%|▌         | 1/20 [02:12<41:53, 132.30s/it]Task 2, Epoch 2/20 => Loss 3.277, Loss_clf 0.580, Loss_fe 0.802, Loss_kd 1.624, Train_accy 54.35:   5%|▌         | 1/20 [04:02<41:53, 132.30s/it]                 Task 2, Epoch 2/20 => Loss 3.277, Loss_clf 0.580, Loss_fe 0.802, Loss_kd 1.624, Train_accy 54.35:  10%|█         | 2/20 [04:02<35:51, 119.51s/it]Task 2, Epoch 3/20 => Loss 3.023, Loss_clf 0.487, Loss_fe 0.657, Loss_kd 1.611, Train_accy 54.48:  10%|█         | 2/20 [05:53<35:51, 119.51s/it]Task 2, Epoch 3/20 => Loss 3.023, Loss_clf 0.487, Loss_fe 0.657, Loss_kd 1.611, Train_accy 54.48:  15%|█▌        | 3/20 [05:53<32:41, 115.36s/it]Task 2, Epoch 4/20 => Loss 2.933, Loss_clf 0.452, Loss_fe 0.593, Loss_kd 1.618, Train_accy 55.58:  15%|█▌        | 3/20 [07:43<32:41, 115.36s/it]Task 2, Epoch 4/20 => Loss 2.933, Loss_clf 0.452, Loss_fe 0.593, Loss_kd 1.618, Train_accy 55.58:  20%|██        | 4/20 [07:43<30:14, 113.40s/it]Task 2, Epoch 5/20 => Loss 2.779, Loss_clf 0.396, Loss_fe 0.501, Loss_kd 1.613, Train_accy 56.28:  20%|██        | 4/20 [09:34<30:14, 113.40s/it]Task 2, Epoch 5/20 => Loss 2.779, Loss_clf 0.396, Loss_fe 0.501, Loss_kd 1.613, Train_accy 56.28:  25%|██▌       | 5/20 [09:34<28:04, 112.31s/it]Task 2, Epoch 6/20 => Loss 2.715, Loss_clf 0.381, Loss_fe 0.468, Loss_kd 1.599, Train_accy 56.68, Test_accy 78.40:  25%|██▌       | 5/20 [11:45<28:04, 112.31s/it]Task 2, Epoch 6/20 => Loss 2.715, Loss_clf 0.381, Loss_fe 0.468, Loss_kd 1.599, Train_accy 56.68, Test_accy 78.40:  30%|███       | 6/20 [11:45<27:44, 118.89s/it]Task 2, Epoch 7/20 => Loss 2.606, Loss_clf 0.335, Loss_fe 0.401, Loss_kd 1.603, Train_accy 57.91:  30%|███       | 6/20 [13:36<27:44, 118.89s/it]                 Task 2, Epoch 7/20 => Loss 2.606, Loss_clf 0.335, Loss_fe 0.401, Loss_kd 1.603, Train_accy 57.91:  35%|███▌      | 7/20 [13:36<25:09, 116.12s/it]Task 2, Epoch 8/20 => Loss 2.536, Loss_clf 0.311, Loss_fe 0.362, Loss_kd 1.596, Train_accy 58.05:  35%|███▌      | 7/20 [15:26<25:09, 116.12s/it]Task 2, Epoch 8/20 => Loss 2.536, Loss_clf 0.311, Loss_fe 0.362, Loss_kd 1.596, Train_accy 58.05:  40%|████      | 8/20 [15:26<22:51, 114.31s/it]Task 2, Epoch 9/20 => Loss 2.526, Loss_clf 0.306, Loss_fe 0.345, Loss_kd 1.607, Train_accy 58.63:  40%|████      | 8/20 [17:16<22:51, 114.31s/it]Task 2, Epoch 9/20 => Loss 2.526, Loss_clf 0.306, Loss_fe 0.345, Loss_kd 1.607, Train_accy 58.63:  45%|████▌     | 9/20 [17:16<20:44, 113.10s/it]Task 2, Epoch 10/20 => Loss 2.500, Loss_clf 0.294, Loss_fe 0.318, Loss_kd 1.617, Train_accy 59.88:  45%|████▌     | 9/20 [19:07<20:44, 113.10s/it]Task 2, Epoch 10/20 => Loss 2.500, Loss_clf 0.294, Loss_fe 0.318, Loss_kd 1.617, Train_accy 59.88:  50%|█████     | 10/20 [19:07<18:43, 112.30s/it]Task 2, Epoch 11/20 => Loss 2.408, Loss_clf 0.254, Loss_fe 0.282, Loss_kd 1.604, Train_accy 60.85, Test_accy 78.13:  50%|█████     | 10/20 [21:19<18:43, 112.30s/it]Task 2, Epoch 11/20 => Loss 2.408, Loss_clf 0.254, Loss_fe 0.282, Loss_kd 1.604, Train_accy 60.85, Test_accy 78.13:  55%|█████▌    | 11/20 [21:19<17:44, 118.31s/it]Task 2, Epoch 12/20 => Loss 2.399, Loss_clf 0.253, Loss_fe 0.275, Loss_kd 1.605, Train_accy 61.47:  55%|█████▌    | 11/20 [23:09<17:44, 118.31s/it]                 Task 2, Epoch 12/20 => Loss 2.399, Loss_clf 0.253, Loss_fe 0.275, Loss_kd 1.605, Train_accy 61.47:  60%|██████    | 12/20 [23:09<15:27, 115.94s/it]Task 2, Epoch 13/20 => Loss 2.358, Loss_clf 0.232, Loss_fe 0.251, Loss_kd 1.607, Train_accy 61.75:  60%|██████    | 12/20 [25:00<15:27, 115.94s/it]Task 2, Epoch 13/20 => Loss 2.358, Loss_clf 0.232, Loss_fe 0.251, Loss_kd 1.607, Train_accy 61.75:  65%|██████▌   | 13/20 [25:00<13:20, 114.29s/it]Task 2, Epoch 14/20 => Loss 2.353, Loss_clf 0.235, Loss_fe 0.239, Loss_kd 1.610, Train_accy 62.00:  65%|██████▌   | 13/20 [26:50<13:20, 114.29s/it]Task 2, Epoch 14/20 => Loss 2.353, Loss_clf 0.235, Loss_fe 0.239, Loss_kd 1.610, Train_accy 62.00:  70%|███████   | 14/20 [26:50<11:18, 113.12s/it]Task 2, Epoch 15/20 => Loss 2.358, Loss_clf 0.231, Loss_fe 0.231, Loss_kd 1.625, Train_accy 61.76:  70%|███████   | 14/20 [28:41<11:18, 113.12s/it]Task 2, Epoch 15/20 => Loss 2.358, Loss_clf 0.231, Loss_fe 0.231, Loss_kd 1.625, Train_accy 61.76:  75%|███████▌  | 15/20 [28:41<09:21, 112.31s/it]Task 2, Epoch 16/20 => Loss 2.286, Loss_clf 0.208, Loss_fe 0.200, Loss_kd 1.609, Train_accy 62.70, Test_accy 78.59:  75%|███████▌  | 15/20 [30:53<09:21, 112.31s/it]Task 2, Epoch 16/20 => Loss 2.286, Loss_clf 0.208, Loss_fe 0.200, Loss_kd 1.609, Train_accy 62.70, Test_accy 78.59:  80%|████████  | 16/20 [30:53<07:52, 118.21s/it]Task 2, Epoch 17/20 => Loss 2.277, Loss_clf 0.214, Loss_fe 0.198, Loss_kd 1.598, Train_accy 63.10:  80%|████████  | 16/20 [32:43<07:52, 118.21s/it]                 Task 2, Epoch 17/20 => Loss 2.277, Loss_clf 0.214, Loss_fe 0.198, Loss_kd 1.598, Train_accy 63.10:  85%|████████▌ | 17/20 [32:43<05:47, 115.90s/it]Task 2, Epoch 18/20 => Loss 2.293, Loss_clf 0.214, Loss_fe 0.209, Loss_kd 1.604, Train_accy 62.48:  85%|████████▌ | 17/20 [34:34<05:47, 115.90s/it]Task 2, Epoch 18/20 => Loss 2.293, Loss_clf 0.214, Loss_fe 0.209, Loss_kd 1.604, Train_accy 62.48:  90%|█████████ | 18/20 [34:34<03:48, 114.30s/it]Task 2, Epoch 19/20 => Loss 2.219, Loss_clf 0.179, Loss_fe 0.175, Loss_kd 1.599, Train_accy 63.10:  90%|█████████ | 18/20 [36:24<03:48, 114.30s/it]Task 2, Epoch 19/20 => Loss 2.219, Loss_clf 0.179, Loss_fe 0.175, Loss_kd 1.599, Train_accy 63.10:  95%|█████████▌| 19/20 [36:24<01:53, 113.12s/it]Task 2, Epoch 20/20 => Loss 2.251, Loss_clf 0.191, Loss_fe 0.185, Loss_kd 1.608, Train_accy 62.33:  95%|█████████▌| 19/20 [38:15<01:53, 113.12s/it]Task 2, Epoch 20/20 => Loss 2.251, Loss_clf 0.191, Loss_fe 0.185, Loss_kd 1.608, Train_accy 62.33: 100%|██████████| 20/20 [38:15<00:00, 112.32s/it]Task 2, Epoch 20/20 => Loss 2.251, Loss_clf 0.191, Loss_fe 0.185, Loss_kd 1.608, Train_accy 62.33: 100%|██████████| 20/20 [38:15<00:00, 114.76s/it]
2024-05-01 05:51:37,749 [foster.py] => Task 2, Epoch 20/20 => Loss 2.251, Loss_clf 0.191, Loss_fe 0.185, Loss_kd 1.608, Train_accy 62.33
2024-05-01 05:51:37,751 [foster.py] => do not weight align teacher!
2024-05-01 05:51:37,760 [foster.py] => per cls weights : [1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816 1.08422816
 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102
 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102
 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102
 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102
 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102 0.49463102]
  0%|          | 0/20 [00:00<?, ?it/s]SNet: Task 2, Epoch 1/20 => Loss 1.865,  Train_accy 46.39, Test_accy 77.11:   0%|          | 0/20 [02:31<?, ?it/s]SNet: Task 2, Epoch 1/20 => Loss 1.865,  Train_accy 46.39, Test_accy 77.11:   5%|▌         | 1/20 [02:31<47:53, 151.26s/it]SNet: Task 2, Epoch 2/20 => Loss 1.713,  Train_accy 51.05:   5%|▌         | 1/20 [04:50<47:53, 151.26s/it]                 SNet: Task 2, Epoch 2/20 => Loss 1.713,  Train_accy 51.05:  10%|█         | 2/20 [04:50<43:19, 144.43s/it]SNet: Task 2, Epoch 3/20 => Loss 1.689,  Train_accy 51.10:  10%|█         | 2/20 [07:10<43:19, 144.43s/it]SNet: Task 2, Epoch 3/20 => Loss 1.689,  Train_accy 51.10:  15%|█▌        | 3/20 [07:10<40:18, 142.26s/it]SNet: Task 2, Epoch 4/20 => Loss 1.686,  Train_accy 51.70:  15%|█▌        | 3/20 [09:30<40:18, 142.26s/it]SNet: Task 2, Epoch 4/20 => Loss 1.686,  Train_accy 51.70:  20%|██        | 4/20 [09:30<37:39, 141.21s/it]SNet: Task 2, Epoch 5/20 => Loss 1.672,  Train_accy 52.32:  20%|██        | 4/20 [11:49<37:39, 141.21s/it]SNet: Task 2, Epoch 5/20 => Loss 1.672,  Train_accy 52.32:  25%|██▌       | 5/20 [11:49<35:09, 140.65s/it]SNet: Task 2, Epoch 6/20 => Loss 1.660,  Train_accy 52.12, Test_accy 77.32:  25%|██▌       | 5/20 [14:21<35:09, 140.65s/it]SNet: Task 2, Epoch 6/20 => Loss 1.660,  Train_accy 52.12, Test_accy 77.32:  30%|███       | 6/20 [14:21<33:39, 144.25s/it]SNet: Task 2, Epoch 7/20 => Loss 1.654,  Train_accy 52.81:  30%|███       | 6/20 [16:40<33:39, 144.25s/it]                 SNet: Task 2, Epoch 7/20 => Loss 1.654,  Train_accy 52.81:  35%|███▌      | 7/20 [16:40<30:55, 142.75s/it]SNet: Task 2, Epoch 8/20 => Loss 1.663,  Train_accy 52.63:  35%|███▌      | 7/20 [19:00<30:55, 142.75s/it]SNet: Task 2, Epoch 8/20 => Loss 1.663,  Train_accy 52.63:  40%|████      | 8/20 [19:00<28:21, 141.78s/it]SNet: Task 2, Epoch 9/20 => Loss 1.664,  Train_accy 53.15:  40%|████      | 8/20 [21:20<28:21, 141.78s/it]SNet: Task 2, Epoch 9/20 => Loss 1.664,  Train_accy 53.15:  45%|████▌     | 9/20 [21:20<25:52, 141.13s/it]SNet: Task 2, Epoch 10/20 => Loss 1.658,  Train_accy 52.76:  45%|████▌     | 9/20 [23:39<25:52, 141.13s/it]SNet: Task 2, Epoch 10/20 => Loss 1.658,  Train_accy 52.76:  50%|█████     | 10/20 [23:39<23:26, 140.68s/it]SNet: Task 2, Epoch 11/20 => Loss 1.649,  Train_accy 52.67, Test_accy 77.32:  50%|█████     | 10/20 [26:11<23:26, 140.68s/it]SNet: Task 2, Epoch 11/20 => Loss 1.649,  Train_accy 52.67, Test_accy 77.32:  55%|█████▌    | 11/20 [26:11<21:35, 143.91s/it]SNet: Task 2, Epoch 12/20 => Loss 1.661,  Train_accy 52.80:  55%|█████▌    | 11/20 [28:30<21:35, 143.91s/it]                 SNet: Task 2, Epoch 12/20 => Loss 1.661,  Train_accy 52.80:  60%|██████    | 12/20 [28:30<19:00, 142.62s/it]SNet: Task 2, Epoch 13/20 => Loss 1.645,  Train_accy 53.33:  60%|██████    | 12/20 [30:50<19:00, 142.62s/it]SNet: Task 2, Epoch 13/20 => Loss 1.645,  Train_accy 53.33:  65%|██████▌   | 13/20 [30:50<16:32, 141.72s/it]SNet: Task 2, Epoch 14/20 => Loss 1.648,  Train_accy 53.35:  65%|██████▌   | 13/20 [33:09<16:32, 141.72s/it]SNet: Task 2, Epoch 14/20 => Loss 1.648,  Train_accy 53.35:  70%|███████   | 14/20 [33:09<14:06, 141.07s/it]SNet: Task 2, Epoch 15/20 => Loss 1.643,  Train_accy 53.16:  70%|███████   | 14/20 [35:29<14:06, 141.07s/it]SNet: Task 2, Epoch 15/20 => Loss 1.643,  Train_accy 53.16:  75%|███████▌  | 15/20 [35:29<11:43, 140.64s/it]SNet: Task 2, Epoch 16/20 => Loss 1.655,  Train_accy 53.00, Test_accy 77.54:  75%|███████▌  | 15/20 [38:00<11:43, 140.64s/it]SNet: Task 2, Epoch 16/20 => Loss 1.655,  Train_accy 53.00, Test_accy 77.54:  80%|████████  | 16/20 [38:00<09:35, 143.81s/it]SNet: Task 2, Epoch 17/20 => Loss 1.661,  Train_accy 52.83:  80%|████████  | 16/20 [40:20<09:35, 143.81s/it]                 SNet: Task 2, Epoch 17/20 => Loss 1.661,  Train_accy 52.83:  85%|████████▌ | 17/20 [40:20<07:07, 142.59s/it]SNet: Task 2, Epoch 18/20 => Loss 1.654,  Train_accy 52.69:  85%|████████▌ | 17/20 [42:40<07:07, 142.59s/it]SNet: Task 2, Epoch 18/20 => Loss 1.654,  Train_accy 52.69:  90%|█████████ | 18/20 [42:40<04:43, 141.71s/it]SNet: Task 2, Epoch 19/20 => Loss 1.656,  Train_accy 53.12:  90%|█████████ | 18/20 [44:59<04:43, 141.71s/it]SNet: Task 2, Epoch 19/20 => Loss 1.656,  Train_accy 53.12:  95%|█████████▌| 19/20 [44:59<02:21, 141.09s/it]SNet: Task 2, Epoch 20/20 => Loss 1.660,  Train_accy 52.75:  95%|█████████▌| 19/20 [47:19<02:21, 141.09s/it]SNet: Task 2, Epoch 20/20 => Loss 1.660,  Train_accy 52.75: 100%|██████████| 20/20 [47:19<00:00, 140.68s/it]SNet: Task 2, Epoch 20/20 => Loss 1.660,  Train_accy 52.75: 100%|██████████| 20/20 [47:19<00:00, 141.98s/it]
2024-05-01 06:38:58,979 [foster.py] => SNet: Task 2, Epoch 20/20 => Loss 1.660,  Train_accy 52.75
2024-05-01 06:38:58,979 [foster.py] => do not weight align student!
2024-05-01 06:39:10,446 [foster.py] => darknet eval: 
2024-05-01 06:39:10,446 [foster.py] => CNN top1 curve: 77.54
2024-05-01 06:39:10,446 [foster.py] => CNN top5 curve: 95.75
2024-05-01 06:39:10,448 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 06:42:46,162 [foster.py] => Exemplar size: 4200
2024-05-01 06:42:46,162 [trainer.py] => CNN: {'total': 78.52, '00-149': 86.51, '150-179': 67.39, '180-209': 49.58, 'old': 83.32, 'new': 49.58}
2024-05-01 06:42:46,162 [trainer.py] => NME: {'total': 82.38, '00-149': 83.3, '150-179': 74.25, '180-209': 85.93, 'old': 81.79, 'new': 85.93}
2024-05-01 06:42:46,162 [trainer.py] => CNN top1 curve: [87.61, 80.93, 78.52]
2024-05-01 06:42:46,162 [trainer.py] => CNN top5 curve: [97.83, 97.02, 96.25]
2024-05-01 06:42:46,162 [trainer.py] => NME top1 curve: [86.81, 84.02, 82.38]
2024-05-01 06:42:46,162 [trainer.py] => NME top5 curve: [97.7, 96.91, 96.32]

Average Accuracy (CNN): 82.35
Average Accuracy (NME): 84.4
2024-05-01 06:42:46,162 [trainer.py] => Average Accuracy (CNN): 82.35
2024-05-01 06:42:46,162 [trainer.py] => Average Accuracy (NME): 84.4
2024-05-01 06:42:46,162 [trainer.py] => Train Time: 15926.14
2024-05-01 06:42:46,162 [trainer.py] => Test Time: 98.1 

2024-05-01 06:42:46,164 [trainer.py] => All params: 172219992
2024-05-01 06:42:46,165 [trainer.py] => Trainable params: 86282916
2024-05-01 06:42:47,821 [foster.py] => Learning on 210-240
2024-05-01 06:42:47,822 [foster.py] => All params: 172312242
2024-05-01 06:42:47,823 [foster.py] => Trainable params: 86352096
2024-05-01 06:42:47,896 [foster.py] => per cls weights : [1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142 1.05848142
 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006
 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006
 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006
 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006
 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006 0.59063006]
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 4.975, Loss_clf 1.190, Loss_fe 1.968, Loss_kd 1.590, Train_accy 44.42, Test_accy 74.96:   0%|          | 0/20 [02:25<?, ?it/s]Task 3, Epoch 1/20 => Loss 4.975, Loss_clf 1.190, Loss_fe 1.968, Loss_kd 1.590, Train_accy 44.42, Test_accy 74.96:   5%|▌         | 1/20 [02:25<45:56, 145.08s/it]Task 3, Epoch 2/20 => Loss 3.354, Loss_clf 0.659, Loss_fe 0.891, Loss_kd 1.578, Train_accy 47.17:   5%|▌         | 1/20 [04:25<45:56, 145.08s/it]                 Task 3, Epoch 2/20 => Loss 3.354, Loss_clf 0.659, Loss_fe 0.891, Loss_kd 1.578, Train_accy 47.17:  10%|█         | 2/20 [04:25<39:05, 130.33s/it]Task 3, Epoch 3/20 => Loss 3.086, Loss_clf 0.553, Loss_fe 0.732, Loss_kd 1.576, Train_accy 47.80:  10%|█         | 2/20 [06:25<39:05, 130.33s/it]Task 3, Epoch 3/20 => Loss 3.086, Loss_clf 0.553, Loss_fe 0.732, Loss_kd 1.576, Train_accy 47.80:  15%|█▌        | 3/20 [06:25<35:34, 125.58s/it]Task 3, Epoch 4/20 => Loss 2.971, Loss_clf 0.529, Loss_fe 0.639, Loss_kd 1.578, Train_accy 48.26:  15%|█▌        | 3/20 [08:24<35:34, 125.58s/it]Task 3, Epoch 4/20 => Loss 2.971, Loss_clf 0.529, Loss_fe 0.639, Loss_kd 1.578, Train_accy 48.26:  20%|██        | 4/20 [08:24<32:53, 123.35s/it]Task 3, Epoch 5/20 => Loss 2.850, Loss_clf 0.483, Loss_fe 0.580, Loss_kd 1.564, Train_accy 48.66:  20%|██        | 4/20 [10:24<32:53, 123.35s/it]Task 3, Epoch 5/20 => Loss 2.850, Loss_clf 0.483, Loss_fe 0.580, Loss_kd 1.564, Train_accy 48.66:  25%|██▌       | 5/20 [10:24<30:32, 122.15s/it]Task 3, Epoch 6/20 => Loss 2.745, Loss_clf 0.437, Loss_fe 0.512, Loss_kd 1.571, Train_accy 49.71, Test_accy 75.67:  25%|██▌       | 5/20 [12:49<30:32, 122.15s/it]Task 3, Epoch 6/20 => Loss 2.745, Loss_clf 0.437, Loss_fe 0.512, Loss_kd 1.571, Train_accy 49.71, Test_accy 75.67:  30%|███       | 6/20 [12:49<30:17, 129.79s/it]Task 3, Epoch 7/20 => Loss 2.677, Loss_clf 0.412, Loss_fe 0.477, Loss_kd 1.565, Train_accy 49.73:  30%|███       | 6/20 [14:49<30:17, 129.79s/it]                 Task 3, Epoch 7/20 => Loss 2.677, Loss_clf 0.412, Loss_fe 0.477, Loss_kd 1.565, Train_accy 49.73:  35%|███▌      | 7/20 [14:49<27:25, 126.54s/it]Task 3, Epoch 8/20 => Loss 2.607, Loss_clf 0.387, Loss_fe 0.432, Loss_kd 1.564, Train_accy 50.42:  35%|███▌      | 7/20 [16:49<27:25, 126.54s/it]Task 3, Epoch 8/20 => Loss 2.607, Loss_clf 0.387, Loss_fe 0.432, Loss_kd 1.564, Train_accy 50.42:  40%|████      | 8/20 [16:49<24:53, 124.46s/it]Task 3, Epoch 9/20 => Loss 2.517, Loss_clf 0.343, Loss_fe 0.386, Loss_kd 1.565, Train_accy 50.99:  40%|████      | 8/20 [18:49<24:53, 124.46s/it]Task 3, Epoch 9/20 => Loss 2.517, Loss_clf 0.343, Loss_fe 0.386, Loss_kd 1.565, Train_accy 50.99:  45%|████▌     | 9/20 [18:49<22:33, 123.04s/it]Task 3, Epoch 10/20 => Loss 2.515, Loss_clf 0.337, Loss_fe 0.371, Loss_kd 1.581, Train_accy 51.91:  45%|████▌     | 9/20 [20:49<22:33, 123.04s/it]Task 3, Epoch 10/20 => Loss 2.515, Loss_clf 0.337, Loss_fe 0.371, Loss_kd 1.581, Train_accy 51.91:  50%|█████     | 10/20 [20:49<20:20, 122.05s/it]Task 3, Epoch 11/20 => Loss 2.450, Loss_clf 0.311, Loss_fe 0.333, Loss_kd 1.581, Train_accy 52.95, Test_accy 75.73:  50%|█████     | 10/20 [23:13<20:20, 122.05s/it]Task 3, Epoch 11/20 => Loss 2.450, Loss_clf 0.311, Loss_fe 0.333, Loss_kd 1.581, Train_accy 52.95, Test_accy 75.73:  55%|█████▌    | 11/20 [23:13<19:19, 128.88s/it]Task 3, Epoch 12/20 => Loss 2.383, Loss_clf 0.290, Loss_fe 0.306, Loss_kd 1.564, Train_accy 51.81:  55%|█████▌    | 11/20 [25:13<19:19, 128.88s/it]                 Task 3, Epoch 12/20 => Loss 2.383, Loss_clf 0.290, Loss_fe 0.306, Loss_kd 1.564, Train_accy 51.81:  60%|██████    | 12/20 [25:13<16:49, 126.17s/it]Task 3, Epoch 13/20 => Loss 2.330, Loss_clf 0.271, Loss_fe 0.278, Loss_kd 1.558, Train_accy 52.30:  60%|██████    | 12/20 [27:13<16:49, 126.17s/it]Task 3, Epoch 13/20 => Loss 2.330, Loss_clf 0.271, Loss_fe 0.278, Loss_kd 1.558, Train_accy 52.30:  65%|██████▌   | 13/20 [27:13<14:29, 124.24s/it]Task 3, Epoch 14/20 => Loss 2.294, Loss_clf 0.251, Loss_fe 0.248, Loss_kd 1.570, Train_accy 53.28:  65%|██████▌   | 13/20 [29:13<14:29, 124.24s/it]Task 3, Epoch 14/20 => Loss 2.294, Loss_clf 0.251, Loss_fe 0.248, Loss_kd 1.570, Train_accy 53.28:  70%|███████   | 14/20 [29:13<12:17, 122.91s/it]Task 3, Epoch 15/20 => Loss 2.261, Loss_clf 0.240, Loss_fe 0.232, Loss_kd 1.565, Train_accy 53.19:  70%|███████   | 14/20 [31:12<12:17, 122.91s/it]Task 3, Epoch 15/20 => Loss 2.261, Loss_clf 0.240, Loss_fe 0.232, Loss_kd 1.565, Train_accy 53.19:  75%|███████▌  | 15/20 [31:12<10:09, 121.97s/it]Task 3, Epoch 16/20 => Loss 2.255, Loss_clf 0.238, Loss_fe 0.227, Loss_kd 1.565, Train_accy 53.26, Test_accy 76.07:  75%|███████▌  | 15/20 [33:36<10:09, 121.97s/it]Task 3, Epoch 16/20 => Loss 2.255, Loss_clf 0.238, Loss_fe 0.227, Loss_kd 1.565, Train_accy 53.26, Test_accy 76.07:  80%|████████  | 16/20 [33:36<08:34, 128.60s/it]Task 3, Epoch 17/20 => Loss 2.253, Loss_clf 0.237, Loss_fe 0.222, Loss_kd 1.570, Train_accy 53.36:  80%|████████  | 16/20 [35:36<08:34, 128.60s/it]                 Task 3, Epoch 17/20 => Loss 2.253, Loss_clf 0.237, Loss_fe 0.222, Loss_kd 1.570, Train_accy 53.36:  85%|████████▌ | 17/20 [35:36<06:17, 125.99s/it]Task 3, Epoch 18/20 => Loss 2.249, Loss_clf 0.235, Loss_fe 0.218, Loss_kd 1.571, Train_accy 53.71:  85%|████████▌ | 17/20 [37:36<06:17, 125.99s/it]Task 3, Epoch 18/20 => Loss 2.249, Loss_clf 0.235, Loss_fe 0.218, Loss_kd 1.571, Train_accy 53.71:  90%|█████████ | 18/20 [37:36<04:08, 124.21s/it]Task 3, Epoch 19/20 => Loss 2.237, Loss_clf 0.228, Loss_fe 0.217, Loss_kd 1.568, Train_accy 53.28:  90%|█████████ | 18/20 [39:36<04:08, 124.21s/it]Task 3, Epoch 19/20 => Loss 2.237, Loss_clf 0.228, Loss_fe 0.217, Loss_kd 1.568, Train_accy 53.28:  95%|█████████▌| 19/20 [39:36<02:02, 122.92s/it]Task 3, Epoch 20/20 => Loss 2.218, Loss_clf 0.216, Loss_fe 0.205, Loss_kd 1.573, Train_accy 53.80:  95%|█████████▌| 19/20 [41:36<02:02, 122.92s/it]Task 3, Epoch 20/20 => Loss 2.218, Loss_clf 0.216, Loss_fe 0.205, Loss_kd 1.573, Train_accy 53.80: 100%|██████████| 20/20 [41:36<00:00, 122.02s/it]Task 3, Epoch 20/20 => Loss 2.218, Loss_clf 0.216, Loss_fe 0.205, Loss_kd 1.573, Train_accy 53.80: 100%|██████████| 20/20 [41:36<00:00, 124.84s/it]
2024-05-01 07:24:24,662 [foster.py] => Task 3, Epoch 20/20 => Loss 2.218, Loss_clf 0.216, Loss_fe 0.205, Loss_kd 1.573, Train_accy 53.80
2024-05-01 07:24:24,664 [foster.py] => do not weight align teacher!
2024-05-01 07:24:24,674 [foster.py] => per cls weights : [1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178 1.07293178
 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755
 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755
 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755
 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755
 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755 0.48947755]
  0%|          | 0/20 [00:00<?, ?it/s]SNet: Task 3, Epoch 1/20 => Loss 1.816,  Train_accy 40.07, Test_accy 74.31:   0%|          | 0/20 [02:44<?, ?it/s]SNet: Task 3, Epoch 1/20 => Loss 1.816,  Train_accy 40.07, Test_accy 74.31:   5%|▌         | 1/20 [02:44<52:10, 164.76s/it]SNet: Task 3, Epoch 2/20 => Loss 1.727,  Train_accy 42.95:   5%|▌         | 1/20 [05:16<52:10, 164.76s/it]                 SNet: Task 3, Epoch 2/20 => Loss 1.727,  Train_accy 42.95:  10%|█         | 2/20 [05:16<47:07, 157.06s/it]SNet: Task 3, Epoch 3/20 => Loss 1.721,  Train_accy 43.56:  10%|█         | 2/20 [07:48<47:07, 157.06s/it]SNet: Task 3, Epoch 3/20 => Loss 1.721,  Train_accy 43.56:  15%|█▌        | 3/20 [07:48<43:48, 154.59s/it]SNet: Task 3, Epoch 4/20 => Loss 1.719,  Train_accy 43.51:  15%|█▌        | 3/20 [10:19<43:48, 154.59s/it]SNet: Task 3, Epoch 4/20 => Loss 1.719,  Train_accy 43.51:  20%|██        | 4/20 [10:19<40:54, 153.41s/it]SNet: Task 3, Epoch 5/20 => Loss 1.713,  Train_accy 43.87:  20%|██        | 4/20 [12:51<40:54, 153.41s/it]SNet: Task 3, Epoch 5/20 => Loss 1.713,  Train_accy 43.87:  25%|██▌       | 5/20 [12:51<38:11, 152.75s/it]SNet: Task 3, Epoch 6/20 => Loss 1.696,  Train_accy 44.27, Test_accy 74.79:  25%|██▌       | 5/20 [15:35<38:11, 152.75s/it]SNet: Task 3, Epoch 6/20 => Loss 1.696,  Train_accy 44.27, Test_accy 74.79:  30%|███       | 6/20 [15:35<36:35, 156.81s/it]SNet: Task 3, Epoch 7/20 => Loss 1.686,  Train_accy 44.47:  30%|███       | 6/20 [18:07<36:35, 156.81s/it]                 SNet: Task 3, Epoch 7/20 => Loss 1.686,  Train_accy 44.47:  35%|███▌      | 7/20 [18:07<33:36, 155.14s/it]SNet: Task 3, Epoch 8/20 => Loss 1.691,  Train_accy 44.39:  35%|███▌      | 7/20 [20:39<33:36, 155.14s/it]SNet: Task 3, Epoch 8/20 => Loss 1.691,  Train_accy 44.39:  40%|████      | 8/20 [20:39<30:48, 154.05s/it]SNet: Task 3, Epoch 9/20 => Loss 1.684,  Train_accy 44.67:  40%|████      | 8/20 [23:11<30:48, 154.05s/it]SNet: Task 3, Epoch 9/20 => Loss 1.684,  Train_accy 44.67:  45%|████▌     | 9/20 [23:11<28:06, 153.33s/it]SNet: Task 3, Epoch 10/20 => Loss 1.681,  Train_accy 44.39:  45%|████▌     | 9/20 [25:42<28:06, 153.33s/it]SNet: Task 3, Epoch 10/20 => Loss 1.681,  Train_accy 44.39:  50%|█████     | 10/20 [25:42<25:27, 152.79s/it]SNet: Task 3, Epoch 11/20 => Loss 1.685,  Train_accy 44.44, Test_accy 74.50:  50%|█████     | 10/20 [28:27<25:27, 152.79s/it]SNet: Task 3, Epoch 11/20 => Loss 1.685,  Train_accy 44.44, Test_accy 74.50:  55%|█████▌    | 11/20 [28:27<23:27, 156.42s/it]SNet: Task 3, Epoch 12/20 => Loss 1.682,  Train_accy 44.88:  55%|█████▌    | 11/20 [30:58<23:27, 156.42s/it]                 SNet: Task 3, Epoch 12/20 => Loss 1.682,  Train_accy 44.88:  60%|██████    | 12/20 [30:58<20:39, 154.97s/it]SNet: Task 3, Epoch 13/20 => Loss 1.684,  Train_accy 44.51:  60%|██████    | 12/20 [33:30<20:39, 154.97s/it]SNet: Task 3, Epoch 13/20 => Loss 1.684,  Train_accy 44.51:  65%|██████▌   | 13/20 [33:30<17:57, 153.98s/it]SNet: Task 3, Epoch 14/20 => Loss 1.675,  Train_accy 44.72:  65%|██████▌   | 13/20 [36:02<17:57, 153.98s/it]SNet: Task 3, Epoch 14/20 => Loss 1.675,  Train_accy 44.72:  70%|███████   | 14/20 [36:02<15:19, 153.26s/it]SNet: Task 3, Epoch 15/20 => Loss 1.673,  Train_accy 44.75:  70%|███████   | 14/20 [38:34<15:19, 153.26s/it]SNet: Task 3, Epoch 15/20 => Loss 1.673,  Train_accy 44.75:  75%|███████▌  | 15/20 [38:34<12:43, 152.80s/it]SNet: Task 3, Epoch 16/20 => Loss 1.679,  Train_accy 44.77, Test_accy 74.54:  75%|███████▌  | 15/20 [41:19<12:43, 152.80s/it]SNet: Task 3, Epoch 16/20 => Loss 1.679,  Train_accy 44.77, Test_accy 74.54:  80%|████████  | 16/20 [41:19<10:25, 156.47s/it]SNet: Task 3, Epoch 17/20 => Loss 1.677,  Train_accy 44.32:  80%|████████  | 16/20 [43:50<10:25, 156.47s/it]                 SNet: Task 3, Epoch 17/20 => Loss 1.677,  Train_accy 44.32:  85%|████████▌ | 17/20 [43:50<07:45, 155.02s/it]SNet: Task 3, Epoch 18/20 => Loss 1.691,  Train_accy 44.67:  85%|████████▌ | 17/20 [46:22<07:45, 155.02s/it]SNet: Task 3, Epoch 18/20 => Loss 1.691,  Train_accy 44.67:  90%|█████████ | 18/20 [46:22<05:08, 154.02s/it]SNet: Task 3, Epoch 19/20 => Loss 1.680,  Train_accy 44.54:  90%|█████████ | 18/20 [48:54<05:08, 154.02s/it]SNet: Task 3, Epoch 19/20 => Loss 1.680,  Train_accy 44.54:  95%|█████████▌| 19/20 [48:54<02:33, 153.35s/it]SNet: Task 3, Epoch 20/20 => Loss 1.668,  Train_accy 44.77:  95%|█████████▌| 19/20 [51:25<02:33, 153.35s/it]SNet: Task 3, Epoch 20/20 => Loss 1.668,  Train_accy 44.77: 100%|██████████| 20/20 [51:25<00:00, 152.89s/it]SNet: Task 3, Epoch 20/20 => Loss 1.668,  Train_accy 44.77: 100%|██████████| 20/20 [51:25<00:00, 154.30s/it]
2024-05-01 08:15:52,754 [foster.py] => SNet: Task 3, Epoch 20/20 => Loss 1.668,  Train_accy 44.77
2024-05-01 08:15:52,754 [foster.py] => do not weight align student!
2024-05-01 08:16:05,839 [foster.py] => darknet eval: 
2024-05-01 08:16:05,839 [foster.py] => CNN top1 curve: 74.58
2024-05-01 08:16:05,839 [foster.py] => CNN top5 curve: 94.95
2024-05-01 08:16:05,842 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 08:20:08,281 [foster.py] => Exemplar size: 4800
2024-05-01 08:20:08,281 [trainer.py] => CNN: {'total': 75.71, '00-149': 85.87, '150-179': 72.07, '180-209': 67.17, '210-239': 37.06, 'old': 81.24, 'new': 37.06}
2024-05-01 08:20:08,281 [trainer.py] => NME: {'total': 80.79, '00-149': 81.66, '150-179': 74.75, '180-209': 78.22, '210-239': 84.97, 'old': 80.19, 'new': 84.97}
2024-05-01 08:20:08,281 [trainer.py] => CNN top1 curve: [87.61, 80.93, 78.52, 75.71]
2024-05-01 08:20:08,281 [trainer.py] => CNN top5 curve: [97.83, 97.02, 96.25, 95.34]
2024-05-01 08:20:08,282 [trainer.py] => NME top1 curve: [86.81, 84.02, 82.38, 80.79]
2024-05-01 08:20:08,282 [trainer.py] => NME top5 curve: [97.7, 96.91, 96.32, 95.78]

Average Accuracy (CNN): 80.69
Average Accuracy (NME): 83.5
2024-05-01 08:20:08,282 [trainer.py] => Average Accuracy (CNN): 80.69
2024-05-01 08:20:08,282 [trainer.py] => Average Accuracy (NME): 83.5
2024-05-01 08:20:08,282 [trainer.py] => Train Time: 21524.14
2024-05-01 08:20:08,282 [trainer.py] => Test Time: 148.63 

2024-05-01 08:20:08,284 [trainer.py] => All params: 172312242
2024-05-01 08:20:08,285 [trainer.py] => Trainable params: 86352096
2024-05-01 08:20:10,896 [foster.py] => Learning on 240-270
2024-05-01 08:20:10,898 [foster.py] => All params: 172404492
2024-05-01 08:20:10,899 [foster.py] => Trainable params: 86421276
2024-05-01 08:20:10,967 [foster.py] => per cls weights : [1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788 1.05164788
 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696
 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696
 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696
 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696
 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696 0.58681696]
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 4.900, Loss_clf 1.010, Loss_fe 1.986, Loss_kd 1.693, Train_accy 47.74, Test_accy 73.86:   0%|          | 0/20 [02:31<?, ?it/s]Task 4, Epoch 1/20 => Loss 4.900, Loss_clf 1.010, Loss_fe 1.986, Loss_kd 1.693, Train_accy 47.74, Test_accy 73.86:   5%|▌         | 1/20 [02:31<48:05, 151.88s/it]Task 4, Epoch 2/20 => Loss 3.345, Loss_clf 0.560, Loss_fe 0.887, Loss_kd 1.686, Train_accy 49.85:   5%|▌         | 1/20 [04:35<48:05, 151.88s/it]                 Task 4, Epoch 2/20 => Loss 3.345, Loss_clf 0.560, Loss_fe 0.887, Loss_kd 1.686, Train_accy 49.85:  10%|█         | 2/20 [04:35<40:38, 135.50s/it]Task 4, Epoch 3/20 => Loss 3.120, Loss_clf 0.493, Loss_fe 0.732, Loss_kd 1.684, Train_accy 50.26:  10%|█         | 2/20 [06:39<40:38, 135.50s/it]Task 4, Epoch 3/20 => Loss 3.120, Loss_clf 0.493, Loss_fe 0.732, Loss_kd 1.684, Train_accy 50.26:  15%|█▌        | 3/20 [06:39<36:54, 130.25s/it]Task 4, Epoch 4/20 => Loss 2.969, Loss_clf 0.444, Loss_fe 0.633, Loss_kd 1.682, Train_accy 51.77:  15%|█▌        | 3/20 [08:43<36:54, 130.25s/it]Task 4, Epoch 4/20 => Loss 2.969, Loss_clf 0.444, Loss_fe 0.633, Loss_kd 1.682, Train_accy 51.77:  20%|██        | 4/20 [08:43<34:04, 127.78s/it]Task 4, Epoch 5/20 => Loss 2.856, Loss_clf 0.415, Loss_fe 0.565, Loss_kd 1.668, Train_accy 51.60:  20%|██        | 4/20 [10:47<34:04, 127.78s/it]Task 4, Epoch 5/20 => Loss 2.856, Loss_clf 0.415, Loss_fe 0.565, Loss_kd 1.668, Train_accy 51.60:  25%|██▌       | 5/20 [10:47<31:36, 126.41s/it]Task 4, Epoch 6/20 => Loss 2.736, Loss_clf 0.372, Loss_fe 0.482, Loss_kd 1.673, Train_accy 53.05, Test_accy 74.68:  25%|██▌       | 5/20 [13:19<31:36, 126.41s/it]Task 4, Epoch 6/20 => Loss 2.736, Loss_clf 0.372, Loss_fe 0.482, Loss_kd 1.673, Train_accy 53.05, Test_accy 74.68:  30%|███       | 6/20 [13:19<31:28, 134.89s/it]Task 4, Epoch 7/20 => Loss 2.712, Loss_clf 0.363, Loss_fe 0.461, Loss_kd 1.678, Train_accy 53.39:  30%|███       | 6/20 [15:23<31:28, 134.89s/it]                 Task 4, Epoch 7/20 => Loss 2.712, Loss_clf 0.363, Loss_fe 0.461, Loss_kd 1.678, Train_accy 53.39:  35%|███▌      | 7/20 [15:23<28:27, 131.36s/it]Task 4, Epoch 8/20 => Loss 2.604, Loss_clf 0.319, Loss_fe 0.399, Loss_kd 1.677, Train_accy 54.96:  35%|███▌      | 7/20 [17:27<28:27, 131.36s/it]Task 4, Epoch 8/20 => Loss 2.604, Loss_clf 0.319, Loss_fe 0.399, Loss_kd 1.677, Train_accy 54.96:  40%|████      | 8/20 [17:27<25:47, 128.98s/it]Task 4, Epoch 9/20 => Loss 2.576, Loss_clf 0.323, Loss_fe 0.379, Loss_kd 1.665, Train_accy 55.26:  40%|████      | 8/20 [19:31<25:47, 128.98s/it]Task 4, Epoch 9/20 => Loss 2.576, Loss_clf 0.323, Loss_fe 0.379, Loss_kd 1.665, Train_accy 55.26:  45%|████▌     | 9/20 [19:31<23:21, 127.41s/it]Task 4, Epoch 10/20 => Loss 2.569, Loss_clf 0.318, Loss_fe 0.358, Loss_kd 1.684, Train_accy 54.33:  45%|████▌     | 9/20 [21:35<23:21, 127.41s/it]Task 4, Epoch 10/20 => Loss 2.569, Loss_clf 0.318, Loss_fe 0.358, Loss_kd 1.684, Train_accy 54.33:  50%|█████     | 10/20 [21:35<21:03, 126.34s/it]Task 4, Epoch 11/20 => Loss 2.534, Loss_clf 0.307, Loss_fe 0.339, Loss_kd 1.678, Train_accy 55.33, Test_accy 74.53:  50%|█████     | 10/20 [24:06<21:03, 126.34s/it]Task 4, Epoch 11/20 => Loss 2.534, Loss_clf 0.307, Loss_fe 0.339, Loss_kd 1.678, Train_accy 55.33, Test_accy 74.53:  55%|█████▌    | 11/20 [24:06<20:06, 134.02s/it]Task 4, Epoch 12/20 => Loss 2.437, Loss_clf 0.273, Loss_fe 0.291, Loss_kd 1.664, Train_accy 56.17:  55%|█████▌    | 11/20 [26:10<20:06, 134.02s/it]                 Task 4, Epoch 12/20 => Loss 2.437, Loss_clf 0.273, Loss_fe 0.291, Loss_kd 1.664, Train_accy 56.17:  60%|██████    | 12/20 [26:10<17:27, 130.95s/it]Task 4, Epoch 13/20 => Loss 2.414, Loss_clf 0.262, Loss_fe 0.280, Loss_kd 1.664, Train_accy 55.29:  60%|██████    | 12/20 [28:14<17:27, 130.95s/it]Task 4, Epoch 13/20 => Loss 2.414, Loss_clf 0.262, Loss_fe 0.280, Loss_kd 1.664, Train_accy 55.29:  65%|██████▌   | 13/20 [28:14<15:01, 128.84s/it]Task 4, Epoch 14/20 => Loss 2.369, Loss_clf 0.248, Loss_fe 0.249, Loss_kd 1.663, Train_accy 56.70:  65%|██████▌   | 13/20 [30:18<15:01, 128.84s/it]Task 4, Epoch 14/20 => Loss 2.369, Loss_clf 0.248, Loss_fe 0.249, Loss_kd 1.663, Train_accy 56.70:  70%|███████   | 14/20 [30:18<12:44, 127.36s/it]Task 4, Epoch 15/20 => Loss 2.384, Loss_clf 0.247, Loss_fe 0.248, Loss_kd 1.679, Train_accy 56.85:  70%|███████   | 14/20 [32:22<12:44, 127.36s/it]Task 4, Epoch 15/20 => Loss 2.384, Loss_clf 0.247, Loss_fe 0.248, Loss_kd 1.679, Train_accy 56.85:  75%|███████▌  | 15/20 [32:22<10:31, 126.33s/it]Task 4, Epoch 16/20 => Loss 2.350, Loss_clf 0.239, Loss_fe 0.227, Loss_kd 1.675, Train_accy 56.52, Test_accy 75.01:  75%|███████▌  | 15/20 [34:53<10:31, 126.33s/it]Task 4, Epoch 16/20 => Loss 2.350, Loss_clf 0.239, Loss_fe 0.227, Loss_kd 1.675, Train_accy 56.52, Test_accy 75.01:  80%|████████  | 16/20 [34:53<08:55, 133.86s/it]Task 4, Epoch 17/20 => Loss 2.326, Loss_clf 0.236, Loss_fe 0.220, Loss_kd 1.662, Train_accy 56.28:  80%|████████  | 16/20 [36:57<08:55, 133.86s/it]                 Task 4, Epoch 17/20 => Loss 2.326, Loss_clf 0.236, Loss_fe 0.220, Loss_kd 1.662, Train_accy 56.28:  85%|████████▌ | 17/20 [36:57<06:32, 130.88s/it]Task 4, Epoch 18/20 => Loss 2.318, Loss_clf 0.228, Loss_fe 0.218, Loss_kd 1.664, Train_accy 57.25:  85%|████████▌ | 17/20 [39:01<06:32, 130.88s/it]Task 4, Epoch 18/20 => Loss 2.318, Loss_clf 0.228, Loss_fe 0.218, Loss_kd 1.664, Train_accy 57.25:  90%|█████████ | 18/20 [39:01<04:17, 128.80s/it]Task 4, Epoch 19/20 => Loss 2.293, Loss_clf 0.220, Loss_fe 0.210, Loss_kd 1.657, Train_accy 57.69:  90%|█████████ | 18/20 [41:05<04:17, 128.80s/it]Task 4, Epoch 19/20 => Loss 2.293, Loss_clf 0.220, Loss_fe 0.210, Loss_kd 1.657, Train_accy 57.69:  95%|█████████▌| 19/20 [41:05<02:07, 127.31s/it]Task 4, Epoch 20/20 => Loss 2.324, Loss_clf 0.230, Loss_fe 0.214, Loss_kd 1.672, Train_accy 57.48:  95%|█████████▌| 19/20 [43:09<02:07, 127.31s/it]Task 4, Epoch 20/20 => Loss 2.324, Loss_clf 0.230, Loss_fe 0.214, Loss_kd 1.672, Train_accy 57.48: 100%|██████████| 20/20 [43:09<00:00, 126.31s/it]Task 4, Epoch 20/20 => Loss 2.324, Loss_clf 0.230, Loss_fe 0.214, Loss_kd 1.672, Train_accy 57.48: 100%|██████████| 20/20 [43:09<00:00, 129.47s/it]
2024-05-01 09:03:20,392 [foster.py] => Task 4, Epoch 20/20 => Loss 2.324, Loss_clf 0.230, Loss_fe 0.214, Loss_kd 1.672, Train_accy 57.48
2024-05-01 09:03:20,393 [foster.py] => do not weight align teacher!
2024-05-01 09:03:20,403 [foster.py] => per cls weights : [1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713 1.06430713
 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293
 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293
 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293
 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293
 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293 0.48554293]
  0%|          | 0/20 [00:00<?, ?it/s]SNet: Task 4, Epoch 1/20 => Loss 1.903,  Train_accy 43.41, Test_accy 73.73:   0%|          | 0/20 [02:51<?, ?it/s]SNet: Task 4, Epoch 1/20 => Loss 1.903,  Train_accy 43.41, Test_accy 73.73:   5%|▌         | 1/20 [02:51<54:14, 171.27s/it]SNet: Task 4, Epoch 2/20 => Loss 1.798,  Train_accy 46.69:   5%|▌         | 1/20 [05:28<54:14, 171.27s/it]                 SNet: Task 4, Epoch 2/20 => Loss 1.798,  Train_accy 46.69:  10%|█         | 2/20 [05:28<48:49, 162.73s/it]SNet: Task 4, Epoch 3/20 => Loss 1.775,  Train_accy 47.18:  10%|█         | 2/20 [08:04<48:49, 162.73s/it]SNet: Task 4, Epoch 3/20 => Loss 1.775,  Train_accy 47.18:  15%|█▌        | 3/20 [08:04<45:19, 159.97s/it]SNet: Task 4, Epoch 4/20 => Loss 1.775,  Train_accy 47.59:  15%|█▌        | 3/20 [10:41<45:19, 159.97s/it]SNet: Task 4, Epoch 4/20 => Loss 1.775,  Train_accy 47.59:  20%|██        | 4/20 [10:41<42:18, 158.67s/it]SNet: Task 4, Epoch 5/20 => Loss 1.767,  Train_accy 48.25:  20%|██        | 4/20 [13:18<42:18, 158.67s/it]SNet: Task 4, Epoch 5/20 => Loss 1.767,  Train_accy 48.25:  25%|██▌       | 5/20 [13:18<39:29, 157.99s/it]SNet: Task 4, Epoch 6/20 => Loss 1.768,  Train_accy 47.98, Test_accy 74.35:  25%|██▌       | 5/20 [16:09<39:29, 157.99s/it]SNet: Task 4, Epoch 6/20 => Loss 1.768,  Train_accy 47.98, Test_accy 74.35:  30%|███       | 6/20 [16:09<37:56, 162.61s/it]SNet: Task 4, Epoch 7/20 => Loss 1.759,  Train_accy 48.42:  30%|███       | 6/20 [18:46<37:56, 162.61s/it]                 SNet: Task 4, Epoch 7/20 => Loss 1.759,  Train_accy 48.42:  35%|███▌      | 7/20 [18:46<34:49, 160.72s/it]SNet: Task 4, Epoch 8/20 => Loss 1.755,  Train_accy 48.32:  35%|███▌      | 7/20 [21:23<34:49, 160.72s/it]SNet: Task 4, Epoch 8/20 => Loss 1.755,  Train_accy 48.32:  40%|████      | 8/20 [21:23<31:53, 159.48s/it]SNet: Task 4, Epoch 9/20 => Loss 1.753,  Train_accy 48.34:  40%|████      | 8/20 [24:00<31:53, 159.48s/it]SNet: Task 4, Epoch 9/20 => Loss 1.753,  Train_accy 48.34:  45%|████▌     | 9/20 [24:00<29:05, 158.65s/it]SNet: Task 4, Epoch 10/20 => Loss 1.768,  Train_accy 48.53:  45%|████▌     | 9/20 [26:37<29:05, 158.65s/it]SNet: Task 4, Epoch 10/20 => Loss 1.768,  Train_accy 48.53:  50%|█████     | 10/20 [26:37<26:20, 158.09s/it]SNet: Task 4, Epoch 11/20 => Loss 1.758,  Train_accy 48.41, Test_accy 74.38:  50%|█████     | 10/20 [29:28<26:20, 158.09s/it]SNet: Task 4, Epoch 11/20 => Loss 1.758,  Train_accy 48.41, Test_accy 74.38:  55%|█████▌    | 11/20 [29:28<24:19, 162.14s/it]SNet: Task 4, Epoch 12/20 => Loss 1.749,  Train_accy 48.33:  55%|█████▌    | 11/20 [32:05<24:19, 162.14s/it]                 SNet: Task 4, Epoch 12/20 => Loss 1.749,  Train_accy 48.33:  60%|██████    | 12/20 [32:05<21:24, 160.52s/it]SNet: Task 4, Epoch 13/20 => Loss 1.752,  Train_accy 48.61:  60%|██████    | 12/20 [34:42<21:24, 160.52s/it]SNet: Task 4, Epoch 13/20 => Loss 1.752,  Train_accy 48.61:  65%|██████▌   | 13/20 [34:42<18:35, 159.40s/it]SNet: Task 4, Epoch 14/20 => Loss 1.748,  Train_accy 48.87:  65%|██████▌   | 13/20 [37:18<18:35, 159.40s/it]SNet: Task 4, Epoch 14/20 => Loss 1.748,  Train_accy 48.87:  70%|███████   | 14/20 [37:18<15:51, 158.58s/it]SNet: Task 4, Epoch 15/20 => Loss 1.753,  Train_accy 48.32:  70%|███████   | 14/20 [39:55<15:51, 158.58s/it]SNet: Task 4, Epoch 15/20 => Loss 1.753,  Train_accy 48.32:  75%|███████▌  | 15/20 [39:55<13:10, 158.04s/it]SNet: Task 4, Epoch 16/20 => Loss 1.756,  Train_accy 48.71, Test_accy 74.48:  75%|███████▌  | 15/20 [42:47<13:10, 158.04s/it]SNet: Task 4, Epoch 16/20 => Loss 1.756,  Train_accy 48.71, Test_accy 74.48:  80%|████████  | 16/20 [42:47<10:48, 162.12s/it]SNet: Task 4, Epoch 17/20 => Loss 1.747,  Train_accy 48.79:  80%|████████  | 16/20 [45:23<10:48, 162.12s/it]                 SNet: Task 4, Epoch 17/20 => Loss 1.747,  Train_accy 48.79:  85%|████████▌ | 17/20 [45:23<08:01, 160.53s/it]SNet: Task 4, Epoch 18/20 => Loss 1.741,  Train_accy 48.91:  85%|████████▌ | 17/20 [48:00<08:01, 160.53s/it]SNet: Task 4, Epoch 18/20 => Loss 1.741,  Train_accy 48.91:  90%|█████████ | 18/20 [48:00<05:18, 159.45s/it]SNet: Task 4, Epoch 19/20 => Loss 1.745,  Train_accy 48.82:  90%|█████████ | 18/20 [50:37<05:18, 159.45s/it]SNet: Task 4, Epoch 19/20 => Loss 1.745,  Train_accy 48.82:  95%|█████████▌| 19/20 [50:37<02:38, 158.66s/it]SNet: Task 4, Epoch 20/20 => Loss 1.755,  Train_accy 49.25:  95%|█████████▌| 19/20 [53:16<02:38, 158.66s/it]SNet: Task 4, Epoch 20/20 => Loss 1.755,  Train_accy 49.25: 100%|██████████| 20/20 [53:16<00:00, 158.82s/it]SNet: Task 4, Epoch 20/20 => Loss 1.755,  Train_accy 49.25: 100%|██████████| 20/20 [53:16<00:00, 159.84s/it]
2024-05-01 09:56:39,539 [foster.py] => SNet: Task 4, Epoch 20/20 => Loss 1.755,  Train_accy 49.25
2024-05-01 09:56:39,539 [foster.py] => do not weight align student!
2024-05-01 09:56:54,353 [foster.py] => darknet eval: 
2024-05-01 09:56:54,353 [foster.py] => CNN top1 curve: 74.53
2024-05-01 09:56:54,353 [foster.py] => CNN top5 curve: 95.03
2024-05-01 09:56:54,356 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 10:01:24,377 [foster.py] => Exemplar size: 5400
2024-05-01 10:01:24,377 [trainer.py] => CNN: {'total': 75.16, '00-149': 85.14, '150-179': 76.25, '180-209': 75.04, '210-239': 60.43, '240-269': 39.07, 'old': 79.68, 'new': 39.07}
2024-05-01 10:01:24,377 [trainer.py] => NME: {'total': 78.86, '00-149': 80.13, '150-179': 73.91, '180-209': 77.22, '210-239': 75.13, '240-269': 82.8, 'old': 78.36, 'new': 82.8}
2024-05-01 10:01:24,377 [trainer.py] => CNN top1 curve: [87.61, 80.93, 78.52, 75.71, 75.16]
2024-05-01 10:01:24,377 [trainer.py] => CNN top5 curve: [97.83, 97.02, 96.25, 95.34, 95.1]
2024-05-01 10:01:24,377 [trainer.py] => NME top1 curve: [86.81, 84.02, 82.38, 80.79, 78.86]
2024-05-01 10:01:24,378 [trainer.py] => NME top5 curve: [97.7, 96.91, 96.32, 95.78, 95.54]

Average Accuracy (CNN): 79.59
Average Accuracy (NME): 82.57
2024-05-01 10:01:24,378 [trainer.py] => Average Accuracy (CNN): 79.59
2024-05-01 10:01:24,378 [trainer.py] => Average Accuracy (NME): 82.57
2024-05-01 10:01:24,378 [trainer.py] => Train Time: 27327.579999999998
2024-05-01 10:01:24,378 [trainer.py] => Test Time: 204.99 

2024-05-01 10:01:24,379 [trainer.py] => All params: 172404492
2024-05-01 10:01:24,381 [trainer.py] => Trainable params: 86421276
2024-05-01 10:01:26,840 [foster.py] => Learning on 270-300
2024-05-01 10:01:26,842 [foster.py] => All params: 172496742
2024-05-01 10:01:26,843 [foster.py] => Trainable params: 86490456
2024-05-01 10:01:26,906 [foster.py] => per cls weights : [1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425 1.04624425
 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175
 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175
 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175
 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175
 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175 0.58380175]
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 5.404, Loss_clf 1.015, Loss_fe 2.193, Loss_kd 1.976, Train_accy 52.91, Test_accy 73.75:   0%|          | 0/20 [02:35<?, ?it/s]Task 5, Epoch 1/20 => Loss 5.404, Loss_clf 1.015, Loss_fe 2.193, Loss_kd 1.976, Train_accy 52.91, Test_accy 73.75:   5%|▌         | 1/20 [02:35<49:10, 155.29s/it]Task 5, Epoch 2/20 => Loss 3.793, Loss_clf 0.626, Loss_fe 0.989, Loss_kd 1.960, Train_accy 55.92:   5%|▌         | 1/20 [04:39<49:10, 155.29s/it]                 Task 5, Epoch 2/20 => Loss 3.793, Loss_clf 0.626, Loss_fe 0.989, Loss_kd 1.960, Train_accy 55.92:  10%|█         | 2/20 [04:39<41:10, 137.27s/it]Task 5, Epoch 3/20 => Loss 3.538, Loss_clf 0.545, Loss_fe 0.811, Loss_kd 1.965, Train_accy 56.53:  10%|█         | 2/20 [06:44<41:10, 137.27s/it]Task 5, Epoch 3/20 => Loss 3.538, Loss_clf 0.545, Loss_fe 0.811, Loss_kd 1.965, Train_accy 56.53:  15%|█▌        | 3/20 [06:44<37:14, 131.44s/it]Task 5, Epoch 4/20 => Loss 3.442, Loss_clf 0.527, Loss_fe 0.750, Loss_kd 1.948, Train_accy 58.04:  15%|█▌        | 3/20 [08:49<37:14, 131.44s/it]Task 5, Epoch 4/20 => Loss 3.442, Loss_clf 0.527, Loss_fe 0.750, Loss_kd 1.948, Train_accy 58.04:  20%|██        | 4/20 [08:49<34:20, 128.76s/it]Task 5, Epoch 5/20 => Loss 3.357, Loss_clf 0.475, Loss_fe 0.706, Loss_kd 1.959, Train_accy 58.96:  20%|██        | 4/20 [10:53<34:20, 128.76s/it]Task 5, Epoch 5/20 => Loss 3.357, Loss_clf 0.475, Loss_fe 0.706, Loss_kd 1.959, Train_accy 58.96:  25%|██▌       | 5/20 [10:53<31:48, 127.23s/it]Task 5, Epoch 6/20 => Loss 3.154, Loss_clf 0.433, Loss_fe 0.563, Loss_kd 1.942, Train_accy 59.96, Test_accy 74.19:  25%|██▌       | 5/20 [13:28<31:48, 127.23s/it]Task 5, Epoch 6/20 => Loss 3.154, Loss_clf 0.433, Loss_fe 0.563, Loss_kd 1.942, Train_accy 59.96, Test_accy 74.19:  30%|███       | 6/20 [13:28<31:53, 136.68s/it]Task 5, Epoch 7/20 => Loss 3.088, Loss_clf 0.405, Loss_fe 0.515, Loss_kd 1.950, Train_accy 59.97:  30%|███       | 6/20 [15:33<31:53, 136.68s/it]                 Task 5, Epoch 7/20 => Loss 3.088, Loss_clf 0.405, Loss_fe 0.515, Loss_kd 1.950, Train_accy 59.97:  35%|███▌      | 7/20 [15:33<28:46, 132.78s/it]Task 5, Epoch 8/20 => Loss 3.001, Loss_clf 0.366, Loss_fe 0.466, Loss_kd 1.952, Train_accy 60.81:  35%|███▌      | 7/20 [17:37<28:46, 132.78s/it]Task 5, Epoch 8/20 => Loss 3.001, Loss_clf 0.366, Loss_fe 0.466, Loss_kd 1.952, Train_accy 60.81:  40%|████      | 8/20 [17:37<26:01, 130.15s/it]Task 5, Epoch 9/20 => Loss 2.957, Loss_clf 0.354, Loss_fe 0.435, Loss_kd 1.950, Train_accy 60.81:  40%|████      | 8/20 [19:42<26:01, 130.15s/it]Task 5, Epoch 9/20 => Loss 2.957, Loss_clf 0.354, Loss_fe 0.435, Loss_kd 1.950, Train_accy 60.81:  45%|████▌     | 9/20 [19:42<23:32, 128.40s/it]Task 5, Epoch 10/20 => Loss 2.897, Loss_clf 0.324, Loss_fe 0.411, Loss_kd 1.946, Train_accy 61.78:  45%|████▌     | 9/20 [21:47<23:32, 128.40s/it]Task 5, Epoch 10/20 => Loss 2.897, Loss_clf 0.324, Loss_fe 0.411, Loss_kd 1.946, Train_accy 61.78:  50%|█████     | 10/20 [21:47<21:12, 127.29s/it]Task 5, Epoch 11/20 => Loss 2.822, Loss_clf 0.312, Loss_fe 0.347, Loss_kd 1.947, Train_accy 61.95, Test_accy 74.87:  50%|█████     | 10/20 [24:22<21:12, 127.29s/it]Task 5, Epoch 11/20 => Loss 2.822, Loss_clf 0.312, Loss_fe 0.347, Loss_kd 1.947, Train_accy 61.95, Test_accy 74.87:  55%|█████▌    | 11/20 [24:22<20:22, 135.84s/it]Task 5, Epoch 12/20 => Loss 2.795, Loss_clf 0.299, Loss_fe 0.333, Loss_kd 1.947, Train_accy 62.26:  55%|█████▌    | 11/20 [26:27<20:22, 135.84s/it]                 Task 5, Epoch 12/20 => Loss 2.795, Loss_clf 0.299, Loss_fe 0.333, Loss_kd 1.947, Train_accy 62.26:  60%|██████    | 12/20 [26:27<17:39, 132.45s/it]Task 5, Epoch 13/20 => Loss 2.810, Loss_clf 0.310, Loss_fe 0.317, Loss_kd 1.965, Train_accy 62.40:  60%|██████    | 12/20 [28:31<17:39, 132.45s/it]Task 5, Epoch 13/20 => Loss 2.810, Loss_clf 0.310, Loss_fe 0.317, Loss_kd 1.965, Train_accy 62.40:  65%|██████▌   | 13/20 [28:31<15:10, 130.12s/it]Task 5, Epoch 14/20 => Loss 2.751, Loss_clf 0.286, Loss_fe 0.297, Loss_kd 1.951, Train_accy 62.41:  65%|██████▌   | 13/20 [30:36<15:10, 130.12s/it]Task 5, Epoch 14/20 => Loss 2.751, Loss_clf 0.286, Loss_fe 0.297, Loss_kd 1.951, Train_accy 62.41:  70%|███████   | 14/20 [30:36<12:50, 128.48s/it]Task 5, Epoch 15/20 => Loss 2.668, Loss_clf 0.254, Loss_fe 0.261, Loss_kd 1.938, Train_accy 63.56:  70%|███████   | 14/20 [32:41<12:50, 128.48s/it]Task 5, Epoch 15/20 => Loss 2.668, Loss_clf 0.254, Loss_fe 0.261, Loss_kd 1.938, Train_accy 63.56:  75%|███████▌  | 15/20 [32:41<10:36, 127.35s/it]Task 5, Epoch 16/20 => Loss 2.645, Loss_clf 0.243, Loss_fe 0.237, Loss_kd 1.949, Train_accy 63.99, Test_accy 74.99:  75%|███████▌  | 15/20 [35:16<10:36, 127.35s/it]Task 5, Epoch 16/20 => Loss 2.645, Loss_clf 0.243, Loss_fe 0.237, Loss_kd 1.949, Train_accy 63.99, Test_accy 74.99:  80%|████████  | 16/20 [35:16<09:02, 135.67s/it]Task 5, Epoch 17/20 => Loss 2.671, Loss_clf 0.251, Loss_fe 0.248, Loss_kd 1.955, Train_accy 63.77:  80%|████████  | 16/20 [37:21<09:02, 135.67s/it]                 Task 5, Epoch 17/20 => Loss 2.671, Loss_clf 0.251, Loss_fe 0.248, Loss_kd 1.955, Train_accy 63.77:  85%|████████▌ | 17/20 [37:21<06:37, 132.37s/it]Task 5, Epoch 18/20 => Loss 2.626, Loss_clf 0.235, Loss_fe 0.229, Loss_kd 1.946, Train_accy 64.21:  85%|████████▌ | 17/20 [39:25<06:37, 132.37s/it]Task 5, Epoch 18/20 => Loss 2.626, Loss_clf 0.235, Loss_fe 0.229, Loss_kd 1.946, Train_accy 64.21:  90%|█████████ | 18/20 [39:25<04:20, 130.04s/it]Task 5, Epoch 19/20 => Loss 2.647, Loss_clf 0.247, Loss_fe 0.234, Loss_kd 1.949, Train_accy 63.82:  90%|█████████ | 18/20 [41:30<04:20, 130.04s/it]Task 5, Epoch 19/20 => Loss 2.647, Loss_clf 0.247, Loss_fe 0.234, Loss_kd 1.949, Train_accy 63.82:  95%|█████████▌| 19/20 [41:30<02:08, 128.40s/it]Task 5, Epoch 20/20 => Loss 2.675, Loss_clf 0.249, Loss_fe 0.247, Loss_kd 1.961, Train_accy 64.00:  95%|█████████▌| 19/20 [43:34<02:08, 128.40s/it]Task 5, Epoch 20/20 => Loss 2.675, Loss_clf 0.249, Loss_fe 0.247, Loss_kd 1.961, Train_accy 64.00: 100%|██████████| 20/20 [43:34<00:00, 127.28s/it]Task 5, Epoch 20/20 => Loss 2.675, Loss_clf 0.249, Loss_fe 0.247, Loss_kd 1.961, Train_accy 64.00: 100%|██████████| 20/20 [43:34<00:00, 130.75s/it]
2024-05-01 10:45:01,825 [foster.py] => Task 5, Epoch 20/20 => Loss 2.675, Loss_clf 0.249, Loss_fe 0.247, Loss_kd 1.961, Train_accy 64.00
2024-05-01 10:45:01,842 [foster.py] => do not weight align teacher!
2024-05-01 10:45:01,854 [foster.py] => per cls weights : [1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661 1.05750661
 0.4824405  0.4824405  0.4824405  0.4824405  0.4824405  0.4824405
 0.4824405  0.4824405  0.4824405  0.4824405  0.4824405  0.4824405
 0.4824405  0.4824405  0.4824405  0.4824405  0.4824405  0.4824405
 0.4824405  0.4824405  0.4824405  0.4824405  0.4824405  0.4824405
 0.4824405  0.4824405  0.4824405  0.4824405  0.4824405  0.4824405 ]
  0%|          | 0/20 [00:00<?, ?it/s]SNet: Task 5, Epoch 1/20 => Loss 2.101,  Train_accy 48.96, Test_accy 73.53:   0%|          | 0/20 [02:53<?, ?it/s]SNet: Task 5, Epoch 1/20 => Loss 2.101,  Train_accy 48.96, Test_accy 73.53:   5%|▌         | 1/20 [02:53<55:03, 173.88s/it]SNet: Task 5, Epoch 2/20 => Loss 2.005,  Train_accy 52.92:   5%|▌         | 1/20 [05:31<55:03, 173.88s/it]                 SNet: Task 5, Epoch 2/20 => Loss 2.005,  Train_accy 52.92:  10%|█         | 2/20 [05:31<49:17, 164.33s/it]SNet: Task 5, Epoch 3/20 => Loss 1.981,  Train_accy 53.31:  10%|█         | 2/20 [08:09<49:17, 164.33s/it]SNet: Task 5, Epoch 3/20 => Loss 1.981,  Train_accy 53.31:  15%|█▌        | 3/20 [08:09<45:40, 161.21s/it]SNet: Task 5, Epoch 4/20 => Loss 1.989,  Train_accy 53.53:  15%|█▌        | 3/20 [10:46<45:40, 161.21s/it]SNet: Task 5, Epoch 4/20 => Loss 1.989,  Train_accy 53.53:  20%|██        | 4/20 [10:46<42:37, 159.84s/it]SNet: Task 5, Epoch 5/20 => Loss 1.959,  Train_accy 53.99:  20%|██        | 4/20 [13:24<42:37, 159.84s/it]SNet: Task 5, Epoch 5/20 => Loss 1.959,  Train_accy 53.99:  25%|██▌       | 5/20 [13:24<39:45, 159.01s/it]SNet: Task 5, Epoch 6/20 => Loss 1.947,  Train_accy 54.02, Test_accy 74.05:  25%|██▌       | 5/20 [16:18<39:45, 159.01s/it]SNet: Task 5, Epoch 6/20 => Loss 1.947,  Train_accy 54.02, Test_accy 74.05:  30%|███       | 6/20 [16:18<38:16, 164.04s/it]SNet: Task 5, Epoch 7/20 => Loss 1.955,  Train_accy 54.51:  30%|███       | 6/20 [18:55<38:16, 164.04s/it]                 SNet: Task 5, Epoch 7/20 => Loss 1.955,  Train_accy 54.51:  35%|███▌      | 7/20 [18:55<35:05, 161.93s/it]SNet: Task 5, Epoch 8/20 => Loss 1.966,  Train_accy 54.57:  35%|███▌      | 7/20 [21:33<35:05, 161.93s/it]SNet: Task 5, Epoch 8/20 => Loss 1.966,  Train_accy 54.57:  40%|████      | 8/20 [21:33<32:06, 160.54s/it]SNet: Task 5, Epoch 9/20 => Loss 1.954,  Train_accy 54.66:  40%|████      | 8/20 [24:10<32:06, 160.54s/it]SNet: Task 5, Epoch 9/20 => Loss 1.954,  Train_accy 54.66:  45%|████▌     | 9/20 [24:10<29:15, 159.63s/it]SNet: Task 5, Epoch 10/20 => Loss 1.961,  Train_accy 54.51:  45%|████▌     | 9/20 [26:48<29:15, 159.63s/it]SNet: Task 5, Epoch 10/20 => Loss 1.961,  Train_accy 54.51:  50%|█████     | 10/20 [26:48<26:30, 159.01s/it]SNet: Task 5, Epoch 11/20 => Loss 1.951,  Train_accy 54.74, Test_accy 74.30:  50%|█████     | 10/20 [29:42<26:30, 159.01s/it]SNet: Task 5, Epoch 11/20 => Loss 1.951,  Train_accy 54.74, Test_accy 74.30:  55%|█████▌    | 11/20 [29:42<24:33, 163.73s/it]SNet: Task 5, Epoch 12/20 => Loss 1.949,  Train_accy 54.90:  55%|█████▌    | 11/20 [32:20<24:33, 163.73s/it]                 SNet: Task 5, Epoch 12/20 => Loss 1.949,  Train_accy 54.90:  60%|██████    | 12/20 [32:20<21:35, 161.88s/it]SNet: Task 5, Epoch 13/20 => Loss 1.961,  Train_accy 54.43:  60%|██████    | 12/20 [34:58<21:35, 161.88s/it]SNet: Task 5, Epoch 13/20 => Loss 1.961,  Train_accy 54.43:  65%|██████▌   | 13/20 [34:58<18:44, 160.57s/it]SNet: Task 5, Epoch 14/20 => Loss 1.948,  Train_accy 54.68:  65%|██████▌   | 13/20 [37:35<18:44, 160.57s/it]SNet: Task 5, Epoch 14/20 => Loss 1.948,  Train_accy 54.68:  70%|███████   | 14/20 [37:35<15:58, 159.71s/it]SNet: Task 5, Epoch 15/20 => Loss 1.948,  Train_accy 55.38:  70%|███████   | 14/20 [40:13<15:58, 159.71s/it]SNet: Task 5, Epoch 15/20 => Loss 1.948,  Train_accy 55.38:  75%|███████▌  | 15/20 [40:13<13:15, 159.11s/it]SNet: Task 5, Epoch 16/20 => Loss 1.953,  Train_accy 55.21, Test_accy 74.24:  75%|███████▌  | 15/20 [43:07<13:15, 159.11s/it]SNet: Task 5, Epoch 16/20 => Loss 1.953,  Train_accy 55.21, Test_accy 74.24:  80%|████████  | 16/20 [43:07<10:54, 163.59s/it]SNet: Task 5, Epoch 17/20 => Loss 1.948,  Train_accy 55.03:  80%|████████  | 16/20 [45:45<10:54, 163.59s/it]                 SNet: Task 5, Epoch 17/20 => Loss 1.948,  Train_accy 55.03:  85%|████████▌ | 17/20 [45:45<08:05, 161.81s/it]SNet: Task 5, Epoch 18/20 => Loss 1.950,  Train_accy 55.02:  85%|████████▌ | 17/20 [48:23<08:05, 161.81s/it]SNet: Task 5, Epoch 18/20 => Loss 1.950,  Train_accy 55.02:  90%|█████████ | 18/20 [48:23<05:21, 160.60s/it]SNet: Task 5, Epoch 19/20 => Loss 1.940,  Train_accy 55.19:  90%|█████████ | 18/20 [51:00<05:21, 160.60s/it]SNet: Task 5, Epoch 19/20 => Loss 1.940,  Train_accy 55.19:  95%|█████████▌| 19/20 [51:00<02:39, 159.71s/it]SNet: Task 5, Epoch 20/20 => Loss 1.955,  Train_accy 54.93:  95%|█████████▌| 19/20 [53:38<02:39, 159.71s/it]SNet: Task 5, Epoch 20/20 => Loss 1.955,  Train_accy 54.93: 100%|██████████| 20/20 [53:38<00:00, 159.09s/it]SNet: Task 5, Epoch 20/20 => Loss 1.955,  Train_accy 54.93: 100%|██████████| 20/20 [53:38<00:00, 160.92s/it]
2024-05-01 11:38:43,136 [foster.py] => SNet: Task 5, Epoch 20/20 => Loss 1.955,  Train_accy 54.93
2024-05-01 11:38:43,136 [foster.py] => do not weight align student!
2024-05-01 11:38:59,608 [foster.py] => darknet eval: 
2024-05-01 11:38:59,608 [foster.py] => CNN top1 curve: 74.34
2024-05-01 11:38:59,608 [foster.py] => CNN top5 curve: 94.32
2024-05-01 11:38:59,610 [base.py] => Constructing exemplars for new classes...(20 per classes)
2024-05-01 11:43:55,613 [foster.py] => Exemplar size: 6000
2024-05-01 11:43:55,613 [trainer.py] => CNN: {'total': 74.84, '00-149': 83.6, '150-179': 75.75, '180-209': 76.05, '210-239': 69.78, '240-269': 58.1, '270-299': 50.67, 'old': 77.52, 'new': 50.67}
2024-05-01 11:43:55,613 [trainer.py] => NME: {'total': 78.23, '00-149': 79.16, '150-179': 73.58, '180-209': 75.21, '210-239': 76.46, '240-269': 72.95, '270-299': 88.29, 'old': 77.11, 'new': 88.29}
2024-05-01 11:43:55,613 [trainer.py] => CNN top1 curve: [87.61, 80.93, 78.52, 75.71, 75.16, 74.84]
2024-05-01 11:43:55,613 [trainer.py] => CNN top5 curve: [97.83, 97.02, 96.25, 95.34, 95.1, 94.87]
2024-05-01 11:43:55,613 [trainer.py] => NME top1 curve: [86.81, 84.02, 82.38, 80.79, 78.86, 78.23]
2024-05-01 11:43:55,613 [trainer.py] => NME top5 curve: [97.7, 96.91, 96.32, 95.78, 95.54, 95.2]

Average Accuracy (CNN): 78.8
Average Accuracy (NME): 81.85
2024-05-01 11:43:55,614 [trainer.py] => Average Accuracy (CNN): 78.8
2024-05-01 11:43:55,614 [trainer.py] => Average Accuracy (NME): 81.85
2024-05-01 11:43:55,614 [trainer.py] => Train Time: 33180.33
2024-05-01 11:43:55,614 [trainer.py] => Test Time: 267.85 

Accuracy Matrix (CNN):
[[87.61 87.27 86.51 85.87 85.14 83.6 ]
 [ 0.   49.16 67.39 72.07 76.25 75.75]
 [ 0.    0.   49.58 67.17 75.04 76.05]
 [ 0.    0.    0.   37.06 60.43 69.78]
 [ 0.    0.    0.    0.   39.07 58.1 ]
 [ 0.    0.    0.    0.    0.   50.67]]
2024-05-01 11:43:55,614 [trainer.py] => Forgetting (CNN): 0.902000000000001
Accuracy Matrix (NME):
[[86.81 83.9  83.3  81.66 80.13 79.16]
 [ 0.   84.62 74.25 74.75 73.91 73.58]
 [ 0.    0.   85.93 78.22 77.22 75.21]
 [ 0.    0.    0.   84.97 75.13 76.46]
 [ 0.    0.    0.    0.   82.8  72.95]
 [ 0.    0.    0.    0.    0.   88.29]]
2024-05-01 11:43:55,615 [trainer.py] => Forgetting (NME): 9.554000000000006
2024-05-01 11:43:59,976 [trainer.py] => config: ./exps/l2p_omn_B150_Inc5.json
2024-05-01 11:43:59,976 [trainer.py] => prefix:  
2024-05-01 11:43:59,976 [trainer.py] => dataset: omnibenchmark
2024-05-01 11:43:59,976 [trainer.py] => memory_size: 0
2024-05-01 11:43:59,976 [trainer.py] => memory_per_class: 0
2024-05-01 11:43:59,976 [trainer.py] => fixed_memory: False
2024-05-01 11:43:59,976 [trainer.py] => shuffle: True
2024-05-01 11:43:59,976 [trainer.py] => init_cls: 150
2024-05-01 11:43:59,976 [trainer.py] => increment: 30
2024-05-01 11:43:59,976 [trainer.py] => model_name: l2p
2024-05-01 11:43:59,977 [trainer.py] => backbone_type: vit_base_patch16_224_in21k_l2p
2024-05-01 11:43:59,977 [trainer.py] => get_original_backbone: True
2024-05-01 11:43:59,977 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-01 11:43:59,977 [trainer.py] => seed: 1993
2024-05-01 11:43:59,977 [trainer.py] => tuned_epoch: 20
2024-05-01 11:43:59,977 [trainer.py] => init_lr: 0.001875
2024-05-01 11:43:59,977 [trainer.py] => batch_size: 48
2024-05-01 11:43:59,977 [trainer.py] => weight_decay: 0
2024-05-01 11:43:59,977 [trainer.py] => min_lr: 1e-05
2024-05-01 11:43:59,977 [trainer.py] => optimizer: adam
2024-05-01 11:43:59,977 [trainer.py] => scheduler: constant
2024-05-01 11:43:59,977 [trainer.py] => reinit_optimizer: True
2024-05-01 11:43:59,977 [trainer.py] => global_pool: token
2024-05-01 11:43:59,977 [trainer.py] => head_type: prompt
2024-05-01 11:43:59,978 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-05-01 11:43:59,978 [trainer.py] => pretrained: True
2024-05-01 11:43:59,978 [trainer.py] => drop: 0.0
2024-05-01 11:43:59,978 [trainer.py] => drop_path: 0.0
2024-05-01 11:43:59,978 [trainer.py] => prompt_pool: True
2024-05-01 11:43:59,978 [trainer.py] => size: 10
2024-05-01 11:43:59,978 [trainer.py] => length: 5
2024-05-01 11:43:59,978 [trainer.py] => top_k: 5
2024-05-01 11:43:59,978 [trainer.py] => initializer: uniform
2024-05-01 11:43:59,978 [trainer.py] => prompt_key: True
2024-05-01 11:43:59,978 [trainer.py] => prompt_key_init: uniform
2024-05-01 11:43:59,978 [trainer.py] => use_prompt_mask: False
2024-05-01 11:43:59,978 [trainer.py] => shared_prompt_pool: False
2024-05-01 11:43:59,978 [trainer.py] => shared_prompt_key: False
2024-05-01 11:43:59,979 [trainer.py] => batchwise_prompt: True
2024-05-01 11:43:59,979 [trainer.py] => embedding_key: cls
2024-05-01 11:43:59,979 [trainer.py] => predefined_key: 
2024-05-01 11:43:59,979 [trainer.py] => pull_constraint: True
2024-05-01 11:43:59,979 [trainer.py] => pull_constraint_coeff: 0.1
2024-05-01 11:44:01,025 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2024-05-01 11:44:05,954 [vit_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-05-01 11:44:05,955 [vit_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-05-01 11:44:09,819 [l2p.py] => 86,094,636 model total parameters.
2024-05-01 11:44:09,820 [l2p.py] => 276,780 model training parameters.
2024-05-01 11:44:09,820 [l2p.py] => prompt.prompt: 38400
2024-05-01 11:44:09,820 [l2p.py] => prompt.prompt_key: 7680
2024-05-01 11:44:09,821 [l2p.py] => head.weight: 230400
2024-05-01 11:44:09,821 [l2p.py] => head.bias: 300
2024-05-01 11:44:09,823 [trainer.py] => All params: 172123992
2024-05-01 11:44:09,824 [trainer.py] => Trainable params: 276780
2024-05-01 11:44:09,824 [l2p.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.118, Train_accy 67.92:   0%|          | 0/20 [06:06<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.118, Train_accy 67.92:   5%|▌         | 1/20 [06:06<1:56:11, 366.92s/it]Task 0, Epoch 2/20 => Loss 0.590, Train_accy 77.35:   5%|▌         | 1/20 [12:13<1:56:11, 366.92s/it]Task 0, Epoch 2/20 => Loss 0.590, Train_accy 77.35:  10%|█         | 2/20 [12:13<1:49:56, 366.47s/it]Task 0, Epoch 3/20 => Loss 0.518, Train_accy 79.08:  10%|█         | 2/20 [18:20<1:49:56, 366.47s/it]Task 0, Epoch 3/20 => Loss 0.518, Train_accy 79.08:  15%|█▌        | 3/20 [18:20<1:43:57, 366.90s/it]Task 0, Epoch 4/20 => Loss 0.460, Train_accy 80.66:  15%|█▌        | 3/20 [24:25<1:43:57, 366.90s/it]Task 0, Epoch 4/20 => Loss 0.460, Train_accy 80.66:  20%|██        | 4/20 [24:25<1:37:41, 366.34s/it]Task 0, Epoch 5/20 => Loss 0.426, Train_accy 81.41, Test_accy 84.24:  20%|██        | 4/20 [30:49<1:37:41, 366.34s/it]Task 0, Epoch 5/20 => Loss 0.426, Train_accy 81.41, Test_accy 84.24:  25%|██▌       | 5/20 [30:49<1:33:09, 372.62s/it]Task 0, Epoch 6/20 => Loss 0.388, Train_accy 82.42:  25%|██▌       | 5/20 [36:55<1:33:09, 372.62s/it]                 Task 0, Epoch 6/20 => Loss 0.388, Train_accy 82.42:  30%|███       | 6/20 [36:55<1:26:25, 370.40s/it]Task 0, Epoch 7/20 => Loss 0.378, Train_accy 82.86:  30%|███       | 6/20 [43:01<1:26:25, 370.40s/it]Task 0, Epoch 7/20 => Loss 0.378, Train_accy 82.86:  35%|███▌      | 7/20 [43:01<1:19:53, 368.77s/it]Task 0, Epoch 8/20 => Loss 0.358, Train_accy 83.29:  35%|███▌      | 7/20 [49:06<1:19:53, 368.77s/it]Task 0, Epoch 8/20 => Loss 0.358, Train_accy 83.29:  40%|████      | 8/20 [49:06<1:13:33, 367.81s/it]Task 0, Epoch 9/20 => Loss 0.342, Train_accy 83.70:  40%|████      | 8/20 [55:13<1:13:33, 367.81s/it]Task 0, Epoch 9/20 => Loss 0.342, Train_accy 83.70:  45%|████▌     | 9/20 [55:13<1:07:19, 367.27s/it]Task 0, Epoch 10/20 => Loss 0.325, Train_accy 84.27, Test_accy 84.34:  45%|████▌     | 9/20 [1:01:32<1:07:19, 367.27s/it]Task 0, Epoch 10/20 => Loss 0.325, Train_accy 84.27, Test_accy 84.34:  50%|█████     | 10/20 [1:01:32<1:01:50, 371.07s/it]Task 0, Epoch 11/20 => Loss 0.323, Train_accy 84.22:  50%|█████     | 10/20 [1:07:38<1:01:50, 371.07s/it]                 Task 0, Epoch 11/20 => Loss 0.323, Train_accy 84.22:  55%|█████▌    | 11/20 [1:07:38<55:24, 369.44s/it]  Task 0, Epoch 12/20 => Loss 0.310, Train_accy 84.78:  55%|█████▌    | 11/20 [1:13:44<55:24, 369.44s/it]Task 0, Epoch 12/20 => Loss 0.310, Train_accy 84.78:  60%|██████    | 12/20 [1:13:44<49:07, 368.38s/it]Task 0, Epoch 13/20 => Loss 0.304, Train_accy 84.98:  60%|██████    | 12/20 [1:19:51<49:07, 368.38s/it]Task 0, Epoch 13/20 => Loss 0.304, Train_accy 84.98:  65%|██████▌   | 13/20 [1:19:51<42:55, 367.86s/it]Task 0, Epoch 14/20 => Loss 0.284, Train_accy 85.32:  65%|██████▌   | 13/20 [1:25:56<42:55, 367.86s/it]Task 0, Epoch 14/20 => Loss 0.284, Train_accy 85.32:  70%|███████   | 14/20 [1:25:56<36:43, 367.17s/it]Task 0, Epoch 15/20 => Loss 0.285, Train_accy 85.09, Test_accy 84.60:  70%|███████   | 14/20 [1:32:20<36:43, 367.17s/it]Task 0, Epoch 15/20 => Loss 0.285, Train_accy 85.09, Test_accy 84.60:  75%|███████▌  | 15/20 [1:32:20<31:01, 372.33s/it]Task 0, Epoch 16/20 => Loss 0.277, Train_accy 85.42:  75%|███████▌  | 15/20 [1:38:29<31:01, 372.33s/it]                 Task 0, Epoch 16/20 => Loss 0.277, Train_accy 85.42:  80%|████████  | 16/20 [1:38:29<24:44, 371.14s/it]Task 0, Epoch 17/20 => Loss 0.274, Train_accy 85.69:  80%|████████  | 16/20 [1:44:35<24:44, 371.14s/it]Task 0, Epoch 17/20 => Loss 0.274, Train_accy 85.69:  85%|████████▌ | 17/20 [1:44:35<18:29, 369.73s/it]Task 0, Epoch 18/20 => Loss 0.275, Train_accy 85.58:  85%|████████▌ | 17/20 [1:50:42<18:29, 369.73s/it]Task 0, Epoch 18/20 => Loss 0.275, Train_accy 85.58:  90%|█████████ | 18/20 [1:50:42<12:17, 368.71s/it]Task 0, Epoch 19/20 => Loss 0.256, Train_accy 86.05:  90%|█████████ | 18/20 [1:56:48<12:17, 368.71s/it]Task 0, Epoch 19/20 => Loss 0.256, Train_accy 86.05:  95%|█████████▌| 19/20 [1:56:48<06:08, 368.00s/it]Task 0, Epoch 20/20 => Loss 0.253, Train_accy 86.13, Test_accy 85.50:  95%|█████████▌| 19/20 [2:03:11<06:08, 368.00s/it]Task 0, Epoch 20/20 => Loss 0.253, Train_accy 86.13, Test_accy 85.50: 100%|██████████| 20/20 [2:03:11<00:00, 372.58s/it]Task 0, Epoch 20/20 => Loss 0.253, Train_accy 86.13, Test_accy 85.50: 100%|██████████| 20/20 [2:03:11<00:00, 369.58s/it]
2024-05-01 13:47:22,238 [l2p.py] => Task 0, Epoch 20/20 => Loss 0.253, Train_accy 86.13, Test_accy 85.50
2024-05-01 13:47:39,020 [trainer.py] => No NME accuracy.
2024-05-01 13:47:39,020 [trainer.py] => CNN: {'total': 85.5, '00-149': 85.5, 'old': 0, 'new': 85.5}
2024-05-01 13:47:39,020 [trainer.py] => CNN top1 curve: [85.5]
2024-05-01 13:47:39,020 [trainer.py] => CNN top5 curve: [97.23]

Average Accuracy (CNN): 85.5
2024-05-01 13:47:39,020 [trainer.py] => Average Accuracy (CNN): 85.5 

2024-05-01 13:47:39,020 [trainer.py] => Train Time: 14784.0
2024-05-01 13:47:39,020 [trainer.py] => Test Time: 16.78 

2024-05-01 13:47:39,021 [trainer.py] => All params: 172123992
2024-05-01 13:47:39,022 [trainer.py] => Trainable params: 276780
2024-05-01 13:47:39,022 [l2p.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.333, Train_accy 84.68:   0%|          | 0/20 [01:14<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.333, Train_accy 84.68:   5%|▌         | 1/20 [01:14<23:29, 74.16s/it]Task 1, Epoch 2/20 => Loss 0.066, Train_accy 90.46:   5%|▌         | 1/20 [02:27<23:29, 74.16s/it]Task 1, Epoch 2/20 => Loss 0.066, Train_accy 90.46:  10%|█         | 2/20 [02:27<22:03, 73.52s/it]Task 1, Epoch 3/20 => Loss 0.027, Train_accy 91.77:  10%|█         | 2/20 [03:40<22:03, 73.52s/it]Task 1, Epoch 3/20 => Loss 0.027, Train_accy 91.77:  15%|█▌        | 3/20 [03:40<20:45, 73.26s/it]Task 1, Epoch 4/20 => Loss -0.000, Train_accy 92.64:  15%|█▌        | 3/20 [04:53<20:45, 73.26s/it]Task 1, Epoch 4/20 => Loss -0.000, Train_accy 92.64:  20%|██        | 4/20 [04:53<19:29, 73.10s/it]Task 1, Epoch 5/20 => Loss -0.025, Train_accy 93.46, Test_accy 73.69:  20%|██        | 4/20 [06:26<19:29, 73.10s/it]Task 1, Epoch 5/20 => Loss -0.025, Train_accy 93.46, Test_accy 73.69:  25%|██▌       | 5/20 [06:26<20:04, 80.29s/it]Task 1, Epoch 6/20 => Loss -0.034, Train_accy 93.59:  25%|██▌       | 5/20 [07:39<20:04, 80.29s/it]                 Task 1, Epoch 6/20 => Loss -0.034, Train_accy 93.59:  30%|███       | 6/20 [07:39<18:09, 77.80s/it]Task 1, Epoch 7/20 => Loss -0.031, Train_accy 93.61:  30%|███       | 6/20 [08:51<18:09, 77.80s/it]Task 1, Epoch 7/20 => Loss -0.031, Train_accy 93.61:  35%|███▌      | 7/20 [08:51<16:30, 76.20s/it]Task 1, Epoch 8/20 => Loss -0.040, Train_accy 94.37:  35%|███▌      | 7/20 [10:04<16:30, 76.20s/it]Task 1, Epoch 8/20 => Loss -0.040, Train_accy 94.37:  40%|████      | 8/20 [10:04<15:02, 75.19s/it]Task 1, Epoch 9/20 => Loss -0.044, Train_accy 94.15:  40%|████      | 8/20 [11:18<15:02, 75.19s/it]Task 1, Epoch 9/20 => Loss -0.044, Train_accy 94.15:  45%|████▌     | 9/20 [11:18<13:39, 74.53s/it]Task 1, Epoch 10/20 => Loss -0.055, Train_accy 94.48, Test_accy 74.69:  45%|████▌     | 9/20 [12:51<13:39, 74.53s/it]Task 1, Epoch 10/20 => Loss -0.055, Train_accy 94.48, Test_accy 74.69:  50%|█████     | 10/20 [12:51<13:22, 80.25s/it]Task 1, Epoch 11/20 => Loss -0.059, Train_accy 94.77:  50%|█████     | 10/20 [14:04<13:22, 80.25s/it]                 Task 1, Epoch 11/20 => Loss -0.059, Train_accy 94.77:  55%|█████▌    | 11/20 [14:04<11:42, 78.05s/it]Task 1, Epoch 12/20 => Loss -0.054, Train_accy 94.40:  55%|█████▌    | 11/20 [15:17<11:42, 78.05s/it]Task 1, Epoch 12/20 => Loss -0.054, Train_accy 94.40:  60%|██████    | 12/20 [15:17<10:12, 76.61s/it]Task 1, Epoch 13/20 => Loss -0.068, Train_accy 94.77:  60%|██████    | 12/20 [16:30<10:12, 76.61s/it]Task 1, Epoch 13/20 => Loss -0.068, Train_accy 94.77:  65%|██████▌   | 13/20 [16:30<08:48, 75.54s/it]Task 1, Epoch 14/20 => Loss -0.061, Train_accy 94.87:  65%|██████▌   | 13/20 [17:43<08:48, 75.54s/it]Task 1, Epoch 14/20 => Loss -0.061, Train_accy 94.87:  70%|███████   | 14/20 [17:43<07:28, 74.75s/it]Task 1, Epoch 15/20 => Loss -0.067, Train_accy 94.93, Test_accy 75.50:  70%|███████   | 14/20 [19:16<07:28, 74.75s/it]Task 1, Epoch 15/20 => Loss -0.067, Train_accy 94.93, Test_accy 75.50:  75%|███████▌  | 15/20 [19:16<06:40, 80.14s/it]Task 1, Epoch 16/20 => Loss -0.076, Train_accy 95.13:  75%|███████▌  | 15/20 [20:28<06:40, 80.14s/it]                 Task 1, Epoch 16/20 => Loss -0.076, Train_accy 95.13:  80%|████████  | 16/20 [20:28<05:11, 77.90s/it]Task 1, Epoch 17/20 => Loss -0.081, Train_accy 95.32:  80%|████████  | 16/20 [21:41<05:11, 77.90s/it]Task 1, Epoch 17/20 => Loss -0.081, Train_accy 95.32:  85%|████████▌ | 17/20 [21:41<03:49, 76.46s/it]Task 1, Epoch 18/20 => Loss -0.081, Train_accy 95.60:  85%|████████▌ | 17/20 [22:54<03:49, 76.46s/it]Task 1, Epoch 18/20 => Loss -0.081, Train_accy 95.60:  90%|█████████ | 18/20 [22:54<02:30, 75.44s/it]Task 1, Epoch 19/20 => Loss -0.061, Train_accy 94.50:  90%|█████████ | 18/20 [24:08<02:30, 75.44s/it]Task 1, Epoch 19/20 => Loss -0.061, Train_accy 94.50:  95%|█████████▌| 19/20 [24:08<01:14, 74.75s/it]Task 1, Epoch 20/20 => Loss -0.081, Train_accy 95.29, Test_accy 76.06:  95%|█████████▌| 19/20 [25:40<01:14, 74.75s/it]Task 1, Epoch 20/20 => Loss -0.081, Train_accy 95.29, Test_accy 76.06: 100%|██████████| 20/20 [25:40<00:00, 80.14s/it]Task 1, Epoch 20/20 => Loss -0.081, Train_accy 95.29, Test_accy 76.06: 100%|██████████| 20/20 [25:40<00:00, 77.04s/it]
2024-05-01 14:13:19,865 [l2p.py] => Task 1, Epoch 20/20 => Loss -0.081, Train_accy 95.29, Test_accy 76.06
2024-05-01 14:13:39,425 [trainer.py] => No NME accuracy.
2024-05-01 14:13:39,425 [trainer.py] => CNN: {'total': 76.06, '00-149': 85.24, '150-179': 30.1, 'old': 85.24, 'new': 30.1}
2024-05-01 14:13:39,425 [trainer.py] => CNN top1 curve: [85.5, 76.06]
2024-05-01 14:13:39,425 [trainer.py] => CNN top5 curve: [97.23, 94.85]

Average Accuracy (CNN): 80.78
2024-05-01 14:13:39,425 [trainer.py] => Average Accuracy (CNN): 80.78 

2024-05-01 14:13:39,425 [trainer.py] => Train Time: 17865.65
2024-05-01 14:13:39,425 [trainer.py] => Test Time: 36.34 

2024-05-01 14:13:39,427 [trainer.py] => All params: 172123992
2024-05-01 14:13:39,428 [trainer.py] => Trainable params: 276780
2024-05-01 14:13:39,428 [l2p.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.261, Train_accy 84.81:   0%|          | 0/20 [01:13<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.261, Train_accy 84.81:   5%|▌         | 1/20 [01:13<23:14, 73.38s/it]Task 2, Epoch 2/20 => Loss 0.045, Train_accy 90.36:   5%|▌         | 1/20 [02:26<23:14, 73.38s/it]Task 2, Epoch 2/20 => Loss 0.045, Train_accy 90.36:  10%|█         | 2/20 [02:26<21:55, 73.07s/it]Task 2, Epoch 3/20 => Loss 0.011, Train_accy 91.85:  10%|█         | 2/20 [03:38<21:55, 73.07s/it]Task 2, Epoch 3/20 => Loss 0.011, Train_accy 91.85:  15%|█▌        | 3/20 [03:38<20:38, 72.83s/it]Task 2, Epoch 4/20 => Loss -0.011, Train_accy 92.60:  15%|█▌        | 3/20 [04:51<20:38, 72.83s/it]Task 2, Epoch 4/20 => Loss -0.011, Train_accy 92.60:  20%|██        | 4/20 [04:51<19:24, 72.81s/it]Task 2, Epoch 5/20 => Loss -0.009, Train_accy 92.57, Test_accy 66.29:  20%|██        | 4/20 [06:27<19:24, 72.81s/it]Task 2, Epoch 5/20 => Loss -0.009, Train_accy 92.57, Test_accy 66.29:  25%|██▌       | 5/20 [06:27<20:16, 81.09s/it]Task 2, Epoch 6/20 => Loss -0.023, Train_accy 93.02:  25%|██▌       | 5/20 [07:40<20:16, 81.09s/it]                 Task 2, Epoch 6/20 => Loss -0.023, Train_accy 93.02:  30%|███       | 6/20 [07:40<18:15, 78.24s/it]Task 2, Epoch 7/20 => Loss -0.025, Train_accy 93.20:  30%|███       | 6/20 [08:52<18:15, 78.24s/it]Task 2, Epoch 7/20 => Loss -0.025, Train_accy 93.20:  35%|███▌      | 7/20 [08:52<16:33, 76.43s/it]Task 2, Epoch 8/20 => Loss -0.027, Train_accy 93.34:  35%|███▌      | 7/20 [10:05<16:33, 76.43s/it]Task 2, Epoch 8/20 => Loss -0.027, Train_accy 93.34:  40%|████      | 8/20 [10:05<15:04, 75.38s/it]Task 2, Epoch 9/20 => Loss -0.046, Train_accy 94.09:  40%|████      | 8/20 [11:18<15:04, 75.38s/it]Task 2, Epoch 9/20 => Loss -0.046, Train_accy 94.09:  45%|████▌     | 9/20 [11:18<13:41, 74.68s/it]Task 2, Epoch 10/20 => Loss -0.040, Train_accy 93.73, Test_accy 68.23:  45%|████▌     | 9/20 [12:54<13:41, 74.68s/it]Task 2, Epoch 10/20 => Loss -0.040, Train_accy 93.73, Test_accy 68.23:  50%|█████     | 10/20 [12:54<13:31, 81.15s/it]Task 2, Epoch 11/20 => Loss -0.050, Train_accy 94.19:  50%|█████     | 10/20 [14:07<13:31, 81.15s/it]                 Task 2, Epoch 11/20 => Loss -0.050, Train_accy 94.19:  55%|█████▌    | 11/20 [14:07<11:46, 78.53s/it]Task 2, Epoch 12/20 => Loss -0.058, Train_accy 94.49:  55%|█████▌    | 11/20 [15:19<11:46, 78.53s/it]Task 2, Epoch 12/20 => Loss -0.058, Train_accy 94.49:  60%|██████    | 12/20 [15:19<10:13, 76.72s/it]Task 2, Epoch 13/20 => Loss -0.050, Train_accy 94.08:  60%|██████    | 12/20 [16:32<10:13, 76.72s/it]Task 2, Epoch 13/20 => Loss -0.050, Train_accy 94.08:  65%|██████▌   | 13/20 [16:32<08:48, 75.43s/it]Task 2, Epoch 14/20 => Loss -0.068, Train_accy 94.85:  65%|██████▌   | 13/20 [17:45<08:48, 75.43s/it]Task 2, Epoch 14/20 => Loss -0.068, Train_accy 94.85:  70%|███████   | 14/20 [17:45<07:28, 74.76s/it]Task 2, Epoch 15/20 => Loss -0.056, Train_accy 94.45, Test_accy 70.23:  70%|███████   | 14/20 [19:21<07:28, 74.76s/it]Task 2, Epoch 15/20 => Loss -0.056, Train_accy 94.45, Test_accy 70.23:  75%|███████▌  | 15/20 [19:21<06:45, 81.13s/it]Task 2, Epoch 16/20 => Loss -0.060, Train_accy 94.37:  75%|███████▌  | 15/20 [20:34<06:45, 81.13s/it]                 Task 2, Epoch 16/20 => Loss -0.060, Train_accy 94.37:  80%|████████  | 16/20 [20:34<05:14, 78.67s/it]Task 2, Epoch 17/20 => Loss -0.065, Train_accy 94.67:  80%|████████  | 16/20 [21:46<05:14, 78.67s/it]Task 2, Epoch 17/20 => Loss -0.065, Train_accy 94.67:  85%|████████▌ | 17/20 [21:46<03:50, 76.78s/it]Task 2, Epoch 18/20 => Loss -0.072, Train_accy 94.68:  85%|████████▌ | 17/20 [22:58<03:50, 76.78s/it]Task 2, Epoch 18/20 => Loss -0.072, Train_accy 94.68:  90%|█████████ | 18/20 [22:58<02:30, 75.41s/it]Task 2, Epoch 19/20 => Loss -0.080, Train_accy 95.16:  90%|█████████ | 18/20 [24:11<02:30, 75.41s/it]Task 2, Epoch 19/20 => Loss -0.080, Train_accy 95.16:  95%|█████████▌| 19/20 [24:11<01:14, 74.70s/it]Task 2, Epoch 20/20 => Loss -0.063, Train_accy 94.59, Test_accy 71.21:  95%|█████████▌| 19/20 [25:48<01:14, 74.70s/it]Task 2, Epoch 20/20 => Loss -0.063, Train_accy 94.59, Test_accy 71.21: 100%|██████████| 20/20 [25:48<00:00, 81.22s/it]Task 2, Epoch 20/20 => Loss -0.063, Train_accy 94.59, Test_accy 71.21: 100%|██████████| 20/20 [25:48<00:00, 77.42s/it]
2024-05-01 14:39:27,836 [l2p.py] => Task 2, Epoch 20/20 => Loss -0.063, Train_accy 94.59, Test_accy 71.21
2024-05-01 14:39:50,803 [trainer.py] => No NME accuracy.
2024-05-01 14:39:50,803 [trainer.py] => CNN: {'total': 71.21, '00-149': 85.34, '150-179': 29.6, '180-209': 42.04, 'old': 76.06, 'new': 42.04}
2024-05-01 14:39:50,803 [trainer.py] => CNN top1 curve: [85.5, 76.06, 71.21]
2024-05-01 14:39:50,803 [trainer.py] => CNN top5 curve: [97.23, 94.85, 92.15]

Average Accuracy (CNN): 77.59
2024-05-01 14:39:50,803 [trainer.py] => Average Accuracy (CNN): 77.59 

2024-05-01 14:39:50,803 [trainer.py] => Train Time: 20962.420000000002
2024-05-01 14:39:50,803 [trainer.py] => Test Time: 59.31 

2024-05-01 14:39:50,805 [trainer.py] => All params: 172123992
2024-05-01 14:39:50,806 [trainer.py] => Trainable params: 276780
2024-05-01 14:39:50,806 [l2p.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.332, Train_accy 82.39:   0%|          | 0/20 [01:18<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.332, Train_accy 82.39:   5%|▌         | 1/20 [01:18<24:50, 78.46s/it]Task 3, Epoch 2/20 => Loss 0.111, Train_accy 88.47:   5%|▌         | 1/20 [02:35<24:50, 78.46s/it]Task 3, Epoch 2/20 => Loss 0.111, Train_accy 88.47:  10%|█         | 2/20 [02:35<23:18, 77.68s/it]Task 3, Epoch 3/20 => Loss 0.077, Train_accy 89.75:  10%|█         | 2/20 [03:52<23:18, 77.68s/it]Task 3, Epoch 3/20 => Loss 0.077, Train_accy 89.75:  15%|█▌        | 3/20 [03:52<21:54, 77.33s/it]Task 3, Epoch 4/20 => Loss 0.049, Train_accy 90.59:  15%|█▌        | 3/20 [05:09<21:54, 77.33s/it]Task 3, Epoch 4/20 => Loss 0.049, Train_accy 90.59:  20%|██        | 4/20 [05:09<20:34, 77.15s/it]Task 3, Epoch 5/20 => Loss 0.027, Train_accy 91.62, Test_accy 63.07:  20%|██        | 4/20 [06:52<20:34, 77.15s/it]Task 3, Epoch 5/20 => Loss 0.027, Train_accy 91.62, Test_accy 63.07:  25%|██▌       | 5/20 [06:52<21:40, 86.69s/it]Task 3, Epoch 6/20 => Loss 0.011, Train_accy 91.93:  25%|██▌       | 5/20 [08:10<21:40, 86.69s/it]                 Task 3, Epoch 6/20 => Loss 0.011, Train_accy 91.93:  30%|███       | 6/20 [08:10<19:27, 83.40s/it]Task 3, Epoch 7/20 => Loss 0.021, Train_accy 91.74:  30%|███       | 6/20 [09:26<19:27, 83.40s/it]Task 3, Epoch 7/20 => Loss 0.021, Train_accy 91.74:  35%|███▌      | 7/20 [09:26<17:34, 81.13s/it]Task 3, Epoch 8/20 => Loss 0.005, Train_accy 92.15:  35%|███▌      | 7/20 [10:42<17:34, 81.13s/it]Task 3, Epoch 8/20 => Loss 0.005, Train_accy 92.15:  40%|████      | 8/20 [10:42<15:53, 79.48s/it]Task 3, Epoch 9/20 => Loss 0.005, Train_accy 92.23:  40%|████      | 8/20 [11:58<15:53, 79.48s/it]Task 3, Epoch 9/20 => Loss 0.005, Train_accy 92.23:  45%|████▌     | 9/20 [11:58<14:23, 78.54s/it]Task 3, Epoch 10/20 => Loss -0.008, Train_accy 92.85, Test_accy 64.62:  45%|████▌     | 9/20 [13:42<14:23, 78.54s/it]Task 3, Epoch 10/20 => Loss -0.008, Train_accy 92.85, Test_accy 64.62:  50%|█████     | 10/20 [13:42<14:21, 86.17s/it]Task 3, Epoch 11/20 => Loss -0.006, Train_accy 92.67:  50%|█████     | 10/20 [14:58<14:21, 86.17s/it]                 Task 3, Epoch 11/20 => Loss -0.006, Train_accy 92.67:  55%|█████▌    | 11/20 [14:58<12:29, 83.29s/it]Task 3, Epoch 12/20 => Loss -0.002, Train_accy 92.33:  55%|█████▌    | 11/20 [16:15<12:29, 83.29s/it]Task 3, Epoch 12/20 => Loss -0.002, Train_accy 92.33:  60%|██████    | 12/20 [16:15<10:49, 81.22s/it]Task 3, Epoch 13/20 => Loss -0.018, Train_accy 92.92:  60%|██████    | 12/20 [17:32<10:49, 81.22s/it]Task 3, Epoch 13/20 => Loss -0.018, Train_accy 92.92:  65%|██████▌   | 13/20 [17:32<09:19, 79.90s/it]Task 3, Epoch 14/20 => Loss -0.025, Train_accy 93.47:  65%|██████▌   | 13/20 [18:49<09:19, 79.90s/it]Task 3, Epoch 14/20 => Loss -0.025, Train_accy 93.47:  70%|███████   | 14/20 [18:49<07:54, 79.03s/it]Task 3, Epoch 15/20 => Loss -0.025, Train_accy 93.31, Test_accy 65.71:  70%|███████   | 14/20 [20:32<07:54, 79.03s/it]Task 3, Epoch 15/20 => Loss -0.025, Train_accy 93.31, Test_accy 65.71:  75%|███████▌  | 15/20 [20:32<07:12, 86.44s/it]Task 3, Epoch 16/20 => Loss -0.025, Train_accy 93.32:  75%|███████▌  | 15/20 [21:49<07:12, 86.44s/it]                 Task 3, Epoch 16/20 => Loss -0.025, Train_accy 93.32:  80%|████████  | 16/20 [21:49<05:34, 83.60s/it]Task 3, Epoch 17/20 => Loss -0.035, Train_accy 93.42:  80%|████████  | 16/20 [23:06<05:34, 83.60s/it]Task 3, Epoch 17/20 => Loss -0.035, Train_accy 93.42:  85%|████████▌ | 17/20 [23:06<04:04, 81.56s/it]Task 3, Epoch 18/20 => Loss -0.034, Train_accy 93.56:  85%|████████▌ | 17/20 [24:22<04:04, 81.56s/it]Task 3, Epoch 18/20 => Loss -0.034, Train_accy 93.56:  90%|█████████ | 18/20 [24:22<02:39, 79.95s/it]Task 3, Epoch 19/20 => Loss -0.034, Train_accy 93.34:  90%|█████████ | 18/20 [25:39<02:39, 79.95s/it]Task 3, Epoch 19/20 => Loss -0.034, Train_accy 93.34:  95%|█████████▌| 19/20 [25:39<01:18, 78.88s/it]Task 3, Epoch 20/20 => Loss -0.023, Train_accy 93.30, Test_accy 66.50:  95%|█████████▌| 19/20 [27:22<01:18, 78.88s/it]Task 3, Epoch 20/20 => Loss -0.023, Train_accy 93.30, Test_accy 66.50: 100%|██████████| 20/20 [27:22<00:00, 86.11s/it]Task 3, Epoch 20/20 => Loss -0.023, Train_accy 93.30, Test_accy 66.50: 100%|██████████| 20/20 [27:22<00:00, 82.11s/it]
2024-05-01 15:07:13,091 [l2p.py] => Task 3, Epoch 20/20 => Loss -0.023, Train_accy 93.30, Test_accy 66.50
2024-05-01 15:07:39,296 [trainer.py] => No NME accuracy.
2024-05-01 15:07:39,296 [trainer.py] => CNN: {'total': 66.5, '00-149': 85.57, '150-179': 30.77, '180-209': 41.21, '210-239': 32.05, 'old': 71.43, 'new': 32.05}
2024-05-01 15:07:39,296 [trainer.py] => CNN top1 curve: [85.5, 76.06, 71.21, 66.5]
2024-05-01 15:07:39,297 [trainer.py] => CNN top5 curve: [97.23, 94.85, 92.15, 90.37]

Average Accuracy (CNN): 74.82
2024-05-01 15:07:39,297 [trainer.py] => Average Accuracy (CNN): 74.82 

2024-05-01 15:07:39,297 [trainer.py] => Train Time: 24246.95
2024-05-01 15:07:39,297 [trainer.py] => Test Time: 85.51 

2024-05-01 15:07:39,298 [trainer.py] => All params: 172123992
2024-05-01 15:07:39,299 [trainer.py] => Trainable params: 276780
2024-05-01 15:07:39,300 [l2p.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.157, Train_accy 89.70:   0%|          | 0/20 [01:16<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.157, Train_accy 89.70:   5%|▌         | 1/20 [01:16<24:18, 76.79s/it]Task 4, Epoch 2/20 => Loss -0.036, Train_accy 94.28:   5%|▌         | 1/20 [02:32<24:18, 76.79s/it]Task 4, Epoch 2/20 => Loss -0.036, Train_accy 94.28:  10%|█         | 2/20 [02:32<22:53, 76.29s/it]Task 4, Epoch 3/20 => Loss -0.062, Train_accy 95.02:  10%|█         | 2/20 [03:48<22:53, 76.29s/it]Task 4, Epoch 3/20 => Loss -0.062, Train_accy 95.02:  15%|█▌        | 3/20 [03:48<21:30, 75.89s/it]Task 4, Epoch 4/20 => Loss -0.062, Train_accy 94.95:  15%|█▌        | 3/20 [05:03<21:30, 75.89s/it]Task 4, Epoch 4/20 => Loss -0.062, Train_accy 94.95:  20%|██        | 4/20 [05:03<20:11, 75.73s/it]Task 4, Epoch 5/20 => Loss -0.081, Train_accy 95.75, Test_accy 59.57:  20%|██        | 4/20 [06:49<20:11, 75.73s/it]Task 4, Epoch 5/20 => Loss -0.081, Train_accy 95.75, Test_accy 59.57:  25%|██▌       | 5/20 [06:49<21:36, 86.43s/it]Task 4, Epoch 6/20 => Loss -0.083, Train_accy 95.64:  25%|██▌       | 5/20 [08:04<21:36, 86.43s/it]                 Task 4, Epoch 6/20 => Loss -0.083, Train_accy 95.64:  30%|███       | 6/20 [08:04<19:19, 82.83s/it]Task 4, Epoch 7/20 => Loss -0.086, Train_accy 95.91:  30%|███       | 6/20 [09:20<19:19, 82.83s/it]Task 4, Epoch 7/20 => Loss -0.086, Train_accy 95.91:  35%|███▌      | 7/20 [09:20<17:24, 80.35s/it]Task 4, Epoch 8/20 => Loss -0.093, Train_accy 96.14:  35%|███▌      | 7/20 [10:35<17:24, 80.35s/it]Task 4, Epoch 8/20 => Loss -0.093, Train_accy 96.14:  40%|████      | 8/20 [10:35<15:43, 78.63s/it]Task 4, Epoch 9/20 => Loss -0.100, Train_accy 96.23:  40%|████      | 8/20 [11:50<15:43, 78.63s/it]Task 4, Epoch 9/20 => Loss -0.100, Train_accy 96.23:  45%|████▌     | 9/20 [11:50<14:12, 77.54s/it]Task 4, Epoch 10/20 => Loss -0.097, Train_accy 96.07, Test_accy 60.79:  45%|████▌     | 9/20 [13:35<14:12, 77.54s/it]Task 4, Epoch 10/20 => Loss -0.097, Train_accy 96.07, Test_accy 60.79:  50%|█████     | 10/20 [13:35<14:20, 86.09s/it]Task 4, Epoch 11/20 => Loss -0.093, Train_accy 95.91:  50%|█████     | 10/20 [14:51<14:20, 86.09s/it]                 Task 4, Epoch 11/20 => Loss -0.093, Train_accy 95.91:  55%|█████▌    | 11/20 [14:51<12:26, 82.89s/it]Task 4, Epoch 12/20 => Loss -0.102, Train_accy 96.43:  55%|█████▌    | 11/20 [16:06<12:26, 82.89s/it]Task 4, Epoch 12/20 => Loss -0.102, Train_accy 96.43:  60%|██████    | 12/20 [16:06<10:44, 80.62s/it]Task 4, Epoch 13/20 => Loss -0.104, Train_accy 96.36:  60%|██████    | 12/20 [17:22<10:44, 80.62s/it]Task 4, Epoch 13/20 => Loss -0.104, Train_accy 96.36:  65%|██████▌   | 13/20 [17:22<09:14, 79.19s/it]Task 4, Epoch 14/20 => Loss -0.118, Train_accy 96.93:  65%|██████▌   | 13/20 [18:38<09:14, 79.19s/it]Task 4, Epoch 14/20 => Loss -0.118, Train_accy 96.93:  70%|███████   | 14/20 [18:38<07:48, 78.15s/it]Task 4, Epoch 15/20 => Loss -0.100, Train_accy 96.21, Test_accy 61.39:  70%|███████   | 14/20 [20:23<07:48, 78.15s/it]Task 4, Epoch 15/20 => Loss -0.100, Train_accy 96.21, Test_accy 61.39:  75%|███████▌  | 15/20 [20:23<07:11, 86.21s/it]Task 4, Epoch 16/20 => Loss -0.114, Train_accy 96.79:  75%|███████▌  | 15/20 [21:38<07:11, 86.21s/it]                 Task 4, Epoch 16/20 => Loss -0.114, Train_accy 96.79:  80%|████████  | 16/20 [21:38<05:31, 82.93s/it]Task 4, Epoch 17/20 => Loss -0.099, Train_accy 96.29:  80%|████████  | 16/20 [22:53<05:31, 82.93s/it]Task 4, Epoch 17/20 => Loss -0.099, Train_accy 96.29:  85%|████████▌ | 17/20 [22:53<04:01, 80.61s/it]Task 4, Epoch 18/20 => Loss -0.104, Train_accy 96.37:  85%|████████▌ | 17/20 [24:08<04:01, 80.61s/it]Task 4, Epoch 18/20 => Loss -0.104, Train_accy 96.37:  90%|█████████ | 18/20 [24:08<02:38, 79.03s/it]Task 4, Epoch 19/20 => Loss -0.111, Train_accy 96.45:  90%|█████████ | 18/20 [25:23<02:38, 79.03s/it]Task 4, Epoch 19/20 => Loss -0.111, Train_accy 96.45:  95%|█████████▌| 19/20 [25:23<01:17, 77.78s/it]Task 4, Epoch 20/20 => Loss -0.117, Train_accy 96.85, Test_accy 62.73:  95%|█████████▌| 19/20 [27:08<01:17, 77.78s/it]Task 4, Epoch 20/20 => Loss -0.117, Train_accy 96.85, Test_accy 62.73: 100%|██████████| 20/20 [27:08<00:00, 85.82s/it]Task 4, Epoch 20/20 => Loss -0.117, Train_accy 96.85, Test_accy 62.73: 100%|██████████| 20/20 [27:08<00:00, 81.42s/it]
2024-05-01 15:34:47,649 [l2p.py] => Task 4, Epoch 20/20 => Loss -0.117, Train_accy 96.85, Test_accy 62.73
2024-05-01 15:35:17,087 [trainer.py] => No NME accuracy.
2024-05-01 15:35:17,087 [trainer.py] => CNN: {'total': 62.73, '00-149': 85.3, '150-179': 29.6, '180-209': 41.54, '210-239': 31.39, '240-269': 35.39, 'old': 66.14, 'new': 35.39}
2024-05-01 15:35:17,087 [trainer.py] => CNN top1 curve: [85.5, 76.06, 71.21, 66.5, 62.73]
2024-05-01 15:35:17,087 [trainer.py] => CNN top5 curve: [97.23, 94.85, 92.15, 90.37, 89.18]

Average Accuracy (CNN): 72.4
2024-05-01 15:35:17,087 [trainer.py] => Average Accuracy (CNN): 72.4 

2024-05-01 15:35:17,087 [trainer.py] => Train Time: 27503.6
2024-05-01 15:35:17,087 [trainer.py] => Test Time: 114.95 

2024-05-01 15:35:17,089 [trainer.py] => All params: 172123992
2024-05-01 15:35:17,090 [trainer.py] => Trainable params: 276780
2024-05-01 15:35:17,090 [l2p.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.163, Train_accy 89.16:   0%|          | 0/20 [01:11<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.163, Train_accy 89.16:   5%|▌         | 1/20 [01:11<22:45, 71.85s/it]Task 5, Epoch 2/20 => Loss -0.031, Train_accy 93.62:   5%|▌         | 1/20 [02:23<22:45, 71.85s/it]Task 5, Epoch 2/20 => Loss -0.031, Train_accy 93.62:  10%|█         | 2/20 [02:23<21:27, 71.54s/it]Task 5, Epoch 3/20 => Loss -0.043, Train_accy 94.15:  10%|█         | 2/20 [03:34<21:27, 71.54s/it]Task 5, Epoch 3/20 => Loss -0.043, Train_accy 94.15:  15%|█▌        | 3/20 [03:34<20:14, 71.47s/it]Task 5, Epoch 4/20 => Loss -0.064, Train_accy 94.94:  15%|█▌        | 3/20 [04:45<20:14, 71.47s/it]Task 5, Epoch 4/20 => Loss -0.064, Train_accy 94.94:  20%|██        | 4/20 [04:45<19:02, 71.42s/it]Task 5, Epoch 5/20 => Loss -0.081, Train_accy 95.56, Test_accy 56.56:  20%|██        | 4/20 [06:29<19:02, 71.42s/it]Task 5, Epoch 5/20 => Loss -0.081, Train_accy 95.56, Test_accy 56.56:  25%|██▌       | 5/20 [06:29<20:46, 83.09s/it]Task 5, Epoch 6/20 => Loss -0.073, Train_accy 95.44:  25%|██▌       | 5/20 [07:41<20:46, 83.09s/it]                 Task 5, Epoch 6/20 => Loss -0.073, Train_accy 95.44:  30%|███       | 6/20 [07:41<18:28, 79.15s/it]Task 5, Epoch 7/20 => Loss -0.081, Train_accy 95.49:  30%|███       | 6/20 [08:52<18:28, 79.15s/it]Task 5, Epoch 7/20 => Loss -0.081, Train_accy 95.49:  35%|███▌      | 7/20 [08:52<16:36, 76.63s/it]Task 5, Epoch 8/20 => Loss -0.095, Train_accy 96.03:  35%|███▌      | 7/20 [10:03<16:36, 76.63s/it]Task 5, Epoch 8/20 => Loss -0.095, Train_accy 96.03:  40%|████      | 8/20 [10:03<14:57, 74.82s/it]Task 5, Epoch 9/20 => Loss -0.089, Train_accy 96.02:  40%|████      | 8/20 [11:14<14:57, 74.82s/it]Task 5, Epoch 9/20 => Loss -0.089, Train_accy 96.02:  45%|████▌     | 9/20 [11:14<13:28, 73.52s/it]Task 5, Epoch 10/20 => Loss -0.091, Train_accy 95.73, Test_accy 58.30:  45%|████▌     | 9/20 [12:57<13:28, 73.52s/it]Task 5, Epoch 10/20 => Loss -0.091, Train_accy 95.73, Test_accy 58.30:  50%|█████     | 10/20 [12:57<13:47, 82.78s/it]Task 5, Epoch 11/20 => Loss -0.096, Train_accy 96.05:  50%|█████     | 10/20 [14:08<13:47, 82.78s/it]                 Task 5, Epoch 11/20 => Loss -0.096, Train_accy 96.05:  55%|█████▌    | 11/20 [14:08<11:52, 79.20s/it]Task 5, Epoch 12/20 => Loss -0.102, Train_accy 96.08:  55%|█████▌    | 11/20 [15:19<11:52, 79.20s/it]Task 5, Epoch 12/20 => Loss -0.102, Train_accy 96.08:  60%|██████    | 12/20 [15:19<10:13, 76.71s/it]Task 5, Epoch 13/20 => Loss -0.107, Train_accy 96.48:  60%|██████    | 12/20 [16:30<10:13, 76.71s/it]Task 5, Epoch 13/20 => Loss -0.107, Train_accy 96.48:  65%|██████▌   | 13/20 [16:30<08:45, 75.01s/it]Task 5, Epoch 14/20 => Loss -0.110, Train_accy 96.61:  65%|██████▌   | 13/20 [17:41<08:45, 75.01s/it]Task 5, Epoch 14/20 => Loss -0.110, Train_accy 96.61:  70%|███████   | 14/20 [17:41<07:22, 73.76s/it]Task 5, Epoch 15/20 => Loss -0.101, Train_accy 96.32, Test_accy 59.08:  70%|███████   | 14/20 [19:24<07:22, 73.76s/it]Task 5, Epoch 15/20 => Loss -0.101, Train_accy 96.32, Test_accy 59.08:  75%|███████▌  | 15/20 [19:24<06:53, 82.62s/it]Task 5, Epoch 16/20 => Loss -0.099, Train_accy 96.16:  75%|███████▌  | 15/20 [20:35<06:53, 82.62s/it]                 Task 5, Epoch 16/20 => Loss -0.099, Train_accy 96.16:  80%|████████  | 16/20 [20:35<05:16, 79.13s/it]Task 5, Epoch 17/20 => Loss -0.103, Train_accy 96.48:  80%|████████  | 16/20 [21:47<05:16, 79.13s/it]Task 5, Epoch 17/20 => Loss -0.103, Train_accy 96.48:  85%|████████▌ | 17/20 [21:47<03:50, 76.72s/it]Task 5, Epoch 18/20 => Loss -0.109, Train_accy 96.51:  85%|████████▌ | 17/20 [22:57<03:50, 76.72s/it]Task 5, Epoch 18/20 => Loss -0.109, Train_accy 96.51:  90%|█████████ | 18/20 [22:57<02:29, 74.96s/it]Task 5, Epoch 19/20 => Loss -0.104, Train_accy 96.44:  90%|█████████ | 18/20 [24:08<02:29, 74.96s/it]Task 5, Epoch 19/20 => Loss -0.104, Train_accy 96.44:  95%|█████████▌| 19/20 [24:08<01:13, 73.76s/it]Task 5, Epoch 20/20 => Loss -0.095, Train_accy 96.11, Test_accy 60.43:  95%|█████████▌| 19/20 [25:52<01:13, 73.76s/it]Task 5, Epoch 20/20 => Loss -0.095, Train_accy 96.11, Test_accy 60.43: 100%|██████████| 20/20 [25:52<00:00, 82.67s/it]Task 5, Epoch 20/20 => Loss -0.095, Train_accy 96.11, Test_accy 60.43: 100%|██████████| 20/20 [25:52<00:00, 77.62s/it]
2024-05-01 16:01:09,474 [l2p.py] => Task 5, Epoch 20/20 => Loss -0.095, Train_accy 96.11, Test_accy 60.43
2024-05-01 16:01:41,761 [trainer.py] => No NME accuracy.
2024-05-01 16:01:41,761 [trainer.py] => CNN: {'total': 60.43, '00-149': 84.87, '150-179': 30.43, '180-209': 42.04, '210-239': 30.72, '240-269': 33.72, '270-299': 42.98, 'old': 62.37, 'new': 42.98}
2024-05-01 16:01:41,761 [trainer.py] => CNN top1 curve: [85.5, 76.06, 71.21, 66.5, 62.73, 60.43]
2024-05-01 16:01:41,761 [trainer.py] => CNN top5 curve: [97.23, 94.85, 92.15, 90.37, 89.18, 88.76]

Average Accuracy (CNN): 70.4
2024-05-01 16:01:41,761 [trainer.py] => Average Accuracy (CNN): 70.4 

2024-05-01 16:01:41,761 [trainer.py] => Train Time: 30608.32
2024-05-01 16:01:41,762 [trainer.py] => Test Time: 147.23000000000002 

Accuracy Matrix (CNN):
[[85.5  85.24 85.34 85.57 85.3  84.87]
 [ 0.   30.1  29.6  30.77 29.6  30.43]
 [ 0.    0.   42.04 41.21 41.54 42.04]
 [ 0.    0.    0.   32.05 31.39 30.72]
 [ 0.    0.    0.    0.   35.39 33.72]
 [ 0.    0.    0.    0.    0.   42.98]]
2024-05-01 16:01:41,763 [trainer.py] => Forgetting (CNN): 0.8079999999999977
2024-05-01 16:01:46,116 [trainer.py] => config: ./exps/dualprompt_omn_B150_Inc5.json
2024-05-01 16:01:46,116 [trainer.py] => prefix:  
2024-05-01 16:01:46,116 [trainer.py] => dataset: omnibenchmark
2024-05-01 16:01:46,116 [trainer.py] => memory_size: 0
2024-05-01 16:01:46,116 [trainer.py] => memory_per_class: 0
2024-05-01 16:01:46,116 [trainer.py] => fixed_memory: False
2024-05-01 16:01:46,116 [trainer.py] => shuffle: True
2024-05-01 16:01:46,116 [trainer.py] => init_cls: 150
2024-05-01 16:01:46,116 [trainer.py] => increment: 30
2024-05-01 16:01:46,116 [trainer.py] => model_name: dualprompt
2024-05-01 16:01:46,116 [trainer.py] => backbone_type: vit_base_patch16_224_in21k_dualprompt
2024-05-01 16:01:46,116 [trainer.py] => get_original_backbone: True
2024-05-01 16:01:46,116 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-01 16:01:46,116 [trainer.py] => seed: 1993
2024-05-01 16:01:46,116 [trainer.py] => tuned_epoch: 20
2024-05-01 16:01:46,116 [trainer.py] => init_lr: 0.001
2024-05-01 16:01:46,116 [trainer.py] => batch_size: 48
2024-05-01 16:01:46,116 [trainer.py] => weight_decay: 0
2024-05-01 16:01:46,116 [trainer.py] => min_lr: 1e-05
2024-05-01 16:01:46,116 [trainer.py] => optimizer: adam
2024-05-01 16:01:46,117 [trainer.py] => scheduler: constant
2024-05-01 16:01:46,117 [trainer.py] => reinit_optimizer: True
2024-05-01 16:01:46,117 [trainer.py] => global_pool: token
2024-05-01 16:01:46,117 [trainer.py] => head_type: token
2024-05-01 16:01:46,117 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-05-01 16:01:46,117 [trainer.py] => pretrained: True
2024-05-01 16:01:46,117 [trainer.py] => drop: 0.0
2024-05-01 16:01:46,117 [trainer.py] => drop_path: 0.0
2024-05-01 16:01:46,117 [trainer.py] => use_g_prompt: True
2024-05-01 16:01:46,117 [trainer.py] => g_prompt_length: 5
2024-05-01 16:01:46,117 [trainer.py] => g_prompt_layer_idx: [0, 1]
2024-05-01 16:01:46,117 [trainer.py] => use_prefix_tune_for_g_prompt: True
2024-05-01 16:01:46,117 [trainer.py] => use_e_prompt: True
2024-05-01 16:01:46,117 [trainer.py] => e_prompt_layer_idx: [2, 3, 4]
2024-05-01 16:01:46,117 [trainer.py] => use_prefix_tune_for_e_prompt: True
2024-05-01 16:01:46,117 [trainer.py] => prompt_pool: True
2024-05-01 16:01:46,117 [trainer.py] => size: 10
2024-05-01 16:01:46,117 [trainer.py] => length: 5
2024-05-01 16:01:46,117 [trainer.py] => top_k: 1
2024-05-01 16:01:46,117 [trainer.py] => initializer: uniform
2024-05-01 16:01:46,117 [trainer.py] => prompt_key: True
2024-05-01 16:01:46,117 [trainer.py] => prompt_key_init: uniform
2024-05-01 16:01:46,117 [trainer.py] => use_prompt_mask: True
2024-05-01 16:01:46,117 [trainer.py] => shared_prompt_pool: True
2024-05-01 16:01:46,117 [trainer.py] => shared_prompt_key: False
2024-05-01 16:01:46,118 [trainer.py] => batchwise_prompt: True
2024-05-01 16:01:46,118 [trainer.py] => embedding_key: cls
2024-05-01 16:01:46,118 [trainer.py] => predefined_key: 
2024-05-01 16:01:46,118 [trainer.py] => pull_constraint: True
2024-05-01 16:01:46,118 [trainer.py] => pull_constraint_coeff: 0.1
2024-05-01 16:01:46,118 [trainer.py] => same_key_value: False
2024-05-01 16:01:47,311 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2024-05-01 16:02:06,396 [dualprompt.py] => 86,282,796 model total parameters.
2024-05-01 16:02:06,397 [dualprompt.py] => 484,140 model training parameters.
2024-05-01 16:02:06,397 [dualprompt.py] => g_prompt: 15360
2024-05-01 16:02:06,397 [dualprompt.py] => e_prompt.prompt: 230400
2024-05-01 16:02:06,397 [dualprompt.py] => e_prompt.prompt_key: 7680
2024-05-01 16:02:06,397 [dualprompt.py] => head.weight: 230400
2024-05-01 16:02:06,398 [dualprompt.py] => head.bias: 300
2024-05-01 16:02:06,399 [trainer.py] => All params: 172312152
2024-05-01 16:02:06,400 [trainer.py] => Trainable params: 484140
2024-05-01 16:02:06,400 [dualprompt.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.006, Train_accy 72.69:   0%|          | 0/20 [05:34<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.006, Train_accy 72.69:   5%|▌         | 1/20 [05:34<1:46:00, 334.74s/it]Task 0, Epoch 2/20 => Loss 0.660, Train_accy 79.95:   5%|▌         | 1/20 [11:08<1:46:00, 334.74s/it]Task 0, Epoch 2/20 => Loss 0.660, Train_accy 79.95:  10%|█         | 2/20 [11:08<1:40:15, 334.18s/it]Task 0, Epoch 3/20 => Loss 0.598, Train_accy 81.51:  10%|█         | 2/20 [16:42<1:40:15, 334.18s/it]Task 0, Epoch 3/20 => Loss 0.598, Train_accy 81.51:  15%|█▌        | 3/20 [16:42<1:34:39, 334.08s/it]Task 0, Epoch 4/20 => Loss 0.561, Train_accy 82.57:  15%|█▌        | 3/20 [22:15<1:34:39, 334.08s/it]Task 0, Epoch 4/20 => Loss 0.561, Train_accy 82.57:  20%|██        | 4/20 [22:15<1:28:59, 333.75s/it]Task 0, Epoch 5/20 => Loss 0.534, Train_accy 83.43, Test_accy 83.97:  20%|██        | 4/20 [28:05<1:28:59, 333.75s/it]Task 0, Epoch 5/20 => Loss 0.534, Train_accy 83.43, Test_accy 83.97:  25%|██▌       | 5/20 [28:05<1:24:51, 339.46s/it]Task 0, Epoch 6/20 => Loss 0.518, Train_accy 83.75:  25%|██▌       | 5/20 [33:39<1:24:51, 339.46s/it]                 Task 0, Epoch 6/20 => Loss 0.518, Train_accy 83.75:  30%|███       | 6/20 [33:39<1:18:46, 337.64s/it]Task 0, Epoch 7/20 => Loss 0.509, Train_accy 84.29:  30%|███       | 6/20 [39:12<1:18:46, 337.64s/it]Task 0, Epoch 7/20 => Loss 0.509, Train_accy 84.29:  35%|███▌      | 7/20 [39:12<1:12:49, 336.14s/it]Task 0, Epoch 8/20 => Loss 0.490, Train_accy 84.53:  35%|███▌      | 7/20 [44:46<1:12:49, 336.14s/it]Task 0, Epoch 8/20 => Loss 0.490, Train_accy 84.53:  40%|████      | 8/20 [44:46<1:07:03, 335.31s/it]Task 0, Epoch 9/20 => Loss 0.482, Train_accy 84.73:  40%|████      | 8/20 [50:19<1:07:03, 335.31s/it]Task 0, Epoch 9/20 => Loss 0.482, Train_accy 84.73:  45%|████▌     | 9/20 [50:19<1:01:20, 334.63s/it]Task 0, Epoch 10/20 => Loss 0.474, Train_accy 85.10, Test_accy 84.74:  45%|████▌     | 9/20 [56:07<1:01:20, 334.63s/it]Task 0, Epoch 10/20 => Loss 0.474, Train_accy 85.10, Test_accy 84.74:  50%|█████     | 10/20 [56:07<56:30, 339.01s/it] Task 0, Epoch 11/20 => Loss 0.472, Train_accy 85.26:  50%|█████     | 10/20 [1:01:41<56:30, 339.01s/it]               Task 0, Epoch 11/20 => Loss 0.472, Train_accy 85.26:  55%|█████▌    | 11/20 [1:01:41<50:35, 337.28s/it]Task 0, Epoch 12/20 => Loss 0.473, Train_accy 85.17:  55%|█████▌    | 11/20 [1:07:14<50:35, 337.28s/it]Task 0, Epoch 12/20 => Loss 0.473, Train_accy 85.17:  60%|██████    | 12/20 [1:07:14<44:49, 336.14s/it]Task 0, Epoch 13/20 => Loss 0.450, Train_accy 85.94:  60%|██████    | 12/20 [1:12:48<44:49, 336.14s/it]Task 0, Epoch 13/20 => Loss 0.450, Train_accy 85.94:  65%|██████▌   | 13/20 [1:12:48<39:08, 335.53s/it]Task 0, Epoch 14/20 => Loss 0.445, Train_accy 85.89:  65%|██████▌   | 13/20 [1:18:23<39:08, 335.53s/it]Task 0, Epoch 14/20 => Loss 0.445, Train_accy 85.89:  70%|███████   | 14/20 [1:18:23<33:31, 335.29s/it]Task 0, Epoch 15/20 => Loss 0.435, Train_accy 86.09, Test_accy 84.50:  70%|███████   | 14/20 [1:24:13<33:31, 335.29s/it]Task 0, Epoch 15/20 => Loss 0.435, Train_accy 86.09, Test_accy 84.50:  75%|███████▌  | 15/20 [1:24:13<28:18, 339.76s/it]Task 0, Epoch 16/20 => Loss 0.436, Train_accy 86.27:  75%|███████▌  | 15/20 [1:29:49<28:18, 339.76s/it]                 Task 0, Epoch 16/20 => Loss 0.436, Train_accy 86.27:  80%|████████  | 16/20 [1:29:49<22:34, 338.57s/it]Task 0, Epoch 17/20 => Loss 0.430, Train_accy 86.45:  80%|████████  | 16/20 [1:35:22<22:34, 338.57s/it]Task 0, Epoch 17/20 => Loss 0.430, Train_accy 86.45:  85%|████████▌ | 17/20 [1:35:22<16:50, 336.93s/it]Task 0, Epoch 18/20 => Loss 0.432, Train_accy 86.55:  85%|████████▌ | 17/20 [1:40:55<16:50, 336.93s/it]Task 0, Epoch 18/20 => Loss 0.432, Train_accy 86.55:  90%|█████████ | 18/20 [1:40:55<11:11, 335.67s/it]Task 0, Epoch 19/20 => Loss 0.425, Train_accy 86.65:  90%|█████████ | 18/20 [1:46:28<11:11, 335.67s/it]Task 0, Epoch 19/20 => Loss 0.425, Train_accy 86.65:  95%|█████████▌| 19/20 [1:46:28<05:34, 334.84s/it]Task 0, Epoch 20/20 => Loss 0.417, Train_accy 86.68, Test_accy 84.80:  95%|█████████▌| 19/20 [1:52:18<05:34, 334.84s/it]Task 0, Epoch 20/20 => Loss 0.417, Train_accy 86.68, Test_accy 84.80: 100%|██████████| 20/20 [1:52:18<00:00, 339.34s/it]Task 0, Epoch 20/20 => Loss 0.417, Train_accy 86.68, Test_accy 84.80: 100%|██████████| 20/20 [1:52:18<00:00, 336.91s/it]
2024-05-01 17:54:25,359 [dualprompt.py] => Task 0, Epoch 20/20 => Loss 0.417, Train_accy 86.68, Test_accy 84.80
2024-05-01 17:54:41,259 [trainer.py] => No NME accuracy.
2024-05-01 17:54:41,260 [trainer.py] => CNN: {'total': 84.8, '00-149': 84.8, 'old': 0, 'new': 84.8}
2024-05-01 17:54:41,260 [trainer.py] => CNN top1 curve: [84.8]
2024-05-01 17:54:41,260 [trainer.py] => CNN top5 curve: [96.83]

Average Accuracy (CNN): 84.8
2024-05-01 17:54:41,260 [trainer.py] => Average Accuracy (CNN): 84.8 

2024-05-01 17:54:41,260 [trainer.py] => Train Time: 13477.119999999999
2024-05-01 17:54:41,260 [trainer.py] => Test Time: 15.9 

2024-05-01 17:54:41,264 [trainer.py] => All params: 172312152
2024-05-01 17:54:41,266 [trainer.py] => Trainable params: 484140
2024-05-01 17:54:41,267 [dualprompt.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.610, Train_accy 82.41:   0%|          | 0/20 [01:06<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.610, Train_accy 82.41:   5%|▌         | 1/20 [01:06<20:58, 66.25s/it]Task 1, Epoch 2/20 => Loss 0.296, Train_accy 89.98:   5%|▌         | 1/20 [02:12<20:58, 66.25s/it]Task 1, Epoch 2/20 => Loss 0.296, Train_accy 89.98:  10%|█         | 2/20 [02:12<19:57, 66.53s/it]Task 1, Epoch 3/20 => Loss 0.235, Train_accy 91.67:  10%|█         | 2/20 [03:19<19:57, 66.53s/it]Task 1, Epoch 3/20 => Loss 0.235, Train_accy 91.67:  15%|█▌        | 3/20 [03:19<18:50, 66.48s/it]Task 1, Epoch 4/20 => Loss 0.191, Train_accy 92.65:  15%|█▌        | 3/20 [04:25<18:50, 66.48s/it]Task 1, Epoch 4/20 => Loss 0.191, Train_accy 92.65:  20%|██        | 4/20 [04:25<17:41, 66.37s/it]Task 1, Epoch 5/20 => Loss 0.163, Train_accy 93.74, Test_accy 74.75:  20%|██        | 4/20 [05:50<17:41, 66.37s/it]Task 1, Epoch 5/20 => Loss 0.163, Train_accy 93.74, Test_accy 74.75:  25%|██▌       | 5/20 [05:50<18:15, 73.05s/it]Task 1, Epoch 6/20 => Loss 0.154, Train_accy 93.84:  25%|██▌       | 5/20 [06:57<18:15, 73.05s/it]                 Task 1, Epoch 6/20 => Loss 0.154, Train_accy 93.84:  30%|███       | 6/20 [06:57<16:33, 70.93s/it]Task 1, Epoch 7/20 => Loss 0.148, Train_accy 93.84:  30%|███       | 6/20 [08:03<16:33, 70.93s/it]Task 1, Epoch 7/20 => Loss 0.148, Train_accy 93.84:  35%|███▌      | 7/20 [08:03<15:02, 69.46s/it]Task 1, Epoch 8/20 => Loss 0.132, Train_accy 94.21:  35%|███▌      | 7/20 [09:10<15:02, 69.46s/it]Task 1, Epoch 8/20 => Loss 0.132, Train_accy 94.21:  40%|████      | 8/20 [09:10<13:42, 68.55s/it]Task 1, Epoch 9/20 => Loss 0.127, Train_accy 94.48:  40%|████      | 8/20 [10:16<13:42, 68.55s/it]Task 1, Epoch 9/20 => Loss 0.127, Train_accy 94.48:  45%|████▌     | 9/20 [10:16<12:27, 67.92s/it]Task 1, Epoch 10/20 => Loss 0.112, Train_accy 95.06, Test_accy 75.33:  45%|████▌     | 9/20 [11:41<12:27, 67.92s/it]Task 1, Epoch 10/20 => Loss 0.112, Train_accy 95.06, Test_accy 75.33:  50%|█████     | 10/20 [11:41<12:11, 73.19s/it]Task 1, Epoch 11/20 => Loss 0.119, Train_accy 94.80:  50%|█████     | 10/20 [12:48<12:11, 73.19s/it]                 Task 1, Epoch 11/20 => Loss 0.119, Train_accy 94.80:  55%|█████▌    | 11/20 [12:48<10:41, 71.24s/it]Task 1, Epoch 12/20 => Loss 0.120, Train_accy 94.70:  55%|█████▌    | 11/20 [13:54<10:41, 71.24s/it]Task 1, Epoch 12/20 => Loss 0.120, Train_accy 94.70:  60%|██████    | 12/20 [13:54<09:17, 69.70s/it]Task 1, Epoch 13/20 => Loss 0.108, Train_accy 94.95:  60%|██████    | 12/20 [15:01<09:17, 69.70s/it]Task 1, Epoch 13/20 => Loss 0.108, Train_accy 94.95:  65%|██████▌   | 13/20 [15:01<08:00, 68.66s/it]Task 1, Epoch 14/20 => Loss 0.107, Train_accy 95.13:  65%|██████▌   | 13/20 [16:07<08:00, 68.66s/it]Task 1, Epoch 14/20 => Loss 0.107, Train_accy 95.13:  70%|███████   | 14/20 [16:07<06:48, 68.03s/it]Task 1, Epoch 15/20 => Loss 0.114, Train_accy 94.99, Test_accy 76.00:  70%|███████   | 14/20 [17:32<06:48, 68.03s/it]Task 1, Epoch 15/20 => Loss 0.114, Train_accy 94.99, Test_accy 76.00:  75%|███████▌  | 15/20 [17:32<06:05, 73.05s/it]Task 1, Epoch 16/20 => Loss 0.105, Train_accy 95.07:  75%|███████▌  | 15/20 [18:39<06:05, 73.05s/it]                 Task 1, Epoch 16/20 => Loss 0.105, Train_accy 95.07:  80%|████████  | 16/20 [18:39<04:44, 71.13s/it]Task 1, Epoch 17/20 => Loss 0.092, Train_accy 95.61:  80%|████████  | 16/20 [19:45<04:44, 71.13s/it]Task 1, Epoch 17/20 => Loss 0.092, Train_accy 95.61:  85%|████████▌ | 17/20 [19:45<03:29, 69.76s/it]Task 1, Epoch 18/20 => Loss 0.103, Train_accy 95.05:  85%|████████▌ | 17/20 [20:52<03:29, 69.76s/it]Task 1, Epoch 18/20 => Loss 0.103, Train_accy 95.05:  90%|█████████ | 18/20 [20:52<02:17, 68.78s/it]Task 1, Epoch 19/20 => Loss 0.114, Train_accy 94.92:  90%|█████████ | 18/20 [21:58<02:17, 68.78s/it]Task 1, Epoch 19/20 => Loss 0.114, Train_accy 94.92:  95%|█████████▌| 19/20 [21:58<01:07, 67.99s/it]Task 1, Epoch 20/20 => Loss 0.091, Train_accy 95.61, Test_accy 76.48:  95%|█████████▌| 19/20 [23:23<01:07, 67.99s/it]Task 1, Epoch 20/20 => Loss 0.091, Train_accy 95.61, Test_accy 76.48: 100%|██████████| 20/20 [23:23<00:00, 73.05s/it]Task 1, Epoch 20/20 => Loss 0.091, Train_accy 95.61, Test_accy 76.48: 100%|██████████| 20/20 [23:23<00:00, 70.16s/it]
2024-05-01 18:18:04,417 [dualprompt.py] => Task 1, Epoch 20/20 => Loss 0.091, Train_accy 95.61, Test_accy 76.48
2024-05-01 18:18:23,000 [trainer.py] => No NME accuracy.
2024-05-01 18:18:23,000 [trainer.py] => CNN: {'total': 76.48, '00-149': 83.9, '150-179': 39.3, 'old': 83.9, 'new': 39.3}
2024-05-01 18:18:23,000 [trainer.py] => CNN top1 curve: [84.8, 76.48]
2024-05-01 18:18:23,000 [trainer.py] => CNN top5 curve: [96.83, 94.68]

Average Accuracy (CNN): 80.64
2024-05-01 18:18:23,001 [trainer.py] => Average Accuracy (CNN): 80.64 

2024-05-01 18:18:23,001 [trainer.py] => Train Time: 16283.369999999999
2024-05-01 18:18:23,001 [trainer.py] => Test Time: 34.48 

2024-05-01 18:18:23,002 [trainer.py] => All params: 172312152
2024-05-01 18:18:23,004 [trainer.py] => Trainable params: 484140
2024-05-01 18:18:23,004 [dualprompt.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.566, Train_accy 81.97:   0%|          | 0/20 [01:06<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.566, Train_accy 81.97:   5%|▌         | 1/20 [01:06<21:05, 66.59s/it]Task 2, Epoch 2/20 => Loss 0.269, Train_accy 89.73:   5%|▌         | 1/20 [02:12<21:05, 66.59s/it]Task 2, Epoch 2/20 => Loss 0.269, Train_accy 89.73:  10%|█         | 2/20 [02:12<19:52, 66.25s/it]Task 2, Epoch 3/20 => Loss 0.211, Train_accy 91.65:  10%|█         | 2/20 [03:18<19:52, 66.25s/it]Task 2, Epoch 3/20 => Loss 0.211, Train_accy 91.65:  15%|█▌        | 3/20 [03:18<18:42, 66.04s/it]Task 2, Epoch 4/20 => Loss 0.182, Train_accy 92.39:  15%|█▌        | 3/20 [04:24<18:42, 66.04s/it]Task 2, Epoch 4/20 => Loss 0.182, Train_accy 92.39:  20%|██        | 4/20 [04:24<17:36, 66.01s/it]Task 2, Epoch 5/20 => Loss 0.168, Train_accy 93.06, Test_accy 68.63:  20%|██        | 4/20 [05:52<17:36, 66.01s/it]Task 2, Epoch 5/20 => Loss 0.168, Train_accy 93.06, Test_accy 68.63:  25%|██▌       | 5/20 [05:52<18:27, 73.86s/it]Task 2, Epoch 6/20 => Loss 0.156, Train_accy 93.13:  25%|██▌       | 5/20 [06:58<18:27, 73.86s/it]                 Task 2, Epoch 6/20 => Loss 0.156, Train_accy 93.13:  30%|███       | 6/20 [06:58<16:36, 71.16s/it]Task 2, Epoch 7/20 => Loss 0.163, Train_accy 92.94:  30%|███       | 6/20 [08:03<16:36, 71.16s/it]Task 2, Epoch 7/20 => Loss 0.163, Train_accy 92.94:  35%|███▌      | 7/20 [08:03<15:02, 69.45s/it]Task 2, Epoch 8/20 => Loss 0.139, Train_accy 93.60:  35%|███▌      | 7/20 [09:10<15:02, 69.45s/it]Task 2, Epoch 8/20 => Loss 0.139, Train_accy 93.60:  40%|████      | 8/20 [09:10<13:41, 68.45s/it]Task 2, Epoch 9/20 => Loss 0.138, Train_accy 93.62:  40%|████      | 8/20 [10:16<13:41, 68.45s/it]Task 2, Epoch 9/20 => Loss 0.138, Train_accy 93.62:  45%|████▌     | 9/20 [10:16<12:24, 67.67s/it]Task 2, Epoch 10/20 => Loss 0.128, Train_accy 93.99, Test_accy 69.68:  45%|████▌     | 9/20 [11:43<12:24, 67.67s/it]Task 2, Epoch 10/20 => Loss 0.128, Train_accy 93.99, Test_accy 69.68:  50%|█████     | 10/20 [11:43<12:17, 73.78s/it]Task 2, Epoch 11/20 => Loss 0.107, Train_accy 94.78:  50%|█████     | 10/20 [12:49<12:17, 73.78s/it]                 Task 2, Epoch 11/20 => Loss 0.107, Train_accy 94.78:  55%|█████▌    | 11/20 [12:49<10:42, 71.41s/it]Task 2, Epoch 12/20 => Loss 0.121, Train_accy 94.39:  55%|█████▌    | 11/20 [13:56<10:42, 71.41s/it]Task 2, Epoch 12/20 => Loss 0.121, Train_accy 94.39:  60%|██████    | 12/20 [13:56<09:20, 70.03s/it]Task 2, Epoch 13/20 => Loss 0.120, Train_accy 94.31:  60%|██████    | 12/20 [15:02<09:20, 70.03s/it]Task 2, Epoch 13/20 => Loss 0.120, Train_accy 94.31:  65%|██████▌   | 13/20 [15:02<08:01, 68.79s/it]Task 2, Epoch 14/20 => Loss 0.109, Train_accy 94.35:  65%|██████▌   | 13/20 [16:08<08:01, 68.79s/it]Task 2, Epoch 14/20 => Loss 0.109, Train_accy 94.35:  70%|███████   | 14/20 [16:08<06:47, 67.98s/it]Task 2, Epoch 15/20 => Loss 0.106, Train_accy 94.87, Test_accy 70.64:  70%|███████   | 14/20 [17:36<06:47, 67.98s/it]Task 2, Epoch 15/20 => Loss 0.106, Train_accy 94.87, Test_accy 70.64:  75%|███████▌  | 15/20 [17:36<06:09, 73.96s/it]Task 2, Epoch 16/20 => Loss 0.097, Train_accy 95.07:  75%|███████▌  | 15/20 [18:42<06:09, 73.96s/it]                 Task 2, Epoch 16/20 => Loss 0.097, Train_accy 95.07:  80%|████████  | 16/20 [18:42<04:46, 71.65s/it]Task 2, Epoch 17/20 => Loss 0.110, Train_accy 94.40:  80%|████████  | 16/20 [19:49<04:46, 71.65s/it]Task 2, Epoch 17/20 => Loss 0.110, Train_accy 94.40:  85%|████████▌ | 17/20 [19:49<03:30, 70.03s/it]Task 2, Epoch 18/20 => Loss 0.106, Train_accy 94.79:  85%|████████▌ | 17/20 [20:55<03:30, 70.03s/it]Task 2, Epoch 18/20 => Loss 0.106, Train_accy 94.79:  90%|█████████ | 18/20 [20:55<02:17, 68.83s/it]Task 2, Epoch 19/20 => Loss 0.104, Train_accy 94.83:  90%|█████████ | 18/20 [22:01<02:17, 68.83s/it]Task 2, Epoch 19/20 => Loss 0.104, Train_accy 94.83:  95%|█████████▌| 19/20 [22:01<01:08, 68.11s/it]Task 2, Epoch 20/20 => Loss 0.107, Train_accy 94.91, Test_accy 72.21:  95%|█████████▌| 19/20 [23:28<01:08, 68.11s/it]Task 2, Epoch 20/20 => Loss 0.107, Train_accy 94.91, Test_accy 72.21: 100%|██████████| 20/20 [23:28<00:00, 73.93s/it]Task 2, Epoch 20/20 => Loss 0.107, Train_accy 94.91, Test_accy 72.21: 100%|██████████| 20/20 [23:28<00:00, 70.45s/it]
2024-05-01 18:41:52,019 [dualprompt.py] => Task 2, Epoch 20/20 => Loss 0.107, Train_accy 94.91, Test_accy 72.21
2024-05-01 18:42:13,396 [trainer.py] => No NME accuracy.
2024-05-01 18:42:13,397 [trainer.py] => CNN: {'total': 72.21, '00-149': 83.87, '150-179': 38.8, '180-209': 47.24, 'old': 76.36, 'new': 47.24}
2024-05-01 18:42:13,397 [trainer.py] => CNN top1 curve: [84.8, 76.48, 72.21]
2024-05-01 18:42:13,397 [trainer.py] => CNN top5 curve: [96.83, 94.68, 92.53]

Average Accuracy (CNN): 77.83
2024-05-01 18:42:13,397 [trainer.py] => Average Accuracy (CNN): 77.83 

2024-05-01 18:42:13,397 [trainer.py] => Train Time: 19101.36
2024-05-01 18:42:13,397 [trainer.py] => Test Time: 55.86 

2024-05-01 18:42:13,398 [trainer.py] => All params: 172312152
2024-05-01 18:42:13,399 [trainer.py] => Trainable params: 484140
2024-05-01 18:42:13,400 [dualprompt.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.645, Train_accy 79.53:   0%|          | 0/20 [01:09<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.645, Train_accy 79.53:   5%|▌         | 1/20 [01:09<22:04, 69.72s/it]Task 3, Epoch 2/20 => Loss 0.351, Train_accy 87.44:   5%|▌         | 1/20 [02:19<22:04, 69.72s/it]Task 3, Epoch 2/20 => Loss 0.351, Train_accy 87.44:  10%|█         | 2/20 [02:19<20:55, 69.75s/it]Task 3, Epoch 3/20 => Loss 0.277, Train_accy 89.57:  10%|█         | 2/20 [03:28<20:55, 69.75s/it]Task 3, Epoch 3/20 => Loss 0.277, Train_accy 89.57:  15%|█▌        | 3/20 [03:28<19:43, 69.62s/it]Task 3, Epoch 4/20 => Loss 0.256, Train_accy 90.30:  15%|█▌        | 3/20 [04:38<19:43, 69.62s/it]Task 3, Epoch 4/20 => Loss 0.256, Train_accy 90.30:  20%|██        | 4/20 [04:38<18:32, 69.51s/it]Task 3, Epoch 5/20 => Loss 0.227, Train_accy 90.67, Test_accy 65.02:  20%|██        | 4/20 [06:12<18:32, 69.51s/it]Task 3, Epoch 5/20 => Loss 0.227, Train_accy 90.67, Test_accy 65.02:  25%|██▌       | 5/20 [06:12<19:34, 78.32s/it]Task 3, Epoch 6/20 => Loss 0.228, Train_accy 90.36:  25%|██▌       | 5/20 [07:21<19:34, 78.32s/it]                 Task 3, Epoch 6/20 => Loss 0.228, Train_accy 90.36:  30%|███       | 6/20 [07:21<17:33, 75.26s/it]Task 3, Epoch 7/20 => Loss 0.203, Train_accy 91.48:  30%|███       | 6/20 [08:31<17:33, 75.26s/it]Task 3, Epoch 7/20 => Loss 0.203, Train_accy 91.48:  35%|███▌      | 7/20 [08:31<15:55, 73.49s/it]Task 3, Epoch 8/20 => Loss 0.184, Train_accy 92.07:  35%|███▌      | 7/20 [09:40<15:55, 73.49s/it]Task 3, Epoch 8/20 => Loss 0.184, Train_accy 92.07:  40%|████      | 8/20 [09:40<14:26, 72.22s/it]Task 3, Epoch 9/20 => Loss 0.195, Train_accy 91.95:  40%|████      | 8/20 [10:50<14:26, 72.22s/it]Task 3, Epoch 9/20 => Loss 0.195, Train_accy 91.95:  45%|████▌     | 9/20 [10:50<13:05, 71.42s/it]Task 3, Epoch 10/20 => Loss 0.181, Train_accy 92.27, Test_accy 66.27:  45%|████▌     | 9/20 [12:24<13:05, 71.42s/it]Task 3, Epoch 10/20 => Loss 0.181, Train_accy 92.27, Test_accy 66.27:  50%|█████     | 10/20 [12:24<13:04, 78.43s/it]Task 3, Epoch 11/20 => Loss 0.196, Train_accy 91.79:  50%|█████     | 10/20 [13:34<13:04, 78.43s/it]                 Task 3, Epoch 11/20 => Loss 0.196, Train_accy 91.79:  55%|█████▌    | 11/20 [13:34<11:21, 75.74s/it]Task 3, Epoch 12/20 => Loss 0.173, Train_accy 92.55:  55%|█████▌    | 11/20 [14:44<11:21, 75.74s/it]Task 3, Epoch 12/20 => Loss 0.173, Train_accy 92.55:  60%|██████    | 12/20 [14:44<09:51, 73.94s/it]Task 3, Epoch 13/20 => Loss 0.166, Train_accy 92.73:  60%|██████    | 12/20 [15:53<09:51, 73.94s/it]Task 3, Epoch 13/20 => Loss 0.166, Train_accy 92.73:  65%|██████▌   | 13/20 [15:53<08:28, 72.64s/it]Task 3, Epoch 14/20 => Loss 0.165, Train_accy 92.53:  65%|██████▌   | 13/20 [17:03<08:28, 72.64s/it]Task 3, Epoch 14/20 => Loss 0.165, Train_accy 92.53:  70%|███████   | 14/20 [17:03<07:10, 71.74s/it]Task 3, Epoch 15/20 => Loss 0.161, Train_accy 92.99, Test_accy 67.25:  70%|███████   | 14/20 [18:37<07:10, 71.74s/it]Task 3, Epoch 15/20 => Loss 0.161, Train_accy 92.99, Test_accy 67.25:  75%|███████▌  | 15/20 [18:37<06:32, 78.45s/it]Task 3, Epoch 16/20 => Loss 0.164, Train_accy 92.65:  75%|███████▌  | 15/20 [19:47<06:32, 78.45s/it]                 Task 3, Epoch 16/20 => Loss 0.164, Train_accy 92.65:  80%|████████  | 16/20 [19:47<05:03, 75.80s/it]Task 3, Epoch 17/20 => Loss 0.155, Train_accy 93.03:  80%|████████  | 16/20 [20:57<05:03, 75.80s/it]Task 3, Epoch 17/20 => Loss 0.155, Train_accy 93.03:  85%|████████▌ | 17/20 [20:57<03:42, 74.02s/it]Task 3, Epoch 18/20 => Loss 0.151, Train_accy 93.46:  85%|████████▌ | 17/20 [22:06<03:42, 74.02s/it]Task 3, Epoch 18/20 => Loss 0.151, Train_accy 93.46:  90%|█████████ | 18/20 [22:06<02:25, 72.69s/it]Task 3, Epoch 19/20 => Loss 0.158, Train_accy 92.85:  90%|█████████ | 18/20 [23:16<02:25, 72.69s/it]Task 3, Epoch 19/20 => Loss 0.158, Train_accy 92.85:  95%|█████████▌| 19/20 [23:16<01:11, 71.88s/it]Task 3, Epoch 20/20 => Loss 0.157, Train_accy 93.10, Test_accy 68.34:  95%|█████████▌| 19/20 [24:51<01:11, 71.88s/it]Task 3, Epoch 20/20 => Loss 0.157, Train_accy 93.10, Test_accy 68.34: 100%|██████████| 20/20 [24:51<00:00, 78.70s/it]Task 3, Epoch 20/20 => Loss 0.157, Train_accy 93.10, Test_accy 68.34: 100%|██████████| 20/20 [24:51<00:00, 74.56s/it]
2024-05-01 19:07:04,610 [dualprompt.py] => Task 3, Epoch 20/20 => Loss 0.157, Train_accy 93.10, Test_accy 68.34
2024-05-01 19:07:29,252 [trainer.py] => No NME accuracy.
2024-05-01 19:07:29,253 [trainer.py] => CNN: {'total': 68.34, '00-149': 84.1, '150-179': 38.46, '180-209': 44.89, '210-239': 42.74, 'old': 72.0, 'new': 42.74}
2024-05-01 19:07:29,253 [trainer.py] => CNN top1 curve: [84.8, 76.48, 72.21, 68.34]
2024-05-01 19:07:29,253 [trainer.py] => CNN top5 curve: [96.83, 94.68, 92.53, 90.04]

Average Accuracy (CNN): 75.46
2024-05-01 19:07:29,253 [trainer.py] => Average Accuracy (CNN): 75.46 

2024-05-01 19:07:29,253 [trainer.py] => Train Time: 22083.73
2024-05-01 19:07:29,253 [trainer.py] => Test Time: 80.5 

2024-05-01 19:07:29,256 [trainer.py] => All params: 172312152
2024-05-01 19:07:29,258 [trainer.py] => Trainable params: 484140
2024-05-01 19:07:29,258 [dualprompt.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.425, Train_accy 87.71:   0%|          | 0/20 [01:08<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.425, Train_accy 87.71:   5%|▌         | 1/20 [01:08<21:43, 68.60s/it]Task 4, Epoch 2/20 => Loss 0.165, Train_accy 94.22:   5%|▌         | 1/20 [02:16<21:43, 68.60s/it]Task 4, Epoch 2/20 => Loss 0.165, Train_accy 94.22:  10%|█         | 2/20 [02:16<20:31, 68.43s/it]Task 4, Epoch 3/20 => Loss 0.130, Train_accy 95.32:  10%|█         | 2/20 [03:25<20:31, 68.43s/it]Task 4, Epoch 3/20 => Loss 0.130, Train_accy 95.32:  15%|█▌        | 3/20 [03:25<19:21, 68.29s/it]Task 4, Epoch 4/20 => Loss 0.131, Train_accy 94.88:  15%|█▌        | 3/20 [04:33<19:21, 68.29s/it]Task 4, Epoch 4/20 => Loss 0.131, Train_accy 94.88:  20%|██        | 4/20 [04:33<18:13, 68.34s/it]Task 4, Epoch 5/20 => Loss 0.101, Train_accy 95.51, Test_accy 62.17:  20%|██        | 4/20 [06:09<18:13, 68.34s/it]Task 4, Epoch 5/20 => Loss 0.101, Train_accy 95.51, Test_accy 62.17:  25%|██▌       | 5/20 [06:09<19:32, 78.20s/it]Task 4, Epoch 6/20 => Loss 0.092, Train_accy 95.89:  25%|██▌       | 5/20 [07:17<19:32, 78.20s/it]                 Task 4, Epoch 6/20 => Loss 0.092, Train_accy 95.89:  30%|███       | 6/20 [07:17<17:28, 74.88s/it]Task 4, Epoch 7/20 => Loss 0.086, Train_accy 96.09:  30%|███       | 6/20 [08:25<17:28, 74.88s/it]Task 4, Epoch 7/20 => Loss 0.086, Train_accy 96.09:  35%|███▌      | 7/20 [08:25<15:45, 72.71s/it]Task 4, Epoch 8/20 => Loss 0.061, Train_accy 96.78:  35%|███▌      | 7/20 [09:34<15:45, 72.71s/it]Task 4, Epoch 8/20 => Loss 0.061, Train_accy 96.78:  40%|████      | 8/20 [09:34<14:16, 71.37s/it]Task 4, Epoch 9/20 => Loss 0.084, Train_accy 96.08:  40%|████      | 8/20 [10:42<14:16, 71.37s/it]Task 4, Epoch 9/20 => Loss 0.084, Train_accy 96.08:  45%|████▌     | 9/20 [10:42<12:55, 70.48s/it]Task 4, Epoch 10/20 => Loss 0.065, Train_accy 96.43, Test_accy 63.32:  45%|████▌     | 9/20 [12:19<12:55, 70.48s/it]Task 4, Epoch 10/20 => Loss 0.065, Train_accy 96.43, Test_accy 63.32:  50%|█████     | 10/20 [12:19<13:04, 78.44s/it]Task 4, Epoch 11/20 => Loss 0.071, Train_accy 96.41:  50%|█████     | 10/20 [13:28<13:04, 78.44s/it]                 Task 4, Epoch 11/20 => Loss 0.071, Train_accy 96.41:  55%|█████▌    | 11/20 [13:28<11:19, 75.54s/it]Task 4, Epoch 12/20 => Loss 0.070, Train_accy 96.42:  55%|█████▌    | 11/20 [14:36<11:19, 75.54s/it]Task 4, Epoch 12/20 => Loss 0.070, Train_accy 96.42:  60%|██████    | 12/20 [14:36<09:46, 73.34s/it]Task 4, Epoch 13/20 => Loss 0.060, Train_accy 96.74:  60%|██████    | 12/20 [15:44<09:46, 73.34s/it]Task 4, Epoch 13/20 => Loss 0.060, Train_accy 96.74:  65%|██████▌   | 13/20 [15:44<08:22, 71.78s/it]Task 4, Epoch 14/20 => Loss 0.071, Train_accy 96.31:  65%|██████▌   | 13/20 [16:53<08:22, 71.78s/it]Task 4, Epoch 14/20 => Loss 0.071, Train_accy 96.31:  70%|███████   | 14/20 [16:53<07:04, 70.80s/it]Task 4, Epoch 15/20 => Loss 0.072, Train_accy 96.41, Test_accy 64.62:  70%|███████   | 14/20 [18:29<07:04, 70.80s/it]Task 4, Epoch 15/20 => Loss 0.072, Train_accy 96.41, Test_accy 64.62:  75%|███████▌  | 15/20 [18:29<06:32, 78.46s/it]Task 4, Epoch 16/20 => Loss 0.048, Train_accy 96.96:  75%|███████▌  | 15/20 [19:37<06:32, 78.46s/it]                 Task 4, Epoch 16/20 => Loss 0.048, Train_accy 96.96:  80%|████████  | 16/20 [19:37<05:02, 75.50s/it]Task 4, Epoch 17/20 => Loss 0.065, Train_accy 96.69:  80%|████████  | 16/20 [20:46<05:02, 75.50s/it]Task 4, Epoch 17/20 => Loss 0.065, Train_accy 96.69:  85%|████████▌ | 17/20 [20:46<03:40, 73.52s/it]Task 4, Epoch 18/20 => Loss 0.051, Train_accy 96.96:  85%|████████▌ | 17/20 [21:55<03:40, 73.52s/it]Task 4, Epoch 18/20 => Loss 0.051, Train_accy 96.96:  90%|█████████ | 18/20 [21:55<02:24, 72.04s/it]Task 4, Epoch 19/20 => Loss 0.069, Train_accy 96.55:  90%|█████████ | 18/20 [23:03<02:24, 72.04s/it]Task 4, Epoch 19/20 => Loss 0.069, Train_accy 96.55:  95%|█████████▌| 19/20 [23:03<01:10, 70.91s/it]Task 4, Epoch 20/20 => Loss 0.056, Train_accy 96.88, Test_accy 65.60:  95%|█████████▌| 19/20 [24:39<01:10, 70.91s/it]Task 4, Epoch 20/20 => Loss 0.056, Train_accy 96.88, Test_accy 65.60: 100%|██████████| 20/20 [24:39<00:00, 78.45s/it]Task 4, Epoch 20/20 => Loss 0.056, Train_accy 96.88, Test_accy 65.60: 100%|██████████| 20/20 [24:39<00:00, 73.99s/it]
2024-05-01 19:32:09,040 [dualprompt.py] => Task 4, Epoch 20/20 => Loss 0.056, Train_accy 96.88, Test_accy 65.60
2024-05-01 19:32:36,623 [trainer.py] => No NME accuracy.
2024-05-01 19:32:36,624 [trainer.py] => CNN: {'total': 65.6, '00-149': 84.07, '150-179': 38.8, '180-209': 45.23, '210-239': 42.24, '240-269': 43.74, 'old': 68.34, 'new': 43.74}
2024-05-01 19:32:36,624 [trainer.py] => CNN top1 curve: [84.8, 76.48, 72.21, 68.34, 65.6]
2024-05-01 19:32:36,624 [trainer.py] => CNN top5 curve: [96.83, 94.68, 92.53, 90.04, 89.64]

Average Accuracy (CNN): 73.49
2024-05-01 19:32:36,624 [trainer.py] => Average Accuracy (CNN): 73.49 

2024-05-01 19:32:36,624 [trainer.py] => Train Time: 25043.239999999998
2024-05-01 19:32:36,624 [trainer.py] => Test Time: 108.08 

2024-05-01 19:32:36,625 [trainer.py] => All params: 172312152
2024-05-01 19:32:36,626 [trainer.py] => Trainable params: 484140
2024-05-01 19:32:36,627 [dualprompt.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.444, Train_accy 86.94:   0%|          | 0/20 [01:05<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.444, Train_accy 86.94:   5%|▌         | 1/20 [01:05<20:36, 65.10s/it]Task 5, Epoch 2/20 => Loss 0.186, Train_accy 93.47:   5%|▌         | 1/20 [02:09<20:36, 65.10s/it]Task 5, Epoch 2/20 => Loss 0.186, Train_accy 93.47:  10%|█         | 2/20 [02:09<19:25, 64.75s/it]Task 5, Epoch 3/20 => Loss 0.155, Train_accy 94.34:  10%|█         | 2/20 [03:14<19:25, 64.75s/it]Task 5, Epoch 3/20 => Loss 0.155, Train_accy 94.34:  15%|█▌        | 3/20 [03:14<18:18, 64.62s/it]Task 5, Epoch 4/20 => Loss 0.124, Train_accy 95.31:  15%|█▌        | 3/20 [04:18<18:18, 64.62s/it]Task 5, Epoch 4/20 => Loss 0.124, Train_accy 95.31:  20%|██        | 4/20 [04:18<17:14, 64.63s/it]Task 5, Epoch 5/20 => Loss 0.109, Train_accy 95.53, Test_accy 60.20:  20%|██        | 4/20 [05:53<17:14, 64.63s/it]Task 5, Epoch 5/20 => Loss 0.109, Train_accy 95.53, Test_accy 60.20:  25%|██▌       | 5/20 [05:53<18:53, 75.58s/it]Task 5, Epoch 6/20 => Loss 0.097, Train_accy 95.65:  25%|██▌       | 5/20 [06:58<18:53, 75.58s/it]                 Task 5, Epoch 6/20 => Loss 0.097, Train_accy 95.65:  30%|███       | 6/20 [06:58<16:44, 71.78s/it]Task 5, Epoch 7/20 => Loss 0.101, Train_accy 95.39:  30%|███       | 6/20 [08:02<16:44, 71.78s/it]Task 5, Epoch 7/20 => Loss 0.101, Train_accy 95.39:  35%|███▌      | 7/20 [08:02<15:01, 69.35s/it]Task 5, Epoch 8/20 => Loss 0.080, Train_accy 96.09:  35%|███▌      | 7/20 [09:07<15:01, 69.35s/it]Task 5, Epoch 8/20 => Loss 0.080, Train_accy 96.09:  40%|████      | 8/20 [09:07<13:34, 67.84s/it]Task 5, Epoch 9/20 => Loss 0.069, Train_accy 96.26:  40%|████      | 8/20 [10:11<13:34, 67.84s/it]Task 5, Epoch 9/20 => Loss 0.069, Train_accy 96.26:  45%|████▌     | 9/20 [10:11<12:14, 66.74s/it]Task 5, Epoch 10/20 => Loss 0.072, Train_accy 96.31, Test_accy 61.70:  45%|████▌     | 9/20 [11:45<12:14, 66.74s/it]Task 5, Epoch 10/20 => Loss 0.072, Train_accy 96.31, Test_accy 61.70:  50%|█████     | 10/20 [11:46<12:33, 75.34s/it]Task 5, Epoch 11/20 => Loss 0.076, Train_accy 96.08:  50%|█████     | 10/20 [12:50<12:33, 75.34s/it]                 Task 5, Epoch 11/20 => Loss 0.076, Train_accy 96.08:  55%|█████▌    | 11/20 [12:50<10:48, 72.00s/it]Task 5, Epoch 12/20 => Loss 0.060, Train_accy 96.74:  55%|█████▌    | 11/20 [13:55<10:48, 72.00s/it]Task 5, Epoch 12/20 => Loss 0.060, Train_accy 96.74:  60%|██████    | 12/20 [13:55<09:18, 69.77s/it]Task 5, Epoch 13/20 => Loss 0.065, Train_accy 96.50:  60%|██████    | 12/20 [14:59<09:18, 69.77s/it]Task 5, Epoch 13/20 => Loss 0.065, Train_accy 96.50:  65%|██████▌   | 13/20 [14:59<07:57, 68.18s/it]Task 5, Epoch 14/20 => Loss 0.055, Train_accy 96.88:  65%|██████▌   | 13/20 [16:04<07:57, 68.18s/it]Task 5, Epoch 14/20 => Loss 0.055, Train_accy 96.88:  70%|███████   | 14/20 [16:04<06:42, 67.16s/it]Task 5, Epoch 15/20 => Loss 0.062, Train_accy 96.79, Test_accy 62.57:  70%|███████   | 14/20 [17:39<06:42, 67.16s/it]Task 5, Epoch 15/20 => Loss 0.062, Train_accy 96.79, Test_accy 62.57:  75%|███████▌  | 15/20 [17:39<06:17, 75.55s/it]Task 5, Epoch 16/20 => Loss 0.054, Train_accy 96.66:  75%|███████▌  | 15/20 [18:43<06:17, 75.55s/it]                 Task 5, Epoch 16/20 => Loss 0.054, Train_accy 96.66:  80%|████████  | 16/20 [18:43<04:48, 72.15s/it]Task 5, Epoch 17/20 => Loss 0.066, Train_accy 96.61:  80%|████████  | 16/20 [19:48<04:48, 72.15s/it]Task 5, Epoch 17/20 => Loss 0.066, Train_accy 96.61:  85%|████████▌ | 17/20 [19:48<03:29, 69.82s/it]Task 5, Epoch 18/20 => Loss 0.063, Train_accy 96.66:  85%|████████▌ | 17/20 [20:52<03:29, 69.82s/it]Task 5, Epoch 18/20 => Loss 0.063, Train_accy 96.66:  90%|█████████ | 18/20 [20:52<02:16, 68.25s/it]Task 5, Epoch 19/20 => Loss 0.050, Train_accy 96.99:  90%|█████████ | 18/20 [21:57<02:16, 68.25s/it]Task 5, Epoch 19/20 => Loss 0.050, Train_accy 96.99:  95%|█████████▌| 19/20 [21:57<01:07, 67.14s/it]Task 5, Epoch 20/20 => Loss 0.060, Train_accy 96.73, Test_accy 63.46:  95%|█████████▌| 19/20 [23:31<01:07, 67.14s/it]Task 5, Epoch 20/20 => Loss 0.060, Train_accy 96.73, Test_accy 63.46: 100%|██████████| 20/20 [23:31<00:00, 75.43s/it]Task 5, Epoch 20/20 => Loss 0.060, Train_accy 96.73, Test_accy 63.46: 100%|██████████| 20/20 [23:31<00:00, 70.60s/it]
2024-05-01 19:56:08,603 [dualprompt.py] => Task 5, Epoch 20/20 => Loss 0.060, Train_accy 96.73, Test_accy 63.46
2024-05-01 19:56:38,853 [trainer.py] => No NME accuracy.
2024-05-01 19:56:38,853 [trainer.py] => CNN: {'total': 63.46, '00-149': 83.67, '150-179': 37.63, '180-209': 45.06, '210-239': 42.4, '240-269': 42.74, '270-299': 48.33, 'old': 65.14, 'new': 48.33}
2024-05-01 19:56:38,854 [trainer.py] => CNN top1 curve: [84.8, 76.48, 72.21, 68.34, 65.6, 63.46]
2024-05-01 19:56:38,854 [trainer.py] => CNN top5 curve: [96.83, 94.68, 92.53, 90.04, 89.64, 89.12]

Average Accuracy (CNN): 71.82
2024-05-01 19:56:38,854 [trainer.py] => Average Accuracy (CNN): 71.82 

2024-05-01 19:56:38,854 [trainer.py] => Train Time: 27867.149999999998
2024-05-01 19:56:38,854 [trainer.py] => Test Time: 138.32999999999998 

Accuracy Matrix (CNN):
[[84.8  83.9  83.87 84.1  84.07 83.67]
 [ 0.   39.3  38.8  38.46 38.8  37.63]
 [ 0.    0.   47.24 44.89 45.23 45.06]
 [ 0.    0.    0.   42.74 42.24 42.4 ]
 [ 0.    0.    0.    0.   43.74 42.74]
 [ 0.    0.    0.    0.    0.   48.33]]
2024-05-01 19:56:38,856 [trainer.py] => Forgetting (CNN): 1.2639999999999987
2024-05-01 19:56:42,491 [trainer.py] => config: ./exps/coda_prompt_omn_B150_Inc5.json
2024-05-01 19:56:42,491 [trainer.py] => prefix:  
2024-05-01 19:56:42,491 [trainer.py] => dataset: omnibenchmark
2024-05-01 19:56:42,491 [trainer.py] => memory_size: 0
2024-05-01 19:56:42,491 [trainer.py] => memory_per_class: 0
2024-05-01 19:56:42,491 [trainer.py] => fixed_memory: False
2024-05-01 19:56:42,491 [trainer.py] => shuffle: False
2024-05-01 19:56:42,491 [trainer.py] => init_cls: 150
2024-05-01 19:56:42,491 [trainer.py] => increment: 30
2024-05-01 19:56:42,491 [trainer.py] => model_name: coda_prompt
2024-05-01 19:56:42,491 [trainer.py] => backbone_type: vit_base_patch16_224_in21k_coda_prompt
2024-05-01 19:56:42,491 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-01 19:56:42,491 [trainer.py] => seed: 1993
2024-05-01 19:56:42,491 [trainer.py] => tuned_epoch: 20
2024-05-01 19:56:42,491 [trainer.py] => init_lr: 0.001
2024-05-01 19:56:42,491 [trainer.py] => batch_size: 48
2024-05-01 19:56:42,492 [trainer.py] => weight_decay: 0
2024-05-01 19:56:42,492 [trainer.py] => min_lr: 1e-05
2024-05-01 19:56:42,492 [trainer.py] => optimizer: adam
2024-05-01 19:56:42,492 [trainer.py] => scheduler: cosine
2024-05-01 19:56:42,492 [trainer.py] => reinit_optimizer: True
2024-05-01 19:56:42,492 [trainer.py] => pretrained: True
2024-05-01 19:56:42,492 [trainer.py] => drop: 0.0
2024-05-01 19:56:42,492 [trainer.py] => drop_path: 0.0
2024-05-01 19:56:42,492 [trainer.py] => prompt_param: [100, 8.0, 0.0]
2024-05-01 19:56:42,778 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]
2024-05-01 19:56:47,062 [coda_prompt.py] => 89,869,356 total parameters.
2024-05-01 19:56:47,062 [coda_prompt.py] => 4,070,700 fc and prompt training parameters.
2024-05-01 19:56:47,063 [trainer.py] => All params: 89869356
2024-05-01 19:56:47,063 [trainer.py] => Trainable params: 89869356
2024-05-01 19:56:47,063 [coda_prompt.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.393, Train_accy 62.13:   0%|          | 0/20 [07:04<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.393, Train_accy 62.13:   5%|▌         | 1/20 [07:04<2:14:26, 424.55s/it]Task 0, Epoch 2/20 => Loss 1.013, Train_accy 70.27:   5%|▌         | 1/20 [14:07<2:14:26, 424.55s/it]Task 0, Epoch 2/20 => Loss 1.013, Train_accy 70.27:  10%|█         | 2/20 [14:07<2:07:09, 423.87s/it]Task 0, Epoch 3/20 => Loss 0.934, Train_accy 72.26:  10%|█         | 2/20 [21:09<2:07:09, 423.87s/it]Task 0, Epoch 3/20 => Loss 0.934, Train_accy 72.26:  15%|█▌        | 3/20 [21:09<1:59:48, 422.87s/it]Task 0, Epoch 4/20 => Loss 0.877, Train_accy 73.72:  15%|█▌        | 3/20 [28:13<1:59:48, 422.87s/it]Task 0, Epoch 4/20 => Loss 0.877, Train_accy 73.72:  20%|██        | 4/20 [28:13<1:52:53, 423.36s/it]Task 0, Epoch 5/20 => Loss 0.839, Train_accy 74.71, Test_accy 74.29:  20%|██        | 4/20 [35:32<1:52:53, 423.36s/it]Task 0, Epoch 5/20 => Loss 0.839, Train_accy 74.71, Test_accy 74.29:  25%|██▌       | 5/20 [35:32<1:47:11, 428.77s/it]Task 0, Epoch 6/20 => Loss 0.796, Train_accy 75.71:  25%|██▌       | 5/20 [42:35<1:47:11, 428.77s/it]                 Task 0, Epoch 6/20 => Loss 0.796, Train_accy 75.71:  30%|███       | 6/20 [42:35<1:39:36, 426.92s/it]Task 0, Epoch 7/20 => Loss 0.779, Train_accy 76.30:  30%|███       | 6/20 [49:38<1:39:36, 426.92s/it]Task 0, Epoch 7/20 => Loss 0.779, Train_accy 76.30:  35%|███▌      | 7/20 [49:38<1:32:12, 425.58s/it]Task 0, Epoch 8/20 => Loss 0.752, Train_accy 77.08:  35%|███▌      | 7/20 [56:41<1:32:12, 425.58s/it]Task 0, Epoch 8/20 => Loss 0.752, Train_accy 77.08:  40%|████      | 8/20 [56:41<1:24:59, 424.97s/it]Task 0, Epoch 9/20 => Loss 0.724, Train_accy 77.74:  40%|████      | 8/20 [1:03:44<1:24:59, 424.97s/it]Task 0, Epoch 9/20 => Loss 0.724, Train_accy 77.74:  45%|████▌     | 9/20 [1:03:44<1:17:48, 424.37s/it]Task 0, Epoch 10/20 => Loss 0.712, Train_accy 77.94, Test_accy 75.36:  45%|████▌     | 9/20 [1:11:05<1:17:48, 424.37s/it]Task 0, Epoch 10/20 => Loss 0.712, Train_accy 77.94, Test_accy 75.36:  50%|█████     | 10/20 [1:11:05<1:11:33, 429.31s/it]Task 0, Epoch 11/20 => Loss 0.695, Train_accy 78.29:  50%|█████     | 10/20 [1:18:09<1:11:33, 429.31s/it]                 Task 0, Epoch 11/20 => Loss 0.695, Train_accy 78.29:  55%|█████▌    | 11/20 [1:18:09<1:04:09, 427.69s/it]Task 0, Epoch 12/20 => Loss 0.667, Train_accy 78.97:  55%|█████▌    | 11/20 [1:25:13<1:04:09, 427.69s/it]Task 0, Epoch 12/20 => Loss 0.667, Train_accy 78.97:  60%|██████    | 12/20 [1:25:13<56:52, 426.59s/it]  Task 0, Epoch 13/20 => Loss 0.652, Train_accy 79.50:  60%|██████    | 12/20 [1:32:16<56:52, 426.59s/it]Task 0, Epoch 13/20 => Loss 0.652, Train_accy 79.50:  65%|██████▌   | 13/20 [1:32:16<49:39, 425.60s/it]Task 0, Epoch 14/20 => Loss 0.636, Train_accy 79.81:  65%|██████▌   | 13/20 [1:39:21<49:39, 425.60s/it]Task 0, Epoch 14/20 => Loss 0.636, Train_accy 79.81:  70%|███████   | 14/20 [1:39:21<42:31, 425.33s/it]Task 0, Epoch 15/20 => Loss 0.611, Train_accy 80.64, Test_accy 76.26:  70%|███████   | 14/20 [1:46:40<42:31, 425.33s/it]Task 0, Epoch 15/20 => Loss 0.611, Train_accy 80.64, Test_accy 76.26:  75%|███████▌  | 15/20 [1:46:40<35:48, 429.60s/it]Task 0, Epoch 16/20 => Loss 0.600, Train_accy 81.08:  75%|███████▌  | 15/20 [1:53:45<35:48, 429.60s/it]                 Task 0, Epoch 16/20 => Loss 0.600, Train_accy 81.08:  80%|████████  | 16/20 [1:53:45<28:31, 427.99s/it]Task 0, Epoch 17/20 => Loss 0.579, Train_accy 81.35:  80%|████████  | 16/20 [2:00:48<28:31, 427.99s/it]Task 0, Epoch 17/20 => Loss 0.579, Train_accy 81.35:  85%|████████▌ | 17/20 [2:00:48<21:19, 426.63s/it]Task 0, Epoch 18/20 => Loss 0.570, Train_accy 81.95:  85%|████████▌ | 17/20 [2:07:52<21:19, 426.63s/it]Task 0, Epoch 18/20 => Loss 0.570, Train_accy 81.95:  90%|█████████ | 18/20 [2:07:52<14:11, 425.69s/it]Task 0, Epoch 19/20 => Loss 0.546, Train_accy 82.40:  90%|█████████ | 18/20 [2:14:53<14:11, 425.69s/it]Task 0, Epoch 19/20 => Loss 0.546, Train_accy 82.40:  95%|█████████▌| 19/20 [2:14:53<07:04, 424.43s/it]Task 0, Epoch 20/20 => Loss 0.534, Train_accy 82.82, Test_accy 76.36:  95%|█████████▌| 19/20 [2:22:12<07:04, 424.43s/it]Task 0, Epoch 20/20 => Loss 0.534, Train_accy 82.82, Test_accy 76.36: 100%|██████████| 20/20 [2:22:12<00:00, 428.72s/it]Task 0, Epoch 20/20 => Loss 0.534, Train_accy 82.82, Test_accy 76.36: 100%|██████████| 20/20 [2:22:12<00:00, 426.62s/it]
2024-05-01 22:18:59,991 [coda_prompt.py] => Task 0, Epoch 20/20 => Loss 0.534, Train_accy 82.82, Test_accy 76.36
2024-05-01 22:19:15,784 [trainer.py] => No NME accuracy.
2024-05-01 22:19:15,784 [trainer.py] => CNN: {'total': 76.36, '00-149': 76.36, 'old': 0, 'new': 76.36}
2024-05-01 22:19:15,784 [trainer.py] => CNN top1 curve: [76.36]
2024-05-01 22:19:15,784 [trainer.py] => CNN top5 curve: [95.66]

Average Accuracy (CNN): 76.36
2024-05-01 22:19:15,784 [trainer.py] => Average Accuracy (CNN): 76.36 

2024-05-01 22:19:15,785 [trainer.py] => Train Time: 17065.26
2024-05-01 22:19:15,785 [trainer.py] => Test Time: 15.79 

2024-05-01 22:19:15,785 [trainer.py] => All params: 89869356
2024-05-01 22:19:15,786 [trainer.py] => Trainable params: 89869356
2024-05-01 22:19:16,714 [coda_prompt.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.374, Train_accy 90.69:   0%|          | 0/20 [01:19<?, ?it/s]Task 1, Epoch 1/20 => Loss 0.374, Train_accy 90.69:   5%|▌         | 1/20 [01:19<25:07, 79.36s/it]Task 1, Epoch 2/20 => Loss 0.110, Train_accy 96.64:   5%|▌         | 1/20 [02:38<25:07, 79.36s/it]Task 1, Epoch 2/20 => Loss 0.110, Train_accy 96.64:  10%|█         | 2/20 [02:38<23:47, 79.29s/it]Task 1, Epoch 3/20 => Loss 0.093, Train_accy 97.29:  10%|█         | 2/20 [03:58<23:47, 79.29s/it]Task 1, Epoch 3/20 => Loss 0.093, Train_accy 97.29:  15%|█▌        | 3/20 [03:58<22:28, 79.34s/it]Task 1, Epoch 4/20 => Loss 0.073, Train_accy 97.73:  15%|█▌        | 3/20 [05:17<22:28, 79.34s/it]Task 1, Epoch 4/20 => Loss 0.073, Train_accy 97.73:  20%|██        | 4/20 [05:17<21:09, 79.34s/it]Task 1, Epoch 5/20 => Loss 0.074, Train_accy 97.71, Test_accy 71.93:  20%|██        | 4/20 [06:55<21:09, 79.34s/it]Task 1, Epoch 5/20 => Loss 0.074, Train_accy 97.71, Test_accy 71.93:  25%|██▌       | 5/20 [06:55<21:34, 86.30s/it]Task 1, Epoch 6/20 => Loss 0.067, Train_accy 97.94:  25%|██▌       | 5/20 [08:15<21:34, 86.30s/it]                 Task 1, Epoch 6/20 => Loss 0.067, Train_accy 97.94:  30%|███       | 6/20 [08:15<19:35, 83.95s/it]Task 1, Epoch 7/20 => Loss 0.059, Train_accy 98.26:  30%|███       | 6/20 [09:35<19:35, 83.95s/it]Task 1, Epoch 7/20 => Loss 0.059, Train_accy 98.26:  35%|███▌      | 7/20 [09:35<17:54, 82.63s/it]Task 1, Epoch 8/20 => Loss 0.058, Train_accy 98.26:  35%|███▌      | 7/20 [10:55<17:54, 82.63s/it]Task 1, Epoch 8/20 => Loss 0.058, Train_accy 98.26:  40%|████      | 8/20 [10:55<16:21, 81.75s/it]Task 1, Epoch 9/20 => Loss 0.058, Train_accy 98.38:  40%|████      | 8/20 [12:14<16:21, 81.75s/it]Task 1, Epoch 9/20 => Loss 0.058, Train_accy 98.38:  45%|████▌     | 9/20 [12:14<14:50, 80.97s/it]Task 1, Epoch 10/20 => Loss 0.054, Train_accy 98.37, Test_accy 72.51:  45%|████▌     | 9/20 [13:52<14:50, 80.97s/it]Task 1, Epoch 10/20 => Loss 0.054, Train_accy 98.37, Test_accy 72.51:  50%|█████     | 10/20 [13:52<14:21, 86.18s/it]Task 1, Epoch 11/20 => Loss 0.063, Train_accy 98.19:  50%|█████     | 10/20 [15:11<14:21, 86.18s/it]                 Task 1, Epoch 11/20 => Loss 0.063, Train_accy 98.19:  55%|█████▌    | 11/20 [15:11<12:36, 84.07s/it]Task 1, Epoch 12/20 => Loss 0.050, Train_accy 98.51:  55%|█████▌    | 11/20 [16:30<12:36, 84.07s/it]Task 1, Epoch 12/20 => Loss 0.050, Train_accy 98.51:  60%|██████    | 12/20 [16:30<11:00, 82.60s/it]Task 1, Epoch 13/20 => Loss 0.050, Train_accy 98.44:  60%|██████    | 12/20 [17:50<11:00, 82.60s/it]Task 1, Epoch 13/20 => Loss 0.050, Train_accy 98.44:  65%|██████▌   | 13/20 [17:50<09:31, 81.59s/it]Task 1, Epoch 14/20 => Loss 0.047, Train_accy 98.61:  65%|██████▌   | 13/20 [19:09<09:31, 81.59s/it]Task 1, Epoch 14/20 => Loss 0.047, Train_accy 98.61:  70%|███████   | 14/20 [19:09<08:05, 80.97s/it]Task 1, Epoch 15/20 => Loss 0.045, Train_accy 98.62, Test_accy 72.93:  70%|███████   | 14/20 [20:47<08:05, 80.97s/it]Task 1, Epoch 15/20 => Loss 0.045, Train_accy 98.62, Test_accy 72.93:  75%|███████▌  | 15/20 [20:47<07:11, 86.23s/it]Task 1, Epoch 16/20 => Loss 0.046, Train_accy 98.71:  75%|███████▌  | 15/20 [22:07<07:11, 86.23s/it]                 Task 1, Epoch 16/20 => Loss 0.046, Train_accy 98.71:  80%|████████  | 16/20 [22:07<05:36, 84.16s/it]Task 1, Epoch 17/20 => Loss 0.042, Train_accy 98.74:  80%|████████  | 16/20 [23:26<05:36, 84.16s/it]Task 1, Epoch 17/20 => Loss 0.042, Train_accy 98.74:  85%|████████▌ | 17/20 [23:26<04:08, 82.75s/it]Task 1, Epoch 18/20 => Loss 0.045, Train_accy 98.67:  85%|████████▌ | 17/20 [24:46<04:08, 82.75s/it]Task 1, Epoch 18/20 => Loss 0.045, Train_accy 98.67:  90%|█████████ | 18/20 [24:46<02:43, 81.84s/it]Task 1, Epoch 19/20 => Loss 0.037, Train_accy 98.89:  90%|█████████ | 18/20 [26:05<02:43, 81.84s/it]Task 1, Epoch 19/20 => Loss 0.037, Train_accy 98.89:  95%|█████████▌| 19/20 [26:05<01:21, 81.06s/it]Task 1, Epoch 20/20 => Loss 0.040, Train_accy 98.77, Test_accy 73.18:  95%|█████████▌| 19/20 [27:43<01:21, 81.06s/it]Task 1, Epoch 20/20 => Loss 0.040, Train_accy 98.77, Test_accy 73.18: 100%|██████████| 20/20 [27:43<00:00, 86.20s/it]Task 1, Epoch 20/20 => Loss 0.040, Train_accy 98.77, Test_accy 73.18: 100%|██████████| 20/20 [27:43<00:00, 83.20s/it]
2024-05-01 22:47:00,710 [coda_prompt.py] => Task 1, Epoch 20/20 => Loss 0.040, Train_accy 98.77, Test_accy 73.18
2024-05-01 22:47:19,566 [trainer.py] => No NME accuracy.
2024-05-01 22:47:19,566 [trainer.py] => CNN: {'total': 73.18, '00-149': 73.56, '150-179': 71.29, 'old': 73.56, 'new': 71.29}
2024-05-01 22:47:19,566 [trainer.py] => CNN top1 curve: [76.36, 73.18]
2024-05-01 22:47:19,566 [trainer.py] => CNN top5 curve: [95.66, 93.6]

Average Accuracy (CNN): 74.77
2024-05-01 22:47:19,566 [trainer.py] => Average Accuracy (CNN): 74.77 

2024-05-01 22:47:19,566 [trainer.py] => Train Time: 20393.21
2024-05-01 22:47:19,566 [trainer.py] => Test Time: 34.64 

2024-05-01 22:47:19,567 [trainer.py] => All params: 89869356
2024-05-01 22:47:19,568 [trainer.py] => Trainable params: 89869356
2024-05-01 22:47:21,103 [coda_prompt.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.484, Train_accy 85.03:   0%|          | 0/20 [01:26<?, ?it/s]Task 2, Epoch 1/20 => Loss 0.484, Train_accy 85.03:   5%|▌         | 1/20 [01:26<27:23, 86.50s/it]Task 2, Epoch 2/20 => Loss 0.218, Train_accy 91.97:   5%|▌         | 1/20 [02:53<27:23, 86.50s/it]Task 2, Epoch 2/20 => Loss 0.218, Train_accy 91.97:  10%|█         | 2/20 [02:53<25:58, 86.58s/it]Task 2, Epoch 3/20 => Loss 0.172, Train_accy 93.55:  10%|█         | 2/20 [04:19<25:58, 86.58s/it]Task 2, Epoch 3/20 => Loss 0.172, Train_accy 93.55:  15%|█▌        | 3/20 [04:19<24:33, 86.69s/it]Task 2, Epoch 4/20 => Loss 0.159, Train_accy 94.16:  15%|█▌        | 3/20 [05:46<24:33, 86.69s/it]Task 2, Epoch 4/20 => Loss 0.159, Train_accy 94.16:  20%|██        | 4/20 [05:46<23:07, 86.70s/it]Task 2, Epoch 5/20 => Loss 0.149, Train_accy 94.46, Test_accy 68.50:  20%|██        | 4/20 [07:35<23:07, 86.70s/it]Task 2, Epoch 5/20 => Loss 0.149, Train_accy 94.46, Test_accy 68.50:  25%|██▌       | 5/20 [07:35<23:38, 94.56s/it]Task 2, Epoch 6/20 => Loss 0.132, Train_accy 95.19:  25%|██▌       | 5/20 [09:02<23:38, 94.56s/it]                 Task 2, Epoch 6/20 => Loss 0.132, Train_accy 95.19:  30%|███       | 6/20 [09:02<21:28, 92.06s/it]Task 2, Epoch 7/20 => Loss 0.126, Train_accy 95.56:  30%|███       | 6/20 [10:29<21:28, 92.06s/it]Task 2, Epoch 7/20 => Loss 0.126, Train_accy 95.56:  35%|███▌      | 7/20 [10:29<19:35, 90.43s/it]Task 2, Epoch 8/20 => Loss 0.124, Train_accy 95.84:  35%|███▌      | 7/20 [11:56<19:35, 90.43s/it]Task 2, Epoch 8/20 => Loss 0.124, Train_accy 95.84:  40%|████      | 8/20 [11:56<17:50, 89.22s/it]Task 2, Epoch 9/20 => Loss 0.116, Train_accy 95.91:  40%|████      | 8/20 [13:22<17:50, 89.22s/it]Task 2, Epoch 9/20 => Loss 0.116, Train_accy 95.91:  45%|████▌     | 9/20 [13:22<16:12, 88.37s/it]Task 2, Epoch 10/20 => Loss 0.115, Train_accy 95.87, Test_accy 69.47:  45%|████▌     | 9/20 [15:11<16:12, 88.37s/it]Task 2, Epoch 10/20 => Loss 0.115, Train_accy 95.87, Test_accy 69.47:  50%|█████     | 10/20 [15:11<15:45, 94.58s/it]Task 2, Epoch 11/20 => Loss 0.101, Train_accy 96.26:  50%|█████     | 10/20 [16:37<15:45, 94.58s/it]                 Task 2, Epoch 11/20 => Loss 0.101, Train_accy 96.26:  55%|█████▌    | 11/20 [16:37<13:49, 92.14s/it]Task 2, Epoch 12/20 => Loss 0.102, Train_accy 96.29:  55%|█████▌    | 11/20 [18:04<13:49, 92.14s/it]Task 2, Epoch 12/20 => Loss 0.102, Train_accy 96.29:  60%|██████    | 12/20 [18:04<12:04, 90.55s/it]Task 2, Epoch 13/20 => Loss 0.087, Train_accy 96.83:  60%|██████    | 12/20 [19:31<12:04, 90.55s/it]Task 2, Epoch 13/20 => Loss 0.087, Train_accy 96.83:  65%|██████▌   | 13/20 [19:31<10:25, 89.33s/it]Task 2, Epoch 14/20 => Loss 0.086, Train_accy 97.03:  65%|██████▌   | 13/20 [20:58<10:25, 89.33s/it]Task 2, Epoch 14/20 => Loss 0.086, Train_accy 97.03:  70%|███████   | 14/20 [20:58<08:51, 88.62s/it]Task 2, Epoch 15/20 => Loss 0.081, Train_accy 97.24, Test_accy 70.33:  70%|███████   | 14/20 [22:47<08:51, 88.62s/it]Task 2, Epoch 15/20 => Loss 0.081, Train_accy 97.24, Test_accy 70.33:  75%|███████▌  | 15/20 [22:47<07:54, 94.82s/it]Task 2, Epoch 16/20 => Loss 0.081, Train_accy 97.13:  75%|███████▌  | 15/20 [24:14<07:54, 94.82s/it]                 Task 2, Epoch 16/20 => Loss 0.081, Train_accy 97.13:  80%|████████  | 16/20 [24:14<06:10, 92.51s/it]Task 2, Epoch 17/20 => Loss 0.084, Train_accy 97.10:  80%|████████  | 16/20 [25:41<06:10, 92.51s/it]Task 2, Epoch 17/20 => Loss 0.084, Train_accy 97.10:  85%|████████▌ | 17/20 [25:41<04:32, 90.81s/it]Task 2, Epoch 18/20 => Loss 0.074, Train_accy 97.25:  85%|████████▌ | 17/20 [27:08<04:32, 90.81s/it]Task 2, Epoch 18/20 => Loss 0.074, Train_accy 97.25:  90%|█████████ | 18/20 [27:08<02:59, 89.58s/it]Task 2, Epoch 19/20 => Loss 0.073, Train_accy 97.28:  90%|█████████ | 18/20 [28:35<02:59, 89.58s/it]Task 2, Epoch 19/20 => Loss 0.073, Train_accy 97.28:  95%|█████████▌| 19/20 [28:35<01:28, 88.90s/it]Task 2, Epoch 20/20 => Loss 0.065, Train_accy 97.93, Test_accy 70.36:  95%|█████████▌| 19/20 [30:24<01:28, 88.90s/it]Task 2, Epoch 20/20 => Loss 0.065, Train_accy 97.93, Test_accy 70.36: 100%|██████████| 20/20 [30:24<00:00, 94.98s/it]Task 2, Epoch 20/20 => Loss 0.065, Train_accy 97.93, Test_accy 70.36: 100%|██████████| 20/20 [30:24<00:00, 91.22s/it]
2024-05-01 23:17:45,576 [coda_prompt.py] => Task 2, Epoch 20/20 => Loss 0.065, Train_accy 97.93, Test_accy 70.36
2024-05-01 23:18:07,112 [trainer.py] => No NME accuracy.
2024-05-01 23:18:07,113 [trainer.py] => CNN: {'total': 70.36, '00-149': 73.42, '150-179': 71.45, '180-209': 53.92, 'old': 73.09, 'new': 53.92}
2024-05-01 23:18:07,113 [trainer.py] => CNN top1 curve: [76.36, 73.18, 70.36]
2024-05-01 23:18:07,113 [trainer.py] => CNN top5 curve: [95.66, 93.6, 94.2]

Average Accuracy (CNN): 73.3
2024-05-01 23:18:07,113 [trainer.py] => Average Accuracy (CNN): 73.3 

2024-05-01 23:18:07,113 [trainer.py] => Train Time: 24042.12
2024-05-01 23:18:07,113 [trainer.py] => Test Time: 56.17 

2024-05-01 23:18:07,115 [trainer.py] => All params: 89869356
2024-05-01 23:18:07,116 [trainer.py] => Trainable params: 89869356
2024-05-01 23:18:09,262 [coda_prompt.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.707, Train_accy 77.42:   0%|          | 0/20 [01:21<?, ?it/s]Task 3, Epoch 1/20 => Loss 0.707, Train_accy 77.42:   5%|▌         | 1/20 [01:21<25:44, 81.28s/it]Task 3, Epoch 2/20 => Loss 0.395, Train_accy 86.41:   5%|▌         | 1/20 [02:42<25:44, 81.28s/it]Task 3, Epoch 2/20 => Loss 0.395, Train_accy 86.41:  10%|█         | 2/20 [02:42<24:26, 81.45s/it]Task 3, Epoch 3/20 => Loss 0.340, Train_accy 88.48:  10%|█         | 2/20 [04:04<24:26, 81.45s/it]Task 3, Epoch 3/20 => Loss 0.340, Train_accy 88.48:  15%|█▌        | 3/20 [04:04<23:02, 81.35s/it]Task 3, Epoch 4/20 => Loss 0.323, Train_accy 88.81:  15%|█▌        | 3/20 [05:25<23:02, 81.35s/it]Task 3, Epoch 4/20 => Loss 0.323, Train_accy 88.81:  20%|██        | 4/20 [05:25<21:41, 81.33s/it]Task 3, Epoch 5/20 => Loss 0.288, Train_accy 90.20, Test_accy 64.30:  20%|██        | 4/20 [07:11<21:41, 81.33s/it]Task 3, Epoch 5/20 => Loss 0.288, Train_accy 90.20, Test_accy 64.30:  25%|██▌       | 5/20 [07:11<22:33, 90.21s/it]Task 3, Epoch 6/20 => Loss 0.267, Train_accy 90.78:  25%|██▌       | 5/20 [08:32<22:33, 90.21s/it]                 Task 3, Epoch 6/20 => Loss 0.267, Train_accy 90.78:  30%|███       | 6/20 [08:32<20:20, 87.19s/it]Task 3, Epoch 7/20 => Loss 0.254, Train_accy 91.25:  30%|███       | 6/20 [09:53<20:20, 87.19s/it]Task 3, Epoch 7/20 => Loss 0.254, Train_accy 91.25:  35%|███▌      | 7/20 [09:53<18:28, 85.28s/it]Task 3, Epoch 8/20 => Loss 0.238, Train_accy 92.03:  35%|███▌      | 7/20 [11:15<18:28, 85.28s/it]Task 3, Epoch 8/20 => Loss 0.238, Train_accy 92.03:  40%|████      | 8/20 [11:15<16:49, 84.11s/it]Task 3, Epoch 9/20 => Loss 0.235, Train_accy 91.88:  40%|████      | 8/20 [12:37<16:49, 84.11s/it]Task 3, Epoch 9/20 => Loss 0.235, Train_accy 91.88:  45%|████▌     | 9/20 [12:37<15:16, 83.34s/it]Task 3, Epoch 10/20 => Loss 0.220, Train_accy 92.79, Test_accy 65.39:  45%|████▌     | 9/20 [14:23<15:16, 83.34s/it]Task 3, Epoch 10/20 => Loss 0.220, Train_accy 92.79, Test_accy 65.39:  50%|█████     | 10/20 [14:23<15:03, 90.33s/it]Task 3, Epoch 11/20 => Loss 0.215, Train_accy 93.11:  50%|█████     | 10/20 [15:44<15:03, 90.33s/it]                 Task 3, Epoch 11/20 => Loss 0.215, Train_accy 93.11:  55%|█████▌    | 11/20 [15:44<13:08, 87.61s/it]Task 3, Epoch 12/20 => Loss 0.207, Train_accy 93.26:  55%|█████▌    | 11/20 [17:06<13:08, 87.61s/it]Task 3, Epoch 12/20 => Loss 0.207, Train_accy 93.26:  60%|██████    | 12/20 [17:06<11:26, 85.77s/it]Task 3, Epoch 13/20 => Loss 0.191, Train_accy 93.33:  60%|██████    | 12/20 [18:27<11:26, 85.77s/it]Task 3, Epoch 13/20 => Loss 0.191, Train_accy 93.33:  65%|██████▌   | 13/20 [18:27<09:51, 84.48s/it]Task 3, Epoch 14/20 => Loss 0.195, Train_accy 93.82:  65%|██████▌   | 13/20 [19:49<09:51, 84.48s/it]Task 3, Epoch 14/20 => Loss 0.195, Train_accy 93.82:  70%|███████   | 14/20 [19:49<08:21, 83.60s/it]Task 3, Epoch 15/20 => Loss 0.189, Train_accy 93.50, Test_accy 65.55:  70%|███████   | 14/20 [21:35<08:21, 83.60s/it]Task 3, Epoch 15/20 => Loss 0.189, Train_accy 93.50, Test_accy 65.55:  75%|███████▌  | 15/20 [21:35<07:32, 90.50s/it]Task 3, Epoch 16/20 => Loss 0.182, Train_accy 93.82:  75%|███████▌  | 15/20 [22:57<07:32, 90.50s/it]                 Task 3, Epoch 16/20 => Loss 0.182, Train_accy 93.82:  80%|████████  | 16/20 [22:57<05:50, 87.74s/it]Task 3, Epoch 17/20 => Loss 0.177, Train_accy 94.36:  80%|████████  | 16/20 [24:18<05:50, 87.74s/it]Task 3, Epoch 17/20 => Loss 0.177, Train_accy 94.36:  85%|████████▌ | 17/20 [24:18<04:17, 85.87s/it]Task 3, Epoch 18/20 => Loss 0.169, Train_accy 94.45:  85%|████████▌ | 17/20 [25:39<04:17, 85.87s/it]Task 3, Epoch 18/20 => Loss 0.169, Train_accy 94.45:  90%|█████████ | 18/20 [25:39<02:48, 84.47s/it]Task 3, Epoch 19/20 => Loss 0.164, Train_accy 94.55:  90%|█████████ | 18/20 [27:01<02:48, 84.47s/it]Task 3, Epoch 19/20 => Loss 0.164, Train_accy 94.55:  95%|█████████▌| 19/20 [27:01<01:23, 83.59s/it]Task 3, Epoch 20/20 => Loss 0.155, Train_accy 94.92, Test_accy 65.60:  95%|█████████▌| 19/20 [28:47<01:23, 83.59s/it]Task 3, Epoch 20/20 => Loss 0.155, Train_accy 94.92, Test_accy 65.60: 100%|██████████| 20/20 [28:47<00:00, 90.30s/it]Task 3, Epoch 20/20 => Loss 0.155, Train_accy 94.92, Test_accy 65.60: 100%|██████████| 20/20 [28:47<00:00, 86.37s/it]
2024-05-01 23:46:56,639 [coda_prompt.py] => Task 3, Epoch 20/20 => Loss 0.155, Train_accy 94.92, Test_accy 65.60
2024-05-01 23:47:21,325 [trainer.py] => No NME accuracy.
2024-05-01 23:47:21,326 [trainer.py] => CNN: {'total': 65.6, '00-149': 72.89, '150-179': 70.95, '180-209': 51.59, '210-239': 37.83, 'old': 69.57, 'new': 37.83}
2024-05-01 23:47:21,326 [trainer.py] => CNN top1 curve: [76.36, 73.18, 70.36, 65.6]
2024-05-01 23:47:21,326 [trainer.py] => CNN top5 curve: [95.66, 93.6, 94.2, 92.36]

Average Accuracy (CNN): 71.38
2024-05-01 23:47:21,326 [trainer.py] => Average Accuracy (CNN): 71.38 

2024-05-01 23:47:21,326 [trainer.py] => Train Time: 27496.829999999998
2024-05-01 23:47:21,326 [trainer.py] => Test Time: 80.85 

2024-05-01 23:47:21,327 [trainer.py] => All params: 89869356
2024-05-01 23:47:21,328 [trainer.py] => Trainable params: 89869356
2024-05-01 23:47:23,784 [coda_prompt.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.775, Train_accy 78.15:   0%|          | 0/20 [01:24<?, ?it/s]Task 4, Epoch 1/20 => Loss 0.775, Train_accy 78.15:   5%|▌         | 1/20 [01:24<26:54, 84.99s/it]Task 4, Epoch 2/20 => Loss 0.483, Train_accy 85.69:   5%|▌         | 1/20 [02:49<26:54, 84.99s/it]Task 4, Epoch 2/20 => Loss 0.483, Train_accy 85.69:  10%|█         | 2/20 [02:49<25:28, 84.90s/it]Task 4, Epoch 3/20 => Loss 0.418, Train_accy 87.27:  10%|█         | 2/20 [04:14<25:28, 84.90s/it]Task 4, Epoch 3/20 => Loss 0.418, Train_accy 87.27:  15%|█▌        | 3/20 [04:14<24:01, 84.82s/it]Task 4, Epoch 4/20 => Loss 0.397, Train_accy 87.77:  15%|█▌        | 3/20 [05:39<24:01, 84.82s/it]Task 4, Epoch 4/20 => Loss 0.397, Train_accy 87.77:  20%|██        | 4/20 [05:39<22:36, 84.79s/it]Task 4, Epoch 5/20 => Loss 0.367, Train_accy 88.83, Test_accy 61.49:  20%|██        | 4/20 [07:31<22:36, 84.79s/it]Task 4, Epoch 5/20 => Loss 0.367, Train_accy 88.83, Test_accy 61.49:  25%|██▌       | 5/20 [07:31<23:40, 94.71s/it]Task 4, Epoch 6/20 => Loss 0.346, Train_accy 89.38:  25%|██▌       | 5/20 [08:56<23:40, 94.71s/it]                 Task 4, Epoch 6/20 => Loss 0.346, Train_accy 89.38:  30%|███       | 6/20 [08:56<21:18, 91.31s/it]Task 4, Epoch 7/20 => Loss 0.322, Train_accy 89.83:  30%|███       | 6/20 [10:20<21:18, 91.31s/it]Task 4, Epoch 7/20 => Loss 0.322, Train_accy 89.83:  35%|███▌      | 7/20 [10:20<19:18, 89.11s/it]Task 4, Epoch 8/20 => Loss 0.333, Train_accy 89.66:  35%|███▌      | 7/20 [11:45<19:18, 89.11s/it]Task 4, Epoch 8/20 => Loss 0.333, Train_accy 89.66:  40%|████      | 8/20 [11:45<17:31, 87.66s/it]Task 4, Epoch 9/20 => Loss 0.294, Train_accy 90.61:  40%|████      | 8/20 [13:09<17:31, 87.66s/it]Task 4, Epoch 9/20 => Loss 0.294, Train_accy 90.61:  45%|████▌     | 9/20 [13:09<15:53, 86.67s/it]Task 4, Epoch 10/20 => Loss 0.288, Train_accy 91.13, Test_accy 61.38:  45%|████▌     | 9/20 [15:02<15:53, 86.67s/it]Task 4, Epoch 10/20 => Loss 0.288, Train_accy 91.13, Test_accy 61.38:  50%|█████     | 10/20 [15:02<15:45, 94.54s/it]Task 4, Epoch 11/20 => Loss 0.265, Train_accy 91.46:  50%|█████     | 10/20 [16:26<15:45, 94.54s/it]                 Task 4, Epoch 11/20 => Loss 0.265, Train_accy 91.46:  55%|█████▌    | 11/20 [16:26<13:43, 91.53s/it]Task 4, Epoch 12/20 => Loss 0.282, Train_accy 91.39:  55%|█████▌    | 11/20 [17:51<13:43, 91.53s/it]Task 4, Epoch 12/20 => Loss 0.282, Train_accy 91.39:  60%|██████    | 12/20 [17:51<11:55, 89.42s/it]Task 4, Epoch 13/20 => Loss 0.273, Train_accy 91.67:  60%|██████    | 12/20 [19:15<11:55, 89.42s/it]Task 4, Epoch 13/20 => Loss 0.273, Train_accy 91.67:  65%|██████▌   | 13/20 [19:15<10:15, 87.88s/it]Task 4, Epoch 14/20 => Loss 0.257, Train_accy 92.14:  65%|██████▌   | 13/20 [20:40<10:15, 87.88s/it]Task 4, Epoch 14/20 => Loss 0.257, Train_accy 92.14:  70%|███████   | 14/20 [20:40<08:41, 86.96s/it]Task 4, Epoch 15/20 => Loss 0.247, Train_accy 92.44, Test_accy 61.12:  70%|███████   | 14/20 [22:32<08:41, 86.96s/it]Task 4, Epoch 15/20 => Loss 0.247, Train_accy 92.44, Test_accy 61.12:  75%|███████▌  | 15/20 [22:32<07:52, 94.59s/it]Task 4, Epoch 16/20 => Loss 0.262, Train_accy 92.02:  75%|███████▌  | 15/20 [23:57<07:52, 94.59s/it]                 Task 4, Epoch 16/20 => Loss 0.262, Train_accy 92.02:  80%|████████  | 16/20 [23:57<06:06, 91.67s/it]Task 4, Epoch 17/20 => Loss 0.238, Train_accy 92.57:  80%|████████  | 16/20 [25:22<06:06, 91.67s/it]Task 4, Epoch 17/20 => Loss 0.238, Train_accy 92.57:  85%|████████▌ | 17/20 [25:22<04:28, 89.54s/it]Task 4, Epoch 18/20 => Loss 0.236, Train_accy 92.56:  85%|████████▌ | 17/20 [26:46<04:28, 89.54s/it]Task 4, Epoch 18/20 => Loss 0.236, Train_accy 92.56:  90%|█████████ | 18/20 [26:46<02:56, 88.08s/it]Task 4, Epoch 19/20 => Loss 0.235, Train_accy 92.61:  90%|█████████ | 18/20 [28:11<02:56, 88.08s/it]Task 4, Epoch 19/20 => Loss 0.235, Train_accy 92.61:  95%|█████████▌| 19/20 [28:11<01:27, 87.02s/it]Task 4, Epoch 20/20 => Loss 0.220, Train_accy 93.37, Test_accy 60.32:  95%|█████████▌| 19/20 [30:03<01:27, 87.02s/it]Task 4, Epoch 20/20 => Loss 0.220, Train_accy 93.37, Test_accy 60.32: 100%|██████████| 20/20 [30:03<00:00, 94.61s/it]Task 4, Epoch 20/20 => Loss 0.220, Train_accy 93.37, Test_accy 60.32: 100%|██████████| 20/20 [30:03<00:00, 90.19s/it]
2024-05-02 00:17:27,632 [coda_prompt.py] => Task 4, Epoch 20/20 => Loss 0.220, Train_accy 93.37, Test_accy 60.32
2024-05-02 00:17:55,313 [trainer.py] => No NME accuracy.
2024-05-02 00:17:55,313 [trainer.py] => CNN: {'total': 60.32, '00-149': 73.19, '150-179': 68.28, '180-209': 50.08, '210-239': 37.0, '240-269': 21.57, 'old': 65.16, 'new': 21.57}
2024-05-02 00:17:55,313 [trainer.py] => CNN top1 curve: [76.36, 73.18, 70.36, 65.6, 60.32]
2024-05-02 00:17:55,314 [trainer.py] => CNN top5 curve: [95.66, 93.6, 94.2, 92.36, 89.32]

Average Accuracy (CNN): 69.16
2024-05-02 00:17:55,314 [trainer.py] => Average Accuracy (CNN): 69.16 

2024-05-02 00:17:55,314 [trainer.py] => Train Time: 31104.499999999996
2024-05-02 00:17:55,314 [trainer.py] => Test Time: 108.53 

2024-05-02 00:17:55,316 [trainer.py] => All params: 89869356
2024-05-02 00:17:55,318 [trainer.py] => Trainable params: 89869356
2024-05-02 00:17:58,304 [coda_prompt.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.726, Train_accy 78.69:   0%|          | 0/20 [01:31<?, ?it/s]Task 5, Epoch 1/20 => Loss 0.726, Train_accy 78.69:   5%|▌         | 1/20 [01:31<28:50, 91.09s/it]Task 5, Epoch 2/20 => Loss 0.439, Train_accy 86.04:   5%|▌         | 1/20 [03:01<28:50, 91.09s/it]Task 5, Epoch 2/20 => Loss 0.439, Train_accy 86.04:  10%|█         | 2/20 [03:01<27:14, 90.82s/it]Task 5, Epoch 3/20 => Loss 0.407, Train_accy 87.39:  10%|█         | 2/20 [04:32<27:14, 90.82s/it]Task 5, Epoch 3/20 => Loss 0.407, Train_accy 87.39:  15%|█▌        | 3/20 [04:32<25:43, 90.76s/it]Task 5, Epoch 4/20 => Loss 0.363, Train_accy 88.31:  15%|█▌        | 3/20 [06:03<25:43, 90.76s/it]Task 5, Epoch 4/20 => Loss 0.363, Train_accy 88.31:  20%|██        | 4/20 [06:03<24:11, 90.75s/it]Task 5, Epoch 5/20 => Loss 0.370, Train_accy 87.99, Test_accy 58.76:  20%|██        | 4/20 [08:04<24:11, 90.75s/it]Task 5, Epoch 5/20 => Loss 0.370, Train_accy 87.99, Test_accy 58.76:  25%|██▌       | 5/20 [08:04<25:25, 101.73s/it]Task 5, Epoch 6/20 => Loss 0.331, Train_accy 89.60:  25%|██▌       | 5/20 [09:35<25:25, 101.73s/it]                 Task 5, Epoch 6/20 => Loss 0.331, Train_accy 89.60:  30%|███       | 6/20 [09:35<22:51, 97.98s/it] Task 5, Epoch 7/20 => Loss 0.320, Train_accy 89.65:  30%|███       | 6/20 [11:05<22:51, 97.98s/it]Task 5, Epoch 7/20 => Loss 0.320, Train_accy 89.65:  35%|███▌      | 7/20 [11:05<20:40, 95.39s/it]Task 5, Epoch 8/20 => Loss 0.304, Train_accy 90.20:  35%|███▌      | 7/20 [12:35<20:40, 95.39s/it]Task 5, Epoch 8/20 => Loss 0.304, Train_accy 90.20:  40%|████      | 8/20 [12:35<18:44, 93.73s/it]Task 5, Epoch 9/20 => Loss 0.295, Train_accy 90.52:  40%|████      | 8/20 [14:05<18:44, 93.73s/it]Task 5, Epoch 9/20 => Loss 0.295, Train_accy 90.52:  45%|████▌     | 9/20 [14:05<17:00, 92.73s/it]Task 5, Epoch 10/20 => Loss 0.299, Train_accy 90.37, Test_accy 59.08:  45%|████▌     | 9/20 [16:06<17:00, 92.73s/it]Task 5, Epoch 10/20 => Loss 0.299, Train_accy 90.37, Test_accy 59.08:  50%|█████     | 10/20 [16:06<16:54, 101.43s/it]Task 5, Epoch 11/20 => Loss 0.276, Train_accy 91.18:  50%|█████     | 10/20 [17:37<16:54, 101.43s/it]                 Task 5, Epoch 11/20 => Loss 0.276, Train_accy 91.18:  55%|█████▌    | 11/20 [17:37<14:43, 98.17s/it] Task 5, Epoch 12/20 => Loss 0.276, Train_accy 91.31:  55%|█████▌    | 11/20 [19:08<14:43, 98.17s/it]Task 5, Epoch 12/20 => Loss 0.276, Train_accy 91.31:  60%|██████    | 12/20 [19:08<12:47, 95.91s/it]Task 5, Epoch 13/20 => Loss 0.268, Train_accy 91.17:  60%|██████    | 12/20 [20:39<12:47, 95.91s/it]Task 5, Epoch 13/20 => Loss 0.268, Train_accy 91.17:  65%|██████▌   | 13/20 [20:39<11:00, 94.37s/it]Task 5, Epoch 14/20 => Loss 0.258, Train_accy 92.10:  65%|██████▌   | 13/20 [22:09<11:00, 94.37s/it]Task 5, Epoch 14/20 => Loss 0.258, Train_accy 92.10:  70%|███████   | 14/20 [22:09<09:19, 93.29s/it]Task 5, Epoch 15/20 => Loss 0.264, Train_accy 91.67, Test_accy 58.86:  70%|███████   | 14/20 [24:11<09:19, 93.29s/it]Task 5, Epoch 15/20 => Loss 0.264, Train_accy 91.67, Test_accy 58.86:  75%|███████▌  | 15/20 [24:11<08:28, 101.78s/it]Task 5, Epoch 16/20 => Loss 0.247, Train_accy 91.93:  75%|███████▌  | 15/20 [25:41<08:28, 101.78s/it]                 Task 5, Epoch 16/20 => Loss 0.247, Train_accy 91.93:  80%|████████  | 16/20 [25:41<06:33, 98.42s/it] Task 5, Epoch 17/20 => Loss 0.242, Train_accy 92.34:  80%|████████  | 16/20 [27:12<06:33, 98.42s/it]Task 5, Epoch 17/20 => Loss 0.242, Train_accy 92.34:  85%|████████▌ | 17/20 [27:12<04:48, 96.18s/it]Task 5, Epoch 18/20 => Loss 0.247, Train_accy 92.06:  85%|████████▌ | 17/20 [28:43<04:48, 96.18s/it]Task 5, Epoch 18/20 => Loss 0.247, Train_accy 92.06:  90%|█████████ | 18/20 [28:43<03:09, 94.63s/it]Task 5, Epoch 19/20 => Loss 0.234, Train_accy 92.58:  90%|█████████ | 18/20 [30:14<03:09, 94.63s/it]Task 5, Epoch 19/20 => Loss 0.234, Train_accy 92.58:  95%|█████████▌| 19/20 [30:14<01:33, 93.52s/it]Task 5, Epoch 20/20 => Loss 0.225, Train_accy 93.03, Test_accy 57.69:  95%|█████████▌| 19/20 [32:16<01:33, 93.52s/it]Task 5, Epoch 20/20 => Loss 0.225, Train_accy 93.03, Test_accy 57.69: 100%|██████████| 20/20 [32:16<00:00, 101.95s/it]Task 5, Epoch 20/20 => Loss 0.225, Train_accy 93.03, Test_accy 57.69: 100%|██████████| 20/20 [32:16<00:00, 96.82s/it] 
2024-05-02 00:50:14,793 [coda_prompt.py] => Task 5, Epoch 20/20 => Loss 0.225, Train_accy 93.03, Test_accy 57.69
2024-05-02 00:50:45,491 [trainer.py] => No NME accuracy.
2024-05-02 00:50:45,491 [trainer.py] => CNN: {'total': 57.69, '00-149': 72.65, '150-179': 70.45, '180-209': 51.92, '210-239': 36.0, '240-269': 23.08, '270-299': 31.99, 'old': 60.53, 'new': 31.99}
2024-05-02 00:50:45,491 [trainer.py] => CNN top1 curve: [76.36, 73.18, 70.36, 65.6, 60.32, 57.69]
2024-05-02 00:50:45,491 [trainer.py] => CNN top5 curve: [95.66, 93.6, 94.2, 92.36, 89.32, 88.35]

Average Accuracy (CNN): 67.25
2024-05-02 00:50:45,491 [trainer.py] => Average Accuracy (CNN): 67.25 

2024-05-02 00:50:45,491 [trainer.py] => Train Time: 34977.43
2024-05-02 00:50:45,491 [trainer.py] => Test Time: 139.23 

Accuracy Matrix (CNN):
[[76.36 73.56 73.42 72.89 73.19 72.65]
 [ 0.   71.29 71.45 70.95 68.28 70.45]
 [ 0.    0.   53.92 51.59 50.08 51.92]
 [ 0.    0.    0.   37.83 37.   36.  ]
 [ 0.    0.    0.    0.   21.57 23.08]
 [ 0.    0.    0.    0.    0.   31.99]]
2024-05-02 00:50:45,492 [trainer.py] => Forgetting (CNN): 1.7079999999999984
2024-05-02 00:50:48,615 [trainer.py] => config: ./exps/simplecil_omn_B150_Inc5.json
2024-05-02 00:50:48,635 [trainer.py] => prefix:  
2024-05-02 00:50:48,635 [trainer.py] => dataset: omnibenchmark
2024-05-02 00:50:48,635 [trainer.py] => memory_size: 0
2024-05-02 00:50:48,635 [trainer.py] => memory_per_class: 0
2024-05-02 00:50:48,635 [trainer.py] => fixed_memory: False
2024-05-02 00:50:48,635 [trainer.py] => shuffle: True
2024-05-02 00:50:48,635 [trainer.py] => init_cls: 150
2024-05-02 00:50:48,635 [trainer.py] => increment: 30
2024-05-02 00:50:48,635 [trainer.py] => model_name: simplecil
2024-05-02 00:50:48,635 [trainer.py] => backbone_type: pretrained_vit_b16_224
2024-05-02 00:50:48,635 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-02 00:50:48,635 [trainer.py] => seed: 1993
2024-05-02 00:50:48,636 [trainer.py] => tuned_epoch: 0
2024-05-02 00:50:48,636 [trainer.py] => init_lr: 0.01
2024-05-02 00:50:48,636 [trainer.py] => batch_size: 48
2024-05-02 00:50:48,636 [trainer.py] => weight_decay: 0.05
2024-05-02 00:50:48,636 [trainer.py] => min_lr: 1e-08
2024-05-02 00:50:48,636 [trainer.py] => optimizer: sgd
2024-05-02 00:50:48,636 [trainer.py] => vpt_type: shallow
2024-05-02 00:50:48,636 [trainer.py] => prompt_token_num: 3
2024-05-02 00:50:48,935 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
This is for the BaseNet initialization.
After BaseNet initialization.
2024-05-02 00:50:56,238 [trainer.py] => All params: 85798656
2024-05-02 00:50:56,239 [trainer.py] => Trainable params: 85798656
2024-05-02 00:50:56,684 [simplecil.py] => Learning on 0-150
2024-05-02 00:53:01,501 [trainer.py] => No NME accuracy.
2024-05-02 00:53:01,501 [trainer.py] => CNN: {'total': 78.66, '00-149': 78.66, 'old': 0, 'new': 78.66}
2024-05-02 00:53:01,501 [trainer.py] => CNN top1 curve: [78.66]
2024-05-02 00:53:01,501 [trainer.py] => CNN top5 curve: [94.46]

Average Accuracy (CNN): 78.66
2024-05-02 00:53:01,502 [trainer.py] => Average Accuracy (CNN): 78.66 

2024-05-02 00:53:01,502 [trainer.py] => Train Time: 115.62
2024-05-02 00:53:01,502 [trainer.py] => Test Time: 9.11 

2024-05-02 00:53:01,502 [trainer.py] => All params: 85913857
2024-05-02 00:53:01,503 [trainer.py] => Trainable params: 85913857
2024-05-02 00:53:01,506 [simplecil.py] => Learning on 150-180
2024-05-02 00:53:36,378 [trainer.py] => No NME accuracy.
2024-05-02 00:53:36,378 [trainer.py] => CNN: {'total': 75.92, '00-149': 76.72, '150-179': 71.91, 'old': 76.72, 'new': 71.91}
2024-05-02 00:53:36,378 [trainer.py] => CNN top1 curve: [78.66, 75.92]
2024-05-02 00:53:36,378 [trainer.py] => CNN top5 curve: [94.46, 92.85]

Average Accuracy (CNN): 77.29
2024-05-02 00:53:36,378 [trainer.py] => Average Accuracy (CNN): 77.29 

2024-05-02 00:53:36,378 [trainer.py] => Train Time: 139.89000000000001
2024-05-02 00:53:36,378 [trainer.py] => Test Time: 19.68 

2024-05-02 00:53:36,379 [trainer.py] => All params: 85936897
2024-05-02 00:53:36,380 [trainer.py] => Trainable params: 85936897
2024-05-02 00:53:36,382 [simplecil.py] => Learning on 180-210
2024-05-02 00:54:12,751 [trainer.py] => No NME accuracy.
2024-05-02 00:54:12,751 [trainer.py] => CNN: {'total': 74.77, '00-149': 75.82, '150-179': 70.57, '180-209': 73.7, 'old': 74.94, 'new': 73.7}
2024-05-02 00:54:12,751 [trainer.py] => CNN top1 curve: [78.66, 75.92, 74.77]
2024-05-02 00:54:12,751 [trainer.py] => CNN top5 curve: [94.46, 92.85, 92.12]

Average Accuracy (CNN): 76.45
2024-05-02 00:54:12,751 [trainer.py] => Average Accuracy (CNN): 76.45 

2024-05-02 00:54:12,751 [trainer.py] => Train Time: 164.26000000000002
2024-05-02 00:54:12,752 [trainer.py] => Test Time: 31.65 

2024-05-02 00:54:12,752 [trainer.py] => All params: 85959937
2024-05-02 00:54:12,753 [trainer.py] => Trainable params: 85959937
2024-05-02 00:54:12,757 [simplecil.py] => Learning on 210-240
2024-05-02 00:54:51,707 [trainer.py] => No NME accuracy.
2024-05-02 00:54:51,707 [trainer.py] => CNN: {'total': 73.02, '00-149': 74.38, '150-179': 68.9, '180-209': 71.86, '210-239': 71.45, 'old': 73.24, 'new': 71.45}
2024-05-02 00:54:51,707 [trainer.py] => CNN top1 curve: [78.66, 75.92, 74.77, 73.02]
2024-05-02 00:54:51,707 [trainer.py] => CNN top5 curve: [94.46, 92.85, 92.12, 90.77]

Average Accuracy (CNN): 75.59
2024-05-02 00:54:51,707 [trainer.py] => Average Accuracy (CNN): 75.59 

2024-05-02 00:54:51,707 [trainer.py] => Train Time: 189.53000000000003
2024-05-02 00:54:51,707 [trainer.py] => Test Time: 45.31 

2024-05-02 00:54:51,708 [trainer.py] => All params: 85982977
2024-05-02 00:54:51,709 [trainer.py] => Trainable params: 85982977
2024-05-02 00:54:51,712 [simplecil.py] => Learning on 240-270
2024-05-02 00:55:32,487 [trainer.py] => No NME accuracy.
2024-05-02 00:55:32,487 [trainer.py] => CNN: {'total': 72.3, '00-149': 73.08, '150-179': 67.73, '180-209': 70.52, '210-239': 71.12, '240-269': 75.96, 'old': 71.85, 'new': 75.96}
2024-05-02 00:55:32,488 [trainer.py] => CNN top1 curve: [78.66, 75.92, 74.77, 73.02, 72.3]
2024-05-02 00:55:32,488 [trainer.py] => CNN top5 curve: [94.46, 92.85, 92.12, 90.77, 90.89]

Average Accuracy (CNN): 74.93
2024-05-02 00:55:32,488 [trainer.py] => Average Accuracy (CNN): 74.93 

2024-05-02 00:55:32,488 [trainer.py] => Train Time: 215.16000000000003
2024-05-02 00:55:32,488 [trainer.py] => Test Time: 60.42 

2024-05-02 00:55:32,489 [trainer.py] => All params: 86006017
2024-05-02 00:55:32,491 [trainer.py] => Trainable params: 86006017
2024-05-02 00:55:32,497 [simplecil.py] => Learning on 270-300
2024-05-02 00:56:12,969 [trainer.py] => No NME accuracy.
2024-05-02 00:56:12,969 [trainer.py] => CNN: {'total': 72.18, '00-149': 72.41, '150-179': 67.06, '180-209': 70.02, '210-239': 70.62, '240-269': 73.62, '270-299': 78.43, 'old': 71.49, 'new': 78.43}
2024-05-02 00:56:12,969 [trainer.py] => CNN top1 curve: [78.66, 75.92, 74.77, 73.02, 72.3, 72.18]
2024-05-02 00:56:12,969 [trainer.py] => CNN top5 curve: [94.46, 92.85, 92.12, 90.77, 90.89, 90.59]

Average Accuracy (CNN): 74.47
2024-05-02 00:56:12,969 [trainer.py] => Average Accuracy (CNN): 74.47 

2024-05-02 00:56:12,969 [trainer.py] => Train Time: 238.69000000000003
2024-05-02 00:56:12,969 [trainer.py] => Test Time: 77.33 

Accuracy Matrix (CNN):
[[78.66 76.72 75.82 74.38 73.08 72.41]
 [ 0.   71.91 70.57 68.9  67.73 67.06]
 [ 0.    0.   73.7  71.86 70.52 70.02]
 [ 0.    0.    0.   71.45 71.12 70.62]
 [ 0.    0.    0.    0.   75.96 73.62]
 [ 0.    0.    0.    0.    0.   78.43]]
2024-05-02 00:56:12,970 [trainer.py] => Forgetting (CNN): 3.5899999999999976
2024-05-02 00:56:15,723 [trainer.py] => config: ./exps/ease_omn_B150_Inc5.json
2024-05-02 00:56:15,723 [trainer.py] => prefix:  
2024-05-02 00:56:15,723 [trainer.py] => dataset: omnibenchmark
2024-05-02 00:56:15,723 [trainer.py] => memory_size: 0
2024-05-02 00:56:15,723 [trainer.py] => memory_per_class: 0
2024-05-02 00:56:15,723 [trainer.py] => fixed_memory: False
2024-05-02 00:56:15,723 [trainer.py] => shuffle: True
2024-05-02 00:56:15,723 [trainer.py] => init_cls: 150
2024-05-02 00:56:15,723 [trainer.py] => increment: 30
2024-05-02 00:56:15,723 [trainer.py] => model_name: ease
2024-05-02 00:56:15,723 [trainer.py] => backbone_type: vit_base_patch16_224_in21k_ease
2024-05-02 00:56:15,724 [trainer.py] => device: [device(type='cuda', index=6)]
2024-05-02 00:56:15,724 [trainer.py] => seed: 1993
2024-05-02 00:56:15,724 [trainer.py] => init_epochs: 20
2024-05-02 00:56:15,724 [trainer.py] => init_lr: 0.05
2024-05-02 00:56:15,724 [trainer.py] => later_epochs: 20
2024-05-02 00:56:15,724 [trainer.py] => later_lr: 0.05
2024-05-02 00:56:15,724 [trainer.py] => batch_size: 48
2024-05-02 00:56:15,724 [trainer.py] => weight_decay: 0.005
2024-05-02 00:56:15,724 [trainer.py] => min_lr: 0
2024-05-02 00:56:15,724 [trainer.py] => optimizer: sgd
2024-05-02 00:56:15,724 [trainer.py] => scheduler: cosine
2024-05-02 00:56:15,724 [trainer.py] => pretrained: True
2024-05-02 00:56:15,724 [trainer.py] => vpt_type: Deep
2024-05-02 00:56:15,724 [trainer.py] => prompt_token_num: 5
2024-05-02 00:56:15,724 [trainer.py] => ffn_num: 64
2024-05-02 00:56:15,724 [trainer.py] => use_diagonal: False
2024-05-02 00:56:15,724 [trainer.py] => recalc_sim: True
2024-05-02 00:56:15,724 [trainer.py] => alpha: 0.1
2024-05-02 00:56:15,724 [trainer.py] => use_init_ptm: False
2024-05-02 00:56:15,724 [trainer.py] => beta: 0
2024-05-02 00:56:15,724 [trainer.py] => use_old_data: False
2024-05-02 00:56:15,724 [trainer.py] => use_reweight: True
2024-05-02 00:56:15,724 [trainer.py] => moni_adam: False
2024-05-02 00:56:15,724 [trainer.py] => adapter_num: -1
2024-05-02 00:56:16,065 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
This is for the BaseNet initialization.
I'm using ViT with adapters.
_IncompatibleKeys(missing_keys=['cur_adapter.0.down_proj.weight', 'cur_adapter.0.down_proj.bias', 'cur_adapter.0.up_proj.weight', 'cur_adapter.0.up_proj.bias', 'cur_adapter.1.down_proj.weight', 'cur_adapter.1.down_proj.bias', 'cur_adapter.1.up_proj.weight', 'cur_adapter.1.up_proj.bias', 'cur_adapter.2.down_proj.weight', 'cur_adapter.2.down_proj.bias', 'cur_adapter.2.up_proj.weight', 'cur_adapter.2.up_proj.bias', 'cur_adapter.3.down_proj.weight', 'cur_adapter.3.down_proj.bias', 'cur_adapter.3.up_proj.weight', 'cur_adapter.3.up_proj.bias', 'cur_adapter.4.down_proj.weight', 'cur_adapter.4.down_proj.bias', 'cur_adapter.4.up_proj.weight', 'cur_adapter.4.up_proj.bias', 'cur_adapter.5.down_proj.weight', 'cur_adapter.5.down_proj.bias', 'cur_adapter.5.up_proj.weight', 'cur_adapter.5.up_proj.bias', 'cur_adapter.6.down_proj.weight', 'cur_adapter.6.down_proj.bias', 'cur_adapter.6.up_proj.weight', 'cur_adapter.6.up_proj.bias', 'cur_adapter.7.down_proj.weight', 'cur_adapter.7.down_proj.bias', 'cur_adapter.7.up_proj.weight', 'cur_adapter.7.up_proj.bias', 'cur_adapter.8.down_proj.weight', 'cur_adapter.8.down_proj.bias', 'cur_adapter.8.up_proj.weight', 'cur_adapter.8.up_proj.bias', 'cur_adapter.9.down_proj.weight', 'cur_adapter.9.down_proj.bias', 'cur_adapter.9.up_proj.weight', 'cur_adapter.9.up_proj.bias', 'cur_adapter.10.down_proj.weight', 'cur_adapter.10.down_proj.bias', 'cur_adapter.10.up_proj.weight', 'cur_adapter.10.up_proj.bias', 'cur_adapter.11.down_proj.weight', 'cur_adapter.11.down_proj.bias', 'cur_adapter.11.up_proj.weight', 'cur_adapter.11.up_proj.bias'], unexpected_keys=[])
After BaseNet initialization.
2024-05-02 00:56:21,511 [trainer.py] => All params: 86988288
2024-05-02 00:56:21,512 [trainer.py] => Trainable params: 1189632
2024-05-02 00:56:21,530 [ease.py] => Learning on 0-150
  0%|          | 0/20 [00:00<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.409, Train_accy 68.15:   0%|          | 0/20 [03:51<?, ?it/s]Task 0, Epoch 1/20 => Loss 1.409, Train_accy 68.15:   5%|▌         | 1/20 [03:51<1:13:16, 231.38s/it]Task 0, Epoch 2/20 => Loss 0.998, Train_accy 73.21:   5%|▌         | 1/20 [07:42<1:13:16, 231.38s/it]Task 0, Epoch 2/20 => Loss 0.998, Train_accy 73.21:  10%|█         | 2/20 [07:42<1:09:20, 231.11s/it]Task 0, Epoch 3/20 => Loss 0.990, Train_accy 73.36:  10%|█         | 2/20 [11:36<1:09:20, 231.11s/it]Task 0, Epoch 3/20 => Loss 0.990, Train_accy 73.36:  15%|█▌        | 3/20 [11:36<1:05:51, 232.45s/it]Task 0, Epoch 4/20 => Loss 0.995, Train_accy 73.36:  15%|█▌        | 3/20 [15:27<1:05:51, 232.45s/it]Task 0, Epoch 4/20 => Loss 0.995, Train_accy 73.36:  20%|██        | 4/20 [15:27<1:01:51, 231.94s/it]Task 0, Epoch 5/20 => Loss 0.987, Train_accy 73.45:  20%|██        | 4/20 [19:18<1:01:51, 231.94s/it]Task 0, Epoch 5/20 => Loss 0.987, Train_accy 73.45:  25%|██▌       | 5/20 [19:18<57:54, 231.62s/it]  Task 0, Epoch 6/20 => Loss 0.977, Train_accy 73.61:  25%|██▌       | 5/20 [23:10<57:54, 231.62s/it]Task 0, Epoch 6/20 => Loss 0.977, Train_accy 73.61:  30%|███       | 6/20 [23:10<54:06, 231.87s/it]Task 0, Epoch 7/20 => Loss 0.977, Train_accy 73.78:  30%|███       | 6/20 [27:01<54:06, 231.87s/it]Task 0, Epoch 7/20 => Loss 0.977, Train_accy 73.78:  35%|███▌      | 7/20 [27:01<50:09, 231.53s/it]Task 0, Epoch 8/20 => Loss 0.961, Train_accy 74.03:  35%|███▌      | 7/20 [30:52<50:09, 231.53s/it]Task 0, Epoch 8/20 => Loss 0.961, Train_accy 74.03:  40%|████      | 8/20 [30:52<46:15, 231.25s/it]Task 0, Epoch 9/20 => Loss 0.959, Train_accy 74.29:  40%|████      | 8/20 [34:43<46:15, 231.25s/it]Task 0, Epoch 9/20 => Loss 0.959, Train_accy 74.29:  45%|████▌     | 9/20 [34:43<42:23, 231.21s/it]Task 0, Epoch 10/20 => Loss 0.949, Train_accy 74.62:  45%|████▌     | 9/20 [38:34<42:23, 231.21s/it]Task 0, Epoch 10/20 => Loss 0.949, Train_accy 74.62:  50%|█████     | 10/20 [38:34<38:29, 231.00s/it]Task 0, Epoch 11/20 => Loss 0.942, Train_accy 74.88:  50%|█████     | 10/20 [42:26<38:29, 231.00s/it]Task 0, Epoch 11/20 => Loss 0.942, Train_accy 74.88:  55%|█████▌    | 11/20 [42:26<34:41, 231.31s/it]Task 0, Epoch 12/20 => Loss 0.931, Train_accy 75.28:  55%|█████▌    | 11/20 [46:17<34:41, 231.31s/it]Task 0, Epoch 12/20 => Loss 0.931, Train_accy 75.28:  60%|██████    | 12/20 [46:17<30:51, 231.39s/it]Task 0, Epoch 13/20 => Loss 0.913, Train_accy 75.69:  60%|██████    | 12/20 [50:09<30:51, 231.39s/it]Task 0, Epoch 13/20 => Loss 0.913, Train_accy 75.69:  65%|██████▌   | 13/20 [50:09<26:59, 231.41s/it]Task 0, Epoch 14/20 => Loss 0.907, Train_accy 76.14:  65%|██████▌   | 13/20 [54:00<26:59, 231.41s/it]Task 0, Epoch 14/20 => Loss 0.907, Train_accy 76.14:  70%|███████   | 14/20 [54:00<23:07, 231.27s/it]Task 0, Epoch 15/20 => Loss 0.891, Train_accy 76.81:  70%|███████   | 14/20 [57:50<23:07, 231.27s/it]Task 0, Epoch 15/20 => Loss 0.891, Train_accy 76.81:  75%|███████▌  | 15/20 [57:50<19:15, 231.10s/it]Task 0, Epoch 16/20 => Loss 0.876, Train_accy 77.16:  75%|███████▌  | 15/20 [1:01:44<19:15, 231.10s/it]Task 0, Epoch 16/20 => Loss 0.876, Train_accy 77.16:  80%|████████  | 16/20 [1:01:44<15:27, 231.78s/it]Task 0, Epoch 17/20 => Loss 0.857, Train_accy 77.90:  80%|████████  | 16/20 [1:05:37<15:27, 231.78s/it]Task 0, Epoch 17/20 => Loss 0.857, Train_accy 77.90:  85%|████████▌ | 17/20 [1:05:37<11:36, 232.25s/it]Task 0, Epoch 18/20 => Loss 0.837, Train_accy 78.74:  85%|████████▌ | 17/20 [1:09:30<11:36, 232.25s/it]Task 0, Epoch 18/20 => Loss 0.837, Train_accy 78.74:  90%|█████████ | 18/20 [1:09:30<07:44, 232.35s/it]Task 0, Epoch 19/20 => Loss 0.828, Train_accy 79.28:  90%|█████████ | 18/20 [1:13:22<07:44, 232.35s/it]Task 0, Epoch 19/20 => Loss 0.828, Train_accy 79.28:  95%|█████████▌| 19/20 [1:13:22<03:52, 232.34s/it]Task 0, Epoch 20/20 => Loss 0.808, Train_accy 80.17:  95%|█████████▌| 19/20 [1:17:14<03:52, 232.34s/it]Task 0, Epoch 20/20 => Loss 0.808, Train_accy 80.17: 100%|██████████| 20/20 [1:17:14<00:00, 232.21s/it]Task 0, Epoch 20/20 => Loss 0.808, Train_accy 80.17: 100%|██████████| 20/20 [1:17:14<00:00, 231.71s/it]
2024-05-02 02:13:35,969 [ease.py] => Task 0, Epoch 20/20 => Loss 0.808, Train_accy 80.17
2024-05-02 02:15:48,563 [ease.py] => Task correct: 83.4001336005344
2024-05-02 02:15:48,563 [ease.py] => Task acc: 90.24716098864396
2024-05-02 02:15:48,597 [trainer.py] => No NME accuracy.
2024-05-02 02:15:48,597 [trainer.py] => CNN: {'total': 80.53, '00-149': 80.53, 'old': 0, 'new': 80.53}
2024-05-02 02:15:48,597 [trainer.py] => CNN top1 curve: [80.53]
2024-05-02 02:15:48,597 [trainer.py] => CNN top5 curve: [95.49]

Average Accuracy (CNN): 80.53
2024-05-02 02:15:48,597 [trainer.py] => Average Accuracy (CNN): 80.53 

2024-05-02 02:15:48,597 [trainer.py] => Train Time: 9268.58
2024-05-02 02:15:48,598 [trainer.py] => Test Time: 9.29 

2024-05-02 02:15:48,598 [trainer.py] => All params: 87218690
2024-05-02 02:15:48,599 [trainer.py] => Trainable params: 1189632
2024-05-02 02:15:48,603 [ease.py] => Learning on 150-180
  0%|          | 0/20 [00:00<?, ?it/s]Task 1, Epoch 1/20 => Loss 1.256, Train_accy 77.09:   0%|          | 0/20 [00:46<?, ?it/s]Task 1, Epoch 1/20 => Loss 1.256, Train_accy 77.09:   5%|▌         | 1/20 [00:46<14:38, 46.26s/it]Task 1, Epoch 2/20 => Loss 0.489, Train_accy 86.99:   5%|▌         | 1/20 [01:32<14:38, 46.26s/it]Task 1, Epoch 2/20 => Loss 0.489, Train_accy 86.99:  10%|█         | 2/20 [01:32<13:50, 46.14s/it]Task 1, Epoch 3/20 => Loss 0.478, Train_accy 87.40:  10%|█         | 2/20 [02:18<13:50, 46.14s/it]Task 1, Epoch 3/20 => Loss 0.478, Train_accy 87.40:  15%|█▌        | 3/20 [02:18<13:05, 46.22s/it]Task 1, Epoch 4/20 => Loss 0.460, Train_accy 87.73:  15%|█▌        | 3/20 [03:05<13:05, 46.22s/it]Task 1, Epoch 4/20 => Loss 0.460, Train_accy 87.73:  20%|██        | 4/20 [03:05<12:22, 46.38s/it]Task 1, Epoch 5/20 => Loss 0.450, Train_accy 87.63:  20%|██        | 4/20 [03:51<12:22, 46.38s/it]Task 1, Epoch 5/20 => Loss 0.450, Train_accy 87.63:  25%|██▌       | 5/20 [03:51<11:35, 46.35s/it]Task 1, Epoch 6/20 => Loss 0.451, Train_accy 87.75:  25%|██▌       | 5/20 [04:38<11:35, 46.35s/it]Task 1, Epoch 6/20 => Loss 0.451, Train_accy 87.75:  30%|███       | 6/20 [04:38<10:49, 46.40s/it]Task 1, Epoch 7/20 => Loss 0.447, Train_accy 87.98:  30%|███       | 6/20 [05:24<10:49, 46.40s/it]Task 1, Epoch 7/20 => Loss 0.447, Train_accy 87.98:  35%|███▌      | 7/20 [05:24<10:03, 46.39s/it]Task 1, Epoch 8/20 => Loss 0.435, Train_accy 88.34:  35%|███▌      | 7/20 [06:10<10:03, 46.39s/it]Task 1, Epoch 8/20 => Loss 0.435, Train_accy 88.34:  40%|████      | 8/20 [06:10<09:16, 46.36s/it]Task 1, Epoch 9/20 => Loss 0.446, Train_accy 88.06:  40%|████      | 8/20 [06:57<09:16, 46.36s/it]Task 1, Epoch 9/20 => Loss 0.446, Train_accy 88.06:  45%|████▌     | 9/20 [06:57<08:30, 46.36s/it]Task 1, Epoch 10/20 => Loss 0.433, Train_accy 88.51:  45%|████▌     | 9/20 [07:43<08:30, 46.36s/it]Task 1, Epoch 10/20 => Loss 0.433, Train_accy 88.51:  50%|█████     | 10/20 [07:43<07:42, 46.27s/it]Task 1, Epoch 11/20 => Loss 0.427, Train_accy 88.65:  50%|█████     | 10/20 [08:29<07:42, 46.27s/it]Task 1, Epoch 11/20 => Loss 0.427, Train_accy 88.65:  55%|█████▌    | 11/20 [08:29<06:57, 46.38s/it]Task 1, Epoch 12/20 => Loss 0.416, Train_accy 88.88:  55%|█████▌    | 11/20 [09:16<06:57, 46.38s/it]Task 1, Epoch 12/20 => Loss 0.416, Train_accy 88.88:  60%|██████    | 12/20 [09:16<06:11, 46.49s/it]Task 1, Epoch 13/20 => Loss 0.418, Train_accy 88.88:  60%|██████    | 12/20 [10:03<06:11, 46.49s/it]Task 1, Epoch 13/20 => Loss 0.418, Train_accy 88.88:  65%|██████▌   | 13/20 [10:03<05:25, 46.56s/it]Task 1, Epoch 14/20 => Loss 0.408, Train_accy 89.27:  65%|██████▌   | 13/20 [10:49<05:25, 46.56s/it]Task 1, Epoch 14/20 => Loss 0.408, Train_accy 89.27:  70%|███████   | 14/20 [10:49<04:39, 46.58s/it]Task 1, Epoch 15/20 => Loss 0.398, Train_accy 89.49:  70%|███████   | 14/20 [11:36<04:39, 46.58s/it]Task 1, Epoch 15/20 => Loss 0.398, Train_accy 89.49:  75%|███████▌  | 15/20 [11:36<03:52, 46.56s/it]Task 1, Epoch 16/20 => Loss 0.403, Train_accy 89.36:  75%|███████▌  | 15/20 [12:22<03:52, 46.56s/it]Task 1, Epoch 16/20 => Loss 0.403, Train_accy 89.36:  80%|████████  | 16/20 [12:22<03:06, 46.53s/it]Task 1, Epoch 17/20 => Loss 0.397, Train_accy 89.81:  80%|████████  | 16/20 [13:09<03:06, 46.53s/it]Task 1, Epoch 17/20 => Loss 0.397, Train_accy 89.81:  85%|████████▌ | 17/20 [13:09<02:19, 46.52s/it]Task 1, Epoch 18/20 => Loss 0.383, Train_accy 90.37:  85%|████████▌ | 17/20 [13:55<02:19, 46.52s/it]Task 1, Epoch 18/20 => Loss 0.383, Train_accy 90.37:  90%|█████████ | 18/20 [13:55<01:32, 46.44s/it]Task 1, Epoch 19/20 => Loss 0.387, Train_accy 90.07:  90%|█████████ | 18/20 [14:41<01:32, 46.44s/it]Task 1, Epoch 19/20 => Loss 0.387, Train_accy 90.07:  95%|█████████▌| 19/20 [14:41<00:46, 46.39s/it]Task 1, Epoch 20/20 => Loss 0.379, Train_accy 90.20:  95%|█████████▌| 19/20 [15:28<00:46, 46.39s/it]Task 1, Epoch 20/20 => Loss 0.379, Train_accy 90.20: 100%|██████████| 20/20 [15:28<00:00, 46.39s/it]Task 1, Epoch 20/20 => Loss 0.379, Train_accy 90.20: 100%|██████████| 20/20 [15:28<00:00, 46.41s/it]
2024-05-02 02:31:16,877 [ease.py] => Task 1, Epoch 20/20 => Loss 0.379, Train_accy 90.20
2024-05-02 02:32:27,625 [ease.py] => Task correct: 79.00890868596882
2024-05-02 02:32:27,625 [ease.py] => Task acc: 89.92204899777283
2024-05-02 02:32:27,795 [trainer.py] => No NME accuracy.
2024-05-02 02:32:27,795 [trainer.py] => CNN: {'total': 75.97, '00-149': 74.98, '150-179': 80.94, 'old': 74.98, 'new': 80.94}
2024-05-02 02:32:27,795 [trainer.py] => CNN top1 curve: [80.53, 75.97]
2024-05-02 02:32:27,795 [trainer.py] => CNN top5 curve: [95.49, 93.74]

Average Accuracy (CNN): 78.25
2024-05-02 02:32:27,795 [trainer.py] => Average Accuracy (CNN): 78.25 

2024-05-02 02:32:27,795 [trainer.py] => Train Time: 11125.08
2024-05-02 02:32:27,795 [trainer.py] => Test Time: 28.82 

2024-05-02 02:32:27,796 [trainer.py] => All params: 87287810
2024-05-02 02:32:27,797 [trainer.py] => Trainable params: 1189632
2024-05-02 02:32:27,803 [ease.py] => Learning on 180-210
  0%|          | 0/20 [00:00<?, ?it/s]Task 2, Epoch 1/20 => Loss 1.215, Train_accy 77.31:   0%|          | 0/20 [00:46<?, ?it/s]Task 2, Epoch 1/20 => Loss 1.215, Train_accy 77.31:   5%|▌         | 1/20 [00:46<14:36, 46.11s/it]Task 2, Epoch 2/20 => Loss 0.462, Train_accy 86.49:   5%|▌         | 1/20 [01:32<14:36, 46.11s/it]Task 2, Epoch 2/20 => Loss 0.462, Train_accy 86.49:  10%|█         | 2/20 [01:32<13:53, 46.32s/it]Task 2, Epoch 3/20 => Loss 0.437, Train_accy 86.35:  10%|█         | 2/20 [02:18<13:53, 46.32s/it]Task 2, Epoch 3/20 => Loss 0.437, Train_accy 86.35:  15%|█▌        | 3/20 [02:18<13:06, 46.27s/it]Task 2, Epoch 4/20 => Loss 0.428, Train_accy 86.94:  15%|█▌        | 3/20 [03:04<13:06, 46.27s/it]Task 2, Epoch 4/20 => Loss 0.428, Train_accy 86.94:  20%|██        | 4/20 [03:04<12:19, 46.20s/it]Task 2, Epoch 5/20 => Loss 0.414, Train_accy 87.74:  20%|██        | 4/20 [03:51<12:19, 46.20s/it]Task 2, Epoch 5/20 => Loss 0.414, Train_accy 87.74:  25%|██▌       | 5/20 [03:51<11:32, 46.19s/it]Task 2, Epoch 6/20 => Loss 0.423, Train_accy 87.20:  25%|██▌       | 5/20 [04:36<11:32, 46.19s/it]Task 2, Epoch 6/20 => Loss 0.423, Train_accy 87.20:  30%|███       | 6/20 [04:36<10:45, 46.08s/it]Task 2, Epoch 7/20 => Loss 0.412, Train_accy 87.18:  30%|███       | 6/20 [05:22<10:45, 46.08s/it]Task 2, Epoch 7/20 => Loss 0.412, Train_accy 87.18:  35%|███▌      | 7/20 [05:22<09:58, 46.01s/it]Task 2, Epoch 8/20 => Loss 0.417, Train_accy 87.14:  35%|███▌      | 7/20 [06:08<09:58, 46.01s/it]Task 2, Epoch 8/20 => Loss 0.417, Train_accy 87.14:  40%|████      | 8/20 [06:08<09:11, 45.99s/it]Task 2, Epoch 9/20 => Loss 0.411, Train_accy 87.46:  40%|████      | 8/20 [06:55<09:11, 45.99s/it]Task 2, Epoch 9/20 => Loss 0.411, Train_accy 87.46:  45%|████▌     | 9/20 [06:55<08:27, 46.12s/it]Task 2, Epoch 10/20 => Loss 0.411, Train_accy 87.73:  45%|████▌     | 9/20 [07:41<08:27, 46.12s/it]Task 2, Epoch 10/20 => Loss 0.411, Train_accy 87.73:  50%|█████     | 10/20 [07:41<07:41, 46.18s/it]Task 2, Epoch 11/20 => Loss 0.411, Train_accy 87.45:  50%|█████     | 10/20 [08:27<07:41, 46.18s/it]Task 2, Epoch 11/20 => Loss 0.411, Train_accy 87.45:  55%|█████▌    | 11/20 [08:27<06:55, 46.14s/it]Task 2, Epoch 12/20 => Loss 0.400, Train_accy 88.24:  55%|█████▌    | 11/20 [09:13<06:55, 46.14s/it]Task 2, Epoch 12/20 => Loss 0.400, Train_accy 88.24:  60%|██████    | 12/20 [09:13<06:09, 46.24s/it]Task 2, Epoch 13/20 => Loss 0.386, Train_accy 88.95:  60%|██████    | 12/20 [10:00<06:09, 46.24s/it]Task 2, Epoch 13/20 => Loss 0.386, Train_accy 88.95:  65%|██████▌   | 13/20 [10:00<05:23, 46.24s/it]Task 2, Epoch 14/20 => Loss 0.390, Train_accy 88.60:  65%|██████▌   | 13/20 [10:46<05:23, 46.24s/it]Task 2, Epoch 14/20 => Loss 0.390, Train_accy 88.60:  70%|███████   | 14/20 [10:46<04:37, 46.21s/it]Task 2, Epoch 15/20 => Loss 0.387, Train_accy 88.81:  70%|███████   | 14/20 [11:32<04:37, 46.21s/it]Task 2, Epoch 15/20 => Loss 0.387, Train_accy 88.81:  75%|███████▌  | 15/20 [11:32<03:50, 46.20s/it]Task 2, Epoch 16/20 => Loss 0.388, Train_accy 88.49:  75%|███████▌  | 15/20 [12:18<03:50, 46.20s/it]Task 2, Epoch 16/20 => Loss 0.388, Train_accy 88.49:  80%|████████  | 16/20 [12:18<03:04, 46.15s/it]Task 2, Epoch 17/20 => Loss 0.375, Train_accy 89.73:  80%|████████  | 16/20 [13:04<03:04, 46.15s/it]Task 2, Epoch 17/20 => Loss 0.375, Train_accy 89.73:  85%|████████▌ | 17/20 [13:04<02:18, 46.09s/it]Task 2, Epoch 18/20 => Loss 0.376, Train_accy 89.52:  85%|████████▌ | 17/20 [13:50<02:18, 46.09s/it]Task 2, Epoch 18/20 => Loss 0.376, Train_accy 89.52:  90%|█████████ | 18/20 [13:50<01:32, 46.09s/it]Task 2, Epoch 19/20 => Loss 0.374, Train_accy 89.94:  90%|█████████ | 18/20 [14:36<01:32, 46.09s/it]Task 2, Epoch 19/20 => Loss 0.374, Train_accy 89.94:  95%|█████████▌| 19/20 [14:36<00:46, 46.08s/it]Task 2, Epoch 20/20 => Loss 0.367, Train_accy 90.07:  95%|█████████▌| 19/20 [15:22<00:46, 46.08s/it]Task 2, Epoch 20/20 => Loss 0.367, Train_accy 90.07: 100%|██████████| 20/20 [15:22<00:00, 46.08s/it]Task 2, Epoch 20/20 => Loss 0.367, Train_accy 90.07: 100%|██████████| 20/20 [15:22<00:00, 46.14s/it]
2024-05-02 02:47:50,554 [ease.py] => Task 2, Epoch 20/20 => Loss 0.367, Train_accy 90.07
2024-05-02 02:49:39,714 [ease.py] => Task correct: 74.12270231558844
2024-05-02 02:49:39,714 [ease.py] => Task acc: 90.23633325375985
2024-05-02 02:49:39,867 [trainer.py] => No NME accuracy.
2024-05-02 02:49:39,867 [trainer.py] => CNN: {'total': 71.66, '00-149': 68.5, '150-179': 71.91, '180-209': 87.27, 'old': 69.07, 'new': 87.27}
2024-05-02 02:49:39,867 [trainer.py] => CNN top1 curve: [80.53, 75.97, 71.66]
2024-05-02 02:49:39,867 [trainer.py] => CNN top5 curve: [95.49, 93.74, 91.98]

Average Accuracy (CNN): 76.05
2024-05-02 02:49:39,868 [trainer.py] => Average Accuracy (CNN): 76.05 

2024-05-02 02:49:39,868 [trainer.py] => Train Time: 12970.539999999999
2024-05-02 02:49:39,868 [trainer.py] => Test Time: 61.67 

2024-05-02 02:49:39,869 [trainer.py] => All params: 87495170
2024-05-02 02:49:39,869 [trainer.py] => Trainable params: 1189632
2024-05-02 02:49:39,880 [ease.py] => Learning on 210-240
  0%|          | 0/20 [00:00<?, ?it/s]Task 3, Epoch 1/20 => Loss 1.266, Train_accy 74.66:   0%|          | 0/20 [00:48<?, ?it/s]Task 3, Epoch 1/20 => Loss 1.266, Train_accy 74.66:   5%|▌         | 1/20 [00:48<15:26, 48.78s/it]Task 3, Epoch 2/20 => Loss 0.550, Train_accy 83.92:   5%|▌         | 1/20 [01:37<15:26, 48.78s/it]Task 3, Epoch 2/20 => Loss 0.550, Train_accy 83.92:  10%|█         | 2/20 [01:37<14:34, 48.57s/it]Task 3, Epoch 3/20 => Loss 0.542, Train_accy 84.19:  10%|█         | 2/20 [02:25<14:34, 48.57s/it]Task 3, Epoch 3/20 => Loss 0.542, Train_accy 84.19:  15%|█▌        | 3/20 [02:25<13:44, 48.49s/it]Task 3, Epoch 4/20 => Loss 0.525, Train_accy 84.79:  15%|█▌        | 3/20 [03:14<13:44, 48.49s/it]Task 3, Epoch 4/20 => Loss 0.525, Train_accy 84.79:  20%|██        | 4/20 [03:14<12:56, 48.50s/it]Task 3, Epoch 5/20 => Loss 0.522, Train_accy 84.42:  20%|██        | 4/20 [04:02<12:56, 48.50s/it]Task 3, Epoch 5/20 => Loss 0.522, Train_accy 84.42:  25%|██▌       | 5/20 [04:02<12:08, 48.56s/it]Task 3, Epoch 6/20 => Loss 0.518, Train_accy 85.08:  25%|██▌       | 5/20 [04:51<12:08, 48.56s/it]Task 3, Epoch 6/20 => Loss 0.518, Train_accy 85.08:  30%|███       | 6/20 [04:51<11:20, 48.63s/it]Task 3, Epoch 7/20 => Loss 0.509, Train_accy 85.34:  30%|███       | 6/20 [05:40<11:20, 48.63s/it]Task 3, Epoch 7/20 => Loss 0.509, Train_accy 85.34:  35%|███▌      | 7/20 [05:40<10:32, 48.65s/it]Task 3, Epoch 8/20 => Loss 0.514, Train_accy 84.96:  35%|███▌      | 7/20 [06:28<10:32, 48.65s/it]Task 3, Epoch 8/20 => Loss 0.514, Train_accy 84.96:  40%|████      | 8/20 [06:28<09:43, 48.65s/it]Task 3, Epoch 9/20 => Loss 0.505, Train_accy 85.17:  40%|████      | 8/20 [07:17<09:43, 48.65s/it]Task 3, Epoch 9/20 => Loss 0.505, Train_accy 85.17:  45%|████▌     | 9/20 [07:17<08:54, 48.60s/it]Task 3, Epoch 10/20 => Loss 0.502, Train_accy 85.53:  45%|████▌     | 9/20 [08:05<08:54, 48.60s/it]Task 3, Epoch 10/20 => Loss 0.502, Train_accy 85.53:  50%|█████     | 10/20 [08:05<08:05, 48.52s/it]Task 3, Epoch 11/20 => Loss 0.487, Train_accy 86.02:  50%|█████     | 10/20 [08:54<08:05, 48.52s/it]Task 3, Epoch 11/20 => Loss 0.487, Train_accy 86.02:  55%|█████▌    | 11/20 [08:54<07:17, 48.61s/it]Task 3, Epoch 12/20 => Loss 0.489, Train_accy 85.98:  55%|█████▌    | 11/20 [09:43<07:17, 48.61s/it]Task 3, Epoch 12/20 => Loss 0.489, Train_accy 85.98:  60%|██████    | 12/20 [09:43<06:29, 48.65s/it]Task 3, Epoch 13/20 => Loss 0.490, Train_accy 85.75:  60%|██████    | 12/20 [10:31<06:29, 48.65s/it]Task 3, Epoch 13/20 => Loss 0.490, Train_accy 85.75:  65%|██████▌   | 13/20 [10:31<05:40, 48.66s/it]Task 3, Epoch 14/20 => Loss 0.479, Train_accy 86.68:  65%|██████▌   | 13/20 [11:20<05:40, 48.66s/it]Task 3, Epoch 14/20 => Loss 0.479, Train_accy 86.68:  70%|███████   | 14/20 [11:20<04:51, 48.64s/it]Task 3, Epoch 15/20 => Loss 0.470, Train_accy 87.38:  70%|███████   | 14/20 [12:09<04:51, 48.64s/it]Task 3, Epoch 15/20 => Loss 0.470, Train_accy 87.38:  75%|███████▌  | 15/20 [12:09<04:02, 48.60s/it]Task 3, Epoch 16/20 => Loss 0.466, Train_accy 87.27:  75%|███████▌  | 15/20 [12:57<04:02, 48.60s/it]Task 3, Epoch 16/20 => Loss 0.466, Train_accy 87.27:  80%|████████  | 16/20 [12:57<03:14, 48.60s/it]Task 3, Epoch 17/20 => Loss 0.470, Train_accy 87.06:  80%|████████  | 16/20 [13:46<03:14, 48.60s/it]Task 3, Epoch 17/20 => Loss 0.470, Train_accy 87.06:  85%|████████▌ | 17/20 [13:46<02:25, 48.53s/it]Task 3, Epoch 18/20 => Loss 0.454, Train_accy 87.89:  85%|████████▌ | 17/20 [14:34<02:25, 48.53s/it]Task 3, Epoch 18/20 => Loss 0.454, Train_accy 87.89:  90%|█████████ | 18/20 [14:34<01:37, 48.50s/it]Task 3, Epoch 19/20 => Loss 0.451, Train_accy 87.88:  90%|█████████ | 18/20 [15:22<01:37, 48.50s/it]Task 3, Epoch 19/20 => Loss 0.451, Train_accy 87.88:  95%|█████████▌| 19/20 [15:22<00:48, 48.47s/it]Task 3, Epoch 20/20 => Loss 0.451, Train_accy 88.27:  95%|█████████▌| 19/20 [16:11<00:48, 48.47s/it]Task 3, Epoch 20/20 => Loss 0.451, Train_accy 88.27: 100%|██████████| 20/20 [16:11<00:00, 48.49s/it]Task 3, Epoch 20/20 => Loss 0.451, Train_accy 88.27: 100%|██████████| 20/20 [16:11<00:00, 48.57s/it]
2024-05-02 03:05:51,306 [ease.py] => Task 3, Epoch 20/20 => Loss 0.451, Train_accy 88.27
2024-05-02 03:08:28,373 [ease.py] => Task correct: 71.51211361737677
2024-05-02 03:08:28,373 [ease.py] => Task acc: 89.93316624895573
2024-05-02 03:08:28,616 [trainer.py] => No NME accuracy.
2024-05-02 03:08:28,616 [trainer.py] => CNN: {'total': 69.55, '00-149': 66.2, '150-179': 66.89, '180-209': 83.58, '210-239': 74.96, 'old': 68.78, 'new': 74.96}
2024-05-02 03:08:28,616 [trainer.py] => CNN top1 curve: [80.53, 75.97, 71.66, 69.55]
2024-05-02 03:08:28,616 [trainer.py] => CNN top5 curve: [95.49, 93.74, 91.98, 90.18]

Average Accuracy (CNN): 74.43
2024-05-02 03:08:28,617 [trainer.py] => Average Accuracy (CNN): 74.43 

2024-05-02 03:08:28,617 [trainer.py] => Train Time: 14913.339999999998
2024-05-02 03:08:28,617 [trainer.py] => Test Time: 110.99000000000001 

2024-05-02 03:08:28,617 [trainer.py] => All params: 87748610
2024-05-02 03:08:28,618 [trainer.py] => Trainable params: 1189632
2024-05-02 03:08:28,638 [ease.py] => Learning on 240-270
  0%|          | 0/20 [00:00<?, ?it/s]Task 4, Epoch 1/20 => Loss 1.084, Train_accy 83.52:   0%|          | 0/20 [00:47<?, ?it/s]Task 4, Epoch 1/20 => Loss 1.084, Train_accy 83.52:   5%|▌         | 1/20 [00:47<15:06, 47.73s/it]Task 4, Epoch 2/20 => Loss 0.335, Train_accy 91.79:   5%|▌         | 1/20 [01:35<15:06, 47.73s/it]Task 4, Epoch 2/20 => Loss 0.335, Train_accy 91.79:  10%|█         | 2/20 [01:35<14:18, 47.72s/it]Task 4, Epoch 3/20 => Loss 0.312, Train_accy 92.44:  10%|█         | 2/20 [02:23<14:18, 47.72s/it]Task 4, Epoch 3/20 => Loss 0.312, Train_accy 92.44:  15%|█▌        | 3/20 [02:23<13:31, 47.76s/it]Task 4, Epoch 4/20 => Loss 0.320, Train_accy 91.93:  15%|█▌        | 3/20 [03:11<13:31, 47.76s/it]Task 4, Epoch 4/20 => Loss 0.320, Train_accy 91.93:  20%|██        | 4/20 [03:11<12:45, 47.82s/it]Task 4, Epoch 5/20 => Loss 0.309, Train_accy 92.21:  20%|██        | 4/20 [03:58<12:45, 47.82s/it]Task 4, Epoch 5/20 => Loss 0.309, Train_accy 92.21:  25%|██▌       | 5/20 [03:58<11:57, 47.80s/it]Task 4, Epoch 6/20 => Loss 0.312, Train_accy 92.18:  25%|██▌       | 5/20 [04:46<11:57, 47.80s/it]Task 4, Epoch 6/20 => Loss 0.312, Train_accy 92.18:  30%|███       | 6/20 [04:46<11:08, 47.75s/it]Task 4, Epoch 7/20 => Loss 0.305, Train_accy 92.02:  30%|███       | 6/20 [05:34<11:08, 47.75s/it]Task 4, Epoch 7/20 => Loss 0.305, Train_accy 92.02:  35%|███▌      | 7/20 [05:34<10:21, 47.82s/it]Task 4, Epoch 8/20 => Loss 0.311, Train_accy 92.21:  35%|███▌      | 7/20 [06:22<10:21, 47.82s/it]Task 4, Epoch 8/20 => Loss 0.311, Train_accy 92.21:  40%|████      | 8/20 [06:22<09:35, 47.92s/it]Task 4, Epoch 9/20 => Loss 0.298, Train_accy 92.28:  40%|████      | 8/20 [07:10<09:35, 47.92s/it]Task 4, Epoch 9/20 => Loss 0.298, Train_accy 92.28:  45%|████▌     | 9/20 [07:10<08:46, 47.85s/it]Task 4, Epoch 10/20 => Loss 0.305, Train_accy 92.56:  45%|████▌     | 9/20 [07:58<08:46, 47.85s/it]Task 4, Epoch 10/20 => Loss 0.305, Train_accy 92.56:  50%|█████     | 10/20 [07:58<07:57, 47.78s/it]Task 4, Epoch 11/20 => Loss 0.294, Train_accy 92.78:  50%|█████     | 10/20 [08:45<07:57, 47.78s/it]Task 4, Epoch 11/20 => Loss 0.294, Train_accy 92.78:  55%|█████▌    | 11/20 [08:45<07:09, 47.70s/it]Task 4, Epoch 12/20 => Loss 0.300, Train_accy 92.42:  55%|█████▌    | 11/20 [09:33<07:09, 47.70s/it]Task 4, Epoch 12/20 => Loss 0.300, Train_accy 92.42:  60%|██████    | 12/20 [09:33<06:21, 47.69s/it]Task 4, Epoch 13/20 => Loss 0.285, Train_accy 93.10:  60%|██████    | 12/20 [10:21<06:21, 47.69s/it]Task 4, Epoch 13/20 => Loss 0.285, Train_accy 93.10:  65%|██████▌   | 13/20 [10:21<05:34, 47.81s/it]Task 4, Epoch 14/20 => Loss 0.289, Train_accy 93.13:  65%|██████▌   | 13/20 [11:08<05:34, 47.81s/it]Task 4, Epoch 14/20 => Loss 0.289, Train_accy 93.13:  70%|███████   | 14/20 [11:08<04:46, 47.77s/it]Task 4, Epoch 15/20 => Loss 0.291, Train_accy 92.63:  70%|███████   | 14/20 [11:56<04:46, 47.77s/it]Task 4, Epoch 15/20 => Loss 0.291, Train_accy 92.63:  75%|███████▌  | 15/20 [11:56<03:59, 47.83s/it]Task 4, Epoch 16/20 => Loss 0.286, Train_accy 92.98:  75%|███████▌  | 15/20 [12:44<03:59, 47.83s/it]Task 4, Epoch 16/20 => Loss 0.286, Train_accy 92.98:  80%|████████  | 16/20 [12:44<03:11, 47.80s/it]Task 4, Epoch 17/20 => Loss 0.282, Train_accy 93.16:  80%|████████  | 16/20 [13:32<03:11, 47.80s/it]Task 4, Epoch 17/20 => Loss 0.282, Train_accy 93.16:  85%|████████▌ | 17/20 [13:32<02:23, 47.79s/it]Task 4, Epoch 18/20 => Loss 0.276, Train_accy 93.33:  85%|████████▌ | 17/20 [14:20<02:23, 47.79s/it]Task 4, Epoch 18/20 => Loss 0.276, Train_accy 93.33:  90%|█████████ | 18/20 [14:20<01:35, 47.80s/it]Task 4, Epoch 19/20 => Loss 0.275, Train_accy 93.75:  90%|█████████ | 18/20 [15:07<01:35, 47.80s/it]Task 4, Epoch 19/20 => Loss 0.275, Train_accy 93.75:  95%|█████████▌| 19/20 [15:07<00:47, 47.78s/it]Task 4, Epoch 20/20 => Loss 0.276, Train_accy 93.46:  95%|█████████▌| 19/20 [15:55<00:47, 47.78s/it]Task 4, Epoch 20/20 => Loss 0.276, Train_accy 93.46: 100%|██████████| 20/20 [15:55<00:00, 47.72s/it]Task 4, Epoch 20/20 => Loss 0.276, Train_accy 93.46: 100%|██████████| 20/20 [15:55<00:00, 47.78s/it]
2024-05-02 03:24:24,220 [ease.py] => Task 4, Epoch 20/20 => Loss 0.276, Train_accy 93.46
2024-05-02 03:27:45,645 [ease.py] => Task correct: 67.38444403192872
2024-05-02 03:27:45,645 [ease.py] => Task acc: 90.45851123074067
2024-05-02 03:27:45,845 [trainer.py] => No NME accuracy.
2024-05-02 03:27:45,845 [trainer.py] => CNN: {'total': 65.81, '00-149': 59.92, '150-179': 58.36, '180-209': 72.03, '210-239': 71.12, '240-269': 91.15, 'old': 62.64, 'new': 91.15}
2024-05-02 03:27:45,846 [trainer.py] => CNN top1 curve: [80.53, 75.97, 71.66, 69.55, 65.81]
2024-05-02 03:27:45,846 [trainer.py] => CNN top5 curve: [95.49, 93.74, 91.98, 90.18, 89.68]

Average Accuracy (CNN): 72.7
2024-05-02 03:27:45,846 [trainer.py] => Average Accuracy (CNN): 72.7 

2024-05-02 03:27:45,846 [trainer.py] => Train Time: 16824.449999999997
2024-05-02 03:27:45,846 [trainer.py] => Test Time: 179.66000000000003 

2024-05-02 03:27:45,847 [trainer.py] => All params: 88048130
2024-05-02 03:27:45,847 [trainer.py] => Trainable params: 1189632
2024-05-02 03:27:45,872 [ease.py] => Learning on 270-300
  0%|          | 0/20 [00:00<?, ?it/s]Task 5, Epoch 1/20 => Loss 1.129, Train_accy 81.00:   0%|          | 0/20 [00:45<?, ?it/s]Task 5, Epoch 1/20 => Loss 1.129, Train_accy 81.00:   5%|▌         | 1/20 [00:45<14:24, 45.48s/it]Task 5, Epoch 2/20 => Loss 0.328, Train_accy 90.91:   5%|▌         | 1/20 [01:30<14:24, 45.48s/it]Task 5, Epoch 2/20 => Loss 0.328, Train_accy 90.91:  10%|█         | 2/20 [01:30<13:37, 45.42s/it]Task 5, Epoch 3/20 => Loss 0.321, Train_accy 91.26:  10%|█         | 2/20 [02:15<13:37, 45.42s/it]Task 5, Epoch 3/20 => Loss 0.321, Train_accy 91.26:  15%|█▌        | 3/20 [02:15<12:49, 45.28s/it]Task 5, Epoch 4/20 => Loss 0.318, Train_accy 91.34:  15%|█▌        | 3/20 [03:01<12:49, 45.28s/it]Task 5, Epoch 4/20 => Loss 0.318, Train_accy 91.34:  20%|██        | 4/20 [03:01<12:04, 45.30s/it]Task 5, Epoch 5/20 => Loss 0.316, Train_accy 91.23:  20%|██        | 4/20 [03:46<12:04, 45.30s/it]Task 5, Epoch 5/20 => Loss 0.316, Train_accy 91.23:  25%|██▌       | 5/20 [03:46<11:20, 45.39s/it]Task 5, Epoch 6/20 => Loss 0.311, Train_accy 91.10:  25%|██▌       | 5/20 [04:32<11:20, 45.39s/it]Task 5, Epoch 6/20 => Loss 0.311, Train_accy 91.10:  30%|███       | 6/20 [04:32<10:34, 45.32s/it]Task 5, Epoch 7/20 => Loss 0.311, Train_accy 91.47:  30%|███       | 6/20 [05:17<10:34, 45.32s/it]Task 5, Epoch 7/20 => Loss 0.311, Train_accy 91.47:  35%|███▌      | 7/20 [05:17<09:50, 45.40s/it]Task 5, Epoch 8/20 => Loss 0.306, Train_accy 91.52:  35%|███▌      | 7/20 [06:02<09:50, 45.40s/it]Task 5, Epoch 8/20 => Loss 0.306, Train_accy 91.52:  40%|████      | 8/20 [06:02<09:03, 45.28s/it]Task 5, Epoch 9/20 => Loss 0.319, Train_accy 90.97:  40%|████      | 8/20 [06:47<09:03, 45.28s/it]Task 5, Epoch 9/20 => Loss 0.319, Train_accy 90.97:  45%|████▌     | 9/20 [06:47<08:18, 45.30s/it]Task 5, Epoch 10/20 => Loss 0.303, Train_accy 92.03:  45%|████▌     | 9/20 [07:32<08:18, 45.30s/it]Task 5, Epoch 10/20 => Loss 0.303, Train_accy 92.03:  50%|█████     | 10/20 [07:32<07:31, 45.15s/it]Task 5, Epoch 11/20 => Loss 0.303, Train_accy 91.40:  50%|█████     | 10/20 [08:17<07:31, 45.15s/it]Task 5, Epoch 11/20 => Loss 0.303, Train_accy 91.40:  55%|█████▌    | 11/20 [08:17<06:45, 45.09s/it]Task 5, Epoch 12/20 => Loss 0.306, Train_accy 91.51:  55%|█████▌    | 11/20 [09:02<06:45, 45.09s/it]Task 5, Epoch 12/20 => Loss 0.306, Train_accy 91.51:  60%|██████    | 12/20 [09:02<06:00, 45.11s/it]Task 5, Epoch 13/20 => Loss 0.296, Train_accy 92.10:  60%|██████    | 12/20 [09:48<06:00, 45.11s/it]Task 5, Epoch 13/20 => Loss 0.296, Train_accy 92.10:  65%|██████▌   | 13/20 [09:48<05:15, 45.12s/it]Task 5, Epoch 14/20 => Loss 0.289, Train_accy 91.93:  65%|██████▌   | 13/20 [10:32<05:15, 45.12s/it]Task 5, Epoch 14/20 => Loss 0.289, Train_accy 91.93:  70%|███████   | 14/20 [10:32<04:30, 45.04s/it]Task 5, Epoch 15/20 => Loss 0.287, Train_accy 92.28:  70%|███████   | 14/20 [11:18<04:30, 45.04s/it]Task 5, Epoch 15/20 => Loss 0.287, Train_accy 92.28:  75%|███████▌  | 15/20 [11:18<03:45, 45.09s/it]Task 5, Epoch 16/20 => Loss 0.284, Train_accy 92.16:  75%|███████▌  | 15/20 [12:03<03:45, 45.09s/it]Task 5, Epoch 16/20 => Loss 0.284, Train_accy 92.16:  80%|████████  | 16/20 [12:03<03:00, 45.17s/it]Task 5, Epoch 17/20 => Loss 0.280, Train_accy 92.71:  80%|████████  | 16/20 [12:48<03:00, 45.17s/it]Task 5, Epoch 17/20 => Loss 0.280, Train_accy 92.71:  85%|████████▌ | 17/20 [12:48<02:15, 45.17s/it]Task 5, Epoch 18/20 => Loss 0.275, Train_accy 92.87:  85%|████████▌ | 17/20 [13:34<02:15, 45.17s/it]Task 5, Epoch 18/20 => Loss 0.275, Train_accy 92.87:  90%|█████████ | 18/20 [13:34<01:30, 45.28s/it]Task 5, Epoch 19/20 => Loss 0.269, Train_accy 93.05:  90%|█████████ | 18/20 [14:19<01:30, 45.28s/it]Task 5, Epoch 19/20 => Loss 0.269, Train_accy 93.05:  95%|█████████▌| 19/20 [14:19<00:45, 45.23s/it]Task 5, Epoch 20/20 => Loss 0.269, Train_accy 92.90:  95%|█████████▌| 19/20 [15:03<00:45, 45.23s/it]Task 5, Epoch 20/20 => Loss 0.269, Train_accy 92.90: 100%|██████████| 20/20 [15:03<00:00, 45.07s/it]Task 5, Epoch 20/20 => Loss 0.269, Train_accy 92.90: 100%|██████████| 20/20 [15:03<00:00, 45.20s/it]
2024-05-02 03:42:49,895 [ease.py] => Task 5, Epoch 20/20 => Loss 0.269, Train_accy 92.90
2024-05-02 03:46:51,687 [ease.py] => Task correct: 66.4828738512949
2024-05-02 03:46:51,688 [ease.py] => Task acc: 90.91060985797827
2024-05-02 03:46:51,847 [trainer.py] => No NME accuracy.
2024-05-02 03:46:51,848 [trainer.py] => CNN: {'total': 65.3, '00-149': 58.88, '150-179': 53.01, '180-209': 64.99, '210-239': 68.11, '240-269': 85.98, '270-299': 86.45, 'old': 62.95, 'new': 86.45}
2024-05-02 03:46:51,848 [trainer.py] => CNN top1 curve: [80.53, 75.97, 71.66, 69.55, 65.81, 65.3]
2024-05-02 03:46:51,848 [trainer.py] => CNN top5 curve: [95.49, 93.74, 91.98, 90.18, 89.68, 87.94]

Average Accuracy (CNN): 71.47
2024-05-02 03:46:51,848 [trainer.py] => Average Accuracy (CNN): 71.47 

2024-05-02 03:46:51,848 [trainer.py] => Train Time: 18632.409999999996
2024-05-02 03:46:51,848 [trainer.py] => Test Time: 270.24 

Accuracy Matrix (CNN):
[[80.53 74.98 68.5  66.2  59.92 58.88]
 [ 0.   80.94 71.91 66.89 58.36 53.01]
 [ 0.    0.   87.27 83.58 72.03 64.99]
 [ 0.    0.    0.   74.96 71.12 68.11]
 [ 0.    0.    0.    0.   91.15 85.98]
 [ 0.    0.    0.    0.    0.   86.45]]
2024-05-02 03:46:51,849 [trainer.py] => Forgetting (CNN): 16.776
